<html>
    <head>
        <meta charset="utf-8">
        
            <script>function neighbourhoodHighlight(params) {
  // console.log("in nieghbourhoodhighlight");
  allNodes = nodes.get({ returnType: "Object" });
  // originalNodes = JSON.parse(JSON.stringify(allNodes));
  // if something is selected:
  if (params.nodes.length > 0) {
    highlightActive = true;
    var i, j;
    var selectedNode = params.nodes[0];
    var degrees = 2;

    // mark all nodes as hard to read.
    for (let nodeId in allNodes) {
      // nodeColors[nodeId] = allNodes[nodeId].color;
      allNodes[nodeId].color = "rgba(200,200,200,0.5)";
      if (allNodes[nodeId].hiddenLabel === undefined) {
        allNodes[nodeId].hiddenLabel = allNodes[nodeId].label;
        allNodes[nodeId].label = undefined;
      }
    }
    var connectedNodes = network.getConnectedNodes(selectedNode);
    var allConnectedNodes = [];

    // get the second degree nodes
    for (i = 1; i < degrees; i++) {
      for (j = 0; j < connectedNodes.length; j++) {
        allConnectedNodes = allConnectedNodes.concat(
          network.getConnectedNodes(connectedNodes[j])
        );
      }
    }

    // all second degree nodes get a different color and their label back
    for (i = 0; i < allConnectedNodes.length; i++) {
      // allNodes[allConnectedNodes[i]].color = "pink";
      allNodes[allConnectedNodes[i]].color = "rgba(150,150,150,0.75)";
      if (allNodes[allConnectedNodes[i]].hiddenLabel !== undefined) {
        allNodes[allConnectedNodes[i]].label =
          allNodes[allConnectedNodes[i]].hiddenLabel;
        allNodes[allConnectedNodes[i]].hiddenLabel = undefined;
      }
    }

    // all first degree nodes get their own color and their label back
    for (i = 0; i < connectedNodes.length; i++) {
      // allNodes[connectedNodes[i]].color = undefined;
      allNodes[connectedNodes[i]].color = nodeColors[connectedNodes[i]];
      if (allNodes[connectedNodes[i]].hiddenLabel !== undefined) {
        allNodes[connectedNodes[i]].label =
          allNodes[connectedNodes[i]].hiddenLabel;
        allNodes[connectedNodes[i]].hiddenLabel = undefined;
      }
    }

    // the main node gets its own color and its label back.
    // allNodes[selectedNode].color = undefined;
    allNodes[selectedNode].color = nodeColors[selectedNode];
    if (allNodes[selectedNode].hiddenLabel !== undefined) {
      allNodes[selectedNode].label = allNodes[selectedNode].hiddenLabel;
      allNodes[selectedNode].hiddenLabel = undefined;
    }
  } else if (highlightActive === true) {
    // console.log("highlightActive was true");
    // reset all nodes
    for (let nodeId in allNodes) {
      // allNodes[nodeId].color = "purple";
      allNodes[nodeId].color = nodeColors[nodeId];
      // delete allNodes[nodeId].color;
      if (allNodes[nodeId].hiddenLabel !== undefined) {
        allNodes[nodeId].label = allNodes[nodeId].hiddenLabel;
        allNodes[nodeId].hiddenLabel = undefined;
      }
    }
    highlightActive = false;
  }

  // transform the object into an array
  var updateArray = [];
  if (params.nodes.length > 0) {
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        // console.log(allNodes[nodeId]);
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  } else {
    // console.log("Nothing was selected");
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        // console.log(allNodes[nodeId]);
        // allNodes[nodeId].color = {};
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  }
}

function filterHighlight(params) {
  allNodes = nodes.get({ returnType: "Object" });
  // if something is selected:
  if (params.nodes.length > 0) {
    filterActive = true;
    let selectedNodes = params.nodes;

    // hiding all nodes and saving the label
    for (let nodeId in allNodes) {
      allNodes[nodeId].hidden = true;
      if (allNodes[nodeId].savedLabel === undefined) {
        allNodes[nodeId].savedLabel = allNodes[nodeId].label;
        allNodes[nodeId].label = undefined;
      }
    }

    for (let i=0; i < selectedNodes.length; i++) {
      allNodes[selectedNodes[i]].hidden = false;
      if (allNodes[selectedNodes[i]].savedLabel !== undefined) {
        allNodes[selectedNodes[i]].label = allNodes[selectedNodes[i]].savedLabel;
        allNodes[selectedNodes[i]].savedLabel = undefined;
      }
    }

  } else if (filterActive === true) {
    // reset all nodes
    for (let nodeId in allNodes) {
      allNodes[nodeId].hidden = false;
      if (allNodes[nodeId].savedLabel !== undefined) {
        allNodes[nodeId].label = allNodes[nodeId].savedLabel;
        allNodes[nodeId].savedLabel = undefined;
      }
    }
    filterActive = false;
  }

  // transform the object into an array
  var updateArray = [];
  if (params.nodes.length > 0) {
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  } else {
    for (let nodeId in allNodes) {
      if (allNodes.hasOwnProperty(nodeId)) {
        updateArray.push(allNodes[nodeId]);
      }
    }
    nodes.update(updateArray);
  }
}

function selectNode(nodes) {
  network.selectNodes(nodes);
  neighbourhoodHighlight({ nodes: nodes });
  return nodes;
}

function selectNodes(nodes) {
  network.selectNodes(nodes);
  filterHighlight({nodes: nodes});
  return nodes;
}

function highlightFilter(filter) {
  let selectedNodes = []
  let selectedProp = filter['property']
  if (filter['item'] === 'node') {
    let allNodes = nodes.get({ returnType: "Object" });
    for (let nodeId in allNodes) {
      if (allNodes[nodeId][selectedProp] && filter['value'].includes((allNodes[nodeId][selectedProp]).toString())) {
        selectedNodes.push(nodeId)
      }
    }
  }
  else if (filter['item'] === 'edge'){
    let allEdges = edges.get({returnType: 'object'});
    // check if the selected property exists for selected edge and select the nodes connected to the edge
    for (let edge in allEdges) {
      if (allEdges[edge][selectedProp] && filter['value'].includes((allEdges[edge][selectedProp]).toString())) {
        selectedNodes.push(allEdges[edge]['from'])
        selectedNodes.push(allEdges[edge]['to'])
      }
    }
  }
  selectNodes(selectedNodes)
}</script>
            <style>.vis-overlay{bottom:0;left:0;position:absolute;right:0;top:0;z-index:10}.vis-active{box-shadow:0 0 10px #86d5f8}.vis [class*=span]{min-height:0;width:auto}div.vis-color-picker{background-color:#fff;border-radius:15px;box-shadow:0 0 10px 0 rgba(0,0,0,.5);display:none;height:444px;left:30px;margin-left:30px;margin-top:-140px;padding:10px;position:absolute;top:0;width:310px;z-index:1}div.vis-color-picker div.vis-arrow{left:5px;position:absolute;top:147px}div.vis-color-picker div.vis-arrow:after,div.vis-color-picker div.vis-arrow:before{border:solid transparent;content:" ";height:0;pointer-events:none;position:absolute;right:100%;top:50%;width:0}div.vis-color-picker div.vis-arrow:after{border-color:hsla(0,0%,100%,0) #fff hsla(0,0%,100%,0) hsla(0,0%,100%,0);border-width:30px;margin-top:-30px}div.vis-color-picker div.vis-color{cursor:pointer;height:289px;position:absolute;width:289px}div.vis-color-picker div.vis-brightness{position:absolute;top:313px}div.vis-color-picker div.vis-opacity{position:absolute;top:350px}div.vis-color-picker div.vis-selector{background:#4c4c4c;background:-moz-linear-gradient(top,#4c4c4c 0,#595959 12%,#666 25%,#474747 39%,#2c2c2c 50%,#000 51%,#111 60%,#2b2b2b 76%,#1c1c1c 91%,#131313 100%);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#4c4c4c),color-stop(12%,#595959),color-stop(25%,#666),color-stop(39%,#474747),color-stop(50%,#2c2c2c),color-stop(51%,#000),color-stop(60%,#111),color-stop(76%,#2b2b2b),color-stop(91%,#1c1c1c),color-stop(100%,#131313));background:-webkit-linear-gradient(top,#4c4c4c,#595959 12%,#666 25%,#474747 39%,#2c2c2c 50%,#000 51%,#111 60%,#2b2b2b 76%,#1c1c1c 91%,#131313);background:-o-linear-gradient(top,#4c4c4c 0,#595959 12%,#666 25%,#474747 39%,#2c2c2c 50%,#000 51%,#111 60%,#2b2b2b 76%,#1c1c1c 91%,#131313 100%);background:-ms-linear-gradient(top,#4c4c4c 0,#595959 12%,#666 25%,#474747 39%,#2c2c2c 50%,#000 51%,#111 60%,#2b2b2b 76%,#1c1c1c 91%,#131313 100%);background:linear-gradient(180deg,#4c4c4c 0,#595959 12%,#666 25%,#474747 39%,#2c2c2c 50%,#000 51%,#111 60%,#2b2b2b 76%,#1c1c1c 91%,#131313);border:1px solid #fff;border-radius:15px;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#4c4c4c",endColorstr="#131313",GradientType=0);height:15px;left:137px;position:absolute;top:137px;width:15px}div.vis-color-picker div.vis-new-color{left:159px;padding-right:2px;text-align:right}div.vis-color-picker div.vis-initial-color,div.vis-color-picker div.vis-new-color{border:1px solid rgba(0,0,0,.1);border-radius:5px;color:rgba(0,0,0,.4);font-size:10px;height:20px;line-height:20px;position:absolute;top:380px;vertical-align:middle;width:140px}div.vis-color-picker div.vis-initial-color{left:10px;padding-left:2px;text-align:left}div.vis-color-picker div.vis-label{left:10px;position:absolute;width:300px}div.vis-color-picker div.vis-label.vis-brightness{top:300px}div.vis-color-picker div.vis-label.vis-opacity{top:338px}div.vis-color-picker div.vis-button{background-color:#f7f7f7;border:2px solid #d9d9d9;border-radius:10px;cursor:pointer;height:25px;line-height:25px;position:absolute;text-align:center;top:410px;vertical-align:middle;width:68px}div.vis-color-picker div.vis-button.vis-cancel{left:5px}div.vis-color-picker div.vis-button.vis-load{left:82px}div.vis-color-picker div.vis-button.vis-apply{left:159px}div.vis-color-picker div.vis-button.vis-save{left:236px}div.vis-color-picker input.vis-range{height:20px;width:290px}div.vis-configuration{display:block;float:left;font-size:12px;position:relative}div.vis-configuration-wrapper{display:block;width:700px}div.vis-configuration-wrapper:after{clear:both;content:"";display:block}div.vis-configuration.vis-config-option-container{background-color:#fff;border:2px solid #f7f8fa;border-radius:4px;display:block;left:10px;margin-top:20px;padding-left:5px;width:495px}div.vis-configuration.vis-config-button{background-color:#f7f8fa;border:2px solid #ceced0;border-radius:4px;cursor:pointer;display:block;height:25px;left:10px;line-height:25px;margin-bottom:30px;margin-top:20px;padding-left:5px;vertical-align:middle;width:495px}div.vis-configuration.vis-config-button.hover{background-color:#4588e6;border:2px solid #214373;color:#fff}div.vis-configuration.vis-config-item{display:block;float:left;height:25px;line-height:25px;vertical-align:middle;width:495px}div.vis-configuration.vis-config-item.vis-config-s2{background-color:#f7f8fa;border-radius:3px;left:10px;padding-left:5px}div.vis-configuration.vis-config-item.vis-config-s3{background-color:#e4e9f0;border-radius:3px;left:20px;padding-left:5px}div.vis-configuration.vis-config-item.vis-config-s4{background-color:#cfd8e6;border-radius:3px;left:30px;padding-left:5px}div.vis-configuration.vis-config-header{font-size:18px;font-weight:700}div.vis-configuration.vis-config-label{height:25px;line-height:25px;width:120px}div.vis-configuration.vis-config-label.vis-config-s3{width:110px}div.vis-configuration.vis-config-label.vis-config-s4{width:100px}div.vis-configuration.vis-config-colorBlock{border:1px solid #444;border-radius:2px;cursor:pointer;height:19px;margin:0;padding:0;top:1px;width:30px}input.vis-configuration.vis-config-checkbox{left:-5px}input.vis-configuration.vis-config-rangeinput{margin:0;padding:1px;pointer-events:none;position:relative;top:-5px;width:60px}input.vis-configuration.vis-config-range{-webkit-appearance:none;background-color:transparent;border:0 solid #fff;height:20px;width:300px}input.vis-configuration.vis-config-range::-webkit-slider-runnable-track{background:#dedede;background:-moz-linear-gradient(top,#dedede 0,#c8c8c8 99%);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#dedede),color-stop(99%,#c8c8c8));background:-webkit-linear-gradient(top,#dedede,#c8c8c8 99%);background:-o-linear-gradient(top,#dedede 0,#c8c8c8 99%);background:-ms-linear-gradient(top,#dedede 0,#c8c8c8 99%);background:linear-gradient(180deg,#dedede 0,#c8c8c8 99%);border:1px solid #999;border-radius:3px;box-shadow:0 0 3px 0 #aaa;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#dedede",endColorstr="#c8c8c8",GradientType=0);height:5px;width:300px}input.vis-configuration.vis-config-range::-webkit-slider-thumb{-webkit-appearance:none;background:#3876c2;background:-moz-linear-gradient(top,#3876c2 0,#385380 100%);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#3876c2),color-stop(100%,#385380));background:-webkit-linear-gradient(top,#3876c2,#385380);background:-o-linear-gradient(top,#3876c2 0,#385380 100%);background:-ms-linear-gradient(top,#3876c2 0,#385380 100%);background:linear-gradient(180deg,#3876c2 0,#385380);border:1px solid #14334b;border-radius:50%;box-shadow:0 0 1px 0 #111927;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#3876c2",endColorstr="#385380",GradientType=0);height:17px;margin-top:-7px;width:17px}input.vis-configuration.vis-config-range:focus{outline:none}input.vis-configuration.vis-config-range:focus::-webkit-slider-runnable-track{background:#9d9d9d;background:-moz-linear-gradient(top,#9d9d9d 0,#c8c8c8 99%);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#9d9d9d),color-stop(99%,#c8c8c8));background:-webkit-linear-gradient(top,#9d9d9d,#c8c8c8 99%);background:-o-linear-gradient(top,#9d9d9d 0,#c8c8c8 99%);background:-ms-linear-gradient(top,#9d9d9d 0,#c8c8c8 99%);background:linear-gradient(180deg,#9d9d9d 0,#c8c8c8 99%);filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#9d9d9d",endColorstr="#c8c8c8",GradientType=0)}input.vis-configuration.vis-config-range::-moz-range-track{background:#dedede;background:-moz-linear-gradient(top,#dedede 0,#c8c8c8 99%);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#dedede),color-stop(99%,#c8c8c8));background:-webkit-linear-gradient(top,#dedede,#c8c8c8 99%);background:-o-linear-gradient(top,#dedede 0,#c8c8c8 99%);background:-ms-linear-gradient(top,#dedede 0,#c8c8c8 99%);background:linear-gradient(180deg,#dedede 0,#c8c8c8 99%);border:1px solid #999;border-radius:3px;box-shadow:0 0 3px 0 #aaa;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#dedede",endColorstr="#c8c8c8",GradientType=0);height:10px;width:300px}input.vis-configuration.vis-config-range::-moz-range-thumb{background:#385380;border:none;border-radius:50%;height:16px;width:16px}input.vis-configuration.vis-config-range:-moz-focusring{outline:1px solid #fff;outline-offset:-1px}input.vis-configuration.vis-config-range::-ms-track{background:transparent;border-color:transparent;border-width:6px 0;color:transparent;height:5px;width:300px}input.vis-configuration.vis-config-range::-ms-fill-lower{background:#777;border-radius:10px}input.vis-configuration.vis-config-range::-ms-fill-upper{background:#ddd;border-radius:10px}input.vis-configuration.vis-config-range::-ms-thumb{background:#385380;border:none;border-radius:50%;height:16px;width:16px}input.vis-configuration.vis-config-range:focus::-ms-fill-lower{background:#888}input.vis-configuration.vis-config-range:focus::-ms-fill-upper{background:#ccc}.vis-configuration-popup{background:rgba(57,76,89,.85);border:2px solid #f2faff;border-radius:4px;color:#fff;font-size:14px;height:30px;line-height:30px;position:absolute;text-align:center;-webkit-transition:opacity .3s ease-in-out;-moz-transition:opacity .3s ease-in-out;transition:opacity .3s ease-in-out;width:150px}.vis-configuration-popup:after,.vis-configuration-popup:before{border:solid transparent;content:" ";height:0;left:100%;pointer-events:none;position:absolute;top:50%;width:0}.vis-configuration-popup:after{border-color:rgba(136,183,213,0) rgba(136,183,213,0) rgba(136,183,213,0) rgba(57,76,89,.85);border-width:8px;margin-top:-8px}.vis-configuration-popup:before{border-color:rgba(194,225,245,0) rgba(194,225,245,0) rgba(194,225,245,0) #f2faff;border-width:12px;margin-top:-12px}div.vis-tooltip{background-color:#f5f4ed;border:1px solid #808074;-moz-border-radius:3px;-webkit-border-radius:3px;border-radius:3px;box-shadow:3px 3px 10px rgba(0,0,0,.2);color:#000;font-family:verdana;font-size:14px;padding:5px;pointer-events:none;position:absolute;visibility:hidden;white-space:nowrap;z-index:5}div.vis-network div.vis-navigation div.vis-button{-webkit-touch-callout:none;background-position:2px 2px;background-repeat:no-repeat;-moz-border-radius:17px;border-radius:17px;cursor:pointer;display:inline-block;height:34px;position:absolute;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:34px}div.vis-network div.vis-navigation div.vis-button:hover{box-shadow:0 0 3px 3px rgba(56,207,21,.3)}div.vis-network div.vis-navigation div.vis-button:active{box-shadow:0 0 1px 3px rgba(56,207,21,.95)}div.vis-network div.vis-navigation div.vis-button.vis-up{background-image:url("data:image/png;base64,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");bottom:50px;left:55px}div.vis-network div.vis-navigation div.vis-button.vis-down{background-image:url("data:image/png;base64,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");bottom:10px;left:55px}div.vis-network div.vis-navigation div.vis-button.vis-left{background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKT2lDQ1BQaG90b3Nob3AgSUNDIHByb2ZpbGUAAHjanVNnVFPpFj333vRCS4iAlEtvUhUIIFJCi4AUkSYqIQkQSoghodkVUcERRUUEG8igiAOOjoCMFVEsDIoK2AfkIaKOg6OIisr74Xuja9a89+bN/rXXPues852zzwfACAyWSDNRNYAMqUIeEeCDx8TG4eQuQIEKJHAAEAizZCFz/SMBAPh+PDwrIsAHvgABeNMLCADATZvAMByH/w/qQplcAYCEAcB0kThLCIAUAEB6jkKmAEBGAYCdmCZTAKAEAGDLY2LjAFAtAGAnf+bTAICd+Jl7AQBblCEVAaCRACATZYhEAGg7AKzPVopFAFgwABRmS8Q5ANgtADBJV2ZIALC3AMDOEAuyAAgMADBRiIUpAAR7AGDIIyN4AISZABRG8lc88SuuEOcqAAB4mbI8uSQ5RYFbCC1xB1dXLh4ozkkXKxQ2YQJhmkAuwnmZGTKBNA/g88wAAKCRFRHgg/P9eM4Ors7ONo62Dl8t6r8G/yJiYuP+5c+rcEAAAOF0ftH+LC+zGoA7BoBt/qIl7gRoXgugdfeLZrIPQLUAoOnaV/Nw+H48PEWhkLnZ2eXk5NhKxEJbYcpXff5nwl/AV/1s+X48/Pf14L7iJIEyXYFHBPjgwsz0TKUcz5IJhGLc5o9H/LcL//wd0yLESWK5WCoU41EScY5EmozzMqUiiUKSKcUl0v9k4t8s+wM+3zUAsGo+AXuRLahdYwP2SycQWHTA4vcAAPK7b8HUKAgDgGiD4c93/+8//UegJQCAZkmScQAAXkQkLlTKsz/HCAAARKCBKrBBG/TBGCzABhzBBdzBC/xgNoRCJMTCQhBCCmSAHHJgKayCQiiGzbAdKmAv1EAdNMBRaIaTcA4uwlW4Dj1wD/phCJ7BKLyBCQRByAgTYSHaiAFiilgjjggXmYX4IcFIBBKLJCDJiBRRIkuRNUgxUopUIFVIHfI9cgI5h1xGupE7yAAygvyGvEcxlIGyUT3UDLVDuag3GoRGogvQZHQxmo8WoJvQcrQaPYw2oefQq2gP2o8+Q8cwwOgYBzPEbDAuxsNCsTgsCZNjy7EirAyrxhqwVqwDu4n1Y8+xdwQSgUXACTYEd0IgYR5BSFhMWE7YSKggHCQ0EdoJNwkDhFHCJyKTqEu0JroR+cQYYjIxh1hILCPWEo8TLxB7iEPENyQSiUMyJ7mQAkmxpFTSEtJG0m5SI+ksqZs0SBojk8naZGuyBzmULCAryIXkneTD5DPkG+Qh8lsKnWJAcaT4U+IoUspqShnlEOU05QZlmDJBVaOaUt2ooVQRNY9aQq2htlKvUYeoEzR1mjnNgxZJS6WtopXTGmgXaPdpr+h0uhHdlR5Ol9BX0svpR+iX6AP0dwwNhhWDx4hnKBmbGAcYZxl3GK+YTKYZ04sZx1QwNzHrmOeZD5lvVVgqtip8FZHKCpVKlSaVGyovVKmqpqreqgtV81XLVI+pXlN9rkZVM1PjqQnUlqtVqp1Q61MbU2epO6iHqmeob1Q/pH5Z/YkGWcNMw09DpFGgsV/jvMYgC2MZs3gsIWsNq4Z1gTXEJrHN2Xx2KruY/R27iz2qqaE5QzNKM1ezUvOUZj8H45hx+Jx0TgnnKKeX836K3hTvKeIpG6Y0TLkxZVxrqpaXllirSKtRq0frvTau7aedpr1Fu1n7gQ5Bx0onXCdHZ4/OBZ3nU9lT3acKpxZNPTr1ri6qa6UbobtEd79up+6Ynr5egJ5Mb6feeb3n+hx9L/1U/W36p/VHDFgGswwkBtsMzhg8xTVxbzwdL8fb8VFDXcNAQ6VhlWGX4YSRudE8o9VGjUYPjGnGXOMk423GbcajJgYmISZLTepN7ppSTbmmKaY7TDtMx83MzaLN1pk1mz0x1zLnm+eb15vft2BaeFostqi2uGVJsuRaplnutrxuhVo5WaVYVVpds0atna0l1rutu6cRp7lOk06rntZnw7Dxtsm2qbcZsOXYBtuutm22fWFnYhdnt8Wuw+6TvZN9un2N/T0HDYfZDqsdWh1+c7RyFDpWOt6azpzuP33F9JbpL2dYzxDP2DPjthPLKcRpnVOb00dnF2e5c4PziIuJS4LLLpc+Lpsbxt3IveRKdPVxXeF60vWdm7Obwu2o26/uNu5p7ofcn8w0nymeWTNz0MPIQ+BR5dE/C5+VMGvfrH5PQ0+BZ7XnIy9jL5FXrdewt6V3qvdh7xc+9j5yn+M+4zw33jLeWV/MN8C3yLfLT8Nvnl+F30N/I/9k/3r/0QCngCUBZwOJgUGBWwL7+Hp8Ib+OPzrbZfay2e1BjKC5QRVBj4KtguXBrSFoyOyQrSH355jOkc5pDoVQfujW0Adh5mGLw34MJ4WHhVeGP45wiFga0TGXNXfR3ENz30T6RJZE3ptnMU85ry1KNSo+qi5qPNo3ujS6P8YuZlnM1VidWElsSxw5LiquNm5svt/87fOH4p3iC+N7F5gvyF1weaHOwvSFpxapLhIsOpZATIhOOJTwQRAqqBaMJfITdyWOCnnCHcJnIi/RNtGI2ENcKh5O8kgqTXqS7JG8NXkkxTOlLOW5hCepkLxMDUzdmzqeFpp2IG0yPTq9MYOSkZBxQqohTZO2Z+pn5mZ2y6xlhbL+xW6Lty8elQfJa7OQrAVZLQq2QqboVFoo1yoHsmdlV2a/zYnKOZarnivN7cyzytuQN5zvn//tEsIS4ZK2pYZLVy0dWOa9rGo5sjxxedsK4xUFK4ZWBqw8uIq2Km3VT6vtV5eufr0mek1rgV7ByoLBtQFr6wtVCuWFfevc1+1dT1gvWd+1YfqGnRs+FYmKrhTbF5cVf9go3HjlG4dvyr+Z3JS0qavEuWTPZtJm6ebeLZ5bDpaql+aXDm4N2dq0Dd9WtO319kXbL5fNKNu7g7ZDuaO/PLi8ZafJzs07P1SkVPRU+lQ27tLdtWHX+G7R7ht7vPY07NXbW7z3/T7JvttVAVVN1WbVZftJ+7P3P66Jqun4lvttXa1ObXHtxwPSA/0HIw6217nU1R3SPVRSj9Yr60cOxx++/p3vdy0NNg1VjZzG4iNwRHnk6fcJ3/ceDTradox7rOEH0x92HWcdL2pCmvKaRptTmvtbYlu6T8w+0dbq3nr8R9sfD5w0PFl5SvNUyWna6YLTk2fyz4ydlZ19fi753GDborZ752PO32oPb++6EHTh0kX/i+c7vDvOXPK4dPKy2+UTV7hXmq86X23qdOo8/pPTT8e7nLuarrlca7nuer21e2b36RueN87d9L158Rb/1tWeOT3dvfN6b/fF9/XfFt1+cif9zsu72Xcn7q28T7xf9EDtQdlD3YfVP1v+3Njv3H9qwHeg89HcR/cGhYPP/pH1jw9DBY+Zj8uGDYbrnjg+OTniP3L96fynQ89kzyaeF/6i/suuFxYvfvjV69fO0ZjRoZfyl5O/bXyl/erA6xmv28bCxh6+yXgzMV70VvvtwXfcdx3vo98PT+R8IH8o/2j5sfVT0Kf7kxmTk/8EA5jz/GMzLdsAAAAgY0hSTQAAeiUAAICDAAD5/wAAgOkAAHUwAADqYAAAOpgAABdvkl/FRgAABt5JREFUeNqsl2lUlOcVx//3Pi9DZRsGBgYiS2RYBQKIjAhEJW4pNrXNMbZpWtTGNkttYmJMG5soSZckRk+0p+dYPYY0Gk0ihlhRj63GhVUgBhDD5oIOy8AAMwzD4lCYtx+GqCQKuNyP7/Pc+3u2+7/3JUzEZFBYLh62S7yIZDmVBEIBqOwsQ4DNdtBFASq2A4cuZAwVgCCPF5LGHM0Chz+E1XamzUyAzCMO7IhMI+5MDCK+HpCANd+U2rYgC/Y7BoflYgVA2RAOoNYtyjDTe45+hk96e5QywaJR+NsAwDhocK61VCjLTYWaclNB0OW+en8mhl22g8C/rn7U+uGEwdov+C0i+Q0mIFWzoD7zwVU1czQ/6pjIreR3HPX5VL9jalHXiQgmBoH+XLHAtH5csDaXtxDLLzIBv5jyfOmG2H9U4S7snbpX43KaPpgBIhDx1rPzOlbfPC5GQT/nd1mS1zABa6PfPf5y5F/rcJeWpp7fPkly6f7KXBRCoOSATFfXll19x74HDsvFCghsJAG8HrvlvytCXm7EPVqc5wyzp5NX15muE1omKXXyMnd9yy5r5Q3wPghvJzrLAlimXV38+7D1DbhPFq1M6O4b6rPVWKsCBfHi5EWWv9TkQBYAEPpLvERMC9N8FtRvjt9dPl6wwo5jPvuas7WV5jNqEjz8wA+CBsaan+w9x1hrrXJtuaZX97ooLfqPLCUEGRR+iOwAsF2X98Uc30W3fb02u41frVqeVmo6FUkkwCAwCWxJ2Ls/0TPFNBb8TNdp9WvnVz4OAKdmX2QOzcMsAAjziDGMBd3asCF6SXHyknJTfqQTK+zpvhnVKT5zawCgzFTgN94pJXvP7gxxjTAIkpB+MnSWRMQZYEDnPVt/K4ejbZ/77726Lb6h95tAAiPELaJ1bcTbRfGeM8xv1azWSeyEa0P9igk+Nr1+oNFfkpwzJCJKIQA679ntN08yDXYo3qh+LuUrc0E4EcNL4dP7VNDzpU8FP3vpekoQQ5CEw4bPdEfa9+sAgEZUmkmAAAS5hLQ9p11XGO+pM8V5JLUfMeQARDMlEMKIGFOVCZYb0C7Fz0oeXmIZ6nZzYoV9od/jVS+GbahUOnn9b7T6sEOviUGyA8bMDlUa0W79wBW/bZf+lrY98cDBUI8YCxGDgHCJiVVEDN8R7QWAE8Z/+1mGut2i3eP1r0S+XRztkdBzq6NbF7WpbF3UprKxjvfHxbrfttla/QBArVDbJJIAQCURMRg8ugrKIAKBSNxzHtN3VdmxY0iQYSZmTeegwTlgknYAAB7RZBh2Nm7urbeeC1r19ROT52kWn3shfH2Fu1AO3RxjY/0fdac7/hPPJMDE11GC+HpBJmIEuAS3Oa6w01lybMbMgvgCE6O255zy24DeCr/Bvckn9+u8ZjXYIYvjxoMJy8oeXZrT9GHIqMWTwA2oI6cFMeDIcAiSEOyibXsmZG0hAFzuq1OyY6xBAnMJgdPOmks08zU/bbsB9x18P37PqS/b8+o/a96ZcLm3PmBH46Z5x40HW1eFvl4Uq0w0MwiCBOb7/qTsd6GvVY537DXWas1Iw1AiNJnOgwJi+bXhAbE08OnvaXSIW0TvYw88eaF/uM/WNdju3m5r9TlhPBzVNNDoPGC/5tRma/GJ80xqjPPUjVuvP2narrMOWd1Jlv/E1fN782UiNPZf9C/qOKa+ndOz2j+cz046sn+6KrVOsODirpOxld0lUxmEBK/ktvGgFd2l6taBZn9BAtEz5xYIvAn4/8rFKkgstAyZ6Yf+S67ezlkiSU73XXRV6xqh93TyssR4JF75efBvymLdE03jgT/Wb5tutLWpGbTm7wHZxQQAT+yDuKLyHRIk4cnAZ4pfCF9/HvfR9uh3xBxtz00BANsVDylnac6wAICaHMiBmW5NRLy4trcq0MtZ3RnpHme5H9AvjYeCc1t3pzMJgOSVnyw4eHZUB9Kyu68iMFPpysSppab8UJVC3Rnp/pDlXqF7mnYsdKQbv7cr6fDGW/Zczbt6jgUtV6kIlFxuyg/tH+6zJXmlGe8G+mlzdsyB1j3pTAwZ9q3/Sspbc9tmDwD0H3UffXCFlyuTlFpnPRdYb612c5c8+idPCu6fCLDKUubzsf6fSaWm0wmO9hbvZU8fDR2zoZ97OuppAu0UJEDEmOISZohT6q7Gek5rD3GN6FEp1DaAYB7sdNYPXPao7anS1Fmrg402g7+jYhGIaOXOaQc+uONfmCwZXJIf8xKx2KRgxYgOS+CROuyoyQKCxIhkOr4T6JWgxGnvZ1HWnf/CfHcBXxcnpRHxYwRKkUjSErFKkAQiNjP4kmBRTHbKm5KkKxwL+K39fwDX1XGF8ct++QAAAABJRU5ErkJggg==");bottom:10px;left:15px}div.vis-network div.vis-navigation div.vis-button.vis-right{background-image:url("data:image/png;base64,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");bottom:10px;left:95px}div.vis-network div.vis-navigation div.vis-button.vis-zoomIn{background-image:url("data:image/png;base64,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");bottom:10px;right:15px}div.vis-network div.vis-navigation div.vis-button.vis-zoomOut{background-image:url("data:image/png;base64,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");bottom:10px;right:55px}div.vis-network div.vis-navigation div.vis-button.vis-zoomExtends{background-image:url("data:image/png;base64,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");bottom:50px;right:15px}div.vis-network div.vis-manipulation{background:#fff;background:-moz-linear-gradient(top,#fff 0,#fcfcfc 48%,#fafafa 50%,#fcfcfc 100%);background:-webkit-gradient(linear,left top,left bottom,color-stop(0,#fff),color-stop(48%,#fcfcfc),color-stop(50%,#fafafa),color-stop(100%,#fcfcfc));background:-webkit-linear-gradient(top,#fff,#fcfcfc 48%,#fafafa 50%,#fcfcfc);background:-o-linear-gradient(top,#fff 0,#fcfcfc 48%,#fafafa 50%,#fcfcfc 100%);background:-ms-linear-gradient(top,#fff 0,#fcfcfc 48%,#fafafa 50%,#fcfcfc 100%);background:linear-gradient(180deg,#fff 0,#fcfcfc 48%,#fafafa 50%,#fcfcfc);border:0 solid #d6d9d8;border-bottom:1px;box-sizing:content-box;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#ffffff",endColorstr="#fcfcfc",GradientType=0);height:28px;left:0;padding-top:4px;position:absolute;top:0;width:100%}div.vis-network button.vis-edit-mode,div.vis-network div.vis-edit-mode{height:30px;left:0;position:absolute;top:5px}div.vis-network button.vis-close{-webkit-touch-callout:none;background-color:transparent;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAcAAAAHCAYAAADEUlfTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKT2lDQ1BQaG90b3Nob3AgSUNDIHByb2ZpbGUAAHjanVNnVFPpFj333vRCS4iAlEtvUhUIIFJCi4AUkSYqIQkQSoghodkVUcERRUUEG8igiAOOjoCMFVEsDIoK2AfkIaKOg6OIisr74Xuja9a89+bN/rXXPues852zzwfACAyWSDNRNYAMqUIeEeCDx8TG4eQuQIEKJHAAEAizZCFz/SMBAPh+PDwrIsAHvgABeNMLCADATZvAMByH/w/qQplcAYCEAcB0kThLCIAUAEB6jkKmAEBGAYCdmCZTAKAEAGDLY2LjAFAtAGAnf+bTAICd+Jl7AQBblCEVAaCRACATZYhEAGg7AKzPVopFAFgwABRmS8Q5ANgtADBJV2ZIALC3AMDOEAuyAAgMADBRiIUpAAR7AGDIIyN4AISZABRG8lc88SuuEOcqAAB4mbI8uSQ5RYFbCC1xB1dXLh4ozkkXKxQ2YQJhmkAuwnmZGTKBNA/g88wAAKCRFRHgg/P9eM4Ors7ONo62Dl8t6r8G/yJiYuP+5c+rcEAAAOF0ftH+LC+zGoA7BoBt/qIl7gRoXgugdfeLZrIPQLUAoOnaV/Nw+H48PEWhkLnZ2eXk5NhKxEJbYcpXff5nwl/AV/1s+X48/Pf14L7iJIEyXYFHBPjgwsz0TKUcz5IJhGLc5o9H/LcL//wd0yLESWK5WCoU41EScY5EmozzMqUiiUKSKcUl0v9k4t8s+wM+3zUAsGo+AXuRLahdYwP2SycQWHTA4vcAAPK7b8HUKAgDgGiD4c93/+8//UegJQCAZkmScQAAXkQkLlTKsz/HCAAARKCBKrBBG/TBGCzABhzBBdzBC/xgNoRCJMTCQhBCCmSAHHJgKayCQiiGzbAdKmAv1EAdNMBRaIaTcA4uwlW4Dj1wD/phCJ7BKLyBCQRByAgTYSHaiAFiilgjjggXmYX4IcFIBBKLJCDJiBRRIkuRNUgxUopUIFVIHfI9cgI5h1xGupE7yAAygvyGvEcxlIGyUT3UDLVDuag3GoRGogvQZHQxmo8WoJvQcrQaPYw2oefQq2gP2o8+Q8cwwOgYBzPEbDAuxsNCsTgsCZNjy7EirAyrxhqwVqwDu4n1Y8+xdwQSgUXACTYEd0IgYR5BSFhMWE7YSKggHCQ0EdoJNwkDhFHCJyKTqEu0JroR+cQYYjIxh1hILCPWEo8TLxB7iEPENyQSiUMyJ7mQAkmxpFTSEtJG0m5SI+ksqZs0SBojk8naZGuyBzmULCAryIXkneTD5DPkG+Qh8lsKnWJAcaT4U+IoUspqShnlEOU05QZlmDJBVaOaUt2ooVQRNY9aQq2htlKvUYeoEzR1mjnNgxZJS6WtopXTGmgXaPdpr+h0uhHdlR5Ol9BX0svpR+iX6AP0dwwNhhWDx4hnKBmbGAcYZxl3GK+YTKYZ04sZx1QwNzHrmOeZD5lvVVgqtip8FZHKCpVKlSaVGyovVKmqpqreqgtV81XLVI+pXlN9rkZVM1PjqQnUlqtVqp1Q61MbU2epO6iHqmeob1Q/pH5Z/YkGWcNMw09DpFGgsV/jvMYgC2MZs3gsIWsNq4Z1gTXEJrHN2Xx2KruY/R27iz2qqaE5QzNKM1ezUvOUZj8H45hx+Jx0TgnnKKeX836K3hTvKeIpG6Y0TLkxZVxrqpaXllirSKtRq0frvTau7aedpr1Fu1n7gQ5Bx0onXCdHZ4/OBZ3nU9lT3acKpxZNPTr1ri6qa6UbobtEd79up+6Ynr5egJ5Mb6feeb3n+hx9L/1U/W36p/VHDFgGswwkBtsMzhg8xTVxbzwdL8fb8VFDXcNAQ6VhlWGX4YSRudE8o9VGjUYPjGnGXOMk423GbcajJgYmISZLTepN7ppSTbmmKaY7TDtMx83MzaLN1pk1mz0x1zLnm+eb15vft2BaeFostqi2uGVJsuRaplnutrxuhVo5WaVYVVpds0atna0l1rutu6cRp7lOk06rntZnw7Dxtsm2qbcZsOXYBtuutm22fWFnYhdnt8Wuw+6TvZN9un2N/T0HDYfZDqsdWh1+c7RyFDpWOt6azpzuP33F9JbpL2dYzxDP2DPjthPLKcRpnVOb00dnF2e5c4PziIuJS4LLLpc+Lpsbxt3IveRKdPVxXeF60vWdm7Obwu2o26/uNu5p7ofcn8w0nymeWTNz0MPIQ+BR5dE/C5+VMGvfrH5PQ0+BZ7XnIy9jL5FXrdewt6V3qvdh7xc+9j5yn+M+4zw33jLeWV/MN8C3yLfLT8Nvnl+F30N/I/9k/3r/0QCngCUBZwOJgUGBWwL7+Hp8Ib+OPzrbZfay2e1BjKC5QRVBj4KtguXBrSFoyOyQrSH355jOkc5pDoVQfujW0Adh5mGLw34MJ4WHhVeGP45wiFga0TGXNXfR3ENz30T6RJZE3ptnMU85ry1KNSo+qi5qPNo3ujS6P8YuZlnM1VidWElsSxw5LiquNm5svt/87fOH4p3iC+N7F5gvyF1weaHOwvSFpxapLhIsOpZATIhOOJTwQRAqqBaMJfITdyWOCnnCHcJnIi/RNtGI2ENcKh5O8kgqTXqS7JG8NXkkxTOlLOW5hCepkLxMDUzdmzqeFpp2IG0yPTq9MYOSkZBxQqohTZO2Z+pn5mZ2y6xlhbL+xW6Lty8elQfJa7OQrAVZLQq2QqboVFoo1yoHsmdlV2a/zYnKOZarnivN7cyzytuQN5zvn//tEsIS4ZK2pYZLVy0dWOa9rGo5sjxxedsK4xUFK4ZWBqw8uIq2Km3VT6vtV5eufr0mek1rgV7ByoLBtQFr6wtVCuWFfevc1+1dT1gvWd+1YfqGnRs+FYmKrhTbF5cVf9go3HjlG4dvyr+Z3JS0qavEuWTPZtJm6ebeLZ5bDpaql+aXDm4N2dq0Dd9WtO319kXbL5fNKNu7g7ZDuaO/PLi8ZafJzs07P1SkVPRU+lQ27tLdtWHX+G7R7ht7vPY07NXbW7z3/T7JvttVAVVN1WbVZftJ+7P3P66Jqun4lvttXa1ObXHtxwPSA/0HIw6217nU1R3SPVRSj9Yr60cOxx++/p3vdy0NNg1VjZzG4iNwRHnk6fcJ3/ceDTradox7rOEH0x92HWcdL2pCmvKaRptTmvtbYlu6T8w+0dbq3nr8R9sfD5w0PFl5SvNUyWna6YLTk2fyz4ydlZ19fi753GDborZ752PO32oPb++6EHTh0kX/i+c7vDvOXPK4dPKy2+UTV7hXmq86X23qdOo8/pPTT8e7nLuarrlca7nuer21e2b36RueN87d9L158Rb/1tWeOT3dvfN6b/fF9/XfFt1+cif9zsu72Xcn7q28T7xf9EDtQdlD3YfVP1v+3Njv3H9qwHeg89HcR/cGhYPP/pH1jw9DBY+Zj8uGDYbrnjg+OTniP3L96fynQ89kzyaeF/6i/suuFxYvfvjV69fO0ZjRoZfyl5O/bXyl/erA6xmv28bCxh6+yXgzMV70VvvtwXfcdx3vo98PT+R8IH8o/2j5sfVT0Kf7kxmTk/8EA5jz/GMzLdsAADvGaVRYdFhNTDpjb20uYWRvYmUueG1wAAAAAAA8P3hwYWNrZXQgYmVnaW49Iu+7vyIgaWQ9Ilc1TTBNcENlaGlIenJlU3pOVGN6a2M5ZCI/Pgo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIiB4OnhtcHRrPSJBZG9iZSBYTVAgQ29yZSA1LjUtYzAyMSA3OS4xNTQ5MTEsIDIwMTMvMTAvMjktMTE6NDc6MTYgICAgICAgICI+CiAgIDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgICAgIDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiCiAgICAgICAgICAgIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyIKICAgICAgICAgICAgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iCiAgICAgICAgICAgIHhtbG5zOnN0RXZ0PSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VFdmVudCMiCiAgICAgICAgICAgIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyIKICAgICAgICAgICAgeG1sbnM6cGhvdG9zaG9wPSJodHRwOi8vbnMuYWRvYmUuY29tL3Bob3Rvc2hvcC8xLjAvIgogICAgICAgICAgICB4bWxuczp0aWZmPSJodHRwOi8vbnMuYWRvYmUuY29tL3RpZmYvMS4wLyIKICAgICAgICAgICAgeG1sbnM6ZXhpZj0iaHR0cDovL25zLmFkb2JlLmNvbS9leGlmLzEuMC8iPgogICAgICAgICA8eG1wOkNyZWF0b3JUb29sPkFkb2JlIFBob3Rvc2hvcCBDQyAoV2luZG93cyk8L3htcDpDcmVhdG9yVG9vbD4KICAgICAgICAgPHhtcDpDcmVhdGVEYXRlPjIwMTQtMDItMTRUMTE6NTU6MzUrMDE6MDA8L3htcDpDcmVhdGVEYXRlPgogICAgICAgICA8eG1wOk1ldGFkYXRhRGF0ZT4yMDE0LTAyLTE0VDEyOjA1OjE3KzAxOjAwPC94bXA6TWV0YWRhdGFEYXRlPgogICAgICAgICA8eG1wOk1vZGlmeURhdGU+MjAxNC0wMi0xNFQxMjowNToxNyswMTowMDwveG1wOk1vZGlmeURhdGU+CiAgICAgICAgIDx4bXBNTTpJbnN0YW5jZUlEPnhtcC5paWQ6NjU0YmM5YmQtMWI2Yi1jYjRhLTllOWQtNWY2MzgxNDVjZjk0PC94bXBNTTpJbnN0YW5jZUlEPgogICAgICAgICA8eG1wTU06RG9jdW1lbnRJRD54bXAuZGlkOjk4MmM2MGIwLWUzZjMtMDk0MC04MjU0LTFiZTliNWE0ZTE4MzwveG1wTU06RG9jdW1lbnRJRD4KICAgICAgICAgPHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD54bXAuZGlkOjk4MmM2MGIwLWUzZjMtMDk0MC04MjU0LTFiZTliNWE0ZTE4MzwveG1wTU06T3JpZ2luYWxEb2N1bWVudElEPgogICAgICAgICA8eG1wTU06SGlzdG9yeT4KICAgICAgICAgICAgPHJkZjpTZXE+CiAgICAgICAgICAgICAgIDxyZGY6bGkgcmRmOnBhcnNlVHlwZT0iUmVzb3VyY2UiPgogICAgICAgICAgICAgICAgICA8c3RFdnQ6YWN0aW9uPmNyZWF0ZWQ8L3N0RXZ0OmFjdGlvbj4KICAgICAgICAgICAgICAgICAgPHN0RXZ0Omluc3RhbmNlSUQ+eG1wLmlpZDo5ODJjNjBiMC1lM2YzLTA5NDAtODI1NC0xYmU5YjVhNGUxODM8L3N0RXZ0Omluc3RhbmNlSUQ+CiAgICAgICAgICAgICAgICAgIDxzdEV2dDp3aGVuPjIwMTQtMDItMTRUMTE6NTU6MzUrMDE6MDA8L3N0RXZ0OndoZW4+CiAgICAgICAgICAgICAgICAgIDxzdEV2dDpzb2Z0d2FyZUFnZW50PkFkb2JlIFBob3Rvc2hvcCBDQyAoV2luZG93cyk8L3N0RXZ0OnNvZnR3YXJlQWdlbnQ+CiAgICAgICAgICAgICAgIDwvcmRmOmxpPgogICAgICAgICAgICAgICA8cmRmOmxpIHJkZjpwYXJzZVR5cGU9IlJlc291cmNlIj4KICAgICAgICAgICAgICAgICAgPHN0RXZ0OmFjdGlvbj5zYXZlZDwvc3RFdnQ6YWN0aW9uPgogICAgICAgICAgICAgICAgICA8c3RFdnQ6aW5zdGFuY2VJRD54bXAuaWlkOjIxODYxNmM2LTM1MWMtNDI0OS04YWFkLWJkZDQ2ZTczNWE0NDwvc3RFdnQ6aW5zdGFuY2VJRD4KICAgICAgICAgICAgICAgICAgPHN0RXZ0OndoZW4+MjAxNC0wMi0xNFQxMTo1NTozNSswMTowMDwvc3RFdnQ6d2hlbj4KICAgICAgICAgICAgICAgICAgPHN0RXZ0OnNvZnR3YXJlQWdlbnQ+QWRvYmUgUGhvdG9zaG9wIENDIChXaW5kb3dzKTwvc3RFdnQ6c29mdHdhcmVBZ2VudD4KICAgICAgICAgICAgICAgICAgPHN0RXZ0OmNoYW5nZWQ+Lzwvc3RFdnQ6Y2hhbmdlZD4KICAgICAgICAgICAgICAgPC9yZGY6bGk+CiAgICAgICAgICAgICAgIDxyZGY6bGkgcmRmOnBhcnNlVHlwZT0iUmVzb3VyY2UiPgogICAgICAgICAgICAgICAgICA8c3RFdnQ6YWN0aW9uPnNhdmVkPC9zdEV2dDphY3Rpb24+CiAgICAgICAgICAgICAgICAgIDxzdEV2dDppbnN0YW5jZUlEPnhtcC5paWQ6NjU0YmM5YmQtMWI2Yi1jYjRhLTllOWQtNWY2MzgxNDVjZjk0PC9zdEV2dDppbnN0YW5jZUlEPgogICAgICAgICAgICAgICAgICA8c3RFdnQ6d2hlbj4yMDE0LTAyLTE0VDEyOjA1OjE3KzAxOjAwPC9zdEV2dDp3aGVuPgogICAgICAgICAgICAgICAgICA8c3RFdnQ6c29mdHdhcmVBZ2VudD5BZG9iZSBQaG90b3Nob3AgQ0MgKFdpbmRvd3MpPC9zdEV2dDpzb2Z0d2FyZUFnZW50PgogICAgICAgICAgICAgICAgICA8c3RFdnQ6Y2hhbmdlZD4vPC9zdEV2dDpjaGFuZ2VkPgogICAgICAgICAgICAgICA8L3JkZjpsaT4KICAgICAgICAgICAgPC9yZGY6U2VxPgogICAgICAgICA8L3htcE1NOkhpc3Rvcnk+CiAgICAgICAgIDxkYzpmb3JtYXQ+aW1hZ2UvcG5nPC9kYzpmb3JtYXQ+CiAgICAgICAgIDxwaG90b3Nob3A6Q29sb3JNb2RlPjM8L3Bob3Rvc2hvcDpDb2xvck1vZGU+CiAgICAgICAgIDxwaG90b3Nob3A6SUNDUHJvZmlsZT5zUkdCIElFQzYxOTY2LTIuMTwvcGhvdG9zaG9wOklDQ1Byb2ZpbGU+CiAgICAgICAgIDx0aWZmOk9yaWVudGF0aW9uPjE8L3RpZmY6T3JpZW50YXRpb24+CiAgICAgICAgIDx0aWZmOlhSZXNvbHV0aW9uPjcyMDAwMC8xMDAwMDwvdGlmZjpYUmVzb2x1dGlvbj4KICAgICAgICAgPHRpZmY6WVJlc29sdXRpb24+NzIwMDAwLzEwMDAwPC90aWZmOllSZXNvbHV0aW9uPgogICAgICAgICA8dGlmZjpSZXNvbHV0aW9uVW5pdD4yPC90aWZmOlJlc29sdXRpb25Vbml0PgogICAgICAgICA8ZXhpZjpDb2xvclNwYWNlPjE8L2V4aWY6Q29sb3JTcGFjZT4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjc8L2V4aWY6UGl4ZWxYRGltZW5zaW9uPgogICAgICAgICA8ZXhpZjpQaXhlbFlEaW1lbnNpb24+NzwvZXhpZjpQaXhlbFlEaW1lbnNpb24+CiAgICAgIDwvcmRmOkRlc2NyaXB0aW9uPgogICA8L3JkZjpSREY+CjwveDp4bXBtZXRhPgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIAo8P3hwYWNrZXQgZW5kPSJ3Ij8+cZUZMwAAACBjSFJNAAB6JQAAgIMAAPn/AACA6QAAdTAAAOpgAAA6mAAAF2+SX8VGAAAA2ElEQVR42gDLADT/AS0tLUQFBQUVFxcXtPHx8fPl5eUNCAgITCkpKesEHx8fGgYGBjH+/v4a+Pj4qgQEBFU6OjodMTExzwQUFBSvEBAQEfX19SD19fVqNDQ0CElJSd/9/f2vAwEBAfrn5+fkBwcHLRYWFgsXFxfz29vbo9LS0uwDDQ0NDfPz81orKysXIyMj+ODg4Avh4eEa/f391gMkJCRYPz8/KUhISOMCAgKh8fHxHRsbGx4UFBQQBDk5OeY7Ozv7CAgItPb29vMEBASaJSUlTQ0NDesDAEwpT0Ko8Ri2AAAAAElFTkSuQmCC");background-position:20px 3px;background-repeat:no-repeat;border:none;cursor:pointer;height:30px;position:absolute;right:0;top:0;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:30px}div.vis-network button.vis-close:hover{opacity:.6}div.vis-network div.vis-edit-mode button.vis-button,div.vis-network div.vis-manipulation button.vis-button{-webkit-touch-callout:none;background-color:transparent;background-position:0 0;background-repeat:no-repeat;border:none;-moz-border-radius:15px;border-radius:15px;box-sizing:content-box;cursor:pointer;float:left;font-family:verdana;font-size:12px;height:24px;margin-left:10px;padding:0 8px;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}div.vis-network div.vis-manipulation button.vis-button:hover{box-shadow:1px 1px 8px rgba(0,0,0,.2)}div.vis-network div.vis-manipulation button.vis-button:active{box-shadow:1px 1px 8px rgba(0,0,0,.5)}div.vis-network div.vis-manipulation button.vis-button.vis-back{background-image:url("data:image/png;base64,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")}div.vis-network div.vis-manipulation div.vis-none:hover{box-shadow:1px 1px 8px transparent;cursor:default}div.vis-network div.vis-manipulation div.vis-none:active{box-shadow:1px 1px 8px transparent}div.vis-network div.vis-manipulation div.vis-none{line-height:23px;padding:0}div.vis-network div.vis-manipulation div.notification{font-weight:700;margin:2px}div.vis-network div.vis-manipulation button.vis-button.vis-add{background-image:url("data:image/png;base64,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")}div.vis-network div.vis-edit-mode button.vis-button.vis-edit,div.vis-network div.vis-manipulation button.vis-button.vis-edit{background-image:url("data:image/png;base64,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")}div.vis-network div.vis-edit-mode button.vis-button.vis-edit.vis-edit-mode{background-color:#fcfcfc;border:1px solid #ccc}div.vis-network div.vis-manipulation button.vis-button.vis-connect{background-image:url("data:image/png;base64,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")}div.vis-network div.vis-manipulation button.vis-button.vis-delete{background-image:url("data:image/png;base64,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")}div.vis-network div.vis-edit-mode div.vis-label,div.vis-network div.vis-manipulation div.vis-label{line-height:25px;margin:0 0 0 23px}div.vis-network div.vis-manipulation div.vis-separator-line{background-color:#bdbdbd;display:inline-block;float:left;height:21px;margin:0 7px 0 15px;width:1px}</style>
            <script>/**
 * vis-network
 * https://visjs.github.io/vis-network/
 *
 * A dynamic, browser-based visualization library.
 *
 * @version 9.1.2
 * @date    2022-03-28T20:17:35.342Z
 *
 * @copyright (c) 2011-2017 Almende B.V, http://almende.com
 * @copyright (c) 2017-2019 visjs contributors, https://github.com/visjs
 *
 * @license
 * vis.js is dual licensed under both
 *
 *   1. The Apache 2.0 License
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *   and
 *
 *   2. The MIT License
 *      http://opensource.org/licenses/MIT
 *
 * vis.js may be distributed under either license.
 */
!function(t,e){"object"==typeof exports&&"undefined"!=typeof module?e(exports):"function"==typeof define&&define.amd?define(["exports"],e):e((t="undefined"!=typeof globalThis?globalThis:t||self).vis=t.vis||{})}(this,(function(t){"use strict";var e="undefined"!=typeof globalThis?globalThis:"undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{},i=function(t){return t&&t.Math==Math&&t},n=i("object"==typeof globalThis&&globalThis)||i("object"==typeof window&&window)||i("object"==typeof self&&self)||i("object"==typeof e&&e)||function(){return this}()||Function("return this")(),o=function(t){try{return!!t()}catch(t){return!0}},r=!o((function(){var t=function(){}.bind();return"function"!=typeof t||t.hasOwnProperty("prototype")})),s=r,a=Function.prototype,h=a.apply,l=a.call,d="object"==typeof Reflect&&Reflect.apply||(s?l.bind(h):function(){return l.apply(h,arguments)}),c=r,u=Function.prototype,f=u.bind,p=u.call,v=c&&f.bind(p,p),g=c?function(t){return t&&v(t)}:function(t){return t&&function(){return p.apply(t,arguments)}},y=function(t){return"function"==typeof t},m={},b=!o((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]})),w=r,k=Function.prototype.call,_=w?k.bind(k):function(){return k.apply(k,arguments)},x={},E={}.propertyIsEnumerable,O=Object.getOwnPropertyDescriptor,C=O&&!E.call({1:2},1);x.f=C?function(t){var e=O(this,t);return!!e&&e.enumerable}:E;var S,T,M=function(t,e){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:e}},P=g,D=P({}.toString),I=P("".slice),B=function(t){return I(D(t),8,-1)},z=g,N=o,F=B,A=n.Object,j=z("".split),R=N((function(){return!A("z").propertyIsEnumerable(0)}))?function(t){return"String"==F(t)?j(t,""):A(t)}:A,L=n.TypeError,H=function(t){if(null==t)throw L("Can't call method on "+t);return t},W=R,q=H,V=function(t){return W(q(t))},U=y,Y=function(t){return"object"==typeof t?null!==t:U(t)},X={},G=X,K=n,$=y,Z=function(t){return $(t)?t:void 0},Q=function(t,e){return arguments.length<2?Z(G[t])||Z(K[t]):G[t]&&G[t][e]||K[t]&&K[t][e]},J=g({}.isPrototypeOf),tt=Q("navigator","userAgent")||"",et=n,it=tt,nt=et.process,ot=et.Deno,rt=nt&&nt.versions||ot&&ot.version,st=rt&&rt.v8;st&&(T=(S=st.split("."))[0]>0&&S[0]<4?1:+(S[0]+S[1])),!T&&it&&(!(S=it.match(/Edge\/(\d+)/))||S[1]>=74)&&(S=it.match(/Chrome\/(\d+)/))&&(T=+S[1]);var at=T,ht=at,lt=o,dt=!!Object.getOwnPropertySymbols&&!lt((function(){var t=Symbol();return!String(t)||!(Object(t)instanceof Symbol)||!Symbol.sham&&ht&&ht<41})),ct=dt&&!Symbol.sham&&"symbol"==typeof Symbol.iterator,ut=Q,ft=y,pt=J,vt=ct,gt=n.Object,yt=vt?function(t){return"symbol"==typeof t}:function(t){var e=ut("Symbol");return ft(e)&&pt(e.prototype,gt(t))},mt=n.String,bt=function(t){try{return mt(t)}catch(t){return"Object"}},wt=y,kt=bt,_t=n.TypeError,xt=function(t){if(wt(t))return t;throw _t(kt(t)+" is not a function")},Et=xt,Ot=function(t,e){var i=t[e];return null==i?void 0:Et(i)},Ct=_,St=y,Tt=Y,Mt=n.TypeError,Pt={exports:{}},Dt=n,It=Object.defineProperty,Bt=function(t,e){try{It(Dt,t,{value:e,configurable:!0,writable:!0})}catch(i){Dt[t]=e}return e},zt="__core-js_shared__",Nt=n[zt]||Bt(zt,{}),Ft=Nt;(Pt.exports=function(t,e){return Ft[t]||(Ft[t]=void 0!==e?e:{})})("versions",[]).push({version:"3.21.1",mode:"pure",copyright:" 2014-2022 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.21.1/LICENSE",source:"https://github.com/zloirock/core-js"});var At=H,jt=n.Object,Rt=function(t){return jt(At(t))},Lt=Rt,Ht=g({}.hasOwnProperty),Wt=Object.hasOwn||function(t,e){return Ht(Lt(t),e)},qt=g,Vt=0,Ut=Math.random(),Yt=qt(1..toString),Xt=function(t){return"Symbol("+(void 0===t?"":t)+")_"+Yt(++Vt+Ut,36)},Gt=n,Kt=Pt.exports,$t=Wt,Zt=Xt,Qt=dt,Jt=ct,te=Kt("wks"),ee=Gt.Symbol,ie=ee&&ee.for,ne=Jt?ee:ee&&ee.withoutSetter||Zt,oe=function(t){if(!$t(te,t)||!Qt&&"string"!=typeof te[t]){var e="Symbol."+t;Qt&&$t(ee,t)?te[t]=ee[t]:te[t]=Jt&&ie?ie(e):ne(e)}return te[t]},re=_,se=Y,ae=yt,he=Ot,le=function(t,e){var i,n;if("string"===e&&St(i=t.toString)&&!Tt(n=Ct(i,t)))return n;if(St(i=t.valueOf)&&!Tt(n=Ct(i,t)))return n;if("string"!==e&&St(i=t.toString)&&!Tt(n=Ct(i,t)))return n;throw Mt("Can't convert object to primitive value")},de=oe,ce=n.TypeError,ue=de("toPrimitive"),fe=function(t,e){if(!se(t)||ae(t))return t;var i,n=he(t,ue);if(n){if(void 0===e&&(e="default"),i=re(n,t,e),!se(i)||ae(i))return i;throw ce("Can't convert object to primitive value")}return void 0===e&&(e="number"),le(t,e)},pe=yt,ve=function(t){var e=fe(t,"string");return pe(e)?e:e+""},ge=Y,ye=n.document,me=ge(ye)&&ge(ye.createElement),be=function(t){return me?ye.createElement(t):{}},we=be,ke=!b&&!o((function(){return 7!=Object.defineProperty(we("div"),"a",{get:function(){return 7}}).a})),_e=b,xe=_,Ee=x,Oe=M,Ce=V,Se=ve,Te=Wt,Me=ke,Pe=Object.getOwnPropertyDescriptor;m.f=_e?Pe:function(t,e){if(t=Ce(t),e=Se(e),Me)try{return Pe(t,e)}catch(t){}if(Te(t,e))return Oe(!xe(Ee.f,t,e),t[e])};var De=o,Ie=y,Be=/#|\.prototype\./,ze=function(t,e){var i=Fe[Ne(t)];return i==je||i!=Ae&&(Ie(e)?De(e):!!e)},Ne=ze.normalize=function(t){return String(t).replace(Be,".").toLowerCase()},Fe=ze.data={},Ae=ze.NATIVE="N",je=ze.POLYFILL="P",Re=ze,Le=xt,He=r,We=g(g.bind),qe=function(t,e){return Le(t),void 0===e?t:He?We(t,e):function(){return t.apply(e,arguments)}},Ve={},Ue=b&&o((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype})),Ye=n,Xe=Y,Ge=Ye.String,Ke=Ye.TypeError,$e=function(t){if(Xe(t))return t;throw Ke(Ge(t)+" is not an object")},Ze=b,Qe=ke,Je=Ue,ti=$e,ei=ve,ii=n.TypeError,ni=Object.defineProperty,oi=Object.getOwnPropertyDescriptor,ri="enumerable",si="configurable",ai="writable";Ve.f=Ze?Je?function(t,e,i){if(ti(t),e=ei(e),ti(i),"function"==typeof t&&"prototype"===e&&"value"in i&&ai in i&&!i.writable){var n=oi(t,e);n&&n.writable&&(t[e]=i.value,i={configurable:si in i?i.configurable:n.configurable,enumerable:ri in i?i.enumerable:n.enumerable,writable:!1})}return ni(t,e,i)}:ni:function(t,e,i){if(ti(t),e=ei(e),ti(i),Qe)try{return ni(t,e,i)}catch(t){}if("get"in i||"set"in i)throw ii("Accessors not supported");return"value"in i&&(t[e]=i.value),t};var hi=Ve,li=M,di=b?function(t,e,i){return hi.f(t,e,li(1,i))}:function(t,e,i){return t[e]=i,t},ci=n,ui=d,fi=g,pi=y,vi=m.f,gi=Re,yi=X,mi=qe,bi=di,wi=Wt,ki=function(t){var e=function(i,n,o){if(this instanceof e){switch(arguments.length){case 0:return new t;case 1:return new t(i);case 2:return new t(i,n)}return new t(i,n,o)}return ui(t,this,arguments)};return e.prototype=t.prototype,e},_i=function(t,e){var i,n,o,r,s,a,h,l,d=t.target,c=t.global,u=t.stat,f=t.proto,p=c?ci:u?ci[d]:(ci[d]||{}).prototype,v=c?yi:yi[d]||bi(yi,d,{})[d],g=v.prototype;for(o in e)i=!gi(c?o:d+(u?".":"#")+o,t.forced)&&p&&wi(p,o),s=v[o],i&&(a=t.noTargetGet?(l=vi(p,o))&&l.value:p[o]),r=i&&a?a:e[o],i&&typeof s==typeof r||(h=t.bind&&i?mi(r,ci):t.wrap&&i?ki(r):f&&pi(r)?fi(r):r,(t.sham||r&&r.sham||s&&s.sham)&&bi(h,"sham",!0),bi(v,o,h),f&&(wi(yi,n=d+"Prototype")||bi(yi,n,{}),bi(yi[n],o,r),t.real&&g&&!g[o]&&bi(g,o,r)))},xi=Math.ceil,Ei=Math.floor,Oi=function(t){var e=+t;return e!=e||0===e?0:(e>0?Ei:xi)(e)},Ci=Oi,Si=Math.max,Ti=Math.min,Mi=function(t,e){var i=Ci(t);return i<0?Si(i+e,0):Ti(i,e)},Pi=Oi,Di=Math.min,Ii=function(t){return t>0?Di(Pi(t),9007199254740991):0},Bi=function(t){return Ii(t.length)},zi=V,Ni=Mi,Fi=Bi,Ai=function(t){return function(e,i,n){var o,r=zi(e),s=Fi(r),a=Ni(n,s);if(t&&i!=i){for(;s>a;)if((o=r[a++])!=o)return!0}else for(;s>a;a++)if((t||a in r)&&r[a]===i)return t||a||0;return!t&&-1}},ji={includes:Ai(!0),indexOf:Ai(!1)},Ri={},Li=Wt,Hi=V,Wi=ji.indexOf,qi=Ri,Vi=g([].push),Ui=function(t,e){var i,n=Hi(t),o=0,r=[];for(i in n)!Li(qi,i)&&Li(n,i)&&Vi(r,i);for(;e.length>o;)Li(n,i=e[o++])&&(~Wi(r,i)||Vi(r,i));return r},Yi=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"],Xi=Ui,Gi=Yi,Ki=Object.keys||function(t){return Xi(t,Gi)},$i={};$i.f=Object.getOwnPropertySymbols;var Zi=b,Qi=g,Ji=_,tn=o,en=Ki,nn=$i,on=x,rn=Rt,sn=R,an=Object.assign,hn=Object.defineProperty,ln=Qi([].concat),dn=!an||tn((function(){if(Zi&&1!==an({b:1},an(hn({},"a",{enumerable:!0,get:function(){hn(this,"b",{value:3,enumerable:!1})}}),{b:2})).b)return!0;var t={},e={},i=Symbol(),n="abcdefghijklmnopqrst";return t[i]=7,n.split("").forEach((function(t){e[t]=t})),7!=an({},t)[i]||en(an({},e)).join("")!=n}))?function(t,e){for(var i=rn(t),n=arguments.length,o=1,r=nn.f,s=on.f;n>o;)for(var a,h=sn(arguments[o++]),l=r?ln(en(h),r(h)):en(h),d=l.length,c=0;d>c;)a=l[c++],Zi&&!Ji(s,h,a)||(i[a]=h[a]);return i}:an,cn=dn;_i({target:"Object",stat:!0,forced:Object.assign!==cn},{assign:cn});var un=X.Object.assign,fn=g([].slice),pn=g,vn=xt,gn=Y,yn=Wt,mn=fn,bn=r,wn=n.Function,kn=pn([].concat),_n=pn([].join),xn={},En=function(t,e,i){if(!yn(xn,e)){for(var n=[],o=0;o<e;o++)n[o]="a["+o+"]";xn[e]=wn("C,a","return new C("+_n(n,",")+")")}return xn[e](t,i)},On=bn?wn.bind:function(t){var e=vn(this),i=e.prototype,n=mn(arguments,1),o=function(){var i=kn(n,mn(arguments));return this instanceof o?En(e,i.length,i):e.apply(t,i)};return gn(i)&&(o.prototype=i),o},Cn=On;_i({target:"Function",proto:!0,forced:Function.bind!==Cn},{bind:Cn});var Sn=X,Tn=function(t){return Sn[t+"Prototype"]},Mn=Tn("Function").bind,Pn=J,Dn=Mn,In=Function.prototype,Bn=function(t){var e=t.bind;return t===In||Pn(In,t)&&e===In.bind?Dn:e},zn=Bn;function Nn(t,e,i,n){t.beginPath(),t.arc(e,i,n,0,2*Math.PI,!1),t.closePath()}function Fn(t,e,i,n,o,r){var s=Math.PI/180;n-2*r<0&&(r=n/2),o-2*r<0&&(r=o/2),t.beginPath(),t.moveTo(e+r,i),t.lineTo(e+n-r,i),t.arc(e+n-r,i+r,r,270*s,360*s,!1),t.lineTo(e+n,i+o-r),t.arc(e+n-r,i+o-r,r,0,90*s,!1),t.lineTo(e+r,i+o),t.arc(e+r,i+o-r,r,90*s,180*s,!1),t.lineTo(e,i+r),t.arc(e+r,i+r,r,180*s,270*s,!1),t.closePath()}function An(t,e,i,n,o){var r=.5522848,s=n/2*r,a=o/2*r,h=e+n,l=i+o,d=e+n/2,c=i+o/2;t.beginPath(),t.moveTo(e,c),t.bezierCurveTo(e,c-a,d-s,i,d,i),t.bezierCurveTo(d+s,i,h,c-a,h,c),t.bezierCurveTo(h,c+a,d+s,l,d,l),t.bezierCurveTo(d-s,l,e,c+a,e,c),t.closePath()}function jn(t,e,i,n,o){var r=o*(1/3),s=.5522848,a=n/2*s,h=r/2*s,l=e+n,d=i+r,c=e+n/2,u=i+r/2,f=i+(o-r/2),p=i+o;t.beginPath(),t.moveTo(l,u),t.bezierCurveTo(l,u+h,c+a,d,c,d),t.bezierCurveTo(c-a,d,e,u+h,e,u),t.bezierCurveTo(e,u-h,c-a,i,c,i),t.bezierCurveTo(c+a,i,l,u-h,l,u),t.lineTo(l,f),t.bezierCurveTo(l,f+h,c+a,p,c,p),t.bezierCurveTo(c-a,p,e,f+h,e,f),t.lineTo(e,u)}function Rn(t,e,i,n,o,r){t.beginPath(),t.moveTo(e,i);for(var s=r.length,a=n-e,h=o-i,l=h/a,d=Math.sqrt(a*a+h*h),c=0,u=!0,f=0,p=+r[0];d>=.1;)(p=+r[c++%s])>d&&(p=d),f=Math.sqrt(p*p/(1+l*l)),e+=f=a<0?-f:f,i+=l*f,!0===u?t.lineTo(e,i):t.moveTo(e,i),d-=p,u=!u}var Ln={circle:Nn,dashedLine:Rn,database:jn,diamond:function(t,e,i,n){t.beginPath(),t.lineTo(e,i+n),t.lineTo(e+n,i),t.lineTo(e,i-n),t.lineTo(e-n,i),t.closePath()},ellipse:An,ellipse_vis:An,hexagon:function(t,e,i,n){t.beginPath();var o=2*Math.PI/6;t.moveTo(e+n,i);for(var r=1;r<6;r++)t.lineTo(e+n*Math.cos(o*r),i+n*Math.sin(o*r));t.closePath()},roundRect:Fn,square:function(t,e,i,n){t.beginPath(),t.rect(e-n,i-n,2*n,2*n),t.closePath()},star:function(t,e,i,n){t.beginPath(),i+=.1*(n*=.82);for(var o=0;o<10;o++){var r=o%2==0?1.3*n:.5*n;t.lineTo(e+r*Math.sin(2*o*Math.PI/10),i-r*Math.cos(2*o*Math.PI/10))}t.closePath()},triangle:function(t,e,i,n){t.beginPath(),i+=.275*(n*=1.15);var o=2*n,r=o/2,s=Math.sqrt(3)/6*o,a=Math.sqrt(o*o-r*r);t.moveTo(e,i-(a-s)),t.lineTo(e+r,i+s),t.lineTo(e-r,i+s),t.lineTo(e,i-(a-s)),t.closePath()},triangleDown:function(t,e,i,n){t.beginPath(),i-=.275*(n*=1.15);var o=2*n,r=o/2,s=Math.sqrt(3)/6*o,a=Math.sqrt(o*o-r*r);t.moveTo(e,i+(a-s)),t.lineTo(e+r,i-s),t.lineTo(e-r,i-s),t.lineTo(e,i+(a-s)),t.closePath()}};var Hn={exports:{}};!function(t){function e(t){if(t)return function(t){for(var i in e.prototype)t[i]=e.prototype[i];return t}(t)}t.exports=e,e.prototype.on=e.prototype.addEventListener=function(t,e){return this._callbacks=this._callbacks||{},(this._callbacks["$"+t]=this._callbacks["$"+t]||[]).push(e),this},e.prototype.once=function(t,e){function i(){this.off(t,i),e.apply(this,arguments)}return i.fn=e,this.on(t,i),this},e.prototype.off=e.prototype.removeListener=e.prototype.removeAllListeners=e.prototype.removeEventListener=function(t,e){if(this._callbacks=this._callbacks||{},0==arguments.length)return this._callbacks={},this;var i,n=this._callbacks["$"+t];if(!n)return this;if(1==arguments.length)return delete this._callbacks["$"+t],this;for(var o=0;o<n.length;o++)if((i=n[o])===e||i.fn===e){n.splice(o,1);break}return 0===n.length&&delete this._callbacks["$"+t],this},e.prototype.emit=function(t){this._callbacks=this._callbacks||{};for(var e=new Array(arguments.length-1),i=this._callbacks["$"+t],n=1;n<arguments.length;n++)e[n-1]=arguments[n];if(i){n=0;for(var o=(i=i.slice(0)).length;n<o;++n)i[n].apply(this,e)}return this},e.prototype.listeners=function(t){return this._callbacks=this._callbacks||{},this._callbacks["$"+t]||[]},e.prototype.hasListeners=function(t){return!!this.listeners(t).length}}(Hn);var Wn=Hn.exports,qn={};qn[oe("toStringTag")]="z";var Vn="[object z]"===String(qn),Un=n,Yn=Vn,Xn=y,Gn=B,Kn=oe("toStringTag"),$n=Un.Object,Zn="Arguments"==Gn(function(){return arguments}()),Qn=Yn?Gn:function(t){var e,i,n;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(i=function(t,e){try{return t[e]}catch(t){}}(e=$n(t),Kn))?i:Zn?Gn(e):"Object"==(n=Gn(e))&&Xn(e.callee)?"Arguments":n},Jn=Qn,to=n.String,eo=function(t){if("Symbol"===Jn(t))throw TypeError("Cannot convert a Symbol value to a string");return to(t)},io=g,no=Oi,oo=eo,ro=H,so=io("".charAt),ao=io("".charCodeAt),ho=io("".slice),lo=function(t){return function(e,i){var n,o,r=oo(ro(e)),s=no(i),a=r.length;return s<0||s>=a?t?"":void 0:(n=ao(r,s))<55296||n>56319||s+1===a||(o=ao(r,s+1))<56320||o>57343?t?so(r,s):n:t?ho(r,s,s+2):o-56320+(n-55296<<10)+65536}},co={codeAt:lo(!1),charAt:lo(!0)},uo=y,fo=Nt,po=g(Function.toString);uo(fo.inspectSource)||(fo.inspectSource=function(t){return po(t)});var vo,go,yo,mo=fo.inspectSource,bo=y,wo=mo,ko=n.WeakMap,_o=bo(ko)&&/native code/.test(wo(ko)),xo=Pt.exports,Eo=Xt,Oo=xo("keys"),Co=function(t){return Oo[t]||(Oo[t]=Eo(t))},So=_o,To=n,Mo=g,Po=Y,Do=di,Io=Wt,Bo=Nt,zo=Co,No=Ri,Fo="Object already initialized",Ao=To.TypeError,jo=To.WeakMap;if(So||Bo.state){var Ro=Bo.state||(Bo.state=new jo),Lo=Mo(Ro.get),Ho=Mo(Ro.has),Wo=Mo(Ro.set);vo=function(t,e){if(Ho(Ro,t))throw new Ao(Fo);return e.facade=t,Wo(Ro,t,e),e},go=function(t){return Lo(Ro,t)||{}},yo=function(t){return Ho(Ro,t)}}else{var qo=zo("state");No[qo]=!0,vo=function(t,e){if(Io(t,qo))throw new Ao(Fo);return e.facade=t,Do(t,qo,e),e},go=function(t){return Io(t,qo)?t[qo]:{}},yo=function(t){return Io(t,qo)}}var Vo={set:vo,get:go,has:yo,enforce:function(t){return yo(t)?go(t):vo(t,{})},getterFor:function(t){return function(e){var i;if(!Po(e)||(i=go(e)).type!==t)throw Ao("Incompatible receiver, "+t+" required");return i}}},Uo=b,Yo=Wt,Xo=Function.prototype,Go=Uo&&Object.getOwnPropertyDescriptor,Ko=Yo(Xo,"name"),$o={EXISTS:Ko,PROPER:Ko&&"something"===function(){}.name,CONFIGURABLE:Ko&&(!Uo||Uo&&Go(Xo,"name").configurable)},Zo={},Qo=b,Jo=Ue,tr=Ve,er=$e,ir=V,nr=Ki;Zo.f=Qo&&!Jo?Object.defineProperties:function(t,e){er(t);for(var i,n=ir(e),o=nr(e),r=o.length,s=0;r>s;)tr.f(t,i=o[s++],n[i]);return t};var or,rr=Q("document","documentElement"),sr=$e,ar=Zo,hr=Yi,lr=Ri,dr=rr,cr=be,ur=Co("IE_PROTO"),fr=function(){},pr=function(t){return"<script>"+t+"</"+"script>"},vr=function(t){t.write(pr("")),t.close();var e=t.parentWindow.Object;return t=null,e},gr=function(){try{or=new ActiveXObject("htmlfile")}catch(t){}var t,e;gr="undefined"!=typeof document?document.domain&&or?vr(or):((e=cr("iframe")).style.display="none",dr.appendChild(e),e.src=String("javascript:"),(t=e.contentWindow.document).open(),t.write(pr("document.F=Object")),t.close(),t.F):vr(or);for(var i=hr.length;i--;)delete gr.prototype[hr[i]];return gr()};lr[ur]=!0;var yr,mr,br,wr=Object.create||function(t,e){var i;return null!==t?(fr.prototype=sr(t),i=new fr,fr.prototype=null,i[ur]=t):i=gr(),void 0===e?i:ar.f(i,e)},kr=!o((function(){function t(){}return t.prototype.constructor=null,Object.getPrototypeOf(new t)!==t.prototype})),_r=n,xr=Wt,Er=y,Or=Rt,Cr=kr,Sr=Co("IE_PROTO"),Tr=_r.Object,Mr=Tr.prototype,Pr=Cr?Tr.getPrototypeOf:function(t){var e=Or(t);if(xr(e,Sr))return e[Sr];var i=e.constructor;return Er(i)&&e instanceof i?i.prototype:e instanceof Tr?Mr:null},Dr=di,Ir=function(t,e,i,n){n&&n.enumerable?t[e]=i:Dr(t,e,i)},Br=o,zr=y,Nr=wr,Fr=Pr,Ar=Ir,jr=oe("iterator"),Rr=!1;[].keys&&("next"in(br=[].keys())?(mr=Fr(Fr(br)))!==Object.prototype&&(yr=mr):Rr=!0);var Lr=null==yr||Br((function(){var t={};return yr[jr].call(t)!==t}));zr((yr=Lr?{}:Nr(yr))[jr])||Ar(yr,jr,(function(){return this}));var Hr={IteratorPrototype:yr,BUGGY_SAFARI_ITERATORS:Rr},Wr=Qn,qr=Vn?{}.toString:function(){return"[object "+Wr(this)+"]"},Vr=Vn,Ur=Ve.f,Yr=di,Xr=Wt,Gr=qr,Kr=oe("toStringTag"),$r=function(t,e,i,n){if(t){var o=i?t:t.prototype;Xr(o,Kr)||Ur(o,Kr,{configurable:!0,value:e}),n&&!Vr&&Yr(o,"toString",Gr)}},Zr={},Qr=Hr.IteratorPrototype,Jr=wr,ts=M,es=$r,is=Zr,ns=function(){return this},os=n,rs=y,ss=os.String,as=os.TypeError,hs=g,ls=$e,ds=function(t){if("object"==typeof t||rs(t))return t;throw as("Can't set "+ss(t)+" as a prototype")},cs=Object.setPrototypeOf||("__proto__"in{}?function(){var t,e=!1,i={};try{(t=hs(Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set))(i,[]),e=i instanceof Array}catch(t){}return function(i,n){return ls(i),ds(n),e?t(i,n):i.__proto__=n,i}}():void 0),us=_i,fs=_,ps=function(t,e,i,n){var o=e+" Iterator";return t.prototype=Jr(Qr,{next:ts(+!n,i)}),es(t,o,!1,!0),is[o]=ns,t},vs=Pr,gs=$r,ys=Ir,ms=Zr,bs=$o.PROPER,ws=Hr.BUGGY_SAFARI_ITERATORS,ks=oe("iterator"),_s="keys",xs="values",Es="entries",Os=function(){return this},Cs=function(t,e,i,n,o,r,s){ps(i,e,n);var a,h,l,d=function(t){if(t===o&&v)return v;if(!ws&&t in f)return f[t];switch(t){case _s:case xs:case Es:return function(){return new i(this,t)}}return function(){return new i(this)}},c=e+" Iterator",u=!1,f=t.prototype,p=f[ks]||f["@@iterator"]||o&&f[o],v=!ws&&p||d(o),g="Array"==e&&f.entries||p;if(g&&(a=vs(g.call(new t)))!==Object.prototype&&a.next&&(gs(a,c,!0,!0),ms[c]=Os),bs&&o==xs&&p&&p.name!==xs&&(u=!0,v=function(){return fs(p,this)}),o)if(h={values:d(xs),keys:r?v:d(_s),entries:d(Es)},s)for(l in h)(ws||u||!(l in f))&&ys(f,l,h[l]);else us({target:e,proto:!0,forced:ws||u},h);return s&&f[ks]!==v&&ys(f,ks,v,{name:o}),ms[e]=v,h},Ss=co.charAt,Ts=eo,Ms=Vo,Ps=Cs,Ds="String Iterator",Is=Ms.set,Bs=Ms.getterFor(Ds);Ps(String,"String",(function(t){Is(this,{type:Ds,string:Ts(t),index:0})}),(function(){var t,e=Bs(this),i=e.string,n=e.index;return n>=i.length?{value:void 0,done:!0}:(t=Ss(i,n),e.index+=t.length,{value:t,done:!1})}));var zs=_,Ns=$e,Fs=Ot,As=function(t,e,i){var n,o;Ns(t);try{if(!(n=Fs(t,"return"))){if("throw"===e)throw i;return i}n=zs(n,t)}catch(t){o=!0,n=t}if("throw"===e)throw i;if(o)throw n;return Ns(n),i},js=$e,Rs=As,Ls=Zr,Hs=oe("iterator"),Ws=Array.prototype,qs=function(t){return void 0!==t&&(Ls.Array===t||Ws[Hs]===t)},Vs=g,Us=o,Ys=y,Xs=Qn,Gs=mo,Ks=function(){},$s=[],Zs=Q("Reflect","construct"),Qs=/^\s*(?:class|function)\b/,Js=Vs(Qs.exec),ta=!Qs.exec(Ks),ea=function(t){if(!Ys(t))return!1;try{return Zs(Ks,$s,t),!0}catch(t){return!1}},ia=function(t){if(!Ys(t))return!1;switch(Xs(t)){case"AsyncFunction":case"GeneratorFunction":case"AsyncGeneratorFunction":return!1}try{return ta||!!Js(Qs,Gs(t))}catch(t){return!0}};ia.sham=!0;var na=!Zs||Us((function(){var t;return ea(ea.call)||!ea(Object)||!ea((function(){t=!0}))||t}))?ia:ea,oa=ve,ra=Ve,sa=M,aa=function(t,e,i){var n=oa(e);n in t?ra.f(t,n,sa(0,i)):t[n]=i},ha=Qn,la=Ot,da=Zr,ca=oe("iterator"),ua=function(t){if(null!=t)return la(t,ca)||la(t,"@@iterator")||da[ha(t)]},fa=_,pa=xt,va=$e,ga=bt,ya=ua,ma=n.TypeError,ba=function(t,e){var i=arguments.length<2?ya(t):e;if(pa(i))return va(fa(i,t));throw ma(ga(t)+" is not iterable")},wa=qe,ka=_,_a=Rt,xa=function(t,e,i,n){try{return n?e(js(i)[0],i[1]):e(i)}catch(e){Rs(t,"throw",e)}},Ea=qs,Oa=na,Ca=Bi,Sa=aa,Ta=ba,Ma=ua,Pa=n.Array,Da=oe("iterator"),Ia=!1;try{var Ba=0,za={next:function(){return{done:!!Ba++}},return:function(){Ia=!0}};za[Da]=function(){return this},Array.from(za,(function(){throw 2}))}catch(t){}var Na=function(t){var e=_a(t),i=Oa(this),n=arguments.length,o=n>1?arguments[1]:void 0,r=void 0!==o;r&&(o=wa(o,n>2?arguments[2]:void 0));var s,a,h,l,d,c,u=Ma(e),f=0;if(!u||this==Pa&&Ea(u))for(s=Ca(e),a=i?new this(s):Pa(s);s>f;f++)c=r?o(e[f],f):e[f],Sa(a,f,c);else for(d=(l=Ta(e,u)).next,a=i?new this:[];!(h=ka(d,l)).done;f++)c=r?xa(l,o,[h.value,f],!0):h.value,Sa(a,f,c);return a.length=f,a},Fa=function(t,e){if(!e&&!Ia)return!1;var i=!1;try{var n={};n[Da]=function(){return{next:function(){return{done:i=!0}}}},t(n)}catch(t){}return i};_i({target:"Array",stat:!0,forced:!Fa((function(t){Array.from(t)}))},{from:Na});var Aa=X.Array.from,ja=Aa,Ra=V,La=Zr,Ha=Vo;Ve.f;var Wa=Cs,qa="Array Iterator",Va=Ha.set,Ua=Ha.getterFor(qa);Wa(Array,"Array",(function(t,e){Va(this,{type:qa,target:Ra(t),index:0,kind:e})}),(function(){var t=Ua(this),e=t.target,i=t.kind,n=t.index++;return!e||n>=e.length?(t.target=void 0,{value:void 0,done:!0}):"keys"==i?{value:n,done:!1}:"values"==i?{value:e[n],done:!1}:{value:[n,e[n]],done:!1}}),"values"),La.Arguments=La.Array;var Ya=ua,Xa={CSSRuleList:0,CSSStyleDeclaration:0,CSSValueList:0,ClientRectList:0,DOMRectList:0,DOMStringList:0,DOMTokenList:1,DataTransferItemList:0,FileList:0,HTMLAllCollection:0,HTMLCollection:0,HTMLFormElement:0,HTMLSelectElement:0,MediaList:0,MimeTypeArray:0,NamedNodeMap:0,NodeList:1,PaintRequestList:0,Plugin:0,PluginArray:0,SVGLengthList:0,SVGNumberList:0,SVGPathSegList:0,SVGPointList:0,SVGStringList:0,SVGTransformList:0,SourceBufferList:0,StyleSheetList:0,TextTrackCueList:0,TextTrackList:0,TouchList:0},Ga=n,Ka=Qn,$a=di,Za=Zr,Qa=oe("toStringTag");for(var Ja in Xa){var th=Ga[Ja],eh=th&&th.prototype;eh&&Ka(eh)!==Qa&&$a(eh,Qa,Ja),Za[Ja]=Za.Array}var ih=Ya,nh=B,oh=Array.isArray||function(t){return"Array"==nh(t)},rh={},sh=Ui,ah=Yi.concat("length","prototype");rh.f=Object.getOwnPropertyNames||function(t){return sh(t,ah)};var hh={},lh=Mi,dh=Bi,ch=aa,uh=n.Array,fh=Math.max,ph=function(t,e,i){for(var n=dh(t),o=lh(e,n),r=lh(void 0===i?n:i,n),s=uh(fh(r-o,0)),a=0;o<r;o++,a++)ch(s,a,t[o]);return s.length=a,s},vh=B,gh=V,yh=rh.f,mh=ph,bh="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[];hh.f=function(t){return bh&&"Window"==vh(t)?function(t){try{return yh(t)}catch(t){return mh(bh)}}(t):yh(gh(t))};var wh={},kh=oe;wh.f=kh;var _h=X,xh=Wt,Eh=wh,Oh=Ve.f,Ch=function(t){var e=_h.Symbol||(_h.Symbol={});xh(e,t)||Oh(e,t,{value:Eh.f(t)})},Sh=n,Th=oh,Mh=na,Ph=Y,Dh=oe("species"),Ih=Sh.Array,Bh=function(t){var e;return Th(t)&&(e=t.constructor,(Mh(e)&&(e===Ih||Th(e.prototype))||Ph(e)&&null===(e=e[Dh]))&&(e=void 0)),void 0===e?Ih:e},zh=function(t,e){return new(Bh(t))(0===e?0:e)},Nh=qe,Fh=R,Ah=Rt,jh=Bi,Rh=zh,Lh=g([].push),Hh=function(t){var e=1==t,i=2==t,n=3==t,o=4==t,r=6==t,s=7==t,a=5==t||r;return function(h,l,d,c){for(var u,f,p=Ah(h),v=Fh(p),g=Nh(l,d),y=jh(v),m=0,b=c||Rh,w=e?b(h,y):i||s?b(h,0):void 0;y>m;m++)if((a||m in v)&&(f=g(u=v[m],m,p),t))if(e)w[m]=f;else if(f)switch(t){case 3:return!0;case 5:return u;case 6:return m;case 2:Lh(w,u)}else switch(t){case 4:return!1;case 7:Lh(w,u)}return r?-1:n||o?o:w}},Wh={forEach:Hh(0),map:Hh(1),filter:Hh(2),some:Hh(3),every:Hh(4),find:Hh(5),findIndex:Hh(6),filterReject:Hh(7)},qh=_i,Vh=n,Uh=Q,Yh=d,Xh=_,Gh=g,Kh=b,$h=dt,Zh=o,Qh=Wt,Jh=oh,tl=y,el=Y,il=J,nl=yt,ol=$e,rl=Rt,sl=V,al=ve,hl=eo,ll=M,dl=wr,cl=Ki,ul=rh,fl=hh,pl=$i,vl=m,gl=Ve,yl=Zo,ml=x,bl=fn,wl=Ir,kl=Pt.exports,_l=Ri,xl=Xt,El=oe,Ol=wh,Cl=Ch,Sl=$r,Tl=Vo,Ml=Wh.forEach,Pl=Co("hidden"),Dl="Symbol",Il=El("toPrimitive"),Bl=Tl.set,zl=Tl.getterFor(Dl),Nl=Object.prototype,Fl=Vh.Symbol,Al=Fl&&Fl.prototype,jl=Vh.TypeError,Rl=Vh.QObject,Ll=Uh("JSON","stringify"),Hl=vl.f,Wl=gl.f,ql=fl.f,Vl=ml.f,Ul=Gh([].push),Yl=kl("symbols"),Xl=kl("op-symbols"),Gl=kl("string-to-symbol-registry"),Kl=kl("symbol-to-string-registry"),$l=kl("wks"),Zl=!Rl||!Rl.prototype||!Rl.prototype.findChild,Ql=Kh&&Zh((function(){return 7!=dl(Wl({},"a",{get:function(){return Wl(this,"a",{value:7}).a}})).a}))?function(t,e,i){var n=Hl(Nl,e);n&&delete Nl[e],Wl(t,e,i),n&&t!==Nl&&Wl(Nl,e,n)}:Wl,Jl=function(t,e){var i=Yl[t]=dl(Al);return Bl(i,{type:Dl,tag:t,description:e}),Kh||(i.description=e),i},td=function(t,e,i){t===Nl&&td(Xl,e,i),ol(t);var n=al(e);return ol(i),Qh(Yl,n)?(i.enumerable?(Qh(t,Pl)&&t[Pl][n]&&(t[Pl][n]=!1),i=dl(i,{enumerable:ll(0,!1)})):(Qh(t,Pl)||Wl(t,Pl,ll(1,{})),t[Pl][n]=!0),Ql(t,n,i)):Wl(t,n,i)},ed=function(t,e){ol(t);var i=sl(e),n=cl(i).concat(rd(i));return Ml(n,(function(e){Kh&&!Xh(id,i,e)||td(t,e,i[e])})),t},id=function(t){var e=al(t),i=Xh(Vl,this,e);return!(this===Nl&&Qh(Yl,e)&&!Qh(Xl,e))&&(!(i||!Qh(this,e)||!Qh(Yl,e)||Qh(this,Pl)&&this[Pl][e])||i)},nd=function(t,e){var i=sl(t),n=al(e);if(i!==Nl||!Qh(Yl,n)||Qh(Xl,n)){var o=Hl(i,n);return!o||!Qh(Yl,n)||Qh(i,Pl)&&i[Pl][n]||(o.enumerable=!0),o}},od=function(t){var e=ql(sl(t)),i=[];return Ml(e,(function(t){Qh(Yl,t)||Qh(_l,t)||Ul(i,t)})),i},rd=function(t){var e=t===Nl,i=ql(e?Xl:sl(t)),n=[];return Ml(i,(function(t){!Qh(Yl,t)||e&&!Qh(Nl,t)||Ul(n,Yl[t])})),n};if($h||(Fl=function(){if(il(Al,this))throw jl("Symbol is not a constructor");var t=arguments.length&&void 0!==arguments[0]?hl(arguments[0]):void 0,e=xl(t),i=function(t){this===Nl&&Xh(i,Xl,t),Qh(this,Pl)&&Qh(this[Pl],e)&&(this[Pl][e]=!1),Ql(this,e,ll(1,t))};return Kh&&Zl&&Ql(Nl,e,{configurable:!0,set:i}),Jl(e,t)},wl(Al=Fl.prototype,"toString",(function(){return zl(this).tag})),wl(Fl,"withoutSetter",(function(t){return Jl(xl(t),t)})),ml.f=id,gl.f=td,yl.f=ed,vl.f=nd,ul.f=fl.f=od,pl.f=rd,Ol.f=function(t){return Jl(El(t),t)},Kh&&Wl(Al,"description",{configurable:!0,get:function(){return zl(this).description}})),qh({global:!0,wrap:!0,forced:!$h,sham:!$h},{Symbol:Fl}),Ml(cl($l),(function(t){Cl(t)})),qh({target:Dl,stat:!0,forced:!$h},{for:function(t){var e=hl(t);if(Qh(Gl,e))return Gl[e];var i=Fl(e);return Gl[e]=i,Kl[i]=e,i},keyFor:function(t){if(!nl(t))throw jl(t+" is not a symbol");if(Qh(Kl,t))return Kl[t]},useSetter:function(){Zl=!0},useSimple:function(){Zl=!1}}),qh({target:"Object",stat:!0,forced:!$h,sham:!Kh},{create:function(t,e){return void 0===e?dl(t):ed(dl(t),e)},defineProperty:td,defineProperties:ed,getOwnPropertyDescriptor:nd}),qh({target:"Object",stat:!0,forced:!$h},{getOwnPropertyNames:od,getOwnPropertySymbols:rd}),qh({target:"Object",stat:!0,forced:Zh((function(){pl.f(1)}))},{getOwnPropertySymbols:function(t){return pl.f(rl(t))}}),Ll){var sd=!$h||Zh((function(){var t=Fl();return"[null]"!=Ll([t])||"{}"!=Ll({a:t})||"{}"!=Ll(Object(t))}));qh({target:"JSON",stat:!0,forced:sd},{stringify:function(t,e,i){var n=bl(arguments),o=e;if((el(e)||void 0!==t)&&!nl(t))return Jh(e)||(e=function(t,e){if(tl(o)&&(e=Xh(o,this,t,e)),!nl(e))return e}),n[1]=e,Yh(Ll,null,n)}})}if(!Al[Il]){var ad=Al.valueOf;wl(Al,Il,(function(t){return Xh(ad,this)}))}Sl(Fl,Dl),_l[Pl]=!0;var hd=X.Object.getOwnPropertySymbols,ld={exports:{}},dd=_i,cd=o,ud=V,fd=m.f,pd=b,vd=cd((function(){fd(1)}));dd({target:"Object",stat:!0,forced:!pd||vd,sham:!pd},{getOwnPropertyDescriptor:function(t,e){return fd(ud(t),e)}});var gd=X.Object,yd=ld.exports=function(t,e){return gd.getOwnPropertyDescriptor(t,e)};gd.getOwnPropertyDescriptor.sham&&(yd.sham=!0);var md=ld.exports,bd=md,wd=Q,kd=rh,_d=$i,xd=$e,Ed=g([].concat),Od=wd("Reflect","ownKeys")||function(t){var e=kd.f(xd(t)),i=_d.f;return i?Ed(e,i(t)):e},Cd=Od,Sd=V,Td=m,Md=aa;_i({target:"Object",stat:!0,sham:!b},{getOwnPropertyDescriptors:function(t){for(var e,i,n=Sd(t),o=Td.f,r=Cd(n),s={},a=0;r.length>a;)void 0!==(i=o(n,e=r[a++]))&&Md(s,e,i);return s}});var Pd=X.Object.getOwnPropertyDescriptors,Dd={exports:{}},Id=_i,Bd=b,zd=Zo.f;Id({target:"Object",stat:!0,forced:Object.defineProperties!==zd,sham:!Bd},{defineProperties:zd});var Nd=X.Object,Fd=Dd.exports=function(t,e){return Nd.defineProperties(t,e)};Nd.defineProperties.sham&&(Fd.sham=!0);var Ad=Dd.exports,jd={exports:{}},Rd=_i,Ld=b,Hd=Ve.f;Rd({target:"Object",stat:!0,forced:Object.defineProperty!==Hd,sham:!Ld},{defineProperty:Hd});var Wd=X.Object,qd=jd.exports=function(t,e,i){return Wd.defineProperty(t,e,i)};Wd.defineProperty.sham&&(qd.sham=!0);var Vd=jd.exports,Ud=Vd;function Yd(t,e){if(!(t instanceof e))throw new TypeError("Cannot call a class as a function")}var Xd=Vd;function Gd(t,e){for(var i=0;i<e.length;i++){var n=e[i];n.enumerable=n.enumerable||!1,n.configurable=!0,"value"in n&&(n.writable=!0),Xd(t,n.key,n)}}function Kd(t,e,i){return e&&Gd(t.prototype,e),i&&Gd(t,i),Xd(t,"prototype",{writable:!1}),t}function $d(t,e,i){return e in t?Xd(t,e,{value:i,enumerable:!0,configurable:!0,writable:!0}):t[e]=i,t}_i({target:"Array",stat:!0},{isArray:oh});var Zd=X.Array.isArray,Qd=Zd;var Jd=o,tc=at,ec=oe("species"),ic=function(t){return tc>=51||!Jd((function(){var e=[];return(e.constructor={})[ec]=function(){return{foo:1}},1!==e[t](Boolean).foo}))},nc=_i,oc=n,rc=o,sc=oh,ac=Y,hc=Rt,lc=Bi,dc=aa,cc=zh,uc=ic,fc=at,pc=oe("isConcatSpreadable"),vc=9007199254740991,gc="Maximum allowed index exceeded",yc=oc.TypeError,mc=fc>=51||!rc((function(){var t=[];return t[pc]=!1,t.concat()[0]!==t})),bc=uc("concat"),wc=function(t){if(!ac(t))return!1;var e=t[pc];return void 0!==e?!!e:sc(t)};nc({target:"Array",proto:!0,forced:!mc||!bc},{concat:function(t){var e,i,n,o,r,s=hc(this),a=cc(s,0),h=0;for(e=-1,n=arguments.length;e<n;e++)if(wc(r=-1===e?s:arguments[e])){if(h+(o=lc(r))>vc)throw yc(gc);for(i=0;i<o;i++,h++)i in r&&dc(a,h,r[i])}else{if(h>=vc)throw yc(gc);dc(a,h++,r)}return a.length=h,a}}),Ch("asyncIterator"),Ch("hasInstance"),Ch("isConcatSpreadable"),Ch("iterator"),Ch("match"),Ch("matchAll"),Ch("replace"),Ch("search"),Ch("species"),Ch("split"),Ch("toPrimitive"),Ch("toStringTag"),Ch("unscopables"),$r(n.JSON,"JSON",!0);var kc=X.Symbol,_c=kc;Ch("asyncDispose"),Ch("dispose"),Ch("matcher"),Ch("metadata"),Ch("observable"),Ch("patternMatch"),Ch("replaceAll");var xc=_c;var Ec=_i,Oc=n,Cc=oh,Sc=na,Tc=Y,Mc=Mi,Pc=Bi,Dc=V,Ic=aa,Bc=oe,zc=fn,Nc=ic("slice"),Fc=Bc("species"),Ac=Oc.Array,jc=Math.max;Ec({target:"Array",proto:!0,forced:!Nc},{slice:function(t,e){var i,n,o,r=Dc(this),s=Pc(r),a=Mc(t,s),h=Mc(void 0===e?s:e,s);if(Cc(r)&&(i=r.constructor,(Sc(i)&&(i===Ac||Cc(i.prototype))||Tc(i)&&null===(i=i[Fc]))&&(i=void 0),i===Ac||void 0===i))return zc(r,a,h);for(n=new(void 0===i?Ac:i)(jc(h-a,0)),o=0;a<h;a++,o++)a in r&&Ic(n,o,r[a]);return n.length=o,n}});var Rc=Tn("Array").slice,Lc=J,Hc=Rc,Wc=Array.prototype,qc=function(t){var e=t.slice;return t===Wc||Lc(Wc,t)&&e===Wc.slice?Hc:e},Vc=qc,Uc=Vc,Yc=Aa;function Xc(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}function Gc(t,e){var i;if(t){if("string"==typeof t)return Xc(t,e);var n=Uc(i=Object.prototype.toString.call(t)).call(i,8,-1);return"Object"===n&&t.constructor&&(n=t.constructor.name),"Map"===n||"Set"===n?Yc(t):"Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?Xc(t,e):void 0}}function Kc(t,e){return function(t){if(Qd(t))return t}(t)||function(t,e){var i=null==t?null:void 0!==xc&&ih(t)||t["@@iterator"];if(null!=i){var n,o,r=[],s=!0,a=!1;try{for(i=i.call(t);!(s=(n=i.next()).done)&&(r.push(n.value),!e||r.length!==e);s=!0);}catch(t){a=!0,o=t}finally{try{s||null==i.return||i.return()}finally{if(a)throw o}}return r}}(t,e)||Gc(t,e)||function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}var $c=wh.f("iterator"),Zc=$c;function Qc(t){return Qc="function"==typeof xc&&"symbol"==typeof Zc?function(t){return typeof t}:function(t){return t&&"function"==typeof xc&&t.constructor===xc&&t!==xc.prototype?"symbol":typeof t},Qc(t)}function Jc(t){return function(t){if(Qd(t))return Xc(t)}(t)||function(t){if(void 0!==xc&&null!=ih(t)||null!=t["@@iterator"])return Yc(t)}(t)||Gc(t)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}var tu=kc,eu=Tn("Array").concat,iu=J,nu=eu,ou=Array.prototype,ru=function(t){var e=t.concat;return t===ou||iu(ou,t)&&e===ou.concat?nu:e},su=ru,au=Vc;_i({target:"Reflect",stat:!0},{ownKeys:Od});var hu=X.Reflect.ownKeys,lu=Zd,du=Wh.map;_i({target:"Array",proto:!0,forced:!ic("map")},{map:function(t){return du(this,t,arguments.length>1?arguments[1]:void 0)}});var cu=Tn("Array").map,uu=J,fu=cu,pu=Array.prototype,vu=function(t){var e=t.map;return t===pu||uu(pu,t)&&e===pu.map?fu:e},gu=vu,yu=Rt,mu=Ki;_i({target:"Object",stat:!0,forced:o((function(){mu(1)}))},{keys:function(t){return mu(yu(t))}});var bu=X.Object.keys,wu=_i,ku=g,_u=n.Date,xu=ku(_u.prototype.getTime);wu({target:"Date",stat:!0},{now:function(){return xu(new _u)}});var Eu=X.Date.now,Ou=o,Cu=function(t,e){var i=[][t];return!!i&&Ou((function(){i.call(null,e||function(){return 1},1)}))},Su=Wh.forEach,Tu=Cu("forEach")?[].forEach:function(t){return Su(this,t,arguments.length>1?arguments[1]:void 0)};_i({target:"Array",proto:!0,forced:[].forEach!=Tu},{forEach:Tu});var Mu=Tn("Array").forEach,Pu=Qn,Du=Wt,Iu=J,Bu=Mu,zu=Array.prototype,Nu={DOMTokenList:!0,NodeList:!0},Fu=function(t){var e=t.forEach;return t===zu||Iu(zu,t)&&e===zu.forEach||Du(Nu,Pu(t))?Bu:e},Au=_i,ju=oh,Ru=g([].reverse),Lu=[1,2];Au({target:"Array",proto:!0,forced:String(Lu)===String(Lu.reverse())},{reverse:function(){return ju(this)&&(this.length=this.length),Ru(this)}});var Hu=Tn("Array").reverse,Wu=J,qu=Hu,Vu=Array.prototype,Uu=function(t){var e=t.reverse;return t===Vu||Wu(Vu,t)&&e===Vu.reverse?qu:e},Yu=Uu,Xu=_i,Gu=n,Ku=Mi,$u=Oi,Zu=Bi,Qu=Rt,Ju=zh,tf=aa,ef=ic("splice"),nf=Gu.TypeError,of=Math.max,rf=Math.min,sf=9007199254740991,af="Maximum allowed length exceeded";Xu({target:"Array",proto:!0,forced:!ef},{splice:function(t,e){var i,n,o,r,s,a,h=Qu(this),l=Zu(h),d=Ku(t,l),c=arguments.length;if(0===c?i=n=0:1===c?(i=0,n=l-d):(i=c-2,n=rf(of($u(e),0),l-d)),l+i-n>sf)throw nf(af);for(o=Ju(h,n),r=0;r<n;r++)(s=d+r)in h&&tf(o,r,h[s]);if(o.length=n,i<n){for(r=d;r<l-n;r++)a=r+i,(s=r+n)in h?h[a]=h[s]:delete h[a];for(r=l;r>l-n+i;r--)delete h[r-1]}else if(i>n)for(r=l-n;r>d;r--)a=r+i-1,(s=r+n-1)in h?h[a]=h[s]:delete h[a];for(r=0;r<i;r++)h[r+d]=arguments[r+2];return h.length=l-n+i,o}});var hf=Tn("Array").splice,lf=J,df=hf,cf=Array.prototype,uf=function(t){var e=t.splice;return t===cf||lf(cf,t)&&e===cf.splice?df:e},ff=uf,pf=ji.includes;_i({target:"Array",proto:!0},{includes:function(t){return pf(this,t,arguments.length>1?arguments[1]:void 0)}});var vf=Tn("Array").includes,gf=Y,yf=B,mf=oe("match"),bf=function(t){var e;return gf(t)&&(void 0!==(e=t[mf])?!!e:"RegExp"==yf(t))},wf=n.TypeError,kf=oe("match"),_f=_i,xf=function(t){if(bf(t))throw wf("The method doesn't accept regular expressions");return t},Ef=H,Of=eo,Cf=function(t){var e=/./;try{"/./"[t](e)}catch(i){try{return e[kf]=!1,"/./"[t](e)}catch(t){}}return!1},Sf=g("".indexOf);_f({target:"String",proto:!0,forced:!Cf("includes")},{includes:function(t){return!!~Sf(Of(Ef(this)),Of(xf(t)),arguments.length>1?arguments[1]:void 0)}});var Tf=Tn("String").includes,Mf=J,Pf=vf,Df=Tf,If=Array.prototype,Bf=String.prototype,zf=function(t){var e=t.includes;return t===If||Mf(If,t)&&e===If.includes?Pf:"string"==typeof t||t===Bf||Mf(Bf,t)&&e===Bf.includes?Df:e},Nf=zf,Ff=Rt,Af=Pr,jf=kr;_i({target:"Object",stat:!0,forced:o((function(){Af(1)})),sham:!jf},{getPrototypeOf:function(t){return Af(Ff(t))}});var Rf=X.Object.getPrototypeOf,Lf=Rf,Hf=Wh.filter;_i({target:"Array",proto:!0,forced:!ic("filter")},{filter:function(t){return Hf(this,t,arguments.length>1?arguments[1]:void 0)}});var Wf=Tn("Array").filter,qf=J,Vf=Wf,Uf=Array.prototype,Yf=function(t){var e=t.filter;return t===Uf||qf(Uf,t)&&e===Uf.filter?Vf:e},Xf=Yf,Gf=b,Kf=g,$f=Ki,Zf=V,Qf=Kf(x.f),Jf=Kf([].push),tp=function(t){return function(e){for(var i,n=Zf(e),o=$f(n),r=o.length,s=0,a=[];r>s;)i=o[s++],Gf&&!Qf(n,i)||Jf(a,t?[i,n[i]]:n[i]);return a}},ep={entries:tp(!0),values:tp(!1)}.values;_i({target:"Object",stat:!0},{values:function(t){return ep(t)}});var ip=X.Object.values,np="\t\n\v\f\r  \u2028\u2029\ufeff",op=H,rp=eo,sp=g("".replace),ap="[\t\n\v\f\r  \u2028\u2029\ufeff]",hp=RegExp("^"+ap+ap+"*"),lp=RegExp(ap+ap+"*$"),dp=function(t){return function(e){var i=rp(op(e));return 1&t&&(i=sp(i,hp,"")),2&t&&(i=sp(i,lp,"")),i}},cp={start:dp(1),end:dp(2),trim:dp(3)},up=n,fp=o,pp=g,vp=eo,gp=cp.trim,yp=np,mp=up.parseInt,bp=up.Symbol,wp=bp&&bp.iterator,kp=/^[+-]?0x/i,_p=pp(kp.exec),xp=8!==mp(yp+"08")||22!==mp(yp+"0x16")||wp&&!fp((function(){mp(Object(wp))}))?function(t,e){var i=gp(vp(t));return mp(i,e>>>0||(_p(kp,i)?16:10))}:mp;_i({global:!0,forced:parseInt!=xp},{parseInt:xp});var Ep=X.parseInt,Op=_i,Cp=ji.indexOf,Sp=Cu,Tp=g([].indexOf),Mp=!!Tp&&1/Tp([1],1,-0)<0,Pp=Sp("indexOf");Op({target:"Array",proto:!0,forced:Mp||!Pp},{indexOf:function(t){var e=arguments.length>1?arguments[1]:void 0;return Mp?Tp(this,t,e)||0:Cp(this,t,e)}});var Dp=Tn("Array").indexOf,Ip=J,Bp=Dp,zp=Array.prototype,Np=function(t){var e=t.indexOf;return t===zp||Ip(zp,t)&&e===zp.indexOf?Bp:e},Fp=Np,Ap=$o.PROPER,jp=o,Rp=np,Lp=cp.trim;_i({target:"String",proto:!0,forced:function(t){return jp((function(){return!!Rp[t]()||""!==""[t]()||Ap&&Rp[t].name!==t}))}("trim")},{trim:function(){return Lp(this)}});var Hp=Tn("String").trim,Wp=J,qp=Hp,Vp=String.prototype,Up=function(t){var e=t.trim;return"string"==typeof t||t===Vp||Wp(Vp,t)&&e===Vp.trim?qp:e},Yp=Up;_i({target:"Object",stat:!0,sham:!b},{create:wr});var Xp=X.Object,Gp=function(t,e){return Xp.create(t,e)},Kp=Gp,$p=_i,Zp=Q,Qp=d,Jp=g,tv=o,ev=n.Array,iv=Zp("JSON","stringify"),nv=Jp(/./.exec),ov=Jp("".charAt),rv=Jp("".charCodeAt),sv=Jp("".replace),av=Jp(1..toString),hv=/[\uD800-\uDFFF]/g,lv=/^[\uD800-\uDBFF]$/,dv=/^[\uDC00-\uDFFF]$/,cv=function(t,e,i){var n=ov(i,e-1),o=ov(i,e+1);return nv(lv,t)&&!nv(dv,o)||nv(dv,t)&&!nv(lv,n)?"\\u"+av(rv(t,0),16):t},uv=tv((function(){return'"\\udf06\\ud834"'!==iv("\udf06\ud834")||'"\\udead"'!==iv("\udead")}));iv&&$p({target:"JSON",stat:!0,forced:uv},{stringify:function(t,e,i){for(var n=0,o=arguments.length,r=ev(o);n<o;n++)r[n]=arguments[n];var s=Qp(iv,null,r);return"string"==typeof s?sv(s,hv,cv):s}});var fv=X,pv=d;fv.JSON||(fv.JSON={stringify:JSON.stringify});var vv=function(t,e,i){return pv(fv.JSON.stringify,null,arguments)},gv=vv,yv=n.TypeError,mv=_i,bv=n,wv=d,kv=y,_v=fn,xv=function(t,e){if(t<e)throw yv("Not enough arguments");return t},Ev=/MSIE .\./.test(tt),Ov=bv.Function,Cv=function(t){return function(e,i){var n=xv(arguments.length,1)>2,o=kv(e)?e:Ov(e),r=n?_v(arguments,2):void 0;return t(n?function(){wv(o,this,r)}:o,i)}};mv({global:!0,bind:!0,forced:Ev},{setTimeout:Cv(bv.setTimeout),setInterval:Cv(bv.setInterval)});var Sv=X.setTimeout,Tv=Rt,Mv=Mi,Pv=Bi,Dv=function(t){for(var e=Tv(this),i=Pv(e),n=arguments.length,o=Mv(n>1?arguments[1]:void 0,i),r=n>2?arguments[2]:void 0,s=void 0===r?i:Mv(r,i);s>o;)e[o++]=t;return e};_i({target:"Array",proto:!0},{fill:Dv});var Iv,Bv=Tn("Array").fill,zv=J,Nv=Bv,Fv=Array.prototype,Av=function(t){var e=t.fill;return t===Fv||zv(Fv,t)&&e===Fv.fill?Nv:e},jv=Av;function Rv(){return Rv=Object.assign||function(t){for(var e=1;e<arguments.length;e++){var i=arguments[e];for(var n in i)Object.prototype.hasOwnProperty.call(i,n)&&(t[n]=i[n])}return t},Rv.apply(this,arguments)}function Lv(t,e){t.prototype=Object.create(e.prototype),t.prototype.constructor=t,t.__proto__=e}function Hv(t){if(void 0===t)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return t}Iv="function"!=typeof Object.assign?function(t){if(null==t)throw new TypeError("Cannot convert undefined or null to object");for(var e=Object(t),i=1;i<arguments.length;i++){var n=arguments[i];if(null!=n)for(var o in n)n.hasOwnProperty(o)&&(e[o]=n[o])}return e}:Object.assign;var Wv,qv=Iv,Vv=["","webkit","Moz","MS","ms","o"],Uv="undefined"==typeof document?{style:{}}:document.createElement("div"),Yv=Math.round,Xv=Math.abs,Gv=Date.now;function Kv(t,e){for(var i,n,o=e[0].toUpperCase()+e.slice(1),r=0;r<Vv.length;){if((n=(i=Vv[r])?i+o:e)in t)return n;r++}}Wv="undefined"==typeof window?{}:window;var $v=Kv(Uv.style,"touchAction"),Zv=void 0!==$v;var Qv="compute",Jv="auto",tg="manipulation",eg="none",ig="pan-x",ng="pan-y",og=function(){if(!Zv)return!1;var t={},e=Wv.CSS&&Wv.CSS.supports;return["auto","manipulation","pan-y","pan-x","pan-x pan-y","none"].forEach((function(i){return t[i]=!e||Wv.CSS.supports("touch-action",i)})),t}(),rg="ontouchstart"in Wv,sg=void 0!==Kv(Wv,"PointerEvent"),ag=rg&&/mobile|tablet|ip(ad|hone|od)|android/i.test(navigator.userAgent),hg="touch",lg="mouse",dg=16,cg=24,ug=["x","y"],fg=["clientX","clientY"];function pg(t,e,i){var n;if(t)if(t.forEach)t.forEach(e,i);else if(void 0!==t.length)for(n=0;n<t.length;)e.call(i,t[n],n,t),n++;else for(n in t)t.hasOwnProperty(n)&&e.call(i,t[n],n,t)}function vg(t,e){return"function"==typeof t?t.apply(e&&e[0]||void 0,e):t}function gg(t,e){return t.indexOf(e)>-1}var yg=function(){function t(t,e){this.manager=t,this.set(e)}var e=t.prototype;return e.set=function(t){t===Qv&&(t=this.compute()),Zv&&this.manager.element.style&&og[t]&&(this.manager.element.style[$v]=t),this.actions=t.toLowerCase().trim()},e.update=function(){this.set(this.manager.options.touchAction)},e.compute=function(){var t=[];return pg(this.manager.recognizers,(function(e){vg(e.options.enable,[e])&&(t=t.concat(e.getTouchAction()))})),function(t){if(gg(t,eg))return eg;var e=gg(t,ig),i=gg(t,ng);return e&&i?eg:e||i?e?ig:ng:gg(t,tg)?tg:Jv}(t.join(" "))},e.preventDefaults=function(t){var e=t.srcEvent,i=t.offsetDirection;if(this.manager.session.prevented)e.preventDefault();else{var n=this.actions,o=gg(n,eg)&&!og.none,r=gg(n,ng)&&!og["pan-y"],s=gg(n,ig)&&!og["pan-x"];if(o){var a=1===t.pointers.length,h=t.distance<2,l=t.deltaTime<250;if(a&&h&&l)return}if(!s||!r)return o||r&&6&i||s&&i&cg?this.preventSrc(e):void 0}},e.preventSrc=function(t){this.manager.session.prevented=!0,t.preventDefault()},t}();function mg(t,e){for(;t;){if(t===e)return!0;t=t.parentNode}return!1}function bg(t){var e=t.length;if(1===e)return{x:Yv(t[0].clientX),y:Yv(t[0].clientY)};for(var i=0,n=0,o=0;o<e;)i+=t[o].clientX,n+=t[o].clientY,o++;return{x:Yv(i/e),y:Yv(n/e)}}function wg(t){for(var e=[],i=0;i<t.pointers.length;)e[i]={clientX:Yv(t.pointers[i].clientX),clientY:Yv(t.pointers[i].clientY)},i++;return{timeStamp:Gv(),pointers:e,center:bg(e),deltaX:t.deltaX,deltaY:t.deltaY}}function kg(t,e,i){i||(i=ug);var n=e[i[0]]-t[i[0]],o=e[i[1]]-t[i[1]];return Math.sqrt(n*n+o*o)}function _g(t,e,i){i||(i=ug);var n=e[i[0]]-t[i[0]],o=e[i[1]]-t[i[1]];return 180*Math.atan2(o,n)/Math.PI}function xg(t,e){return t===e?1:Xv(t)>=Xv(e)?t<0?2:4:e<0?8:dg}function Eg(t,e,i){return{x:e/t||0,y:i/t||0}}function Og(t,e){var i=t.session,n=e.pointers,o=n.length;i.firstInput||(i.firstInput=wg(e)),o>1&&!i.firstMultiple?i.firstMultiple=wg(e):1===o&&(i.firstMultiple=!1);var r=i.firstInput,s=i.firstMultiple,a=s?s.center:r.center,h=e.center=bg(n);e.timeStamp=Gv(),e.deltaTime=e.timeStamp-r.timeStamp,e.angle=_g(a,h),e.distance=kg(a,h),function(t,e){var i=e.center,n=t.offsetDelta||{},o=t.prevDelta||{},r=t.prevInput||{};1!==e.eventType&&4!==r.eventType||(o=t.prevDelta={x:r.deltaX||0,y:r.deltaY||0},n=t.offsetDelta={x:i.x,y:i.y}),e.deltaX=o.x+(i.x-n.x),e.deltaY=o.y+(i.y-n.y)}(i,e),e.offsetDirection=xg(e.deltaX,e.deltaY);var l,d,c=Eg(e.deltaTime,e.deltaX,e.deltaY);e.overallVelocityX=c.x,e.overallVelocityY=c.y,e.overallVelocity=Xv(c.x)>Xv(c.y)?c.x:c.y,e.scale=s?(l=s.pointers,kg((d=n)[0],d[1],fg)/kg(l[0],l[1],fg)):1,e.rotation=s?function(t,e){return _g(e[1],e[0],fg)+_g(t[1],t[0],fg)}(s.pointers,n):0,e.maxPointers=i.prevInput?e.pointers.length>i.prevInput.maxPointers?e.pointers.length:i.prevInput.maxPointers:e.pointers.length,function(t,e){var i,n,o,r,s=t.lastInterval||e,a=e.timeStamp-s.timeStamp;if(8!==e.eventType&&(a>25||void 0===s.velocity)){var h=e.deltaX-s.deltaX,l=e.deltaY-s.deltaY,d=Eg(a,h,l);n=d.x,o=d.y,i=Xv(d.x)>Xv(d.y)?d.x:d.y,r=xg(h,l),t.lastInterval=e}else i=s.velocity,n=s.velocityX,o=s.velocityY,r=s.direction;e.velocity=i,e.velocityX=n,e.velocityY=o,e.direction=r}(i,e);var u,f=t.element,p=e.srcEvent;mg(u=p.composedPath?p.composedPath()[0]:p.path?p.path[0]:p.target,f)&&(f=u),e.target=f}function Cg(t,e,i){var n=i.pointers.length,o=i.changedPointers.length,r=1&e&&n-o==0,s=12&e&&n-o==0;i.isFirst=!!r,i.isFinal=!!s,r&&(t.session={}),i.eventType=e,Og(t,i),t.emit("hammer.input",i),t.recognize(i),t.session.prevInput=i}function Sg(t){return t.trim().split(/\s+/g)}function Tg(t,e,i){pg(Sg(e),(function(e){t.addEventListener(e,i,!1)}))}function Mg(t,e,i){pg(Sg(e),(function(e){t.removeEventListener(e,i,!1)}))}function Pg(t){var e=t.ownerDocument||t;return e.defaultView||e.parentWindow||window}var Dg=function(){function t(t,e){var i=this;this.manager=t,this.callback=e,this.element=t.element,this.target=t.options.inputTarget,this.domHandler=function(e){vg(t.options.enable,[t])&&i.handler(e)},this.init()}var e=t.prototype;return e.handler=function(){},e.init=function(){this.evEl&&Tg(this.element,this.evEl,this.domHandler),this.evTarget&&Tg(this.target,this.evTarget,this.domHandler),this.evWin&&Tg(Pg(this.element),this.evWin,this.domHandler)},e.destroy=function(){this.evEl&&Mg(this.element,this.evEl,this.domHandler),this.evTarget&&Mg(this.target,this.evTarget,this.domHandler),this.evWin&&Mg(Pg(this.element),this.evWin,this.domHandler)},t}();function Ig(t,e,i){if(t.indexOf&&!i)return t.indexOf(e);for(var n=0;n<t.length;){if(i&&t[n][i]==e||!i&&t[n]===e)return n;n++}return-1}var Bg={pointerdown:1,pointermove:2,pointerup:4,pointercancel:8,pointerout:8},zg={2:hg,3:"pen",4:lg,5:"kinect"},Ng="pointerdown",Fg="pointermove pointerup pointercancel";Wv.MSPointerEvent&&!Wv.PointerEvent&&(Ng="MSPointerDown",Fg="MSPointerMove MSPointerUp MSPointerCancel");var Ag=function(t){function e(){var i,n=e.prototype;return n.evEl=Ng,n.evWin=Fg,(i=t.apply(this,arguments)||this).store=i.manager.session.pointerEvents=[],i}return Lv(e,t),e.prototype.handler=function(t){var e=this.store,i=!1,n=t.type.toLowerCase().replace("ms",""),o=Bg[n],r=zg[t.pointerType]||t.pointerType,s=r===hg,a=Ig(e,t.pointerId,"pointerId");1&o&&(0===t.button||s)?a<0&&(e.push(t),a=e.length-1):12&o&&(i=!0),a<0||(e[a]=t,this.callback(this.manager,o,{pointers:e,changedPointers:[t],pointerType:r,srcEvent:t}),i&&e.splice(a,1))},e}(Dg);function jg(t){return Array.prototype.slice.call(t,0)}function Rg(t,e,i){for(var n=[],o=[],r=0;r<t.length;){var s=e?t[r][e]:t[r];Ig(o,s)<0&&n.push(t[r]),o[r]=s,r++}return i&&(n=e?n.sort((function(t,i){return t[e]>i[e]})):n.sort()),n}var Lg={touchstart:1,touchmove:2,touchend:4,touchcancel:8},Hg="touchstart touchmove touchend touchcancel",Wg=function(t){function e(){var i;return e.prototype.evTarget=Hg,(i=t.apply(this,arguments)||this).targetIds={},i}return Lv(e,t),e.prototype.handler=function(t){var e=Lg[t.type],i=qg.call(this,t,e);i&&this.callback(this.manager,e,{pointers:i[0],changedPointers:i[1],pointerType:hg,srcEvent:t})},e}(Dg);function qg(t,e){var i,n,o=jg(t.touches),r=this.targetIds;if(3&e&&1===o.length)return r[o[0].identifier]=!0,[o,o];var s=jg(t.changedTouches),a=[],h=this.target;if(n=o.filter((function(t){return mg(t.target,h)})),1===e)for(i=0;i<n.length;)r[n[i].identifier]=!0,i++;for(i=0;i<s.length;)r[s[i].identifier]&&a.push(s[i]),12&e&&delete r[s[i].identifier],i++;return a.length?[Rg(n.concat(a),"identifier",!0),a]:void 0}var Vg={mousedown:1,mousemove:2,mouseup:4},Ug="mousedown",Yg="mousemove mouseup",Xg=function(t){function e(){var i,n=e.prototype;return n.evEl=Ug,n.evWin=Yg,(i=t.apply(this,arguments)||this).pressed=!1,i}return Lv(e,t),e.prototype.handler=function(t){var e=Vg[t.type];1&e&&0===t.button&&(this.pressed=!0),2&e&&1!==t.which&&(e=4),this.pressed&&(4&e&&(this.pressed=!1),this.callback(this.manager,e,{pointers:[t],changedPointers:[t],pointerType:lg,srcEvent:t}))},e}(Dg);function Gg(t){var e=t.changedPointers[0];if(e.identifier===this.primaryTouch){var i={x:e.clientX,y:e.clientY},n=this.lastTouches;this.lastTouches.push(i);setTimeout((function(){var t=n.indexOf(i);t>-1&&n.splice(t,1)}),2500)}}function Kg(t,e){1&t?(this.primaryTouch=e.changedPointers[0].identifier,Gg.call(this,e)):12&t&&Gg.call(this,e)}function $g(t){for(var e=t.srcEvent.clientX,i=t.srcEvent.clientY,n=0;n<this.lastTouches.length;n++){var o=this.lastTouches[n],r=Math.abs(e-o.x),s=Math.abs(i-o.y);if(r<=25&&s<=25)return!0}return!1}var Zg=function(){return function(t){function e(e,i){var n;return(n=t.call(this,e,i)||this).handler=function(t,e,i){var o=i.pointerType===hg,r=i.pointerType===lg;if(!(r&&i.sourceCapabilities&&i.sourceCapabilities.firesTouchEvents)){if(o)Kg.call(Hv(Hv(n)),e,i);else if(r&&$g.call(Hv(Hv(n)),i))return;n.callback(t,e,i)}},n.touch=new Wg(n.manager,n.handler),n.mouse=new Xg(n.manager,n.handler),n.primaryTouch=null,n.lastTouches=[],n}return Lv(e,t),e.prototype.destroy=function(){this.touch.destroy(),this.mouse.destroy()},e}(Dg)}();function Qg(t,e,i){return!!Array.isArray(t)&&(pg(t,i[e],i),!0)}var Jg=32,ty=1;function ey(t,e){var i=e.manager;return i?i.get(t):t}function iy(t){return 16&t?"cancel":8&t?"end":4&t?"move":2&t?"start":""}var ny=function(){function t(t){void 0===t&&(t={}),this.options=Rv({enable:!0},t),this.id=ty++,this.manager=null,this.state=1,this.simultaneous={},this.requireFail=[]}var e=t.prototype;return e.set=function(t){return qv(this.options,t),this.manager&&this.manager.touchAction.update(),this},e.recognizeWith=function(t){if(Qg(t,"recognizeWith",this))return this;var e=this.simultaneous;return e[(t=ey(t,this)).id]||(e[t.id]=t,t.recognizeWith(this)),this},e.dropRecognizeWith=function(t){return Qg(t,"dropRecognizeWith",this)||(t=ey(t,this),delete this.simultaneous[t.id]),this},e.requireFailure=function(t){if(Qg(t,"requireFailure",this))return this;var e=this.requireFail;return-1===Ig(e,t=ey(t,this))&&(e.push(t),t.requireFailure(this)),this},e.dropRequireFailure=function(t){if(Qg(t,"dropRequireFailure",this))return this;t=ey(t,this);var e=Ig(this.requireFail,t);return e>-1&&this.requireFail.splice(e,1),this},e.hasRequireFailures=function(){return this.requireFail.length>0},e.canRecognizeWith=function(t){return!!this.simultaneous[t.id]},e.emit=function(t){var e=this,i=this.state;function n(i){e.manager.emit(i,t)}i<8&&n(e.options.event+iy(i)),n(e.options.event),t.additionalEvent&&n(t.additionalEvent),i>=8&&n(e.options.event+iy(i))},e.tryEmit=function(t){if(this.canEmit())return this.emit(t);this.state=Jg},e.canEmit=function(){for(var t=0;t<this.requireFail.length;){if(!(33&this.requireFail[t].state))return!1;t++}return!0},e.recognize=function(t){var e=qv({},t);if(!vg(this.options.enable,[this,e]))return this.reset(),void(this.state=Jg);56&this.state&&(this.state=1),this.state=this.process(e),30&this.state&&this.tryEmit(e)},e.process=function(t){},e.getTouchAction=function(){},e.reset=function(){},t}(),oy=function(t){function e(e){var i;return void 0===e&&(e={}),(i=t.call(this,Rv({event:"tap",pointers:1,taps:1,interval:300,time:250,threshold:9,posThreshold:10},e))||this).pTime=!1,i.pCenter=!1,i._timer=null,i._input=null,i.count=0,i}Lv(e,t);var i=e.prototype;return i.getTouchAction=function(){return[tg]},i.process=function(t){var e=this,i=this.options,n=t.pointers.length===i.pointers,o=t.distance<i.threshold,r=t.deltaTime<i.time;if(this.reset(),1&t.eventType&&0===this.count)return this.failTimeout();if(o&&r&&n){if(4!==t.eventType)return this.failTimeout();var s=!this.pTime||t.timeStamp-this.pTime<i.interval,a=!this.pCenter||kg(this.pCenter,t.center)<i.posThreshold;if(this.pTime=t.timeStamp,this.pCenter=t.center,a&&s?this.count+=1:this.count=1,this._input=t,0===this.count%i.taps)return this.hasRequireFailures()?(this._timer=setTimeout((function(){e.state=8,e.tryEmit()}),i.interval),2):8}return Jg},i.failTimeout=function(){var t=this;return this._timer=setTimeout((function(){t.state=Jg}),this.options.interval),Jg},i.reset=function(){clearTimeout(this._timer)},i.emit=function(){8===this.state&&(this._input.tapCount=this.count,this.manager.emit(this.options.event,this._input))},e}(ny),ry=function(t){function e(e){return void 0===e&&(e={}),t.call(this,Rv({pointers:1},e))||this}Lv(e,t);var i=e.prototype;return i.attrTest=function(t){var e=this.options.pointers;return 0===e||t.pointers.length===e},i.process=function(t){var e=this.state,i=t.eventType,n=6&e,o=this.attrTest(t);return n&&(8&i||!o)?16|e:n||o?4&i?8|e:2&e?4|e:2:Jg},e}(ny);function sy(t){return t===dg?"down":8===t?"up":2===t?"left":4===t?"right":""}var ay=function(t){function e(e){var i;return void 0===e&&(e={}),(i=t.call(this,Rv({event:"pan",threshold:10,pointers:1,direction:30},e))||this).pX=null,i.pY=null,i}Lv(e,t);var i=e.prototype;return i.getTouchAction=function(){var t=this.options.direction,e=[];return 6&t&&e.push(ng),t&cg&&e.push(ig),e},i.directionTest=function(t){var e=this.options,i=!0,n=t.distance,o=t.direction,r=t.deltaX,s=t.deltaY;return o&e.direction||(6&e.direction?(o=0===r?1:r<0?2:4,i=r!==this.pX,n=Math.abs(t.deltaX)):(o=0===s?1:s<0?8:dg,i=s!==this.pY,n=Math.abs(t.deltaY))),t.direction=o,i&&n>e.threshold&&o&e.direction},i.attrTest=function(t){return ry.prototype.attrTest.call(this,t)&&(2&this.state||!(2&this.state)&&this.directionTest(t))},i.emit=function(e){this.pX=e.deltaX,this.pY=e.deltaY;var i=sy(e.direction);i&&(e.additionalEvent=this.options.event+i),t.prototype.emit.call(this,e)},e}(ry),hy=function(t){function e(e){return void 0===e&&(e={}),t.call(this,Rv({event:"swipe",threshold:10,velocity:.3,direction:30,pointers:1},e))||this}Lv(e,t);var i=e.prototype;return i.getTouchAction=function(){return ay.prototype.getTouchAction.call(this)},i.attrTest=function(e){var i,n=this.options.direction;return 30&n?i=e.overallVelocity:6&n?i=e.overallVelocityX:n&cg&&(i=e.overallVelocityY),t.prototype.attrTest.call(this,e)&&n&e.offsetDirection&&e.distance>this.options.threshold&&e.maxPointers===this.options.pointers&&Xv(i)>this.options.velocity&&4&e.eventType},i.emit=function(t){var e=sy(t.offsetDirection);e&&this.manager.emit(this.options.event+e,t),this.manager.emit(this.options.event,t)},e}(ry),ly=function(t){function e(e){return void 0===e&&(e={}),t.call(this,Rv({event:"pinch",threshold:0,pointers:2},e))||this}Lv(e,t);var i=e.prototype;return i.getTouchAction=function(){return[eg]},i.attrTest=function(e){return t.prototype.attrTest.call(this,e)&&(Math.abs(e.scale-1)>this.options.threshold||2&this.state)},i.emit=function(e){if(1!==e.scale){var i=e.scale<1?"in":"out";e.additionalEvent=this.options.event+i}t.prototype.emit.call(this,e)},e}(ry),dy=function(t){function e(e){return void 0===e&&(e={}),t.call(this,Rv({event:"rotate",threshold:0,pointers:2},e))||this}Lv(e,t);var i=e.prototype;return i.getTouchAction=function(){return[eg]},i.attrTest=function(e){return t.prototype.attrTest.call(this,e)&&(Math.abs(e.rotation)>this.options.threshold||2&this.state)},e}(ry),cy=function(t){function e(e){var i;return void 0===e&&(e={}),(i=t.call(this,Rv({event:"press",pointers:1,time:251,threshold:9},e))||this)._timer=null,i._input=null,i}Lv(e,t);var i=e.prototype;return i.getTouchAction=function(){return[Jv]},i.process=function(t){var e=this,i=this.options,n=t.pointers.length===i.pointers,o=t.distance<i.threshold,r=t.deltaTime>i.time;if(this._input=t,!o||!n||12&t.eventType&&!r)this.reset();else if(1&t.eventType)this.reset(),this._timer=setTimeout((function(){e.state=8,e.tryEmit()}),i.time);else if(4&t.eventType)return 8;return Jg},i.reset=function(){clearTimeout(this._timer)},i.emit=function(t){8===this.state&&(t&&4&t.eventType?this.manager.emit(this.options.event+"up",t):(this._input.timeStamp=Gv(),this.manager.emit(this.options.event,this._input)))},e}(ny),uy={domEvents:!1,touchAction:Qv,enable:!0,inputTarget:null,inputClass:null,cssProps:{userSelect:"none",touchSelect:"none",touchCallout:"none",contentZooming:"none",userDrag:"none",tapHighlightColor:"rgba(0,0,0,0)"}},fy=[[dy,{enable:!1}],[ly,{enable:!1},["rotate"]],[hy,{direction:6}],[ay,{direction:6},["swipe"]],[oy],[oy,{event:"doubletap",taps:2},["tap"]],[cy]];function py(t,e){var i,n=t.element;n.style&&(pg(t.options.cssProps,(function(o,r){i=Kv(n.style,r),e?(t.oldCssProps[i]=n.style[i],n.style[i]=o):n.style[i]=t.oldCssProps[i]||""})),e||(t.oldCssProps={}))}var vy=function(){function t(t,e){var i,n=this;this.options=qv({},uy,e||{}),this.options.inputTarget=this.options.inputTarget||t,this.handlers={},this.session={},this.recognizers=[],this.oldCssProps={},this.element=t,this.input=new((i=this).options.inputClass||(sg?Ag:ag?Wg:rg?Zg:Xg))(i,Cg),this.touchAction=new yg(this,this.options.touchAction),py(this,!0),pg(this.options.recognizers,(function(t){var e=n.add(new t[0](t[1]));t[2]&&e.recognizeWith(t[2]),t[3]&&e.requireFailure(t[3])}),this)}var e=t.prototype;return e.set=function(t){return qv(this.options,t),t.touchAction&&this.touchAction.update(),t.inputTarget&&(this.input.destroy(),this.input.target=t.inputTarget,this.input.init()),this},e.stop=function(t){this.session.stopped=t?2:1},e.recognize=function(t){var e=this.session;if(!e.stopped){var i;this.touchAction.preventDefaults(t);var n=this.recognizers,o=e.curRecognizer;(!o||o&&8&o.state)&&(e.curRecognizer=null,o=null);for(var r=0;r<n.length;)i=n[r],2===e.stopped||o&&i!==o&&!i.canRecognizeWith(o)?i.reset():i.recognize(t),!o&&14&i.state&&(e.curRecognizer=i,o=i),r++}},e.get=function(t){if(t instanceof ny)return t;for(var e=this.recognizers,i=0;i<e.length;i++)if(e[i].options.event===t)return e[i];return null},e.add=function(t){if(Qg(t,"add",this))return this;var e=this.get(t.options.event);return e&&this.remove(e),this.recognizers.push(t),t.manager=this,this.touchAction.update(),t},e.remove=function(t){if(Qg(t,"remove",this))return this;var e=this.get(t);if(t){var i=this.recognizers,n=Ig(i,e);-1!==n&&(i.splice(n,1),this.touchAction.update())}return this},e.on=function(t,e){if(void 0===t||void 0===e)return this;var i=this.handlers;return pg(Sg(t),(function(t){i[t]=i[t]||[],i[t].push(e)})),this},e.off=function(t,e){if(void 0===t)return this;var i=this.handlers;return pg(Sg(t),(function(t){e?i[t]&&i[t].splice(Ig(i[t],e),1):delete i[t]})),this},e.emit=function(t,e){this.options.domEvents&&function(t,e){var i=document.createEvent("Event");i.initEvent(t,!0,!0),i.gesture=e,e.target.dispatchEvent(i)}(t,e);var i=this.handlers[t]&&this.handlers[t].slice();if(i&&i.length){e.type=t,e.preventDefault=function(){e.srcEvent.preventDefault()};for(var n=0;n<i.length;)i[n](e),n++}},e.destroy=function(){this.element&&py(this,!1),this.handlers={},this.session={},this.input.destroy(),this.element=null},t}(),gy={touchstart:1,touchmove:2,touchend:4,touchcancel:8},yy="touchstart",my="touchstart touchmove touchend touchcancel",by=function(t){function e(){var i,n=e.prototype;return n.evTarget=yy,n.evWin=my,(i=t.apply(this,arguments)||this).started=!1,i}return Lv(e,t),e.prototype.handler=function(t){var e=gy[t.type];if(1===e&&(this.started=!0),this.started){var i=wy.call(this,t,e);12&e&&i[0].length-i[1].length==0&&(this.started=!1),this.callback(this.manager,e,{pointers:i[0],changedPointers:i[1],pointerType:hg,srcEvent:t})}},e}(Dg);function wy(t,e){var i=jg(t.touches),n=jg(t.changedTouches);return 12&e&&(i=Rg(i.concat(n),"identifier",!0)),[i,n]}function ky(t,e,i){var n="DEPRECATED METHOD: "+e+"\n"+i+" AT \n";return function(){var e=new Error("get-stack-trace"),i=e&&e.stack?e.stack.replace(/^[^\(]+?[\n$]/gm,"").replace(/^\s+at\s+/gm,"").replace(/^Object.<anonymous>\s*\(/gm,"{anonymous}()@"):"Unknown Stack Trace",o=window.console&&(window.console.warn||window.console.log);return o&&o.call(window.console,n,i),t.apply(this,arguments)}}var _y=ky((function(t,e,i){for(var n=Object.keys(e),o=0;o<n.length;)(!i||i&&void 0===t[n[o]])&&(t[n[o]]=e[n[o]]),o++;return t}),"extend","Use `assign`."),xy=ky((function(t,e){return _y(t,e,!0)}),"merge","Use `assign`.");function Ey(t,e,i){var n,o=e.prototype;(n=t.prototype=Object.create(o)).constructor=t,n._super=o,i&&qv(n,i)}function Oy(t,e){return function(){return t.apply(e,arguments)}}var Cy=function(){var t=function(t,e){return void 0===e&&(e={}),new vy(t,Rv({recognizers:fy.concat()},e))};return t.VERSION="2.0.17-rc",t.DIRECTION_ALL=30,t.DIRECTION_DOWN=dg,t.DIRECTION_LEFT=2,t.DIRECTION_RIGHT=4,t.DIRECTION_UP=8,t.DIRECTION_HORIZONTAL=6,t.DIRECTION_VERTICAL=cg,t.DIRECTION_NONE=1,t.DIRECTION_DOWN=dg,t.INPUT_START=1,t.INPUT_MOVE=2,t.INPUT_END=4,t.INPUT_CANCEL=8,t.STATE_POSSIBLE=1,t.STATE_BEGAN=2,t.STATE_CHANGED=4,t.STATE_ENDED=8,t.STATE_RECOGNIZED=8,t.STATE_CANCELLED=16,t.STATE_FAILED=Jg,t.Manager=vy,t.Input=Dg,t.TouchAction=yg,t.TouchInput=Wg,t.MouseInput=Xg,t.PointerEventInput=Ag,t.TouchMouseInput=Zg,t.SingleTouchInput=by,t.Recognizer=ny,t.AttrRecognizer=ry,t.Tap=oy,t.Pan=ay,t.Swipe=hy,t.Pinch=ly,t.Rotate=dy,t.Press=cy,t.on=Tg,t.off=Mg,t.each=pg,t.merge=xy,t.extend=_y,t.bindFn=Oy,t.assign=qv,t.inherit=Ey,t.bindFn=Oy,t.prefixed=Kv,t.toArray=jg,t.inArray=Ig,t.uniqueArray=Rg,t.splitStr=Sg,t.boolOrFn=vg,t.hasParent=mg,t.addEventListeners=Tg,t.removeEventListeners=Mg,t.defaults=qv({},uy,{preset:fy}),t}(),Sy=Cy;function Ty(t,e){var i=bu(t);if(hd){var n=hd(t);e&&(n=Xf(n).call(n,(function(e){return bd(t,e).enumerable}))),i.push.apply(i,n)}return i}function My(t){for(var e=1;e<arguments.length;e++){var i,n,o=null!=arguments[e]?arguments[e]:{};e%2?Fu(i=Ty(Object(o),!0)).call(i,(function(e){$d(t,e,o[e])})):Pd?Ad(t,Pd(o)):Fu(n=Ty(Object(o))).call(n,(function(e){Ud(t,e,bd(o,e))}))}return t}function Py(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return Dy(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return Dy(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function Dy(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}var Iy=tu("DELETE");function By(t){for(var e,i=arguments.length,n=new Array(i>1?i-1:0),o=1;o<i;o++)n[o-1]=arguments[o];return zy.apply(void 0,su(e=[{},t]).call(e,n))}function zy(){var t=Ny.apply(void 0,arguments);return Ay(t),t}function Ny(){for(var t=arguments.length,e=new Array(t),i=0;i<t;i++)e[i]=arguments[i];if(e.length<2)return e[0];var n;if(e.length>2)return Ny.apply(void 0,su(n=[zy(e[0],e[1])]).call(n,Jc(au(e).call(e,2))));var o,r=e[0],s=e[1],a=Py(hu(s));try{for(a.s();!(o=a.n()).done;){var h=o.value;Object.prototype.propertyIsEnumerable.call(s,h)&&(s[h]===Iy?delete r[h]:null===r[h]||null===s[h]||"object"!==Qc(r[h])||"object"!==Qc(s[h])||lu(r[h])||lu(s[h])?r[h]=Fy(s[h]):r[h]=Ny(r[h],s[h]))}}catch(t){a.e(t)}finally{a.f()}return r}function Fy(t){return lu(t)?gu(t).call(t,(function(t){return Fy(t)})):"object"===Qc(t)&&null!==t?Ny({},t):t}function Ay(t){for(var e=0,i=bu(t);e<i.length;e++){var n=i[e];t[n]===Iy?delete t[n]:"object"===Qc(t[n])&&null!==t[n]&&Ay(t[n])}}function jy(){for(var t=arguments.length,e=new Array(t),i=0;i<t;i++)e[i]=arguments[i];return Ry(e.length?e:[Eu()])}function Ry(t){var e=function(){for(var t=Ly(),e=t(" "),i=t(" "),n=t(" "),o=0;o<arguments.length;o++)(e-=t(o<0||arguments.length<=o?void 0:arguments[o]))<0&&(e+=1),(i-=t(o<0||arguments.length<=o?void 0:arguments[o]))<0&&(i+=1),(n-=t(o<0||arguments.length<=o?void 0:arguments[o]))<0&&(n+=1);return[e,i,n]}(t),i=Kc(e,3),n=i[0],o=i[1],r=i[2],s=1,a=function(){var t=2091639*n+2.3283064365386963e-10*s;return n=o,o=r,r=t-(s=0|t)};return a.uint32=function(){return 4294967296*a()},a.fract53=function(){return a()+11102230246251565e-32*(2097152*a()|0)},a.algorithm="Alea",a.seed=t,a.version="0.9",a}function Ly(){var t=4022871197;return function(e){for(var i=e.toString(),n=0;n<i.length;n++){var o=.02519603282416938*(t+=i.charCodeAt(n));o-=t=o>>>0,t=(o*=t)>>>0,t+=4294967296*(o-=t)}return 2.3283064365386963e-10*(t>>>0)}}var Hy="undefined"!=typeof window?window.Hammer||Sy:function(){return function(){var t=function(){};return{on:t,off:t,destroy:t,emit:t,get:function(){return{set:t}}}}()};function Wy(t){var e,i=this;this._cleanupQueue=[],this.active=!1,this._dom={container:t,overlay:document.createElement("div")},this._dom.overlay.classList.add("vis-overlay"),this._dom.container.appendChild(this._dom.overlay),this._cleanupQueue.push((function(){i._dom.overlay.parentNode.removeChild(i._dom.overlay)}));var n=Hy(this._dom.overlay);n.on("tap",zn(e=this._onTapOverlay).call(e,this)),this._cleanupQueue.push((function(){n.destroy()}));var o=["tap","doubletap","press","pinch","pan","panstart","panmove","panend"];Fu(o).call(o,(function(t){n.on(t,(function(t){t.srcEvent.stopPropagation()}))})),document&&document.body&&(this._onClick=function(e){(function(t,e){for(;t;){if(t===e)return!0;t=t.parentNode}return!1})(e.target,t)||i.deactivate()},document.body.addEventListener("click",this._onClick),this._cleanupQueue.push((function(){document.body.removeEventListener("click",i._onClick)}))),this._escListener=function(t){("key"in t?"Escape"===t.key:27===t.keyCode)&&i.deactivate()}}Wn(Wy.prototype),Wy.current=null,Wy.prototype.destroy=function(){var t,e;this.deactivate();var i,n=Py(Yu(t=ff(e=this._cleanupQueue).call(e,0)).call(t));try{for(n.s();!(i=n.n()).done;){(0,i.value)()}}catch(t){n.e(t)}finally{n.f()}},Wy.prototype.activate=function(){Wy.current&&Wy.current.deactivate(),Wy.current=this,this.active=!0,this._dom.overlay.style.display="none",this._dom.container.classList.add("vis-active"),this.emit("change"),this.emit("activate"),document.body.addEventListener("keydown",this._escListener)},Wy.prototype.deactivate=function(){this.active=!1,this._dom.overlay.style.display="block",this._dom.container.classList.remove("vis-active"),document.body.removeEventListener("keydown",this._escListener),this.emit("change"),this.emit("deactivate")},Wy.prototype._onTapOverlay=function(t){this.activate(),t.srcEvent.stopPropagation()};var qy=/^\/?Date\((-?\d+)/i,Vy=/^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i,Uy=/^#?([a-f\d])([a-f\d])([a-f\d])$/i,Yy=/^rgb\( *(1?\d{1,2}|2[0-4]\d|25[0-5]) *, *(1?\d{1,2}|2[0-4]\d|25[0-5]) *, *(1?\d{1,2}|2[0-4]\d|25[0-5]) *\)$/i,Xy=/^rgba\( *(1?\d{1,2}|2[0-4]\d|25[0-5]) *, *(1?\d{1,2}|2[0-4]\d|25[0-5]) *, *(1?\d{1,2}|2[0-4]\d|25[0-5]) *, *([01]|0?\.\d+) *\)$/i;function Gy(t){return t instanceof Number||"number"==typeof t}function Ky(t){if(t)for(;!0===t.hasChildNodes();){var e=t.firstChild;e&&(Ky(e),t.removeChild(e))}}function $y(t){return t instanceof String||"string"==typeof t}function Zy(t){return"object"===Qc(t)&&null!==t}function Qy(t,e,i,n){var o=!1;!0===n&&(o=null===e[i]&&void 0!==t[i]),o?delete t[i]:t[i]=e[i]}function Jy(t,e){var i=arguments.length>2&&void 0!==arguments[2]&&arguments[2];for(var n in t)if(void 0!==e[n])if(null===e[n]||"object"!==Qc(e[n]))Qy(t,e,n,i);else{var o=t[n],r=e[n];Zy(o)&&Zy(r)&&Jy(o,r,i)}}var tm=un;function em(t,e,i){var n=arguments.length>3&&void 0!==arguments[3]&&arguments[3];if(lu(i))throw new TypeError("Arrays are not supported by deepExtend");for(var o=0;o<t.length;o++){var r=t[o];if(Object.prototype.hasOwnProperty.call(i,r))if(i[r]&&i[r].constructor===Object)void 0===e[r]&&(e[r]={}),e[r].constructor===Object?nm(e[r],i[r],!1,n):Qy(e,i,r,n);else{if(lu(i[r]))throw new TypeError("Arrays are not supported by deepExtend");Qy(e,i,r,n)}}return e}function im(t,e,i){var n=arguments.length>3&&void 0!==arguments[3]&&arguments[3];if(lu(i))throw new TypeError("Arrays are not supported by deepExtend");for(var o in i)if(Object.prototype.hasOwnProperty.call(i,o)&&!Nf(t).call(t,o))if(i[o]&&i[o].constructor===Object)void 0===e[o]&&(e[o]={}),e[o].constructor===Object?nm(e[o],i[o]):Qy(e,i,o,n);else if(lu(i[o])){e[o]=[];for(var r=0;r<i[o].length;r++)e[o].push(i[o][r])}else Qy(e,i,o,n);return e}function nm(t,e){var i=arguments.length>2&&void 0!==arguments[2]&&arguments[2],n=arguments.length>3&&void 0!==arguments[3]&&arguments[3];for(var o in e)if(Object.prototype.hasOwnProperty.call(e,o)||!0===i)if("object"===Qc(e[o])&&null!==e[o]&&Lf(e[o])===Object.prototype)void 0===t[o]?t[o]=nm({},e[o],i):"object"===Qc(t[o])&&null!==t[o]&&Lf(t[o])===Object.prototype?nm(t[o],e[o],i):Qy(t,e,o,n);else if(lu(e[o])){var r;t[o]=au(r=e[o]).call(r)}else Qy(t,e,o,n);return t}function om(t,e){var i;return su(i=[]).call(i,Jc(t),[e])}function rm(t){return au(t).call(t)}function sm(t){return t.getBoundingClientRect().left}function am(t){return t.getBoundingClientRect().top}function hm(t,e){if(lu(t))for(var i=t.length,n=0;n<i;n++)e(t[n],n,t);else for(var o in t)Object.prototype.hasOwnProperty.call(t,o)&&e(t[o],o,t)}var lm=ip;function dm(t,e,i,n){var o;t.addEventListener?(void 0===n&&(n=!1),"mousewheel"===e&&Nf(o=navigator.userAgent).call(o,"Firefox")&&(e="DOMMouseScroll"),t.addEventListener(e,i,n)):t.attachEvent("on"+e,i)}function cm(t,e,i,n){var o;t.removeEventListener?(void 0===n&&(n=!1),"mousewheel"===e&&Nf(o=navigator.userAgent).call(o,"Firefox")&&(e="DOMMouseScroll"),t.removeEventListener(e,i,n)):t.detachEvent("on"+e,i)}var um={asBoolean:function(t,e){return"function"==typeof t&&(t=t()),null!=t?0!=t:e||null},asNumber:function(t,e){return"function"==typeof t&&(t=t()),null!=t?Number(t)||e||null:e||null},asString:function(t,e){return"function"==typeof t&&(t=t()),null!=t?String(t):e||null},asSize:function(t,e){return"function"==typeof t&&(t=t()),$y(t)?t:Gy(t)?t+"px":e||null},asElement:function(t,e){return"function"==typeof t&&(t=t()),t||e||null}};function fm(t){var e;switch(t.length){case 3:case 4:return(e=Uy.exec(t))?{r:Ep(e[1]+e[1],16),g:Ep(e[2]+e[2],16),b:Ep(e[3]+e[3],16)}:null;case 6:case 7:return(e=Vy.exec(t))?{r:Ep(e[1],16),g:Ep(e[2],16),b:Ep(e[3],16)}:null;default:return null}}function pm(t,e){if(Nf(t).call(t,"rgba"))return t;if(Nf(t).call(t,"rgb")){var i=t.substr(Fp(t).call(t,"(")+1).replace(")","").split(",");return"rgba("+i[0]+","+i[1]+","+i[2]+","+e+")"}var n=fm(t);return null==n?t:"rgba("+n.r+","+n.g+","+n.b+","+e+")"}function vm(t,e,i){var n;return"#"+au(n=((1<<24)+(t<<16)+(e<<8)+i).toString(16)).call(n,1)}function gm(t,e){if($y(t)){var i=t;if(Em(i)){var n,o=gu(n=i.substr(4).substr(0,i.length-5).split(",")).call(n,(function(t){return Ep(t)}));i=vm(o[0],o[1],o[2])}if(!0===xm(i)){var r=_m(i),s={h:r.h,s:.8*r.s,v:Math.min(1,1.02*r.v)},a={h:r.h,s:Math.min(1,1.25*r.s),v:.8*r.v},h=km(a.h,a.s,a.v),l=km(s.h,s.s,s.v);return{background:i,border:h,highlight:{background:l,border:h},hover:{background:l,border:h}}}return{background:i,border:i,highlight:{background:i,border:i},hover:{background:i,border:i}}}return e?{background:t.background||e.background,border:t.border||e.border,highlight:$y(t.highlight)?{border:t.highlight,background:t.highlight}:{background:t.highlight&&t.highlight.background||e.highlight.background,border:t.highlight&&t.highlight.border||e.highlight.border},hover:$y(t.hover)?{border:t.hover,background:t.hover}:{border:t.hover&&t.hover.border||e.hover.border,background:t.hover&&t.hover.background||e.hover.background}}:{background:t.background||void 0,border:t.border||void 0,highlight:$y(t.highlight)?{border:t.highlight,background:t.highlight}:{background:t.highlight&&t.highlight.background||void 0,border:t.highlight&&t.highlight.border||void 0},hover:$y(t.hover)?{border:t.hover,background:t.hover}:{border:t.hover&&t.hover.border||void 0,background:t.hover&&t.hover.background||void 0}}}function ym(t,e,i){t/=255,e/=255,i/=255;var n=Math.min(t,Math.min(e,i)),o=Math.max(t,Math.max(e,i));return n===o?{h:0,s:0,v:n}:{h:60*((t===n?3:i===n?1:5)-(t===n?e-i:i===n?t-e:i-t)/(o-n))/360,s:(o-n)/o,v:o}}var mm=function(t){var e,i={};return Fu(e=t.split(";")).call(e,(function(t){if(""!=Yp(t).call(t)){var e,n,o=t.split(":"),r=Yp(e=o[0]).call(e),s=Yp(n=o[1]).call(n);i[r]=s}})),i},bm=function(t){var e;return gu(e=bu(t)).call(e,(function(e){return e+": "+t[e]})).join("; ")};function wm(t,e,i){var n,o,r,s=Math.floor(6*t),a=6*t-s,h=i*(1-e),l=i*(1-a*e),d=i*(1-(1-a)*e);switch(s%6){case 0:n=i,o=d,r=h;break;case 1:n=l,o=i,r=h;break;case 2:n=h,o=i,r=d;break;case 3:n=h,o=l,r=i;break;case 4:n=d,o=h,r=i;break;case 5:n=i,o=h,r=l}return{r:Math.floor(255*n),g:Math.floor(255*o),b:Math.floor(255*r)}}function km(t,e,i){var n=wm(t,e,i);return vm(n.r,n.g,n.b)}function _m(t){var e=fm(t);if(!e)throw new TypeError("'".concat(t,"' is not a valid color."));return ym(e.r,e.g,e.b)}function xm(t){return/(^#[0-9A-F]{6}$)|(^#[0-9A-F]{3}$)/i.test(t)}function Em(t){return Yy.test(t)}function Om(t){return Xy.test(t)}function Cm(t){if(null===t||"object"!==Qc(t))return null;if(t instanceof Element)return t;var e=Kp(t);for(var i in t)Object.prototype.hasOwnProperty.call(t,i)&&"object"==Qc(t[i])&&(e[i]=Cm(t[i]));return e}function Sm(t,e,i){var n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{},o=function(t){return null!=t},r=function(t){return null!==t&&"object"===Qc(t)},s=function(t){for(var e in t)if(Object.prototype.hasOwnProperty.call(t,e))return!1;return!0};if(!r(t))throw new Error("Parameter mergeTarget must be an object");if(!r(e))throw new Error("Parameter options must be an object");if(!o(i))throw new Error("Parameter option must have a value");if(!r(n))throw new Error("Parameter globalOptions must be an object");var a=function(t,e,i){r(t[i])||(t[i]={});var n=e[i],o=t[i];for(var s in n)Object.prototype.hasOwnProperty.call(n,s)&&(o[s]=n[s])},h=e[i],l=r(n)&&!s(n),d=l?n[i]:void 0,c=d?d.enabled:void 0;if(void 0!==h){if("boolean"==typeof h)return r(t[i])||(t[i]={}),void(t[i].enabled=h);if(null===h&&!r(t[i])){if(!o(d))return;t[i]=Kp(d)}if(r(h)){var u=!0;void 0!==h.enabled?u=h.enabled:void 0!==c&&(u=d.enabled),a(t,e,i),t[i].enabled=u}}}var Tm={linear:function(t){return t},easeInQuad:function(t){return t*t},easeOutQuad:function(t){return t*(2-t)},easeInOutQuad:function(t){return t<.5?2*t*t:(4-2*t)*t-1},easeInCubic:function(t){return t*t*t},easeOutCubic:function(t){return--t*t*t+1},easeInOutCubic:function(t){return t<.5?4*t*t*t:(t-1)*(2*t-2)*(2*t-2)+1},easeInQuart:function(t){return t*t*t*t},easeOutQuart:function(t){return 1- --t*t*t*t},easeInOutQuart:function(t){return t<.5?8*t*t*t*t:1-8*--t*t*t*t},easeInQuint:function(t){return t*t*t*t*t},easeOutQuint:function(t){return 1+--t*t*t*t*t},easeInOutQuint:function(t){return t<.5?16*t*t*t*t*t:1+16*--t*t*t*t*t}};function Mm(t,e){var i;lu(e)||(e=[e]);var n,o=Py(t);try{for(o.s();!(n=o.n()).done;){var r=n.value;if(r){i=r[e[0]];for(var s=1;s<e.length;s++)i&&(i=i[e[s]]);if(void 0!==i)break}}}catch(t){o.e(t)}finally{o.f()}return i}var Pm={black:"#000000",navy:"#000080",darkblue:"#00008B",mediumblue:"#0000CD",blue:"#0000FF",darkgreen:"#006400",green:"#008000",teal:"#008080",darkcyan:"#008B8B",deepskyblue:"#00BFFF",darkturquoise:"#00CED1",mediumspringgreen:"#00FA9A",lime:"#00FF00",springgreen:"#00FF7F",aqua:"#00FFFF",cyan:"#00FFFF",midnightblue:"#191970",dodgerblue:"#1E90FF",lightseagreen:"#20B2AA",forestgreen:"#228B22",seagreen:"#2E8B57",darkslategray:"#2F4F4F",limegreen:"#32CD32",mediumseagreen:"#3CB371",turquoise:"#40E0D0",royalblue:"#4169E1",steelblue:"#4682B4",darkslateblue:"#483D8B",mediumturquoise:"#48D1CC",indigo:"#4B0082",darkolivegreen:"#556B2F",cadetblue:"#5F9EA0",cornflowerblue:"#6495ED",mediumaquamarine:"#66CDAA",dimgray:"#696969",slateblue:"#6A5ACD",olivedrab:"#6B8E23",slategray:"#708090",lightslategray:"#778899",mediumslateblue:"#7B68EE",lawngreen:"#7CFC00",chartreuse:"#7FFF00",aquamarine:"#7FFFD4",maroon:"#800000",purple:"#800080",olive:"#808000",gray:"#808080",skyblue:"#87CEEB",lightskyblue:"#87CEFA",blueviolet:"#8A2BE2",darkred:"#8B0000",darkmagenta:"#8B008B",saddlebrown:"#8B4513",darkseagreen:"#8FBC8F",lightgreen:"#90EE90",mediumpurple:"#9370D8",darkviolet:"#9400D3",palegreen:"#98FB98",darkorchid:"#9932CC",yellowgreen:"#9ACD32",sienna:"#A0522D",brown:"#A52A2A",darkgray:"#A9A9A9",lightblue:"#ADD8E6",greenyellow:"#ADFF2F",paleturquoise:"#AFEEEE",lightsteelblue:"#B0C4DE",powderblue:"#B0E0E6",firebrick:"#B22222",darkgoldenrod:"#B8860B",mediumorchid:"#BA55D3",rosybrown:"#BC8F8F",darkkhaki:"#BDB76B",silver:"#C0C0C0",mediumvioletred:"#C71585",indianred:"#CD5C5C",peru:"#CD853F",chocolate:"#D2691E",tan:"#D2B48C",lightgrey:"#D3D3D3",palevioletred:"#D87093",thistle:"#D8BFD8",orchid:"#DA70D6",goldenrod:"#DAA520",crimson:"#DC143C",gainsboro:"#DCDCDC",plum:"#DDA0DD",burlywood:"#DEB887",lightcyan:"#E0FFFF",lavender:"#E6E6FA",darksalmon:"#E9967A",violet:"#EE82EE",palegoldenrod:"#EEE8AA",lightcoral:"#F08080",khaki:"#F0E68C",aliceblue:"#F0F8FF",honeydew:"#F0FFF0",azure:"#F0FFFF",sandybrown:"#F4A460",wheat:"#F5DEB3",beige:"#F5F5DC",whitesmoke:"#F5F5F5",mintcream:"#F5FFFA",ghostwhite:"#F8F8FF",salmon:"#FA8072",antiquewhite:"#FAEBD7",linen:"#FAF0E6",lightgoldenrodyellow:"#FAFAD2",oldlace:"#FDF5E6",red:"#FF0000",fuchsia:"#FF00FF",magenta:"#FF00FF",deeppink:"#FF1493",orangered:"#FF4500",tomato:"#FF6347",hotpink:"#FF69B4",coral:"#FF7F50",darkorange:"#FF8C00",lightsalmon:"#FFA07A",orange:"#FFA500",lightpink:"#FFB6C1",pink:"#FFC0CB",gold:"#FFD700",peachpuff:"#FFDAB9",navajowhite:"#FFDEAD",moccasin:"#FFE4B5",bisque:"#FFE4C4",mistyrose:"#FFE4E1",blanchedalmond:"#FFEBCD",papayawhip:"#FFEFD5",lavenderblush:"#FFF0F5",seashell:"#FFF5EE",cornsilk:"#FFF8DC",lemonchiffon:"#FFFACD",floralwhite:"#FFFAF0",snow:"#FFFAFA",yellow:"#FFFF00",lightyellow:"#FFFFE0",ivory:"#FFFFF0",white:"#FFFFFF"},Dm=function(){function t(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:1;Yd(this,t),this.pixelRatio=e,this.generated=!1,this.centerCoordinates={x:144.5,y:144.5},this.r=289*.49,this.color={r:255,g:255,b:255,a:1},this.hueCircle=void 0,this.initialColor={r:255,g:255,b:255,a:1},this.previousColor=void 0,this.applied=!1,this.updateCallback=function(){},this.closeCallback=function(){},this._create()}return Kd(t,[{key:"insertTo",value:function(t){void 0!==this.hammer&&(this.hammer.destroy(),this.hammer=void 0),this.container=t,this.container.appendChild(this.frame),this._bindHammer(),this._setSize()}},{key:"setUpdateCallback",value:function(t){if("function"!=typeof t)throw new Error("Function attempted to set as colorPicker update callback is not a function.");this.updateCallback=t}},{key:"setCloseCallback",value:function(t){if("function"!=typeof t)throw new Error("Function attempted to set as colorPicker closing callback is not a function.");this.closeCallback=t}},{key:"_isColorString",value:function(t){if("string"==typeof t)return Pm[t]}},{key:"setColor",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];if("none"!==t){var i,n=this._isColorString(t);if(void 0!==n&&(t=n),!0===$y(t)){if(!0===Em(t)){var o=t.substr(4).substr(0,t.length-5).split(",");i={r:o[0],g:o[1],b:o[2],a:1}}else if(!0===Om(t)){var r=t.substr(5).substr(0,t.length-6).split(",");i={r:r[0],g:r[1],b:r[2],a:r[3]}}else if(!0===xm(t)){var s=fm(t);i={r:s.r,g:s.g,b:s.b,a:1}}}else if(t instanceof Object&&void 0!==t.r&&void 0!==t.g&&void 0!==t.b){var a=void 0!==t.a?t.a:"1.0";i={r:t.r,g:t.g,b:t.b,a:a}}if(void 0===i)throw new Error("Unknown color passed to the colorPicker. Supported are strings: rgb, hex, rgba. Object: rgb ({r:r,g:g,b:b,[a:a]}). Supplied: "+gv(t));this._setColor(i,e)}}},{key:"show",value:function(){void 0!==this.closeCallback&&(this.closeCallback(),this.closeCallback=void 0),this.applied=!1,this.frame.style.display="block",this._generateHueCircle()}},{key:"_hide",value:function(){var t=this,e=!(arguments.length>0&&void 0!==arguments[0])||arguments[0];!0===e&&(this.previousColor=un({},this.color)),!0===this.applied&&this.updateCallback(this.initialColor),this.frame.style.display="none",Sv((function(){void 0!==t.closeCallback&&(t.closeCallback(),t.closeCallback=void 0)}),0)}},{key:"_save",value:function(){this.updateCallback(this.color),this.applied=!1,this._hide()}},{key:"_apply",value:function(){this.applied=!0,this.updateCallback(this.color),this._updatePicker(this.color)}},{key:"_loadLast",value:function(){void 0!==this.previousColor?this.setColor(this.previousColor,!1):alert("There is no last color to load...")}},{key:"_setColor",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];!0===e&&(this.initialColor=un({},t)),this.color=t;var i=ym(t.r,t.g,t.b),n=2*Math.PI,o=this.r*i.s,r=this.centerCoordinates.x+o*Math.sin(n*i.h),s=this.centerCoordinates.y+o*Math.cos(n*i.h);this.colorPickerSelector.style.left=r-.5*this.colorPickerSelector.clientWidth+"px",this.colorPickerSelector.style.top=s-.5*this.colorPickerSelector.clientHeight+"px",this._updatePicker(t)}},{key:"_setOpacity",value:function(t){this.color.a=t/100,this._updatePicker(this.color)}},{key:"_setBrightness",value:function(t){var e=ym(this.color.r,this.color.g,this.color.b);e.v=t/100;var i=wm(e.h,e.s,e.v);i.a=this.color.a,this.color=i,this._updatePicker()}},{key:"_updatePicker",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.color,e=ym(t.r,t.g,t.b),i=this.colorPickerCanvas.getContext("2d");void 0===this.pixelRation&&(this.pixelRatio=(window.devicePixelRatio||1)/(i.webkitBackingStorePixelRatio||i.mozBackingStorePixelRatio||i.msBackingStorePixelRatio||i.oBackingStorePixelRatio||i.backingStorePixelRatio||1)),i.setTransform(this.pixelRatio,0,0,this.pixelRatio,0,0);var n=this.colorPickerCanvas.clientWidth,o=this.colorPickerCanvas.clientHeight;i.clearRect(0,0,n,o),i.putImageData(this.hueCircle,0,0),i.fillStyle="rgba(0,0,0,"+(1-e.v)+")",i.circle(this.centerCoordinates.x,this.centerCoordinates.y,this.r),jv(i).call(i),this.brightnessRange.value=100*e.v,this.opacityRange.value=100*t.a,this.initialColorDiv.style.backgroundColor="rgba("+this.initialColor.r+","+this.initialColor.g+","+this.initialColor.b+","+this.initialColor.a+")",this.newColorDiv.style.backgroundColor="rgba("+this.color.r+","+this.color.g+","+this.color.b+","+this.color.a+")"}},{key:"_setSize",value:function(){this.colorPickerCanvas.style.width="100%",this.colorPickerCanvas.style.height="100%",this.colorPickerCanvas.width=289*this.pixelRatio,this.colorPickerCanvas.height=289*this.pixelRatio}},{key:"_create",value:function(){var t,e,i,n;if(this.frame=document.createElement("div"),this.frame.className="vis-color-picker",this.colorPickerDiv=document.createElement("div"),this.colorPickerSelector=document.createElement("div"),this.colorPickerSelector.className="vis-selector",this.colorPickerDiv.appendChild(this.colorPickerSelector),this.colorPickerCanvas=document.createElement("canvas"),this.colorPickerDiv.appendChild(this.colorPickerCanvas),this.colorPickerCanvas.getContext){var o=this.colorPickerCanvas.getContext("2d");this.pixelRatio=(window.devicePixelRatio||1)/(o.webkitBackingStorePixelRatio||o.mozBackingStorePixelRatio||o.msBackingStorePixelRatio||o.oBackingStorePixelRatio||o.backingStorePixelRatio||1),this.colorPickerCanvas.getContext("2d").setTransform(this.pixelRatio,0,0,this.pixelRatio,0,0)}else{var r=document.createElement("DIV");r.style.color="red",r.style.fontWeight="bold",r.style.padding="10px",r.innerText="Error: your browser does not support HTML canvas",this.colorPickerCanvas.appendChild(r)}this.colorPickerDiv.className="vis-color",this.opacityDiv=document.createElement("div"),this.opacityDiv.className="vis-opacity",this.brightnessDiv=document.createElement("div"),this.brightnessDiv.className="vis-brightness",this.arrowDiv=document.createElement("div"),this.arrowDiv.className="vis-arrow",this.opacityRange=document.createElement("input");try{this.opacityRange.type="range",this.opacityRange.min="0",this.opacityRange.max="100"}catch(t){}this.opacityRange.value="100",this.opacityRange.className="vis-range",this.brightnessRange=document.createElement("input");try{this.brightnessRange.type="range",this.brightnessRange.min="0",this.brightnessRange.max="100"}catch(t){}this.brightnessRange.value="100",this.brightnessRange.className="vis-range",this.opacityDiv.appendChild(this.opacityRange),this.brightnessDiv.appendChild(this.brightnessRange);var s=this;this.opacityRange.onchange=function(){s._setOpacity(this.value)},this.opacityRange.oninput=function(){s._setOpacity(this.value)},this.brightnessRange.onchange=function(){s._setBrightness(this.value)},this.brightnessRange.oninput=function(){s._setBrightness(this.value)},this.brightnessLabel=document.createElement("div"),this.brightnessLabel.className="vis-label vis-brightness",this.brightnessLabel.innerText="brightness:",this.opacityLabel=document.createElement("div"),this.opacityLabel.className="vis-label vis-opacity",this.opacityLabel.innerText="opacity:",this.newColorDiv=document.createElement("div"),this.newColorDiv.className="vis-new-color",this.newColorDiv.innerText="new",this.initialColorDiv=document.createElement("div"),this.initialColorDiv.className="vis-initial-color",this.initialColorDiv.innerText="initial",this.cancelButton=document.createElement("div"),this.cancelButton.className="vis-button vis-cancel",this.cancelButton.innerText="cancel",this.cancelButton.onclick=zn(t=this._hide).call(t,this,!1),this.applyButton=document.createElement("div"),this.applyButton.className="vis-button vis-apply",this.applyButton.innerText="apply",this.applyButton.onclick=zn(e=this._apply).call(e,this),this.saveButton=document.createElement("div"),this.saveButton.className="vis-button vis-save",this.saveButton.innerText="save",this.saveButton.onclick=zn(i=this._save).call(i,this),this.loadButton=document.createElement("div"),this.loadButton.className="vis-button vis-load",this.loadButton.innerText="load last",this.loadButton.onclick=zn(n=this._loadLast).call(n,this),this.frame.appendChild(this.colorPickerDiv),this.frame.appendChild(this.arrowDiv),this.frame.appendChild(this.brightnessLabel),this.frame.appendChild(this.brightnessDiv),this.frame.appendChild(this.opacityLabel),this.frame.appendChild(this.opacityDiv),this.frame.appendChild(this.newColorDiv),this.frame.appendChild(this.initialColorDiv),this.frame.appendChild(this.cancelButton),this.frame.appendChild(this.applyButton),this.frame.appendChild(this.saveButton),this.frame.appendChild(this.loadButton)}},{key:"_bindHammer",value:function(){var t=this;this.drag={},this.pinch={},this.hammer=new Hy(this.colorPickerCanvas),this.hammer.get("pinch").set({enable:!0}),this.hammer.on("hammer.input",(function(e){e.isFirst&&t._moveSelector(e)})),this.hammer.on("tap",(function(e){t._moveSelector(e)})),this.hammer.on("panstart",(function(e){t._moveSelector(e)})),this.hammer.on("panmove",(function(e){t._moveSelector(e)})),this.hammer.on("panend",(function(e){t._moveSelector(e)}))}},{key:"_generateHueCircle",value:function(){if(!1===this.generated){var t=this.colorPickerCanvas.getContext("2d");void 0===this.pixelRation&&(this.pixelRatio=(window.devicePixelRatio||1)/(t.webkitBackingStorePixelRatio||t.mozBackingStorePixelRatio||t.msBackingStorePixelRatio||t.oBackingStorePixelRatio||t.backingStorePixelRatio||1)),t.setTransform(this.pixelRatio,0,0,this.pixelRatio,0,0);var e,i,n,o,r=this.colorPickerCanvas.clientWidth,s=this.colorPickerCanvas.clientHeight;t.clearRect(0,0,r,s),this.centerCoordinates={x:.5*r,y:.5*s},this.r=.49*r;var a,h=2*Math.PI/360,l=1/this.r;for(n=0;n<360;n++)for(o=0;o<this.r;o++)e=this.centerCoordinates.x+o*Math.sin(h*n),i=this.centerCoordinates.y+o*Math.cos(h*n),a=wm(.002777777777777778*n,o*l,1),t.fillStyle="rgb("+a.r+","+a.g+","+a.b+")",t.fillRect(e-.5,i-.5,2,2);t.strokeStyle="rgba(0,0,0,1)",t.circle(this.centerCoordinates.x,this.centerCoordinates.y,this.r),t.stroke(),this.hueCircle=t.getImageData(0,0,r,s)}this.generated=!0}},{key:"_moveSelector",value:function(t){var e=this.colorPickerDiv.getBoundingClientRect(),i=t.center.x-e.left,n=t.center.y-e.top,o=.5*this.colorPickerDiv.clientHeight,r=.5*this.colorPickerDiv.clientWidth,s=i-r,a=n-o,h=Math.atan2(s,a),l=.98*Math.min(Math.sqrt(s*s+a*a),r),d=Math.cos(h)*l+o,c=Math.sin(h)*l+r;this.colorPickerSelector.style.top=d-.5*this.colorPickerSelector.clientHeight+"px",this.colorPickerSelector.style.left=c-.5*this.colorPickerSelector.clientWidth+"px";var u=h/(2*Math.PI);u=u<0?u+1:u;var f=l/this.r,p=ym(this.color.r,this.color.g,this.color.b);p.h=u,p.s=f;var v=wm(p.h,p.s,p.v);v.a=this.color.a,this.color=v,this.initialColorDiv.style.backgroundColor="rgba("+this.initialColor.r+","+this.initialColor.g+","+this.initialColor.b+","+this.initialColor.a+")",this.newColorDiv.style.backgroundColor="rgba("+this.color.r+","+this.color.g+","+this.color.b+","+this.color.a+")"}}]),t}();function Im(){for(var t=arguments.length,e=new Array(t),i=0;i<t;i++)e[i]=arguments[i];if(e.length<1)throw new TypeError("Invalid arguments.");if(1===e.length)return document.createTextNode(e[0]);var n=document.createElement(e[0]);return n.appendChild(Im.apply(void 0,Jc(au(e).call(e,1)))),n}var Bm,zm=function(){function t(e,i,n){var o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1,r=arguments.length>4&&void 0!==arguments[4]?arguments[4]:function(){return!1};Yd(this,t),this.parent=e,this.changedOptions=[],this.container=i,this.allowCreation=!1,this.hideOption=r,this.options={},this.initialized=!1,this.popupCounter=0,this.defaultOptions={enabled:!1,filter:!0,container:void 0,showButton:!0},un(this.options,this.defaultOptions),this.configureOptions=n,this.moduleOptions={},this.domElements=[],this.popupDiv={},this.popupLimit=5,this.popupHistory={},this.colorPicker=new Dm(o),this.wrapper=void 0}return Kd(t,[{key:"setOptions",value:function(t){if(void 0!==t){this.popupHistory={},this._removePopup();var e=!0;if("string"==typeof t)this.options.filter=t;else if(lu(t))this.options.filter=t.join();else if("object"===Qc(t)){if(null==t)throw new TypeError("options cannot be null");void 0!==t.container&&(this.options.container=t.container),void 0!==Xf(t)&&(this.options.filter=Xf(t)),void 0!==t.showButton&&(this.options.showButton=t.showButton),void 0!==t.enabled&&(e=t.enabled)}else"boolean"==typeof t?(this.options.filter=!0,e=t):"function"==typeof t&&(this.options.filter=t,e=!0);!1===Xf(this.options)&&(e=!1),this.options.enabled=e}this._clean()}},{key:"setModuleOptions",value:function(t){this.moduleOptions=t,!0===this.options.enabled&&(this._clean(),void 0!==this.options.container&&(this.container=this.options.container),this._create())}},{key:"_create",value:function(){this._clean(),this.changedOptions=[];var t=Xf(this.options),e=0,i=!1;for(var n in this.configureOptions)Object.prototype.hasOwnProperty.call(this.configureOptions,n)&&(this.allowCreation=!1,i=!1,"function"==typeof t?i=(i=t(n,[]))||this._handleObject(this.configureOptions[n],[n],!0):!0!==t&&-1===Fp(t).call(t,n)||(i=!0),!1!==i&&(this.allowCreation=!0,e>0&&this._makeItem([]),this._makeHeader(n),this._handleObject(this.configureOptions[n],[n])),e++);this._makeButton(),this._push()}},{key:"_push",value:function(){this.wrapper=document.createElement("div"),this.wrapper.className="vis-configuration-wrapper",this.container.appendChild(this.wrapper);for(var t=0;t<this.domElements.length;t++)this.wrapper.appendChild(this.domElements[t]);this._showPopupIfNeeded()}},{key:"_clean",value:function(){for(var t=0;t<this.domElements.length;t++)this.wrapper.removeChild(this.domElements[t]);void 0!==this.wrapper&&(this.container.removeChild(this.wrapper),this.wrapper=void 0),this.domElements=[],this._removePopup()}},{key:"_getValue",value:function(t){for(var e=this.moduleOptions,i=0;i<t.length;i++){if(void 0===e[t[i]]){e=void 0;break}e=e[t[i]]}return e}},{key:"_makeItem",value:function(t){if(!0===this.allowCreation){var e=document.createElement("div");e.className="vis-configuration vis-config-item vis-config-s"+t.length;for(var i=arguments.length,n=new Array(i>1?i-1:0),o=1;o<i;o++)n[o-1]=arguments[o];return Fu(n).call(n,(function(t){e.appendChild(t)})),this.domElements.push(e),this.domElements.length}return 0}},{key:"_makeHeader",value:function(t){var e=document.createElement("div");e.className="vis-configuration vis-config-header",e.innerText=t,this._makeItem([],e)}},{key:"_makeLabel",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]&&arguments[2],n=document.createElement("div");if(n.className="vis-configuration vis-config-label vis-config-s"+e.length,!0===i){for(;n.firstChild;)n.removeChild(n.firstChild);n.appendChild(Im("i","b",t))}else n.innerText=t+":";return n}},{key:"_makeDropdown",value:function(t,e,i){var n=document.createElement("select");n.className="vis-configuration vis-config-select";var o=0;void 0!==e&&-1!==Fp(t).call(t,e)&&(o=Fp(t).call(t,e));for(var r=0;r<t.length;r++){var s=document.createElement("option");s.value=t[r],r===o&&(s.selected="selected"),s.innerText=t[r],n.appendChild(s)}var a=this;n.onchange=function(){a._update(this.value,i)};var h=this._makeLabel(i[i.length-1],i);this._makeItem(i,h,n)}},{key:"_makeRange",value:function(t,e,i){var n=t[0],o=t[1],r=t[2],s=t[3],a=document.createElement("input");a.className="vis-configuration vis-config-range";try{a.type="range",a.min=o,a.max=r}catch(t){}a.step=s;var h="",l=0;if(void 0!==e){var d=1.2;e<0&&e*d<o?(a.min=Math.ceil(e*d),l=a.min,h="range increased"):e/d<o&&(a.min=Math.ceil(e/d),l=a.min,h="range increased"),e*d>r&&1!==r&&(a.max=Math.ceil(e*d),l=a.max,h="range increased"),a.value=e}else a.value=n;var c=document.createElement("input");c.className="vis-configuration vis-config-rangeinput",c.value=a.value;var u=this;a.onchange=function(){c.value=this.value,u._update(Number(this.value),i)},a.oninput=function(){c.value=this.value};var f=this._makeLabel(i[i.length-1],i),p=this._makeItem(i,f,a,c);""!==h&&this.popupHistory[p]!==l&&(this.popupHistory[p]=l,this._setupPopup(h,p))}},{key:"_makeButton",value:function(){var t=this;if(!0===this.options.showButton){var e=document.createElement("div");e.className="vis-configuration vis-config-button",e.innerText="generate options",e.onclick=function(){t._printOptions()},e.onmouseover=function(){e.className="vis-configuration vis-config-button hover"},e.onmouseout=function(){e.className="vis-configuration vis-config-button"},this.optionsContainer=document.createElement("div"),this.optionsContainer.className="vis-configuration vis-config-option-container",this.domElements.push(this.optionsContainer),this.domElements.push(e)}}},{key:"_setupPopup",value:function(t,e){var i=this;if(!0===this.initialized&&!0===this.allowCreation&&this.popupCounter<this.popupLimit){var n=document.createElement("div");n.id="vis-configuration-popup",n.className="vis-configuration-popup",n.innerText=t,n.onclick=function(){i._removePopup()},this.popupCounter+=1,this.popupDiv={html:n,index:e}}}},{key:"_removePopup",value:function(){void 0!==this.popupDiv.html&&(this.popupDiv.html.parentNode.removeChild(this.popupDiv.html),clearTimeout(this.popupDiv.hideTimeout),clearTimeout(this.popupDiv.deleteTimeout),this.popupDiv={})}},{key:"_showPopupIfNeeded",value:function(){var t=this;if(void 0!==this.popupDiv.html){var e=this.domElements[this.popupDiv.index].getBoundingClientRect();this.popupDiv.html.style.left=e.left+"px",this.popupDiv.html.style.top=e.top-30+"px",document.body.appendChild(this.popupDiv.html),this.popupDiv.hideTimeout=Sv((function(){t.popupDiv.html.style.opacity=0}),1500),this.popupDiv.deleteTimeout=Sv((function(){t._removePopup()}),1800)}}},{key:"_makeCheckbox",value:function(t,e,i){var n=document.createElement("input");n.type="checkbox",n.className="vis-configuration vis-config-checkbox",n.checked=t,void 0!==e&&(n.checked=e,e!==t&&("object"===Qc(t)?e!==t.enabled&&this.changedOptions.push({path:i,value:e}):this.changedOptions.push({path:i,value:e})));var o=this;n.onchange=function(){o._update(this.checked,i)};var r=this._makeLabel(i[i.length-1],i);this._makeItem(i,r,n)}},{key:"_makeTextInput",value:function(t,e,i){var n=document.createElement("input");n.type="text",n.className="vis-configuration vis-config-text",n.value=e,e!==t&&this.changedOptions.push({path:i,value:e});var o=this;n.onchange=function(){o._update(this.value,i)};var r=this._makeLabel(i[i.length-1],i);this._makeItem(i,r,n)}},{key:"_makeColorField",value:function(t,e,i){var n=this,o=t[1],r=document.createElement("div");"none"!==(e=void 0===e?o:e)?(r.className="vis-configuration vis-config-colorBlock",r.style.backgroundColor=e):r.className="vis-configuration vis-config-colorBlock none",e=void 0===e?o:e,r.onclick=function(){n._showColorPicker(e,r,i)};var s=this._makeLabel(i[i.length-1],i);this._makeItem(i,s,r)}},{key:"_showColorPicker",value:function(t,e,i){var n=this;e.onclick=function(){},this.colorPicker.insertTo(e),this.colorPicker.show(),this.colorPicker.setColor(t),this.colorPicker.setUpdateCallback((function(t){var o="rgba("+t.r+","+t.g+","+t.b+","+t.a+")";e.style.backgroundColor=o,n._update(o,i)})),this.colorPicker.setCloseCallback((function(){e.onclick=function(){n._showColorPicker(t,e,i)}}))}},{key:"_handleObject",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:[],i=arguments.length>2&&void 0!==arguments[2]&&arguments[2],n=!1,o=Xf(this.options),r=!1;for(var s in t)if(Object.prototype.hasOwnProperty.call(t,s)){n=!0;var a=t[s],h=om(e,s);if("function"==typeof o&&!1===(n=o(s,e))&&!lu(a)&&"string"!=typeof a&&"boolean"!=typeof a&&a instanceof Object&&(this.allowCreation=!1,n=this._handleObject(a,h,!0),this.allowCreation=!1===i),!1!==n){r=!0;var l=this._getValue(h);if(lu(a))this._handleArray(a,l,h);else if("string"==typeof a)this._makeTextInput(a,l,h);else if("boolean"==typeof a)this._makeCheckbox(a,l,h);else if(a instanceof Object){if(!this.hideOption(e,s,this.moduleOptions))if(void 0!==a.enabled){var d=om(h,"enabled"),c=this._getValue(d);if(!0===c){var u=this._makeLabel(s,h,!0);this._makeItem(h,u),r=this._handleObject(a,h)||r}else this._makeCheckbox(a,c,h)}else{var f=this._makeLabel(s,h,!0);this._makeItem(h,f),r=this._handleObject(a,h)||r}}else console.error("dont know how to handle",a,s,h)}}return r}},{key:"_handleArray",value:function(t,e,i){"string"==typeof t[0]&&"color"===t[0]?(this._makeColorField(t,e,i),t[1]!==e&&this.changedOptions.push({path:i,value:e})):"string"==typeof t[0]?(this._makeDropdown(t,e,i),t[0]!==e&&this.changedOptions.push({path:i,value:e})):"number"==typeof t[0]&&(this._makeRange(t,e,i),t[0]!==e&&this.changedOptions.push({path:i,value:Number(e)}))}},{key:"_update",value:function(t,e){var i=this._constructOptions(t,e);this.parent.body&&this.parent.body.emitter&&this.parent.body.emitter.emit&&this.parent.body.emitter.emit("configChange",i),this.initialized=!0,this.parent.setOptions(i)}},{key:"_constructOptions",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},n=i;t="false"!==(t="true"===t||t)&&t;for(var o=0;o<e.length;o++)"global"!==e[o]&&(void 0===n[e[o]]&&(n[e[o]]={}),o!==e.length-1?n=n[e[o]]:n[e[o]]=t);return i}},{key:"_printOptions",value:function(){for(var t=this.getOptions();this.optionsContainer.firstChild;)this.optionsContainer.removeChild(this.optionsContainer.firstChild);this.optionsContainer.appendChild(Im("pre","const options = "+gv(t,null,2)))}},{key:"getOptions",value:function(){for(var t={},e=0;e<this.changedOptions.length;e++)this._constructOptions(this.changedOptions[e].value,this.changedOptions[e].path,t);return t}}]),t}(),Nm=function(){function t(e,i){Yd(this,t),this.container=e,this.overflowMethod=i||"cap",this.x=0,this.y=0,this.padding=5,this.hidden=!1,this.frame=document.createElement("div"),this.frame.className="vis-tooltip",this.container.appendChild(this.frame)}return Kd(t,[{key:"setPosition",value:function(t,e){this.x=Ep(t),this.y=Ep(e)}},{key:"setText",value:function(t){if(t instanceof Element){for(;this.frame.firstChild;)this.frame.removeChild(this.frame.firstChild);this.frame.appendChild(t)}else this.frame.innerText=t}},{key:"show",value:function(t){if(void 0===t&&(t=!0),!0===t){var e=this.frame.clientHeight,i=this.frame.clientWidth,n=this.frame.parentNode.clientHeight,o=this.frame.parentNode.clientWidth,r=0,s=0;if("flip"==this.overflowMethod){var a=!1,h=!0;this.y-e<this.padding&&(h=!1),this.x+i>o-this.padding&&(a=!0),r=a?this.x-i:this.x,s=h?this.y-e:this.y}else(s=this.y-e)+e+this.padding>n&&(s=n-e-this.padding),s<this.padding&&(s=this.padding),(r=this.x)+i+this.padding>o&&(r=o-i-this.padding),r<this.padding&&(r=this.padding);this.frame.style.left=r+"px",this.frame.style.top=s+"px",this.frame.style.visibility="visible",this.hidden=!1}else this.hide()}},{key:"hide",value:function(){this.hidden=!0,this.frame.style.left="0",this.frame.style.top="0",this.frame.style.visibility="hidden"}},{key:"destroy",value:function(){this.frame.parentNode.removeChild(this.frame)}}]),t}(),Fm=!1,Am="background: #FFeeee; color: #dd0000",jm=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"validate",value:function(e,i,n){Fm=!1,Bm=i;var o=i;return void 0!==n&&(o=i[n]),t.parse(e,o,[]),Fm}},{key:"parse",value:function(e,i,n){for(var o in e)Object.prototype.hasOwnProperty.call(e,o)&&t.check(o,e,i,n)}},{key:"check",value:function(e,i,n,o){if(void 0!==n[e]||void 0!==n.__any__){var r=e,s=!0;void 0===n[e]&&void 0!==n.__any__&&(r="__any__",s="object"===t.getType(i[e]));var a=n[r];s&&void 0!==a.__type__&&(a=a.__type__),t.checkFields(e,i,n,r,a,o)}else t.getSuggestion(e,n,o)}},{key:"checkFields",value:function(e,i,n,o,r,s){var a=function(i){console.error("%c"+i+t.printLocation(s,e),Am)},h=t.getType(i[e]),l=r[h];void 0!==l?"array"===t.getType(l)&&-1===Fp(l).call(l,i[e])?(a('Invalid option detected in "'+e+'". Allowed values are:'+t.print(l)+' not "'+i[e]+'". '),Fm=!0):"object"===h&&"__any__"!==o&&(s=om(s,e),t.parse(i[e],n[o],s)):void 0===r.any&&(a('Invalid type received for "'+e+'". Expected: '+t.print(bu(r))+". Received ["+h+'] "'+i[e]+'"'),Fm=!0)}},{key:"getType",value:function(t){var e=Qc(t);return"object"===e?null===t?"null":t instanceof Boolean?"boolean":t instanceof Number?"number":t instanceof String?"string":lu(t)?"array":t instanceof Date?"date":void 0!==t.nodeType?"dom":!0===t._isAMomentObject?"moment":"object":"number"===e?"number":"boolean"===e?"boolean":"string"===e?"string":void 0===e?"undefined":e}},{key:"getSuggestion",value:function(e,i,n){var o,r=t.findInOptions(e,i,n,!1),s=t.findInOptions(e,Bm,[],!0);o=void 0!==r.indexMatch?" in "+t.printLocation(r.path,e,"")+'Perhaps it was incomplete? Did you mean: "'+r.indexMatch+'"?\n\n':s.distance<=4&&r.distance>s.distance?" in "+t.printLocation(r.path,e,"")+"Perhaps it was misplaced? Matching option found at: "+t.printLocation(s.path,s.closestMatch,""):r.distance<=8?'. Did you mean "'+r.closestMatch+'"?'+t.printLocation(r.path,e):". Did you mean one of these: "+t.print(bu(i))+t.printLocation(n,e),console.error('%cUnknown option detected: "'+e+'"'+o,Am),Fm=!0}},{key:"findInOptions",value:function(e,i,n){var o=arguments.length>3&&void 0!==arguments[3]&&arguments[3],r=1e9,s="",a=[],h=e.toLowerCase(),l=void 0;for(var d in i){var c=void 0;if(void 0!==i[d].__type__&&!0===o){var u=t.findInOptions(e,i[d],om(n,d));r>u.distance&&(s=u.closestMatch,a=u.path,r=u.distance,l=u.indexMatch)}else{var f;-1!==Fp(f=d.toLowerCase()).call(f,h)&&(l=d),r>(c=t.levenshteinDistance(e,d))&&(s=d,a=rm(n),r=c)}}return{closestMatch:s,path:a,distance:r,indexMatch:l}}},{key:"printLocation",value:function(t,e){for(var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:"Problem value found at: \n",n="\n\n"+i+"options = {\n",o=0;o<t.length;o++){for(var r=0;r<o+1;r++)n+="  ";n+=t[o]+": {\n"}for(var s=0;s<t.length+1;s++)n+="  ";n+=e+"\n";for(var a=0;a<t.length+1;a++){for(var h=0;h<t.length-a;h++)n+="  ";n+="}\n"}return n+"\n\n"}},{key:"print",value:function(t){return gv(t).replace(/(")|(\[)|(\])|(,"__type__")/g,"").replace(/(,)/g,", ")}},{key:"levenshteinDistance",value:function(t,e){if(0===t.length)return e.length;if(0===e.length)return t.length;var i,n,o=[];for(i=0;i<=e.length;i++)o[i]=[i];for(n=0;n<=t.length;n++)o[0][n]=n;for(i=1;i<=e.length;i++)for(n=1;n<=t.length;n++)e.charAt(i-1)==t.charAt(n-1)?o[i][n]=o[i-1][n-1]:o[i][n]=Math.min(o[i-1][n-1]+1,Math.min(o[i][n-1]+1,o[i-1][n]+1));return o[e.length][t.length]}}]),t}(),Rm=Wy,Lm=Dm,Hm=zm,Wm=Hy,qm=Nm,Vm=Am,Um=jm,Ym=Object.freeze({__proto__:null,Activator:Rm,Alea:jy,ColorPicker:Lm,Configurator:Hm,DELETE:Iy,HSVToHex:km,HSVToRGB:wm,Hammer:Wm,Popup:qm,RGBToHSV:ym,RGBToHex:vm,VALIDATOR_PRINT_STYLE:Vm,Validator:Um,addClassName:function(t,e){var i=t.className.split(" "),n=e.split(" ");i=su(i).call(i,Xf(n).call(n,(function(t){return!Nf(i).call(i,t)}))),t.className=i.join(" ")},addCssText:function(t,e){var i=mm(t.style.cssText),n=mm(e),o=My(My({},i),n);t.style.cssText=bm(o)},addEventListener:dm,binarySearchCustom:function(t,e,i,n){for(var o=0,r=0,s=t.length-1;r<=s&&o<1e4;){var a=Math.floor((r+s)/2),h=t[a],l=e(void 0===n?h[i]:h[i][n]);if(0==l)return a;-1==l?r=a+1:s=a-1,o++}return-1},binarySearchValue:function(t,e,i,n,o){var r,s,a,h,l=0,d=0,c=t.length-1;for(o=null!=o?o:function(t,e){return t==e?0:t<e?-1:1};d<=c&&l<1e4;){if(h=Math.floor(.5*(c+d)),r=t[Math.max(0,h-1)][i],s=t[h][i],a=t[Math.min(t.length-1,h+1)][i],0==o(s,e))return h;if(o(r,e)<0&&o(s,e)>0)return"before"==n?Math.max(0,h-1):h;if(o(s,e)<0&&o(a,e)>0)return"before"==n?h:Math.min(t.length-1,h+1);o(s,e)<0?d=h+1:c=h-1,l++}return-1},bridgeObject:Cm,copyAndExtendArray:om,copyArray:rm,deepExtend:nm,deepObjectAssign:zy,easingFunctions:Tm,equalArray:function(t,e){if(t.length!==e.length)return!1;for(var i=0,n=t.length;i<n;i++)if(t[i]!=e[i])return!1;return!0},extend:tm,fillIfDefined:Jy,forEach:hm,getAbsoluteLeft:sm,getAbsoluteRight:function(t){return t.getBoundingClientRect().right},getAbsoluteTop:am,getScrollBarWidth:function(){var t=document.createElement("p");t.style.width="100%",t.style.height="200px";var e=document.createElement("div");e.style.position="absolute",e.style.top="0px",e.style.left="0px",e.style.visibility="hidden",e.style.width="200px",e.style.height="150px",e.style.overflow="hidden",e.appendChild(t),document.body.appendChild(e);var i=t.offsetWidth;e.style.overflow="scroll";var n=t.offsetWidth;return i==n&&(n=e.clientWidth),document.body.removeChild(e),i-n},getTarget:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:window.event,e=null;return t&&(t.target?e=t.target:t.srcElement&&(e=t.srcElement)),e instanceof Element&&(null==e.nodeType||3!=e.nodeType||(e=e.parentNode)instanceof Element)?e:null},getType:function(t){var e=Qc(t);return"object"===e?null===t?"null":t instanceof Boolean?"Boolean":t instanceof Number?"Number":t instanceof String?"String":lu(t)?"Array":t instanceof Date?"Date":"Object":"number"===e?"Number":"boolean"===e?"Boolean":"string"===e?"String":void 0===e?"undefined":e},hasParent:function(t,e){for(var i=t;i;){if(i===e)return!0;if(!i.parentNode)return!1;i=i.parentNode}return!1},hexToHSV:_m,hexToRGB:fm,insertSort:function(t,e){for(var i=0;i<t.length;i++){var n=t[i],o=void 0;for(o=i;o>0&&e(n,t[o-1])<0;o--)t[o]=t[o-1];t[o]=n}return t},isDate:function(t){if(t instanceof Date)return!0;if($y(t)){if(qy.exec(t))return!0;if(!isNaN(Date.parse(t)))return!0}return!1},isNumber:Gy,isObject:Zy,isString:$y,isValidHex:xm,isValidRGB:Em,isValidRGBA:Om,mergeOptions:Sm,option:um,overrideOpacity:pm,parseColor:gm,preventDefault:function(t){t||(t=window.event),t&&(t.preventDefault?t.preventDefault():t.returnValue=!1)},pureDeepObjectAssign:By,recursiveDOMDelete:Ky,removeClassName:function(t,e){var i=t.className.split(" "),n=e.split(" ");i=Xf(i).call(i,(function(t){return!Nf(n).call(n,t)})),t.className=i.join(" ")},removeCssText:function(t,e){var i=mm(t.style.cssText),n=mm(e);for(var o in n)Object.prototype.hasOwnProperty.call(n,o)&&delete i[o];t.style.cssText=bm(i)},removeEventListener:cm,selectiveBridgeObject:function(t,e){if(null!==e&&"object"===Qc(e)){for(var i=Kp(e),n=0;n<t.length;n++)Object.prototype.hasOwnProperty.call(e,t[n])&&"object"==Qc(e[t[n]])&&(i[t[n]]=Cm(e[t[n]]));return i}return null},selectiveDeepExtend:em,selectiveExtend:function(t,e){if(!lu(t))throw new Error("Array with property names expected as first argument");for(var i=arguments.length,n=new Array(i>2?i-2:0),o=2;o<i;o++)n[o-2]=arguments[o];for(var r=0,s=n;r<s.length;r++)for(var a=s[r],h=0;h<t.length;h++){var l=t[h];a&&Object.prototype.hasOwnProperty.call(a,l)&&(e[l]=a[l])}return e},selectiveNotDeepExtend:im,throttle:function(t){var e=!1;return function(){e||(e=!0,requestAnimationFrame((function(){e=!1,t()})))}},toArray:lm,topMost:Mm,updateProperty:function(t,e,i){return t[e]!==i&&(t[e]=i,!0)}});function Xm(t){return eb=t,function(){var t={};ib=0,void(nb=eb.charAt(0)),pb(),"strict"===ob&&(t.strict=!0,pb());"graph"!==ob&&"digraph"!==ob||(t.type=ob,pb());rb===Qm&&(t.id=ob,pb());if("{"!=ob)throw wb("Angle bracket { expected");if(pb(),vb(t),"}"!=ob)throw wb("Angle bracket } expected");if(pb(),""!==ob)throw wb("End of file expected");return pb(),delete t.node,delete t.edge,delete t.graph,t}()}var Gm={fontsize:"font.size",fontcolor:"font.color",labelfontcolor:"font.color",fontname:"font.face",color:["color.border","color.background"],fillcolor:"color.background",tooltip:"title",labeltooltip:"title"},Km=Kp(Gm);Km.color="color.color",Km.style="dashes";var $m=0,Zm=1,Qm=2,Jm=3,tb={"{":!0,"}":!0,"[":!0,"]":!0,";":!0,"=":!0,",":!0,"->":!0,"--":!0},eb="",ib=0,nb="",ob="",rb=$m;function sb(){ib++,nb=eb.charAt(ib)}function ab(){return eb.charAt(ib+1)}function hb(t){var e=t.charCodeAt(0);return e<47?35===e||46===e:e<59?e>47:e<91?e>64:e<96?95===e:e<123&&e>96}function lb(t,e){if(t||(t={}),e)for(var i in e)e.hasOwnProperty(i)&&(t[i]=e[i]);return t}function db(t,e,i){for(var n=e.split("."),o=t;n.length;){var r=n.shift();n.length?(o[r]||(o[r]={}),o=o[r]):o[r]=i}}function cb(t,e){for(var i,n,o=null,r=[t],s=t;s.parent;)r.push(s.parent),s=s.parent;if(s.nodes)for(i=0,n=s.nodes.length;i<n;i++)if(e.id===s.nodes[i].id){o=s.nodes[i];break}for(o||(o={id:e.id},t.node&&(o.attr=lb(o.attr,t.node))),i=r.length-1;i>=0;i--){var a,h=r[i];h.nodes||(h.nodes=[]),-1===Fp(a=h.nodes).call(a,o)&&h.nodes.push(o)}e.attr&&(o.attr=lb(o.attr,e.attr))}function ub(t,e){if(t.edges||(t.edges=[]),t.edges.push(e),t.edge){var i=lb({},t.edge);e.attr=lb(i,e.attr)}}function fb(t,e,i,n,o){var r={from:e,to:i,type:n};return t.edge&&(r.attr=lb({},t.edge)),r.attr=lb(r.attr||{},o),null!=o&&o.hasOwnProperty("arrows")&&null!=o.arrows&&(r.arrows={to:{enabled:!0,type:o.arrows.type}},o.arrows=null),r}function pb(){for(rb=$m,ob="";" "===nb||"\t"===nb||"\n"===nb||"\r"===nb;)sb();do{var t=!1;if("#"===nb){for(var e=ib-1;" "===eb.charAt(e)||"\t"===eb.charAt(e);)e--;if("\n"===eb.charAt(e)||""===eb.charAt(e)){for(;""!=nb&&"\n"!=nb;)sb();t=!0}}if("/"===nb&&"/"===ab()){for(;""!=nb&&"\n"!=nb;)sb();t=!0}if("/"===nb&&"*"===ab()){for(;""!=nb;){if("*"===nb&&"/"===ab()){sb(),sb();break}sb()}t=!0}for(;" "===nb||"\t"===nb||"\n"===nb||"\r"===nb;)sb()}while(t);if(""!==nb){var i=nb+ab();if(tb[i])return rb=Zm,ob=i,sb(),void sb();if(tb[nb])return rb=Zm,ob=nb,void sb();if(hb(nb)||"-"===nb){for(ob+=nb,sb();hb(nb);)ob+=nb,sb();return"false"===ob?ob=!1:"true"===ob?ob=!0:isNaN(Number(ob))||(ob=Number(ob)),void(rb=Qm)}if('"'===nb){for(sb();""!=nb&&('"'!=nb||'"'===nb&&'"'===ab());)'"'===nb?(ob+=nb,sb()):"\\"===nb&&"n"===ab()?(ob+="\n",sb()):ob+=nb,sb();if('"'!=nb)throw wb('End of string " expected');return sb(),void(rb=Qm)}for(rb=Jm;""!=nb;)ob+=nb,sb();throw new SyntaxError('Syntax error in part "'+kb(ob,30)+'"')}rb=Zm}function vb(t){for(;""!==ob&&"}"!=ob;)gb(t),";"===ob&&pb()}function gb(t){var e=yb(t);if(e)mb(t,e);else{var i=function(t){if("node"===ob)return pb(),t.node=bb(),"node";if("edge"===ob)return pb(),t.edge=bb(),"edge";if("graph"===ob)return pb(),t.graph=bb(),"graph";return null}(t);if(!i){if(rb!=Qm)throw wb("Identifier expected");var n=ob;if(pb(),"="===ob){if(pb(),rb!=Qm)throw wb("Identifier expected");t[n]=ob,pb()}else!function(t,e){var i={id:e},n=bb();n&&(i.attr=n);cb(t,i),mb(t,e)}(t,n)}}}function yb(t){var e=null;if("subgraph"===ob&&((e={}).type="subgraph",pb(),rb===Qm&&(e.id=ob,pb())),"{"===ob){if(pb(),e||(e={}),e.parent=t,e.node=t.node,e.edge=t.edge,e.graph=t.graph,vb(e),"}"!=ob)throw wb("Angle bracket } expected");pb(),delete e.node,delete e.edge,delete e.graph,delete e.parent,t.subgraphs||(t.subgraphs=[]),t.subgraphs.push(e)}return e}function mb(t,e){for(;"->"===ob||"--"===ob;){var i,n=ob;pb();var o=yb(t);if(o)i=o;else{if(rb!=Qm)throw wb("Identifier or subgraph expected");cb(t,{id:i=ob}),pb()}ub(t,fb(t,e,i,n,bb())),e=i}}function bb(){for(var t,e,i=null,n={dashed:!0,solid:!1,dotted:[1,5]},o={dot:"circle",box:"box",crow:"crow",curve:"curve",icurve:"inv_curve",normal:"triangle",inv:"inv_triangle",diamond:"diamond",tee:"bar",vee:"vee"},r=new Array,s=new Array;"["===ob;){for(pb(),i={};""!==ob&&"]"!=ob;){if(rb!=Qm)throw wb("Attribute name expected");var a=ob;if(pb(),"="!=ob)throw wb("Equal sign = expected");if(pb(),rb!=Qm)throw wb("Attribute value expected");var h=ob;"style"===a&&(h=n[h]),"arrowhead"===a&&(a="arrows",h={to:{enabled:!0,type:o[h]}}),"arrowtail"===a&&(a="arrows",h={from:{enabled:!0,type:o[h]}}),r.push({attr:i,name:a,value:h}),s.push(a),pb(),","==ob&&pb()}if("]"!=ob)throw wb("Bracket ] expected");pb()}if(Nf(s).call(s,"dir")){var l={arrows:{}};for(t=0;t<r.length;t++)if("arrows"===r[t].name)if(null!=r[t].value.to)l.arrows.to=t;else{if(null==r[t].value.from)throw wb("Invalid value of arrows");l.arrows.from=t}else"dir"===r[t].name&&(l.dir=t);var d,c,u=r[l.dir].value;if(!Nf(s).call(s,"arrows"))if("both"===u)r.push({attr:r[l.dir].attr,name:"arrows",value:{to:{enabled:!0}}}),l.arrows.to=r.length-1,r.push({attr:r[l.dir].attr,name:"arrows",value:{from:{enabled:!0}}}),l.arrows.from=r.length-1;else if("forward"===u)r.push({attr:r[l.dir].attr,name:"arrows",value:{to:{enabled:!0}}}),l.arrows.to=r.length-1;else if("back"===u)r.push({attr:r[l.dir].attr,name:"arrows",value:{from:{enabled:!0}}}),l.arrows.from=r.length-1;else{if("none"!==u)throw wb('Invalid dir type "'+u+'"');r.push({attr:r[l.dir].attr,name:"arrows",value:""}),l.arrows.to=r.length-1}if("both"===u)l.arrows.to&&l.arrows.from?(c=r[l.arrows.to].value.to.type,d=r[l.arrows.from].value.from.type,r[l.arrows.to]={attr:r[l.arrows.to].attr,name:r[l.arrows.to].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}},ff(r).call(r,l.arrows.from,1)):l.arrows.to?(c=r[l.arrows.to].value.to.type,d="arrow",r[l.arrows.to]={attr:r[l.arrows.to].attr,name:r[l.arrows.to].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}}):l.arrows.from&&(c="arrow",d=r[l.arrows.from].value.from.type,r[l.arrows.from]={attr:r[l.arrows.from].attr,name:r[l.arrows.from].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}});else if("back"===u)l.arrows.to&&l.arrows.from?(c="",d=r[l.arrows.from].value.from.type,r[l.arrows.from]={attr:r[l.arrows.from].attr,name:r[l.arrows.from].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}}):l.arrows.to?(c="",d="arrow",l.arrows.from=l.arrows.to,r[l.arrows.from]={attr:r[l.arrows.from].attr,name:r[l.arrows.from].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}}):l.arrows.from&&(c="",d=r[l.arrows.from].value.from.type,r[l.arrows.to]={attr:r[l.arrows.from].attr,name:r[l.arrows.from].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}}),r[l.arrows.from]={attr:r[l.arrows.from].attr,name:r[l.arrows.from].name,value:{from:{enabled:!0,type:r[l.arrows.from].value.from.type}}};else if("none"===u){var f;r[f=l.arrows.to?l.arrows.to:l.arrows.from]={attr:r[f].attr,name:r[f].name,value:""}}else{if("forward"!==u)throw wb('Invalid dir type "'+u+'"');l.arrows.to&&l.arrows.from||l.arrows.to?(c=r[l.arrows.to].value.to.type,d="",r[l.arrows.to]={attr:r[l.arrows.to].attr,name:r[l.arrows.to].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}}):l.arrows.from&&(c="arrow",d="",l.arrows.to=l.arrows.from,r[l.arrows.to]={attr:r[l.arrows.to].attr,name:r[l.arrows.to].name,value:{to:{enabled:!0,type:c},from:{enabled:!0,type:d}}}),r[l.arrows.to]={attr:r[l.arrows.to].attr,name:r[l.arrows.to].name,value:{to:{enabled:!0,type:r[l.arrows.to].value.to.type}}}}ff(r).call(r,l.dir,1)}if(Nf(s).call(s,"penwidth")){var p=[];for(e=r.length,t=0;t<e;t++)"width"!==r[t].name&&("penwidth"===r[t].name&&(r[t].name="width"),p.push(r[t]));r=p}for(e=r.length,t=0;t<e;t++)db(r[t].attr,r[t].name,r[t].value);return i}function wb(t){return new SyntaxError(t+', got "'+kb(ob,30)+'" (char '+ib+")")}function kb(t,e){return t.length<=e?t:t.substr(0,27)+"..."}function _b(t,e,i){for(var n=e.split("."),o=n.pop(),r=t,s=0;s<n.length;s++){var a=n[s];a in r||(r[a]={}),r=r[a]}return r[o]=i,t}function xb(t,e){var i={};for(var n in t)if(t.hasOwnProperty(n)){var o=e[n];lu(o)?Fu(o).call(o,(function(e){_b(i,e,t[n])})):_b(i,"string"==typeof o?o:n,t[n])}return i}function Eb(t){var e,i=Xm(t),n={nodes:[],edges:[],options:{}};i.nodes&&Fu(e=i.nodes).call(e,(function(t){var e={id:t.id,label:String(t.label||t.id)};lb(e,xb(t.attr,Gm)),e.image&&(e.shape="image"),n.nodes.push(e)}));if(i.edges){var o,r=function(t){var e={from:t.from,to:t.to};return lb(e,xb(t.attr,Km)),null==e.arrows&&"->"===t.type&&(e.arrows="to"),e};Fu(o=i.edges).call(o,(function(t){var e,i,o,s,a,h,l;(e=t.from instanceof Object?t.from.nodes:{id:t.from},i=t.to instanceof Object?t.to.nodes:{id:t.to},t.from instanceof Object&&t.from.edges)&&Fu(o=t.from.edges).call(o,(function(t){var e=r(t);n.edges.push(e)}));(a=i,h=function(e,i){var o=fb(n,e.id,i.id,t.type,t.attr),s=r(o);n.edges.push(s)},lu(s=e)?Fu(s).call(s,(function(t){lu(a)?Fu(a).call(a,(function(e){h(t,e)})):h(t,a)})):lu(a)?Fu(a).call(a,(function(t){h(s,t)})):h(s,a),t.to instanceof Object&&t.to.edges)&&Fu(l=t.to.edges).call(l,(function(t){var e=r(t);n.edges.push(e)}))}))}return i.attr&&(n.options=i.attr),n}var Ob=Object.freeze({__proto__:null,parseDOT:Xm,DOTToGraph:Eb});function Cb(t,e){var i,n={edges:{inheritColor:!1},nodes:{fixed:!1,parseColor:!1}};null!=e&&(null!=e.fixed&&(n.nodes.fixed=e.fixed),null!=e.parseColor&&(n.nodes.parseColor=e.parseColor),null!=e.inheritColor&&(n.edges.inheritColor=e.inheritColor));var o=t.edges,r=gu(o).call(o,(function(t){var e={from:t.source,id:t.id,to:t.target};return null!=t.attributes&&(e.attributes=t.attributes),null!=t.label&&(e.label=t.label),null!=t.attributes&&null!=t.attributes.title&&(e.title=t.attributes.title),"Directed"===t.type&&(e.arrows="to"),t.color&&!1===n.edges.inheritColor&&(e.color=t.color),e}));return{nodes:gu(i=t.nodes).call(i,(function(t){var e={id:t.id,fixed:n.nodes.fixed&&null!=t.x&&null!=t.y};return null!=t.attributes&&(e.attributes=t.attributes),null!=t.label&&(e.label=t.label),null!=t.size&&(e.size=t.size),null!=t.attributes&&null!=t.attributes.title&&(e.title=t.attributes.title),null!=t.title&&(e.title=t.title),null!=t.x&&(e.x=t.x),null!=t.y&&(e.y=t.y),null!=t.color&&(!0===n.nodes.parseColor?e.color=t.color:e.color={background:t.color,border:t.color,highlight:{background:t.color,border:t.color},hover:{background:t.color,border:t.color}}),e})),edges:r}}var Sb=Object.freeze({__proto__:null,parseGephi:Cb}),Tb=Object.freeze({__proto__:null,en:{addDescription:"Click in an empty space to place a new node.",addEdge:"Add Edge",addNode:"Add Node",back:"Back",close:"Close",createEdgeError:"Cannot link edges to a cluster.",del:"Delete selected",deleteClusterError:"Clusters cannot be deleted.",edgeDescription:"Click on a node and drag the edge to another node to connect them.",edit:"Edit",editClusterError:"Clusters cannot be edited.",editEdge:"Edit Edge",editEdgeDescription:"Click on the control points and drag them to a node to connect to it.",editNode:"Edit Node"},de:{addDescription:"Klicke auf eine freie Stelle, um einen neuen Knoten zu plazieren.",addEdge:"Kante hinzufgen",addNode:"Knoten hinzufgen",back:"Zurck",close:"Schlieen",createEdgeError:"Es ist nicht mglich, Kanten mit Clustern zu verbinden.",del:"Lsche Auswahl",deleteClusterError:"Cluster knnen nicht gelscht werden.",edgeDescription:"Klicke auf einen Knoten und ziehe die Kante zu einem anderen Knoten, um diese zu verbinden.",edit:"Editieren",editClusterError:"Cluster knnen nicht editiert werden.",editEdge:"Kante editieren",editEdgeDescription:"Klicke auf die Verbindungspunkte und ziehe diese auf einen Knoten, um sie zu verbinden.",editNode:"Knoten editieren"},es:{addDescription:"Haga clic en un lugar vaco para colocar un nuevo nodo.",addEdge:"Aadir arista",addNode:"Aadir nodo",back:"Atrs",close:"Cerrar",createEdgeError:"No se puede conectar una arista a un grupo.",del:"Eliminar seleccin",deleteClusterError:"No es posible eliminar grupos.",edgeDescription:"Haga clic en un nodo y arrastre la arista hacia otro nodo para conectarlos.",edit:"Editar",editClusterError:"No es posible editar grupos.",editEdge:"Editar arista",editEdgeDescription:"Haga clic en un punto de control y arrastrelo a un nodo para conectarlo.",editNode:"Editar nodo"},it:{addDescription:"Clicca per aggiungere un nuovo nodo",addEdge:"Aggiungi un vertice",addNode:"Aggiungi un nodo",back:"Indietro",close:"Chiudere",createEdgeError:"Non si possono collegare vertici ad un cluster",del:"Cancella la selezione",deleteClusterError:"I cluster non possono essere cancellati",edgeDescription:"Clicca su un nodo e trascinalo ad un altro nodo per connetterli.",edit:"Modifica",editClusterError:"I clusters non possono essere modificati.",editEdge:"Modifica il vertice",editEdgeDescription:"Clicca sui Punti di controllo e trascinali ad un nodo per connetterli.",editNode:"Modifica il nodo"},nl:{addDescription:"Klik op een leeg gebied om een nieuwe node te maken.",addEdge:"Link toevoegen",addNode:"Node toevoegen",back:"Terug",close:"Sluiten",createEdgeError:"Kan geen link maken naar een cluster.",del:"Selectie verwijderen",deleteClusterError:"Clusters kunnen niet worden verwijderd.",edgeDescription:"Klik op een node en sleep de link naar een andere node om ze te verbinden.",edit:"Wijzigen",editClusterError:"Clusters kunnen niet worden aangepast.",editEdge:"Link wijzigen",editEdgeDescription:"Klik op de verbindingspunten en sleep ze naar een node om daarmee te verbinden.",editNode:"Node wijzigen"},pt:{addDescription:"Clique em um espao em branco para adicionar um novo n",addEdge:"Adicionar aresta",addNode:"Adicionar n",back:"Voltar",close:"Fechar",createEdgeError:"No foi possvel linkar arestas a um cluster.",del:"Remover selecionado",deleteClusterError:"Clusters no puderam ser removidos.",edgeDescription:"Clique em um n e arraste a aresta at outro n para conect-los",edit:"Editar",editClusterError:"Clusters no puderam ser editados.",editEdge:"Editar aresta",editEdgeDescription:"Clique nos pontos de controle e os arraste para um n para conect-los",editNode:"Editar n"},ru:{addDescription:"   ,    .",addEdge:" ",addNode:" ",back:"",close:"",createEdgeError:"    .",del:" ",deleteClusterError:"    ",edgeDescription:"        ,   .",edit:"",editClusterError:"   .",editEdge:" ",editEdgeDescription:"        ,    .",editNode:" "},cn:{addDescription:"",addEdge:"",addNode:"",back:"",close:"",createEdgeError:"",del:"",deleteClusterError:"",edgeDescription:"",edit:"",editClusterError:"",editEdge:"",editEdgeDescription:"",editNode:""},uk:{addDescription:"K   ,    .",addEdge:" ",addNode:" ",back:"",close:"",createEdgeError:"  '   .",del:" ",deleteClusterError:"    .",edgeDescription:"        ,   '.",edit:"",editClusterError:"   .",editEdge:" ",editEdgeDescription:"        ,    .",editNode:" "},fr:{addDescription:"Cliquez dans un endroit vide pour placer un nud.",addEdge:"Ajouter un lien",addNode:"Ajouter un nud",back:"Retour",close:"Fermer",createEdgeError:"Impossible de crer un lien vers un cluster.",del:"Effacer la slection",deleteClusterError:"Les clusters ne peuvent pas tre effacs.",edgeDescription:"Cliquez sur un nud et glissez le lien vers un autre nud pour les connecter.",edit:"diter",editClusterError:"Les clusters ne peuvent pas tre dits.",editEdge:"diter le lien",editEdgeDescription:"Cliquez sur les points de contrle et glissez-les pour connecter un nud.",editNode:"diter le nud"},cs:{addDescription:"Kluknutm do przdnho prostoru mete pidat nov vrchol.",addEdge:"Pidat hranu",addNode:"Pidat vrchol",back:"Zpt",close:"Zavt",createEdgeError:"Nelze pipojit hranu ke shluku.",del:"Smazat vbr",deleteClusterError:"Nelze mazat shluky.",edgeDescription:"Petaenm z jednoho vrcholu do druhho mete spojit tyto vrcholy novou hranou.",edit:"Upravit",editClusterError:"Nelze upravovat shluky.",editEdge:"Upravit hranu",editEdgeDescription:"Petaenm kontrolnho vrcholu hrany ji mete pipojit k jinmu vrcholu.",editNode:"Upravit vrchol"}});var Mb=function(){function t(){Yd(this,t),this.NUM_ITERATIONS=4,this.image=new Image,this.canvas=document.createElement("canvas")}return Kd(t,[{key:"init",value:function(){if(!this.initialized()){this.src=this.image.src;var t=this.image.width,e=this.image.height;this.width=t,this.height=e;var i=Math.floor(e/2),n=Math.floor(e/4),o=Math.floor(e/8),r=Math.floor(e/16),s=Math.floor(t/2),a=Math.floor(t/4),h=Math.floor(t/8),l=Math.floor(t/16);this.canvas.width=3*a,this.canvas.height=i,this.coordinates=[[0,0,s,i],[s,0,a,n],[s,n,h,o],[5*h,n,l,r]],this._fillMipMap()}}},{key:"initialized",value:function(){return void 0!==this.coordinates}},{key:"_fillMipMap",value:function(){var t=this.canvas.getContext("2d"),e=this.coordinates[0];t.drawImage(this.image,e[0],e[1],e[2],e[3]);for(var i=1;i<this.NUM_ITERATIONS;i++){var n=this.coordinates[i-1],o=this.coordinates[i];t.drawImage(this.canvas,n[0],n[1],n[2],n[3],o[0],o[1],o[2],o[3])}}},{key:"drawImageAtPosition",value:function(t,e,i,n,o,r){if(this.initialized())if(e>2){e*=.5;for(var s=0;e>2&&s<this.NUM_ITERATIONS;)e*=.5,s+=1;s>=this.NUM_ITERATIONS&&(s=this.NUM_ITERATIONS-1);var a=this.coordinates[s];t.drawImage(this.canvas,a[0],a[1],a[2],a[3],i,n,o,r)}else t.drawImage(this.image,i,n,o,r)}}]),t}(),Pb=function(){function t(e){Yd(this,t),this.images={},this.imageBroken={},this.callback=e}return Kd(t,[{key:"_tryloadBrokenUrl",value:function(t,e,i){void 0!==t&&void 0!==i&&(void 0!==e?(i.image.onerror=function(){console.error("Could not load brokenImage:",e)},i.image.src=e):console.warn("No broken url image defined"))}},{key:"_redrawWithImage",value:function(t){this.callback&&this.callback(t)}},{key:"load",value:function(t,e){var i=this,n=this.images[t];if(n)return n;var o=new Mb;return this.images[t]=o,o.image.onload=function(){i._fixImageCoordinates(o.image),o.init(),i._redrawWithImage(o)},o.image.onerror=function(){console.error("Could not load image:",t),i._tryloadBrokenUrl(t,e,o)},o.image.src=t,o}},{key:"_fixImageCoordinates",value:function(t){0===t.width&&(document.body.appendChild(t),t.width=t.offsetWidth,t.height=t.offsetHeight,document.body.removeChild(t))}}]),t}(),Db={exports:{}},Ib=o((function(){if("function"==typeof ArrayBuffer){var t=new ArrayBuffer(8);Object.isExtensible(t)&&Object.defineProperty(t,"a",{value:8})}})),Bb=o,zb=Y,Nb=B,Fb=Ib,Ab=Object.isExtensible,jb=Bb((function(){Ab(1)}))||Fb?function(t){return!!zb(t)&&((!Fb||"ArrayBuffer"!=Nb(t))&&(!Ab||Ab(t)))}:Ab,Rb=!o((function(){return Object.isExtensible(Object.preventExtensions({}))})),Lb=_i,Hb=g,Wb=Ri,qb=Y,Vb=Wt,Ub=Ve.f,Yb=rh,Xb=hh,Gb=jb,Kb=Rb,$b=!1,Zb=Xt("meta"),Qb=0,Jb=function(t){Ub(t,Zb,{value:{objectID:"O"+Qb++,weakData:{}}})},tw=Db.exports={enable:function(){tw.enable=function(){},$b=!0;var t=Yb.f,e=Hb([].splice),i={};i[Zb]=1,t(i).length&&(Yb.f=function(i){for(var n=t(i),o=0,r=n.length;o<r;o++)if(n[o]===Zb){e(n,o,1);break}return n},Lb({target:"Object",stat:!0,forced:!0},{getOwnPropertyNames:Xb.f}))},fastKey:function(t,e){if(!qb(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!Vb(t,Zb)){if(!Gb(t))return"F";if(!e)return"E";Jb(t)}return t[Zb].objectID},getWeakData:function(t,e){if(!Vb(t,Zb)){if(!Gb(t))return!0;if(!e)return!1;Jb(t)}return t[Zb].weakData},onFreeze:function(t){return Kb&&$b&&Gb(t)&&!Vb(t,Zb)&&Jb(t),t}};Wb[Zb]=!0;var ew=qe,iw=_,nw=$e,ow=bt,rw=qs,sw=Bi,aw=J,hw=ba,lw=ua,dw=As,cw=n.TypeError,uw=function(t,e){this.stopped=t,this.result=e},fw=uw.prototype,pw=function(t,e,i){var n,o,r,s,a,h,l,d=i&&i.that,c=!(!i||!i.AS_ENTRIES),u=!(!i||!i.IS_ITERATOR),f=!(!i||!i.INTERRUPTED),p=ew(e,d),v=function(t){return n&&dw(n,"normal",t),new uw(!0,t)},g=function(t){return c?(nw(t),f?p(t[0],t[1],v):p(t[0],t[1])):f?p(t,v):p(t)};if(u)n=t;else{if(!(o=lw(t)))throw cw(ow(t)+" is not iterable");if(rw(o)){for(r=0,s=sw(t);s>r;r++)if((a=g(t[r]))&&aw(fw,a))return a;return new uw(!1)}n=hw(t,o)}for(h=n.next;!(l=iw(h,n)).done;){try{a=g(l.value)}catch(t){dw(n,"throw",t)}if("object"==typeof a&&a&&aw(fw,a))return a}return new uw(!1)},vw=J,gw=n.TypeError,yw=function(t,e){if(vw(e,t))return t;throw gw("Incorrect invocation")},mw=_i,bw=n,ww=Db.exports,kw=o,_w=di,xw=pw,Ew=yw,Ow=y,Cw=Y,Sw=$r,Tw=Ve.f,Mw=Wh.forEach,Pw=b,Dw=Vo.set,Iw=Vo.getterFor,Bw=function(t,e,i){var n,o=-1!==t.indexOf("Map"),r=-1!==t.indexOf("Weak"),s=o?"set":"add",a=bw[t],h=a&&a.prototype,l={};if(Pw&&Ow(a)&&(r||h.forEach&&!kw((function(){(new a).entries().next()})))){var d=(n=e((function(e,i){Dw(Ew(e,d),{type:t,collection:new a}),null!=i&&xw(i,e[s],{that:e,AS_ENTRIES:o})}))).prototype,c=Iw(t);Mw(["add","clear","delete","forEach","get","has","set","keys","values","entries"],(function(t){var e="add"==t||"set"==t;!(t in h)||r&&"clear"==t||_w(d,t,(function(i,n){var o=c(this).collection;if(!e&&r&&!Cw(i))return"get"==t&&void 0;var s=o[t](0===i?0:i,n);return e?this:s}))})),r||Tw(d,"size",{configurable:!0,get:function(){return c(this).collection.size}})}else n=i.getConstructor(e,t,o,s),ww.enable();return Sw(n,t,!1,!0),l[t]=n,mw({global:!0,forced:!0},l),r||i.setStrong(n,t,o),n},zw=Ir,Nw=function(t,e,i){for(var n in e)i&&i.unsafe&&t[n]?t[n]=e[n]:zw(t,n,e[n],i);return t},Fw=Q,Aw=Ve,jw=b,Rw=oe("species"),Lw=Ve.f,Hw=wr,Ww=Nw,qw=qe,Vw=yw,Uw=pw,Yw=Cs,Xw=function(t){var e=Fw(t),i=Aw.f;jw&&e&&!e[Rw]&&i(e,Rw,{configurable:!0,get:function(){return this}})},Gw=b,Kw=Db.exports.fastKey,$w=Vo.set,Zw=Vo.getterFor,Qw={getConstructor:function(t,e,i,n){var o=t((function(t,o){Vw(t,r),$w(t,{type:e,index:Hw(null),first:void 0,last:void 0,size:0}),Gw||(t.size=0),null!=o&&Uw(o,t[n],{that:t,AS_ENTRIES:i})})),r=o.prototype,s=Zw(e),a=function(t,e,i){var n,o,r=s(t),a=h(t,e);return a?a.value=i:(r.last=a={index:o=Kw(e,!0),key:e,value:i,previous:n=r.last,next:void 0,removed:!1},r.first||(r.first=a),n&&(n.next=a),Gw?r.size++:t.size++,"F"!==o&&(r.index[o]=a)),t},h=function(t,e){var i,n=s(t),o=Kw(e);if("F"!==o)return n.index[o];for(i=n.first;i;i=i.next)if(i.key==e)return i};return Ww(r,{clear:function(){for(var t=s(this),e=t.index,i=t.first;i;)i.removed=!0,i.previous&&(i.previous=i.previous.next=void 0),delete e[i.index],i=i.next;t.first=t.last=void 0,Gw?t.size=0:this.size=0},delete:function(t){var e=this,i=s(e),n=h(e,t);if(n){var o=n.next,r=n.previous;delete i.index[n.index],n.removed=!0,r&&(r.next=o),o&&(o.previous=r),i.first==n&&(i.first=o),i.last==n&&(i.last=r),Gw?i.size--:e.size--}return!!n},forEach:function(t){for(var e,i=s(this),n=qw(t,arguments.length>1?arguments[1]:void 0);e=e?e.next:i.first;)for(n(e.value,e.key,this);e&&e.removed;)e=e.previous},has:function(t){return!!h(this,t)}}),Ww(r,i?{get:function(t){var e=h(this,t);return e&&e.value},set:function(t,e){return a(this,0===t?0:t,e)}}:{add:function(t){return a(this,t=0===t?0:t,t)}}),Gw&&Lw(r,"size",{get:function(){return s(this).size}}),o},setStrong:function(t,e,i){var n=e+" Iterator",o=Zw(e),r=Zw(n);Yw(t,e,(function(t,e){$w(this,{type:n,target:t,state:o(t),kind:e,last:void 0})}),(function(){for(var t=r(this),e=t.kind,i=t.last;i&&i.removed;)i=i.previous;return t.target&&(t.last=i=i?i.next:t.state.first)?"keys"==e?{value:i.key,done:!1}:"values"==e?{value:i.value,done:!1}:{value:[i.key,i.value],done:!1}:(t.target=void 0,{value:void 0,done:!0})}),i?"entries":"values",!i,!0),Xw(e)}};Bw("Map",(function(t){return function(){return t(this,arguments.length?arguments[0]:void 0)}}),Qw);var Jw=X.Map,tk=function(){function t(){Yd(this,t),this.clear(),this._defaultIndex=0,this._groupIndex=0,this._defaultGroups=[{border:"#2B7CE9",background:"#97C2FC",highlight:{border:"#2B7CE9",background:"#D2E5FF"},hover:{border:"#2B7CE9",background:"#D2E5FF"}},{border:"#FFA500",background:"#FFFF00",highlight:{border:"#FFA500",background:"#FFFFA3"},hover:{border:"#FFA500",background:"#FFFFA3"}},{border:"#FA0A10",background:"#FB7E81",highlight:{border:"#FA0A10",background:"#FFAFB1"},hover:{border:"#FA0A10",background:"#FFAFB1"}},{border:"#41A906",background:"#7BE141",highlight:{border:"#41A906",background:"#A1EC76"},hover:{border:"#41A906",background:"#A1EC76"}},{border:"#E129F0",background:"#EB7DF4",highlight:{border:"#E129F0",background:"#F0B3F5"},hover:{border:"#E129F0",background:"#F0B3F5"}},{border:"#7C29F0",background:"#AD85E4",highlight:{border:"#7C29F0",background:"#D3BDF0"},hover:{border:"#7C29F0",background:"#D3BDF0"}},{border:"#C37F00",background:"#FFA807",highlight:{border:"#C37F00",background:"#FFCA66"},hover:{border:"#C37F00",background:"#FFCA66"}},{border:"#4220FB",background:"#6E6EFD",highlight:{border:"#4220FB",background:"#9B9BFD"},hover:{border:"#4220FB",background:"#9B9BFD"}},{border:"#FD5A77",background:"#FFC0CB",highlight:{border:"#FD5A77",background:"#FFD1D9"},hover:{border:"#FD5A77",background:"#FFD1D9"}},{border:"#4AD63A",background:"#C2FABC",highlight:{border:"#4AD63A",background:"#E6FFE3"},hover:{border:"#4AD63A",background:"#E6FFE3"}},{border:"#990000",background:"#EE0000",highlight:{border:"#BB0000",background:"#FF3333"},hover:{border:"#BB0000",background:"#FF3333"}},{border:"#FF6000",background:"#FF6000",highlight:{border:"#FF6000",background:"#FF6000"},hover:{border:"#FF6000",background:"#FF6000"}},{border:"#97C2FC",background:"#2B7CE9",highlight:{border:"#D2E5FF",background:"#2B7CE9"},hover:{border:"#D2E5FF",background:"#2B7CE9"}},{border:"#399605",background:"#255C03",highlight:{border:"#399605",background:"#255C03"},hover:{border:"#399605",background:"#255C03"}},{border:"#B70054",background:"#FF007E",highlight:{border:"#B70054",background:"#FF007E"},hover:{border:"#B70054",background:"#FF007E"}},{border:"#AD85E4",background:"#7C29F0",highlight:{border:"#D3BDF0",background:"#7C29F0"},hover:{border:"#D3BDF0",background:"#7C29F0"}},{border:"#4557FA",background:"#000EA1",highlight:{border:"#6E6EFD",background:"#000EA1"},hover:{border:"#6E6EFD",background:"#000EA1"}},{border:"#FFC0CB",background:"#FD5A77",highlight:{border:"#FFD1D9",background:"#FD5A77"},hover:{border:"#FFD1D9",background:"#FD5A77"}},{border:"#C2FABC",background:"#74D66A",highlight:{border:"#E6FFE3",background:"#74D66A"},hover:{border:"#E6FFE3",background:"#74D66A"}},{border:"#EE0000",background:"#990000",highlight:{border:"#FF3333",background:"#BB0000"},hover:{border:"#FF3333",background:"#BB0000"}}],this.options={},this.defaultOptions={useDefaultGroups:!0},un(this.options,this.defaultOptions)}return Kd(t,[{key:"setOptions",value:function(t){var e=["useDefaultGroups"];if(void 0!==t)for(var i in t)if(Object.prototype.hasOwnProperty.call(t,i)&&-1===Fp(e).call(e,i)){var n=t[i];this.add(i,n)}}},{key:"clear",value:function(){this._groups=new Jw,this._groupNames=[]}},{key:"get",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1],i=this._groups.get(t);if(void 0===i&&e)if(!1===this.options.useDefaultGroups&&this._groupNames.length>0){var n=this._groupIndex%this._groupNames.length;++this._groupIndex,(i={}).color=this._groups.get(this._groupNames[n]),this._groups.set(t,i)}else{var o=this._defaultIndex%this._defaultGroups.length;this._defaultIndex++,(i={}).color=this._defaultGroups[o],this._groups.set(t,i)}return i}},{key:"add",value:function(t,e){return this._groups.has(t)||this._groupNames.push(t),this._groups.set(t,e),e}}]),t}();_i({target:"Number",stat:!0},{isNaN:function(t){return t!=t}});var ek=X.Number.isNaN,ik=n.isFinite,nk=Number.isFinite||function(t){return"number"==typeof t&&ik(t)};_i({target:"Number",stat:!0},{isFinite:nk});var ok=X.Number.isFinite,rk=Wh.some;_i({target:"Array",proto:!0,forced:!Cu("some")},{some:function(t){return rk(this,t,arguments.length>1?arguments[1]:void 0)}});var sk=Tn("Array").some,ak=J,hk=sk,lk=Array.prototype,dk=function(t){var e=t.some;return t===lk||ak(lk,t)&&e===lk.some?hk:e},ck=dk,uk=na,fk=bt,pk=n.TypeError,vk=_i,gk=d,yk=On,mk=function(t){if(uk(t))return t;throw pk(fk(t)+" is not a constructor")},bk=$e,wk=Y,kk=wr,_k=o,xk=Q("Reflect","construct"),Ek=Object.prototype,Ok=[].push,Ck=_k((function(){function t(){}return!(xk((function(){}),[],t)instanceof t)})),Sk=!_k((function(){xk((function(){}))})),Tk=Ck||Sk;vk({target:"Reflect",stat:!0,forced:Tk,sham:Tk},{construct:function(t,e){mk(t),bk(e);var i=arguments.length<3?t:mk(arguments[2]);if(Sk&&!Ck)return xk(t,e,i);if(t==i){switch(e.length){case 0:return new t;case 1:return new t(e[0]);case 2:return new t(e[0],e[1]);case 3:return new t(e[0],e[1],e[2]);case 4:return new t(e[0],e[1],e[2],e[3])}var n=[null];return gk(Ok,n,e),new(gk(yk,t,n))}var o=i.prototype,r=kk(wk(o)?o:Ek),s=gk(t,r,e);return wk(s)?s:r}});var Mk=X.Reflect.construct;function Pk(t){if(void 0===t)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return t}var Dk=Gp;_i({target:"Object",stat:!0},{setPrototypeOf:cs});var Ik=X.Object.setPrototypeOf;function Bk(t,e){return Bk=Ik||function(t,e){return t.__proto__=e,t},Bk(t,e)}function zk(t,e){if("function"!=typeof e&&null!==e)throw new TypeError("Super expression must either be null or a function");t.prototype=Dk(e&&e.prototype,{constructor:{value:t,writable:!0,configurable:!0}}),Xd(t,"prototype",{writable:!1}),e&&Bk(t,e)}function Nk(t,e){if(e&&("object"===Qc(e)||"function"==typeof e))return e;if(void 0!==e)throw new TypeError("Derived constructors may only return object or undefined");return Pk(t)}var Fk=Rf;function Ak(t){return Ak=Ik?Fk:function(t){return t.__proto__||Fk(t)},Ak(t)}var jk={exports:{}};!function(t){var e=function(t){var e,i=Object.prototype,n=i.hasOwnProperty,o="function"==typeof Symbol?Symbol:{},r=o.iterator||"@@iterator",s=o.asyncIterator||"@@asyncIterator",a=o.toStringTag||"@@toStringTag";function h(t,e,i){return Object.defineProperty(t,e,{value:i,enumerable:!0,configurable:!0,writable:!0}),t[e]}try{h({},"")}catch(t){h=function(t,e,i){return t[e]=i}}function l(t,e,i,n){var o=e&&e.prototype instanceof g?e:g,r=Object.create(o.prototype),s=new T(n||[]);return r._invoke=function(t,e,i){var n=c;return function(o,r){if(n===f)throw new Error("Generator is already running");if(n===p){if("throw"===o)throw r;return P()}for(i.method=o,i.arg=r;;){var s=i.delegate;if(s){var a=O(s,i);if(a){if(a===v)continue;return a}}if("next"===i.method)i.sent=i._sent=i.arg;else if("throw"===i.method){if(n===c)throw n=p,i.arg;i.dispatchException(i.arg)}else"return"===i.method&&i.abrupt("return",i.arg);n=f;var h=d(t,e,i);if("normal"===h.type){if(n=i.done?p:u,h.arg===v)continue;return{value:h.arg,done:i.done}}"throw"===h.type&&(n=p,i.method="throw",i.arg=h.arg)}}}(t,i,s),r}function d(t,e,i){try{return{type:"normal",arg:t.call(e,i)}}catch(t){return{type:"throw",arg:t}}}t.wrap=l;var c="suspendedStart",u="suspendedYield",f="executing",p="completed",v={};function g(){}function y(){}function m(){}var b={};h(b,r,(function(){return this}));var w=Object.getPrototypeOf,k=w&&w(w(M([])));k&&k!==i&&n.call(k,r)&&(b=k);var _=m.prototype=g.prototype=Object.create(b);function x(t){["next","throw","return"].forEach((function(e){h(t,e,(function(t){return this._invoke(e,t)}))}))}function E(t,e){function i(o,r,s,a){var h=d(t[o],t,r);if("throw"!==h.type){var l=h.arg,c=l.value;return c&&"object"==typeof c&&n.call(c,"__await")?e.resolve(c.__await).then((function(t){i("next",t,s,a)}),(function(t){i("throw",t,s,a)})):e.resolve(c).then((function(t){l.value=t,s(l)}),(function(t){return i("throw",t,s,a)}))}a(h.arg)}var o;this._invoke=function(t,n){function r(){return new e((function(e,o){i(t,n,e,o)}))}return o=o?o.then(r,r):r()}}function O(t,i){var n=t.iterator[i.method];if(n===e){if(i.delegate=null,"throw"===i.method){if(t.iterator.return&&(i.method="return",i.arg=e,O(t,i),"throw"===i.method))return v;i.method="throw",i.arg=new TypeError("The iterator does not provide a 'throw' method")}return v}var o=d(n,t.iterator,i.arg);if("throw"===o.type)return i.method="throw",i.arg=o.arg,i.delegate=null,v;var r=o.arg;return r?r.done?(i[t.resultName]=r.value,i.next=t.nextLoc,"return"!==i.method&&(i.method="next",i.arg=e),i.delegate=null,v):r:(i.method="throw",i.arg=new TypeError("iterator result is not an object"),i.delegate=null,v)}function C(t){var e={tryLoc:t[0]};1 in t&&(e.catchLoc=t[1]),2 in t&&(e.finallyLoc=t[2],e.afterLoc=t[3]),this.tryEntries.push(e)}function S(t){var e=t.completion||{};e.type="normal",delete e.arg,t.completion=e}function T(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(C,this),this.reset(!0)}function M(t){if(t){var i=t[r];if(i)return i.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var o=-1,s=function i(){for(;++o<t.length;)if(n.call(t,o))return i.value=t[o],i.done=!1,i;return i.value=e,i.done=!0,i};return s.next=s}}return{next:P}}function P(){return{value:e,done:!0}}return y.prototype=m,h(_,"constructor",m),h(m,"constructor",y),y.displayName=h(m,a,"GeneratorFunction"),t.isGeneratorFunction=function(t){var e="function"==typeof t&&t.constructor;return!!e&&(e===y||"GeneratorFunction"===(e.displayName||e.name))},t.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,m):(t.__proto__=m,h(t,a,"GeneratorFunction")),t.prototype=Object.create(_),t},t.awrap=function(t){return{__await:t}},x(E.prototype),h(E.prototype,s,(function(){return this})),t.AsyncIterator=E,t.async=function(e,i,n,o,r){void 0===r&&(r=Promise);var s=new E(l(e,i,n,o),r);return t.isGeneratorFunction(i)?s:s.next().then((function(t){return t.done?t.value:s.next()}))},x(_),h(_,a,"Generator"),h(_,r,(function(){return this})),h(_,"toString",(function(){return"[object Generator]"})),t.keys=function(t){var e=[];for(var i in t)e.push(i);return e.reverse(),function i(){for(;e.length;){var n=e.pop();if(n in t)return i.value=n,i.done=!1,i}return i.done=!0,i}},t.values=M,T.prototype={constructor:T,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=e,this.done=!1,this.delegate=null,this.method="next",this.arg=e,this.tryEntries.forEach(S),!t)for(var i in this)"t"===i.charAt(0)&&n.call(this,i)&&!isNaN(+i.slice(1))&&(this[i]=e)},stop:function(){this.done=!0;var t=this.tryEntries[0].completion;if("throw"===t.type)throw t.arg;return this.rval},dispatchException:function(t){if(this.done)throw t;var i=this;function o(n,o){return a.type="throw",a.arg=t,i.next=n,o&&(i.method="next",i.arg=e),!!o}for(var r=this.tryEntries.length-1;r>=0;--r){var s=this.tryEntries[r],a=s.completion;if("root"===s.tryLoc)return o("end");if(s.tryLoc<=this.prev){var h=n.call(s,"catchLoc"),l=n.call(s,"finallyLoc");if(h&&l){if(this.prev<s.catchLoc)return o(s.catchLoc,!0);if(this.prev<s.finallyLoc)return o(s.finallyLoc)}else if(h){if(this.prev<s.catchLoc)return o(s.catchLoc,!0)}else{if(!l)throw new Error("try statement without catch or finally");if(this.prev<s.finallyLoc)return o(s.finallyLoc)}}}},abrupt:function(t,e){for(var i=this.tryEntries.length-1;i>=0;--i){var o=this.tryEntries[i];if(o.tryLoc<=this.prev&&n.call(o,"finallyLoc")&&this.prev<o.finallyLoc){var r=o;break}}r&&("break"===t||"continue"===t)&&r.tryLoc<=e&&e<=r.finallyLoc&&(r=null);var s=r?r.completion:{};return s.type=t,s.arg=e,r?(this.method="next",this.next=r.finallyLoc,v):this.complete(s)},complete:function(t,e){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&e&&(this.next=e),v},finish:function(t){for(var e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e];if(i.finallyLoc===t)return this.complete(i.completion,i.afterLoc),S(i),v}},catch:function(t){for(var e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e];if(i.tryLoc===t){var n=i.completion;if("throw"===n.type){var o=n.arg;S(i)}return o}}throw new Error("illegal catch attempt")},delegateYield:function(t,i,n){return this.delegate={iterator:M(t),resultName:i,nextLoc:n},"next"===this.method&&(this.arg=e),v}},t}(t.exports);try{regeneratorRuntime=e}catch(t){"object"==typeof globalThis?globalThis.regeneratorRuntime=e:Function("r","regeneratorRuntime = r")(e)}}(jk);var Rk=jk.exports,Lk=xt,Hk=Rt,Wk=R,qk=Bi,Vk=n.TypeError,Uk=function(t){return function(e,i,n,o){Lk(i);var r=Hk(e),s=Wk(r),a=qk(r),h=t?a-1:0,l=t?-1:1;if(n<2)for(;;){if(h in s){o=s[h],h+=l;break}if(h+=l,t?h<0:a<=h)throw Vk("Reduce of empty array with no initial value")}for(;t?h>=0:a>h;h+=l)h in s&&(o=i(o,s[h],h,r));return o}},Yk={left:Uk(!1),right:Uk(!0)},Xk="process"==B(n.process),Gk=Yk.left,Kk=at,$k=Xk;_i({target:"Array",proto:!0,forced:!Cu("reduce")||!$k&&Kk>79&&Kk<83},{reduce:function(t){var e=arguments.length;return Gk(this,t,e,e>1?arguments[1]:void 0)}});var Zk=Tn("Array").reduce,Qk=J,Jk=Zk,t_=Array.prototype,e_=function(t){var e=t.reduce;return t===t_||Qk(t_,t)&&e===t_.reduce?Jk:e},i_=e_,n_=oh,o_=Bi,r_=qe,s_=n.TypeError,a_=function(t,e,i,n,o,r,s,a){for(var h,l,d=o,c=0,u=!!s&&r_(s,a);c<n;){if(c in i){if(h=u?u(i[c],c,e):i[c],r>0&&n_(h))l=o_(h),d=a_(t,e,h,l,d,r-1)-1;else{if(d>=9007199254740991)throw s_("Exceed the acceptable array length");t[d]=h}d++}c++}return d},h_=a_,l_=xt,d_=Rt,c_=Bi,u_=zh;_i({target:"Array",proto:!0},{flatMap:function(t){var e,i=d_(this),n=c_(i);return l_(t),(e=u_(i,0)).length=h_(e,i,i,n,0,1,t,arguments.length>1?arguments[1]:void 0),e}});var f_=Tn("Array").flatMap,p_=J,v_=f_,g_=Array.prototype,y_=function(t){var e=t.flatMap;return t===g_||p_(g_,t)&&e===g_.flatMap?v_:e},m_=y_;Bw("Set",(function(t){return function(){return t(this,arguments.length?arguments[0]:void 0)}}),Qw);var b_=X.Set,w_=$c,k_=ba,__=ph,x_=Math.floor,E_=function(t,e){var i=t.length,n=x_(i/2);return i<8?O_(t,e):C_(t,E_(__(t,0,n),e),E_(__(t,n),e),e)},O_=function(t,e){for(var i,n,o=t.length,r=1;r<o;){for(n=r,i=t[r];n&&e(t[n-1],i)>0;)t[n]=t[--n];n!==r++&&(t[n]=i)}return t},C_=function(t,e,i,n){for(var o=e.length,r=i.length,s=0,a=0;s<o||a<r;)t[s+a]=s<o&&a<r?n(e[s],i[a])<=0?e[s++]:i[a++]:s<o?e[s++]:i[a++];return t},S_=E_,T_=tt.match(/firefox\/(\d+)/i),M_=!!T_&&+T_[1],P_=/MSIE|Trident/.test(tt),D_=tt.match(/AppleWebKit\/(\d+)\./),I_=!!D_&&+D_[1],B_=_i,z_=g,N_=xt,F_=Rt,A_=Bi,j_=eo,R_=o,L_=S_,H_=Cu,W_=M_,q_=P_,V_=at,U_=I_,Y_=[],X_=z_(Y_.sort),G_=z_(Y_.push),K_=R_((function(){Y_.sort(void 0)})),$_=R_((function(){Y_.sort(null)})),Z_=H_("sort"),Q_=!R_((function(){if(V_)return V_<70;if(!(W_&&W_>3)){if(q_)return!0;if(U_)return U_<603;var t,e,i,n,o="";for(t=65;t<76;t++){switch(e=String.fromCharCode(t),t){case 66:case 69:case 70:case 72:i=3;break;case 68:case 71:i=4;break;default:i=2}for(n=0;n<47;n++)Y_.push({k:e+n,v:i})}for(Y_.sort((function(t,e){return e.v-t.v})),n=0;n<Y_.length;n++)e=Y_[n].k.charAt(0),o.charAt(o.length-1)!==e&&(o+=e);return"DGBEFHACIJK"!==o}}));B_({target:"Array",proto:!0,forced:K_||!$_||!Z_||!Q_},{sort:function(t){void 0!==t&&N_(t);var e=F_(this);if(Q_)return void 0===t?X_(e):X_(e,t);var i,n,o=[],r=A_(e);for(n=0;n<r;n++)n in e&&G_(o,e[n]);for(L_(o,function(t){return function(e,i){return void 0===i?-1:void 0===e?1:void 0!==t?+t(e,i)||0:j_(e)>j_(i)?1:-1}}(t)),i=o.length,n=0;n<i;)e[n]=o[n++];for(;n<r;)delete e[n++];return e}});var J_,tx=Tn("Array").sort,ex=J,ix=tx,nx=Array.prototype,ox=function(t){var e=t.sort;return t===nx||ex(nx,t)&&e===nx.sort?ix:e},rx=ox,sx=Tn("Array").keys,ax=Qn,hx=Wt,lx=J,dx=sx,cx=Array.prototype,ux={DOMTokenList:!0,NodeList:!0},fx=function(t){var e=t.keys;return t===cx||lx(cx,t)&&e===cx.keys||hx(ux,ax(t))?dx:e},px=Tn("Array").values,vx=Qn,gx=Wt,yx=J,mx=px,bx=Array.prototype,wx={DOMTokenList:!0,NodeList:!0},kx=function(t){var e=t.values;return t===bx||yx(bx,t)&&e===bx.values||gx(wx,vx(t))?mx:e},_x=Tn("Array").entries,xx=Qn,Ex=Wt,Ox=J,Cx=_x,Sx=Array.prototype,Tx={DOMTokenList:!0,NodeList:!0},Mx=function(t){var e=t.entries;return t===Sx||Ox(Sx,t)&&e===Sx.entries||Ex(Tx,xx(t))?Cx:e},Px=new Uint8Array(16);function Dx(){if(!J_&&!(J_="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return J_(Px)}var Ix=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;function Bx(t){return"string"==typeof t&&Ix.test(t)}for(var zx,Nx=[],Fx=0;Fx<256;++Fx)Nx.push((Fx+256).toString(16).substr(1));function Ax(t,e,i){var n=(t=t||{}).random||(t.rng||Dx)();if(n[6]=15&n[6]|64,n[8]=63&n[8]|128,e){i=i||0;for(var o=0;o<16;++o)e[i+o]=n[o];return e}return function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,i=(Nx[t[e+0]]+Nx[t[e+1]]+Nx[t[e+2]]+Nx[t[e+3]]+"-"+Nx[t[e+4]]+Nx[t[e+5]]+"-"+Nx[t[e+6]]+Nx[t[e+7]]+"-"+Nx[t[e+8]]+Nx[t[e+9]]+"-"+Nx[t[e+10]]+Nx[t[e+11]]+Nx[t[e+12]]+Nx[t[e+13]]+Nx[t[e+14]]+Nx[t[e+15]]).toLowerCase();if(!Bx(i))throw TypeError("Stringified UUID is invalid");return i}(n)}function jx(t,e){var i=bu(t);if(hd){var n=hd(t);e&&(n=Xf(n).call(n,(function(e){return bd(t,e).enumerable}))),i.push.apply(i,n)}return i}function Rx(t){for(var e=1;e<arguments.length;e++){var i,n,o=null!=arguments[e]?arguments[e]:{};e%2?Fu(i=jx(Object(o),!0)).call(i,(function(e){$d(t,e,o[e])})):Pd?Ad(t,Pd(o)):Fu(n=jx(Object(o))).call(n,(function(e){Ud(t,e,bd(o,e))}))}return t}function Lx(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}function Hx(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return Wx(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return Wx(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function Wx(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}var qx=function(){function t(e,i,n){var o,r,s;Yd(this,t),$d(this,"_source",void 0),$d(this,"_transformers",void 0),$d(this,"_target",void 0),$d(this,"_listeners",{add:zn(o=this._add).call(o,this),remove:zn(r=this._remove).call(r,this),update:zn(s=this._update).call(s,this)}),this._source=e,this._transformers=i,this._target=n}return Kd(t,[{key:"all",value:function(){return this._target.update(this._transformItems(this._source.get())),this}},{key:"start",value:function(){return this._source.on("add",this._listeners.add),this._source.on("remove",this._listeners.remove),this._source.on("update",this._listeners.update),this}},{key:"stop",value:function(){return this._source.off("add",this._listeners.add),this._source.off("remove",this._listeners.remove),this._source.off("update",this._listeners.update),this}},{key:"_transformItems",value:function(t){var e;return i_(e=this._transformers).call(e,(function(t,e){return e(t)}),t)}},{key:"_add",value:function(t,e){null!=e&&this._target.add(this._transformItems(this._source.get(e.items)))}},{key:"_update",value:function(t,e){null!=e&&this._target.update(this._transformItems(this._source.get(e.items)))}},{key:"_remove",value:function(t,e){null!=e&&this._target.remove(this._transformItems(e.oldData))}}]),t}(),Vx=function(){function t(e){Yd(this,t),$d(this,"_source",void 0),$d(this,"_transformers",[]),this._source=e}return Kd(t,[{key:"filter",value:function(t){return this._transformers.push((function(e){return Xf(e).call(e,t)})),this}},{key:"map",value:function(t){return this._transformers.push((function(e){return gu(e).call(e,t)})),this}},{key:"flatMap",value:function(t){return this._transformers.push((function(e){return m_(e).call(e,t)})),this}},{key:"to",value:function(t){return new qx(this._source,this._transformers,t)}}]),t}();function Ux(t){return"string"==typeof t||"number"==typeof t}var Yx=function(){function t(e){Yd(this,t),$d(this,"delay",void 0),$d(this,"max",void 0),$d(this,"_queue",[]),$d(this,"_timeout",null),$d(this,"_extended",null),this.delay=null,this.max=1/0,this.setOptions(e)}return Kd(t,[{key:"setOptions",value:function(t){t&&void 0!==t.delay&&(this.delay=t.delay),t&&void 0!==t.max&&(this.max=t.max),this._flushIfNeeded()}},{key:"destroy",value:function(){if(this.flush(),this._extended){for(var t=this._extended.object,e=this._extended.methods,i=0;i<e.length;i++){var n=e[i];n.original?t[n.name]=n.original:delete t[n.name]}this._extended=null}}},{key:"replace",value:function(t,e){var i=this,n=t[e];if(!n)throw new Error("Method "+e+" undefined");t[e]=function(){for(var t=arguments.length,e=new Array(t),o=0;o<t;o++)e[o]=arguments[o];i.queue({args:e,fn:n,context:this})}}},{key:"queue",value:function(t){"function"==typeof t?this._queue.push({fn:t}):this._queue.push(t),this._flushIfNeeded()}},{key:"_flushIfNeeded",value:function(){var t=this;this._queue.length>this.max&&this.flush(),null!=this._timeout&&(clearTimeout(this._timeout),this._timeout=null),this.queue.length>0&&"number"==typeof this.delay&&(this._timeout=Sv((function(){t.flush()}),this.delay))}},{key:"flush",value:function(){var t,e;Fu(t=ff(e=this._queue).call(e,0)).call(t,(function(t){t.fn.apply(t.context||t.fn,t.args||[])}))}}],[{key:"extend",value:function(e,i){var n=new t(i);if(void 0!==e.flush)throw new Error("Target object already has a property flush");e.flush=function(){n.flush()};var o=[{name:"flush",original:void 0}];if(i&&i.replace)for(var r=0;r<i.replace.length;r++){var s=i.replace[r];o.push({name:s,original:e[s]}),n.replace(e,s)}return n._extended={object:e,methods:o},n}}]),t}(),Xx=function(){function t(){Yd(this,t),$d(this,"_subscribers",{"*":[],add:[],remove:[],update:[]}),$d(this,"subscribe",t.prototype.on),$d(this,"unsubscribe",t.prototype.off)}return Kd(t,[{key:"_trigger",value:function(t,e,i){var n,o;if("*"===t)throw new Error("Cannot trigger event *");Fu(n=su(o=[]).call(o,Jc(this._subscribers[t]),Jc(this._subscribers["*"]))).call(n,(function(n){n(t,e,null!=i?i:null)}))}},{key:"on",value:function(t,e){"function"==typeof e&&this._subscribers[t].push(e)}},{key:"off",value:function(t,e){var i;this._subscribers[t]=Xf(i=this._subscribers[t]).call(i,(function(t){return t!==e}))}}]),t}();zx=w_;var Gx=function(){function t(e){Yd(this,t),$d(this,"_pairs",void 0),this._pairs=e}return Kd(t,[{key:zx,value:Rk.mark((function t(){var e,i,n,o,r;return Rk.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:e=Hx(this._pairs),t.prev=1,e.s();case 3:if((i=e.n()).done){t.next=9;break}return n=Kc(i.value,2),o=n[0],r=n[1],t.next=7,[o,r];case 7:t.next=3;break;case 9:t.next=14;break;case 11:t.prev=11,t.t0=t.catch(1),e.e(t.t0);case 14:return t.prev=14,e.f(),t.finish(14);case 17:case"end":return t.stop()}}),t,this,[[1,11,14,17]])}))},{key:"entries",value:Rk.mark((function t(){var e,i,n,o,r;return Rk.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:e=Hx(this._pairs),t.prev=1,e.s();case 3:if((i=e.n()).done){t.next=9;break}return n=Kc(i.value,2),o=n[0],r=n[1],t.next=7,[o,r];case 7:t.next=3;break;case 9:t.next=14;break;case 11:t.prev=11,t.t0=t.catch(1),e.e(t.t0);case 14:return t.prev=14,e.f(),t.finish(14);case 17:case"end":return t.stop()}}),t,this,[[1,11,14,17]])}))},{key:"keys",value:Rk.mark((function t(){var e,i,n,o;return Rk.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:e=Hx(this._pairs),t.prev=1,e.s();case 3:if((i=e.n()).done){t.next=9;break}return n=Kc(i.value,1),o=n[0],t.next=7,o;case 7:t.next=3;break;case 9:t.next=14;break;case 11:t.prev=11,t.t0=t.catch(1),e.e(t.t0);case 14:return t.prev=14,e.f(),t.finish(14);case 17:case"end":return t.stop()}}),t,this,[[1,11,14,17]])}))},{key:"values",value:Rk.mark((function t(){var e,i,n,o;return Rk.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:e=Hx(this._pairs),t.prev=1,e.s();case 3:if((i=e.n()).done){t.next=9;break}return n=Kc(i.value,2),o=n[1],t.next=7,o;case 7:t.next=3;break;case 9:t.next=14;break;case 11:t.prev=11,t.t0=t.catch(1),e.e(t.t0);case 14:return t.prev=14,e.f(),t.finish(14);case 17:case"end":return t.stop()}}),t,this,[[1,11,14,17]])}))},{key:"toIdArray",value:function(){var t;return gu(t=Jc(this._pairs)).call(t,(function(t){return t[0]}))}},{key:"toItemArray",value:function(){var t;return gu(t=Jc(this._pairs)).call(t,(function(t){return t[1]}))}},{key:"toEntryArray",value:function(){return Jc(this._pairs)}},{key:"toObjectMap",value:function(){var t,e=Kp(null),i=Hx(this._pairs);try{for(i.s();!(t=i.n()).done;){var n=Kc(t.value,2),o=n[0],r=n[1];e[o]=r}}catch(t){i.e(t)}finally{i.f()}return e}},{key:"toMap",value:function(){return new Jw(this._pairs)}},{key:"toIdSet",value:function(){return new b_(this.toIdArray())}},{key:"toItemSet",value:function(){return new b_(this.toItemArray())}},{key:"cache",value:function(){return new t(Jc(this._pairs))}},{key:"distinct",value:function(t){var e,i=new b_,n=Hx(this._pairs);try{for(n.s();!(e=n.n()).done;){var o=Kc(e.value,2),r=o[0],s=o[1];i.add(t(s,r))}}catch(t){n.e(t)}finally{n.f()}return i}},{key:"filter",value:function(e){var i=this._pairs;return new t($d({},w_,Rk.mark((function t(){var n,o,r,s,a;return Rk.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:n=Hx(i),t.prev=1,n.s();case 3:if((o=n.n()).done){t.next=10;break}if(r=Kc(o.value,2),s=r[0],a=r[1],!e(a,s)){t.next=8;break}return t.next=8,[s,a];case 8:t.next=3;break;case 10:t.next=15;break;case 12:t.prev=12,t.t0=t.catch(1),n.e(t.t0);case 15:return t.prev=15,n.f(),t.finish(15);case 18:case"end":return t.stop()}}),t,null,[[1,12,15,18]])}))))}},{key:"forEach",value:function(t){var e,i=Hx(this._pairs);try{for(i.s();!(e=i.n()).done;){var n=Kc(e.value,2),o=n[0];t(n[1],o)}}catch(t){i.e(t)}finally{i.f()}}},{key:"map",value:function(e){var i=this._pairs;return new t($d({},w_,Rk.mark((function t(){var n,o,r,s,a;return Rk.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:n=Hx(i),t.prev=1,n.s();case 3:if((o=n.n()).done){t.next=9;break}return r=Kc(o.value,2),s=r[0],a=r[1],t.next=7,[s,e(a,s)];case 7:t.next=3;break;case 9:t.next=14;break;case 11:t.prev=11,t.t0=t.catch(1),n.e(t.t0);case 14:return t.prev=14,n.f(),t.finish(14);case 17:case"end":return t.stop()}}),t,null,[[1,11,14,17]])}))))}},{key:"max",value:function(t){var e=k_(this._pairs),i=e.next();if(i.done)return null;for(var n=i.value[1],o=t(i.value[1],i.value[0]);!(i=e.next()).done;){var r=Kc(i.value,2),s=r[0],a=r[1],h=t(a,s);h>o&&(o=h,n=a)}return n}},{key:"min",value:function(t){var e=k_(this._pairs),i=e.next();if(i.done)return null;for(var n=i.value[1],o=t(i.value[1],i.value[0]);!(i=e.next()).done;){var r=Kc(i.value,2),s=r[0],a=r[1],h=t(a,s);h<o&&(o=h,n=a)}return n}},{key:"reduce",value:function(t,e){var i,n=Hx(this._pairs);try{for(n.s();!(i=n.n()).done;){var o=Kc(i.value,2),r=o[0];e=t(e,o[1],r)}}catch(t){n.e(t)}finally{n.f()}return e}},{key:"sort",value:function(e){var i=this;return new t($d({},w_,(function(){var t;return k_(rx(t=Jc(i._pairs)).call(t,(function(t,i){var n=Kc(t,2),o=n[0],r=n[1],s=Kc(i,2),a=s[0],h=s[1];return e(r,h,o,a)})))})))}}]),t}();var Kx=function(t){zk(i,t);var e=Lx(i);function i(t,n){var o;return Yd(this,i),$d(Pk(o=e.call(this)),"flush",void 0),$d(Pk(o),"length",void 0),$d(Pk(o),"_options",void 0),$d(Pk(o),"_data",void 0),$d(Pk(o),"_idProp",void 0),$d(Pk(o),"_queue",null),t&&!lu(t)&&(n=t,t=[]),o._options=n||{},o._data=new Jw,o.length=0,o._idProp=o._options.fieldId||"id",t&&t.length&&o.add(t),o.setOptions(n),o}return Kd(i,[{key:"idProp",get:function(){return this._idProp}},{key:"setOptions",value:function(t){t&&void 0!==t.queue&&(!1===t.queue?this._queue&&(this._queue.destroy(),this._queue=null):(this._queue||(this._queue=Yx.extend(this,{replace:["add","update","remove"]})),t.queue&&"object"===Qc(t.queue)&&this._queue.setOptions(t.queue)))}},{key:"add",value:function(t,e){var i,n=this,o=[];if(lu(t)){var r=gu(t).call(t,(function(t){return t[n._idProp]}));if(ck(r).call(r,(function(t){return n._data.has(t)})))throw new Error("A duplicate id was found in the parameter array.");for(var s=0,a=t.length;s<a;s++)i=this._addItem(t[s]),o.push(i)}else{if(!t||"object"!==Qc(t))throw new Error("Unknown dataType");i=this._addItem(t),o.push(i)}return o.length&&this._trigger("add",{items:o},e),o}},{key:"update",value:function(t,e){var i=this,n=[],o=[],r=[],s=[],a=this._idProp,h=function(t){var e=t[a];if(null!=e&&i._data.has(e)){var h=t,l=un({},i._data.get(e)),d=i._updateItem(h);o.push(d),s.push(h),r.push(l)}else{var c=i._addItem(t);n.push(c)}};if(lu(t))for(var l=0,d=t.length;l<d;l++)t[l]&&"object"===Qc(t[l])?h(t[l]):console.warn("Ignoring input item, which is not an object at index "+l);else{if(!t||"object"!==Qc(t))throw new Error("Unknown dataType");h(t)}if(n.length&&this._trigger("add",{items:n},e),o.length){var c={items:o,oldData:r,data:s};this._trigger("update",c,e)}return su(n).call(n,o)}},{key:"updateOnly",value:function(t,e){var i,n=this;lu(t)||(t=[t]);var o=gu(i=gu(t).call(t,(function(t){var e=n._data.get(t[n._idProp]);if(null==e)throw new Error("Updating non-existent items is not allowed.");return{oldData:e,update:t}}))).call(i,(function(t){var e=t.oldData,i=t.update,o=e[n._idProp],r=By(e,i);return n._data.set(o,r),{id:o,oldData:e,updatedData:r}}));if(o.length){var r={items:gu(o).call(o,(function(t){return t.id})),oldData:gu(o).call(o,(function(t){return t.oldData})),data:gu(o).call(o,(function(t){return t.updatedData}))};return this._trigger("update",r,e),r.items}return[]}},{key:"get",value:function(t,e){var i=void 0,n=void 0,o=void 0;Ux(t)?(i=t,o=e):lu(t)?(n=t,o=e):o=t;var r,s=o&&"Object"===o.returnType?"Object":"Array",a=o&&Xf(o),h=[],l=void 0,d=void 0,c=void 0;if(null!=i)(l=this._data.get(i))&&a&&!a(l)&&(l=void 0);else if(null!=n)for(var u=0,f=n.length;u<f;u++)null==(l=this._data.get(n[u]))||a&&!a(l)||h.push(l);else for(var p,v=0,g=(d=Jc(fx(p=this._data).call(p))).length;v<g;v++)c=d[v],null==(l=this._data.get(c))||a&&!a(l)||h.push(l);if(o&&o.order&&null==i&&this._sort(h,o.order),o&&o.fields){var y=o.fields;if(null!=i&&null!=l)l=this._filterFields(l,y);else for(var m=0,b=h.length;m<b;m++)h[m]=this._filterFields(h[m],y)}if("Object"==s){for(var w={},k=0,_=h.length;k<_;k++){var x=h[k];w[x[this._idProp]]=x}return w}return null!=i?null!==(r=l)&&void 0!==r?r:null:h}},{key:"getIds",value:function(t){var e=this._data,i=t&&Xf(t),n=t&&t.order,o=Jc(fx(e).call(e)),r=[];if(i)if(n){for(var s=[],a=0,h=o.length;a<h;a++){var l=o[a],d=this._data.get(l);null!=d&&i(d)&&s.push(d)}this._sort(s,n);for(var c=0,u=s.length;c<u;c++)r.push(s[c][this._idProp])}else for(var f=0,p=o.length;f<p;f++){var v=o[f],g=this._data.get(v);null!=g&&i(g)&&r.push(g[this._idProp])}else if(n){for(var y=[],m=0,b=o.length;m<b;m++){var w=o[m];y.push(e.get(w))}this._sort(y,n);for(var k=0,_=y.length;k<_;k++)r.push(y[k][this._idProp])}else for(var x=0,E=o.length;x<E;x++){var O=o[x],C=e.get(O);null!=C&&r.push(C[this._idProp])}return r}},{key:"getDataSet",value:function(){return this}},{key:"forEach",value:function(t,e){var i=e&&Xf(e),n=this._data,o=Jc(fx(n).call(n));if(e&&e.order)for(var r=this.get(e),s=0,a=r.length;s<a;s++){var h=r[s];t(h,h[this._idProp])}else for(var l=0,d=o.length;l<d;l++){var c=o[l],u=this._data.get(c);null==u||i&&!i(u)||t(u,c)}}},{key:"map",value:function(t,e){for(var i=e&&Xf(e),n=[],o=this._data,r=Jc(fx(o).call(o)),s=0,a=r.length;s<a;s++){var h=r[s],l=this._data.get(h);null==l||i&&!i(l)||n.push(t(l,h))}return e&&e.order&&this._sort(n,e.order),n}},{key:"_filterFields",value:function(t,e){var i;return t?i_(i=lu(e)?e:bu(e)).call(i,(function(e,i){return e[i]=t[i],e}),{}):t}},{key:"_sort",value:function(t,e){if("string"==typeof e){var i=e;rx(t).call(t,(function(t,e){var n=t[i],o=e[i];return n>o?1:n<o?-1:0}))}else{if("function"!=typeof e)throw new TypeError("Order must be a function or a string");rx(t).call(t,e)}}},{key:"remove",value:function(t,e){for(var i=[],n=[],o=lu(t)?t:[t],r=0,s=o.length;r<s;r++){var a=this._remove(o[r]);if(a){var h=a[this._idProp];null!=h&&(i.push(h),n.push(a))}}return i.length&&this._trigger("remove",{items:i,oldData:n},e),i}},{key:"_remove",value:function(t){var e;if(Ux(t)?e=t:t&&"object"===Qc(t)&&(e=t[this._idProp]),null!=e&&this._data.has(e)){var i=this._data.get(e)||null;return this._data.delete(e),--this.length,i}return null}},{key:"clear",value:function(t){for(var e,i=Jc(fx(e=this._data).call(e)),n=[],o=0,r=i.length;o<r;o++)n.push(this._data.get(i[o]));return this._data.clear(),this.length=0,this._trigger("remove",{items:i,oldData:n},t),i}},{key:"max",value:function(t){var e,i,n=null,o=null,r=Hx(kx(e=this._data).call(e));try{for(r.s();!(i=r.n()).done;){var s=i.value,a=s[t];"number"==typeof a&&(null==o||a>o)&&(n=s,o=a)}}catch(t){r.e(t)}finally{r.f()}return n||null}},{key:"min",value:function(t){var e,i,n=null,o=null,r=Hx(kx(e=this._data).call(e));try{for(r.s();!(i=r.n()).done;){var s=i.value,a=s[t];"number"==typeof a&&(null==o||a<o)&&(n=s,o=a)}}catch(t){r.e(t)}finally{r.f()}return n||null}},{key:"distinct",value:function(t){for(var e=this._data,i=Jc(fx(e).call(e)),n=[],o=0,r=0,s=i.length;r<s;r++){for(var a=i[r],h=e.get(a)[t],l=!1,d=0;d<o;d++)if(n[d]==h){l=!0;break}l||void 0===h||(n[o]=h,o++)}return n}},{key:"_addItem",value:function(t){var e=function(t,e){return null==t[e]&&(t[e]=Ax()),t}(t,this._idProp),i=e[this._idProp];if(this._data.has(i))throw new Error("Cannot add item: item with id "+i+" already exists");return this._data.set(i,e),++this.length,i}},{key:"_updateItem",value:function(t){var e=t[this._idProp];if(null==e)throw new Error("Cannot update item: item has no id (item: "+gv(t)+")");var i=this._data.get(e);if(!i)throw new Error("Cannot update item: no item with id "+e+" found");return this._data.set(e,Rx(Rx({},i),t)),e}},{key:"stream",value:function(t){if(t){var e=this._data;return new Gx($d({},w_,Rk.mark((function i(){var n,o,r,s;return Rk.wrap((function(i){for(;;)switch(i.prev=i.next){case 0:n=Hx(t),i.prev=1,n.s();case 3:if((o=n.n()).done){i.next=11;break}if(r=o.value,null==(s=e.get(r))){i.next=9;break}return i.next=9,[r,s];case 9:i.next=3;break;case 11:i.next=16;break;case 13:i.prev=13,i.t0=i.catch(1),n.e(i.t0);case 16:return i.prev=16,n.f(),i.finish(16);case 19:case"end":return i.stop()}}),i,null,[[1,13,16,19]])}))))}var i;return new Gx($d({},w_,zn(i=Mx(this._data)).call(i,this._data)))}}]),i}(Xx),$x=function(t){zk(i,t);var e=Lx(i);function i(t,n){var o,r;return Yd(this,i),$d(Pk(r=e.call(this)),"length",0),$d(Pk(r),"_listener",void 0),$d(Pk(r),"_data",void 0),$d(Pk(r),"_ids",new b_),$d(Pk(r),"_options",void 0),r._options=n||{},r._listener=zn(o=r._onEvent).call(o,Pk(r)),r.setData(t),r}return Kd(i,[{key:"idProp",get:function(){return this.getDataSet().idProp}},{key:"setData",value:function(t){if(this._data){this._data.off&&this._data.off("*",this._listener);var e=this._data.getIds({filter:Xf(this._options)}),i=this._data.get(e);this._ids.clear(),this.length=0,this._trigger("remove",{items:e,oldData:i})}if(null!=t){this._data=t;for(var n=this._data.getIds({filter:Xf(this._options)}),o=0,r=n.length;o<r;o++){var s=n[o];this._ids.add(s)}this.length=n.length,this._trigger("add",{items:n})}else this._data=new Kx;this._data.on&&this._data.on("*",this._listener)}},{key:"refresh",value:function(){for(var t=this._data.getIds({filter:Xf(this._options)}),e=Jc(this._ids),i={},n=[],o=[],r=[],s=0,a=t.length;s<a;s++){var h=t[s];i[h]=!0,this._ids.has(h)||(n.push(h),this._ids.add(h))}for(var l=0,d=e.length;l<d;l++){var c=e[l],u=this._data.get(c);null==u?console.error("If you see this, report it please."):i[c]||(o.push(c),r.push(u),this._ids.delete(c))}this.length+=n.length-o.length,n.length&&this._trigger("add",{items:n}),o.length&&this._trigger("remove",{items:o,oldData:r})}},{key:"get",value:function(t,e){if(null==this._data)return null;var i,n=null;Ux(t)||lu(t)?(n=t,i=e):i=t;var o=un({},this._options,i),r=Xf(this._options),s=i&&Xf(i);return r&&s&&(o.filter=function(t){return r(t)&&s(t)}),null==n?this._data.get(o):this._data.get(n,o)}},{key:"getIds",value:function(t){if(this._data.length){var e,i=Xf(this._options),n=null!=t?Xf(t):null;return e=n?i?function(t){return i(t)&&n(t)}:n:i,this._data.getIds({filter:e,order:t&&t.order})}return[]}},{key:"forEach",value:function(t,e){if(this._data){var i,n,o=Xf(this._options),r=e&&Xf(e);n=r?o?function(t){return o(t)&&r(t)}:r:o,Fu(i=this._data).call(i,t,{filter:n,order:e&&e.order})}}},{key:"map",value:function(t,e){if(this._data){var i,n,o=Xf(this._options),r=e&&Xf(e);return n=r?o?function(t){return o(t)&&r(t)}:r:o,gu(i=this._data).call(i,t,{filter:n,order:e&&e.order})}return[]}},{key:"getDataSet",value:function(){return this._data.getDataSet()}},{key:"stream",value:function(t){var e;return this._data.stream(t||$d({},w_,zn(e=fx(this._ids)).call(e,this._ids)))}},{key:"dispose",value:function(){var t;null!==(t=this._data)&&void 0!==t&&t.off&&this._data.off("*",this._listener);var e,n="This data view has already been disposed of.",o={get:function(){throw new Error(n)},set:function(){throw new Error(n)},configurable:!1},r=Hx(hu(i.prototype));try{for(r.s();!(e=r.n()).done;){var s=e.value;Ud(this,s,o)}}catch(t){r.e(t)}finally{r.f()}}},{key:"_onEvent",value:function(t,e,i){if(e&&e.items&&this._data){var n=e.items,o=[],r=[],s=[],a=[],h=[],l=[];switch(t){case"add":for(var d=0,c=n.length;d<c;d++){var u=n[d];this.get(u)&&(this._ids.add(u),o.push(u))}break;case"update":for(var f=0,p=n.length;f<p;f++){var v=n[f];this.get(v)?this._ids.has(v)?(r.push(v),h.push(e.data[f]),a.push(e.oldData[f])):(this._ids.add(v),o.push(v)):this._ids.has(v)&&(this._ids.delete(v),s.push(v),l.push(e.oldData[f]))}break;case"remove":for(var g=0,y=n.length;g<y;g++){var m=n[g];this._ids.has(m)&&(this._ids.delete(m),s.push(m),l.push(e.oldData[g]))}}this.length+=o.length-s.length,o.length&&this._trigger("add",{items:o},i),r.length&&this._trigger("update",{items:r,oldData:a,data:h},i),s.length&&this._trigger("remove",{items:s,oldData:l},i)}}}]),i}(Xx);function Zx(t,e){return"object"===Qc(e)&&null!==e&&t===e.idProp&&"function"==typeof e.add&&"function"==typeof e.clear&&"function"==typeof e.distinct&&"function"==typeof Fu(e)&&"function"==typeof e.get&&"function"==typeof e.getDataSet&&"function"==typeof e.getIds&&"number"==typeof e.length&&"function"==typeof gu(e)&&"function"==typeof e.max&&"function"==typeof e.min&&"function"==typeof e.off&&"function"==typeof e.on&&"function"==typeof e.remove&&"function"==typeof e.setOptions&&"function"==typeof e.stream&&"function"==typeof e.update&&"function"==typeof e.updateOnly}function Qx(t,e){return"object"===Qc(e)&&null!==e&&t===e.idProp&&"function"==typeof Fu(e)&&"function"==typeof e.get&&"function"==typeof e.getDataSet&&"function"==typeof e.getIds&&"number"==typeof e.length&&"function"==typeof gu(e)&&"function"==typeof e.off&&"function"==typeof e.on&&"function"==typeof e.stream&&Zx(t,e.getDataSet())}var Jx=Object.freeze({__proto__:null,DELETE:Iy,DataSet:Kx,DataStream:Gx,DataView:$x,Queue:Yx,createNewDataPipeFrom:function(t){return new Vx(t)},isDataSetLike:Zx,isDataViewLike:Qx}),tE=n,eE=o,iE=eo,nE=cp.trim,oE=g("".charAt),rE=tE.parseFloat,sE=tE.Symbol,aE=sE&&sE.iterator,hE=1/rE("\t\n\v\f\r  \u2028\u2029\ufeff-0")!=-1/0||aE&&!eE((function(){rE(Object(aE))}))?function(t){var e=nE(iE(t)),i=rE(e);return 0===i&&"-"==oE(e,0)?-0:i}:rE;_i({global:!0,forced:parseFloat!=hE},{parseFloat:hE});var lE=X.parseFloat,dE=_i,cE=o,uE=hh.f;dE({target:"Object",stat:!0,forced:cE((function(){return!Object.getOwnPropertyNames(1)}))},{getOwnPropertyNames:uE});var fE=X.Object,pE=function(t){return fE.getOwnPropertyNames(t)},vE=pE;function gE(t,e){var i=["node","edge","label"],n=!0,o=Mm(e,"chosen");if("boolean"==typeof o)n=o;else if("object"===Qc(o)){if(-1===Fp(i).call(i,t))throw new Error("choosify: subOption '"+t+"' should be one of '"+i.join("', '")+"'");var r=Mm(e,["chosen",t]);"boolean"!=typeof r&&"function"!=typeof r||(n=r)}return n}function yE(t,e,i){if(t.width<=0||t.height<=0)return!1;if(void 0!==i){var n={x:e.x-i.x,y:e.y-i.y};if(0!==i.angle){var o=-i.angle;e={x:Math.cos(o)*n.x-Math.sin(o)*n.y,y:Math.sin(o)*n.x+Math.cos(o)*n.y}}else e=n}var r=t.x+t.width,s=t.y+t.width;return t.left<e.x&&r>e.x&&t.top<e.y&&s>e.y}function mE(t){return"string"==typeof t&&""!==t}function bE(t,e,i,n){var o=n.x,r=n.y;if("function"==typeof n.distanceToBorder){var s=n.distanceToBorder(t,e),a=Math.sin(e)*s,h=Math.cos(e)*s;h===s?(o+=s,r=n.y):a===s?(o=n.x,r-=s):(o+=h,r-=a)}else n.shape.width>n.shape.height?(o=n.x+.5*n.shape.width,r=n.y-i):(o=n.x+i,r=n.y-.5*n.shape.height);return{x:o,y:r}}var wE=function(){function t(e){Yd(this,t),this.measureText=e,this.current=0,this.width=0,this.height=0,this.lines=[]}return Kd(t,[{key:"_add",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:"normal";void 0===this.lines[t]&&(this.lines[t]={width:0,height:0,blocks:[]});var n=e;void 0!==e&&""!==e||(n=" ");var o=this.measureText(n,i),r=un({},kx(o));r.text=e,r.width=o.width,r.mod=i,void 0!==e&&""!==e||(r.width=0),this.lines[t].blocks.push(r),this.lines[t].width+=r.width}},{key:"curWidth",value:function(){var t=this.lines[this.current];return void 0===t?0:t.width}},{key:"append",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"normal";this._add(this.current,t,e)}},{key:"newLine",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"normal";this._add(this.current,t,e),this.current++}},{key:"determineLineHeights",value:function(){for(var t=0;t<this.lines.length;t++){var e=this.lines[t],i=0;if(void 0!==e.blocks)for(var n=0;n<e.blocks.length;n++){var o=e.blocks[n];i<o.height&&(i=o.height)}e.height=i}}},{key:"determineLabelSize",value:function(){for(var t=0,e=0,i=0;i<this.lines.length;i++){var n=this.lines[i];n.width>t&&(t=n.width),e+=n.height}this.width=t,this.height=e}},{key:"removeEmptyBlocks",value:function(){for(var t=[],e=0;e<this.lines.length;e++){var i=this.lines[e];if(0!==i.blocks.length&&(e!==this.lines.length-1||0!==i.width)){var n={};un(n,i),n.blocks=[];for(var o=void 0,r=[],s=0;s<i.blocks.length;s++){var a=i.blocks[s];0!==a.width?r.push(a):void 0===o&&(o=a)}0===r.length&&void 0!==o&&r.push(o),n.blocks=r,t.push(n)}}return t}},{key:"finalize",value:function(){this.determineLineHeights(),this.determineLabelSize();var t=this.removeEmptyBlocks();return{width:this.width,height:this.height,lines:t}}}]),t}(),kE={"<b>":/<b>/,"<i>":/<i>/,"<code>":/<code>/,"</b>":/<\/b>/,"</i>":/<\/i>/,"</code>":/<\/code>/,"*":/\*/,_:/_/,"`":/`/,afterBold:/[^*]/,afterItal:/[^_]/,afterMono:/[^`]/},_E=function(){function t(e){Yd(this,t),this.text=e,this.bold=!1,this.ital=!1,this.mono=!1,this.spacing=!1,this.position=0,this.buffer="",this.modStack=[],this.blocks=[]}return Kd(t,[{key:"mod",value:function(){return 0===this.modStack.length?"normal":this.modStack[0]}},{key:"modName",value:function(){return 0===this.modStack.length?"normal":"mono"===this.modStack[0]?"mono":this.bold&&this.ital?"boldital":this.bold?"bold":this.ital?"ital":void 0}},{key:"emitBlock",value:function(){this.spacing&&(this.add(" "),this.spacing=!1),this.buffer.length>0&&(this.blocks.push({text:this.buffer,mod:this.modName()}),this.buffer="")}},{key:"add",value:function(t){" "===t&&(this.spacing=!0),this.spacing&&(this.buffer+=" ",this.spacing=!1)," "!=t&&(this.buffer+=t)}},{key:"parseWS",value:function(t){return!!/[ \t]/.test(t)&&(this.mono?this.add(t):this.spacing=!0,!0)}},{key:"setTag",value:function(t){this.emitBlock(),this[t]=!0,this.modStack.unshift(t)}},{key:"unsetTag",value:function(t){this.emitBlock(),this[t]=!1,this.modStack.shift()}},{key:"parseStartTag",value:function(t,e){return!(this.mono||this[t]||!this.match(e))&&(this.setTag(t),!0)}},{key:"match",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1],i=this.prepareRegExp(t),n=Kc(i,2),o=n[0],r=n[1],s=o.test(this.text.substr(this.position,r));return s&&e&&(this.position+=r-1),s}},{key:"parseEndTag",value:function(t,e,i){var n=this.mod()===t;return!(!(n="mono"===t?n&&this.mono:n&&!this.mono)||!this.match(e))&&(void 0!==i?(this.position===this.text.length-1||this.match(i,!1))&&this.unsetTag(t):this.unsetTag(t),!0)}},{key:"replace",value:function(t,e){return!!this.match(t)&&(this.add(e),this.position+=length-1,!0)}},{key:"prepareRegExp",value:function(t){var e,i;if(t instanceof RegExp)i=t,e=1;else{var n=kE[t];i=void 0!==n?n:new RegExp(t),e=t.length}return[i,e]}}]),t}(),xE=function(){function t(e,i,n,o){var r=this;Yd(this,t),this.ctx=e,this.parent=i,this.selected=n,this.hover=o;this.lines=new wE((function(t,i){if(void 0===t)return 0;var s=r.parent.getFormattingValues(e,n,o,i),a=0;""!==t&&(a=r.ctx.measureText(t).width);return{width:a,values:s}}))}return Kd(t,[{key:"process",value:function(t){if(!mE(t))return this.lines.finalize();var e=this.parent.fontOptions;t=(t=t.replace(/\r\n/g,"\n")).replace(/\r/g,"\n");var i=String(t).split("\n"),n=i.length;if(e.multi)for(var o=0;o<n;o++){var r=this.splitBlocks(i[o],e.multi);if(void 0!==r)if(0!==r.length){if(e.maxWdt>0)for(var s=0;s<r.length;s++){var a=r[s].mod,h=r[s].text;this.splitStringIntoLines(h,a,!0)}else for(var l=0;l<r.length;l++){var d=r[l].mod,c=r[l].text;this.lines.append(c,d)}this.lines.newLine()}else this.lines.newLine("")}else if(e.maxWdt>0)for(var u=0;u<n;u++)this.splitStringIntoLines(i[u]);else for(var f=0;f<n;f++)this.lines.newLine(i[f]);return this.lines.finalize()}},{key:"decodeMarkupSystem",value:function(t){var e="none";return"markdown"===t||"md"===t?e="markdown":!0!==t&&"html"!==t||(e="html"),e}},{key:"splitHtmlBlocks",value:function(t){for(var e=new _E(t),i=function(t){return!!/&/.test(t)&&(e.replace(e.text,"&lt;","<")||e.replace(e.text,"&amp;","&")||e.add("&"),!0)};e.position<e.text.length;){var n=e.text.charAt(e.position);e.parseWS(n)||/</.test(n)&&(e.parseStartTag("bold","<b>")||e.parseStartTag("ital","<i>")||e.parseStartTag("mono","<code>")||e.parseEndTag("bold","</b>")||e.parseEndTag("ital","</i>")||e.parseEndTag("mono","</code>"))||i(n)||e.add(n),e.position++}return e.emitBlock(),e.blocks}},{key:"splitMarkdownBlocks",value:function(t){for(var e=this,i=new _E(t),n=!0,o=function(t){return!!/\\/.test(t)&&(i.position<e.text.length+1&&(i.position++,t=e.text.charAt(i.position),/ \t/.test(t)?i.spacing=!0:(i.add(t),n=!1)),!0)};i.position<i.text.length;){var r=i.text.charAt(i.position);i.parseWS(r)||o(r)||(n||i.spacing)&&(i.parseStartTag("bold","*")||i.parseStartTag("ital","_")||i.parseStartTag("mono","`"))||i.parseEndTag("bold","*","afterBold")||i.parseEndTag("ital","_","afterItal")||i.parseEndTag("mono","`","afterMono")||(i.add(r),n=!1),i.position++}return i.emitBlock(),i.blocks}},{key:"splitBlocks",value:function(t,e){var i=this.decodeMarkupSystem(e);return"none"===i?[{text:t,mod:"normal"}]:"markdown"===i?this.splitMarkdownBlocks(t):"html"===i?this.splitHtmlBlocks(t):void 0}},{key:"overMaxWidth",value:function(t){var e=this.ctx.measureText(t).width;return this.lines.curWidth()+e>this.parent.fontOptions.maxWdt}},{key:"getLongestFit",value:function(t){for(var e="",i=0;i<t.length;){var n=e+(""===e?"":" ")+t[i];if(this.overMaxWidth(n))break;e=n,i++}return i}},{key:"getLongestFitWord",value:function(t){for(var e=0;e<t.length&&!this.overMaxWidth(au(t).call(t,0,e));)e++;return e}},{key:"splitStringIntoLines",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"normal",i=arguments.length>2&&void 0!==arguments[2]&&arguments[2];this.parent.getFormattingValues(this.ctx,this.selected,this.hover,e);for(var n=(t=(t=t.replace(/^( +)/g,"$1\r")).replace(/([^\r][^ ]*)( +)/g,"$1\r$2\r")).split("\r");n.length>0;){var o=this.getLongestFit(n);if(0===o){var r=n[0],s=this.getLongestFitWord(r);this.lines.newLine(au(r).call(r,0,s),e),n[0]=au(r).call(r,s)}else{var a=o;" "===n[o-1]?o--:" "===n[a]&&a++;var h=au(n).call(n,0,o).join("");o==n.length&&i?this.lines.append(h,e):this.lines.newLine(h,e),n=au(n).call(n,a)}}}}]),t}(),EE=["bold","ital","boldital","mono"],OE=function(){function t(e,i){var n=arguments.length>2&&void 0!==arguments[2]&&arguments[2];Yd(this,t),this.body=e,this.pointToSelf=!1,this.baseSize=void 0,this.fontOptions={},this.setOptions(i),this.size={top:0,left:0,width:0,height:0,yLine:0},this.isEdgeLabel=n}return Kd(t,[{key:"setOptions",value:function(t){if(this.elementOptions=t,this.initFontOptions(t.font),mE(t.label)?this.labelDirty=!0:t.label=void 0,void 0!==t.font&&null!==t.font)if("string"==typeof t.font)this.baseSize=this.fontOptions.size;else if("object"===Qc(t.font)){var e=t.font.size;void 0!==e&&(this.baseSize=e)}}},{key:"initFontOptions",value:function(e){var i=this;hm(EE,(function(t){i.fontOptions[t]={}})),t.parseFontString(this.fontOptions,e)?this.fontOptions.vadjust=0:hm(e,(function(t,e){null!=t&&"object"!==Qc(t)&&(i.fontOptions[e]=t)}))}},{key:"constrain",value:function(t){var e={constrainWidth:!1,maxWdt:-1,minWdt:-1,constrainHeight:!1,minHgt:-1,valign:"middle"},i=Mm(t,"widthConstraint");if("number"==typeof i)e.maxWdt=Number(i),e.minWdt=Number(i);else if("object"===Qc(i)){var n=Mm(t,["widthConstraint","maximum"]);"number"==typeof n&&(e.maxWdt=Number(n));var o=Mm(t,["widthConstraint","minimum"]);"number"==typeof o&&(e.minWdt=Number(o))}var r=Mm(t,"heightConstraint");if("number"==typeof r)e.minHgt=Number(r);else if("object"===Qc(r)){var s=Mm(t,["heightConstraint","minimum"]);"number"==typeof s&&(e.minHgt=Number(s));var a=Mm(t,["heightConstraint","valign"]);"string"==typeof a&&("top"!==a&&"bottom"!==a||(e.valign=a))}return e}},{key:"update",value:function(t,e){this.setOptions(t,!0),this.propagateFonts(e),nm(this.fontOptions,this.constrain(e)),this.fontOptions.chooser=gE("label",e)}},{key:"adjustSizes",value:function(t){var e=t?t.right+t.left:0;this.fontOptions.constrainWidth&&(this.fontOptions.maxWdt-=e,this.fontOptions.minWdt-=e);var i=t?t.top+t.bottom:0;this.fontOptions.constrainHeight&&(this.fontOptions.minHgt-=i)}},{key:"addFontOptionsToPile",value:function(t,e){for(var i=0;i<e.length;++i)this.addFontToPile(t,e[i])}},{key:"addFontToPile",value:function(t,e){if(void 0!==e&&void 0!==e.font&&null!==e.font){var i=e.font;t.push(i)}}},{key:"getBasicOptions",value:function(e){for(var i={},n=0;n<e.length;++n){var o=e[n],r={};t.parseFontString(r,o)&&(o=r),hm(o,(function(t,e){void 0!==t&&(Object.prototype.hasOwnProperty.call(i,e)||(-1!==Fp(EE).call(EE,e)?i[e]={}:i[e]=t))}))}return i}},{key:"getFontOption",value:function(e,i,n){for(var o,r=0;r<e.length;++r){var s=e[r];if(Object.prototype.hasOwnProperty.call(s,i)){if(null==(o=s[i]))continue;var a={};if(t.parseFontString(a,o)&&(o=a),Object.prototype.hasOwnProperty.call(o,n))return o[n]}}if(Object.prototype.hasOwnProperty.call(this.fontOptions,n))return this.fontOptions[n];throw new Error("Did not find value for multi-font for property: '"+n+"'")}},{key:"getFontOptions",value:function(t,e){for(var i={},n=["color","size","face","mod","vadjust"],o=0;o<n.length;++o){var r=n[o];i[r]=this.getFontOption(t,e,r)}return i}},{key:"propagateFonts",value:function(t){var e=this,i=[];this.addFontOptionsToPile(i,t),this.fontOptions=this.getBasicOptions(i);for(var n=function(t){var n=EE[t],o=e.fontOptions[n];hm(e.getFontOptions(i,n),(function(t,e){o[e]=t})),o.size=Number(o.size),o.vadjust=Number(o.vadjust)},o=0;o<EE.length;++o)n(o)}},{key:"draw",value:function(t,e,i,n,o){var r=arguments.length>5&&void 0!==arguments[5]?arguments[5]:"middle";if(void 0!==this.elementOptions.label){var s=this.fontOptions.size*this.body.view.scale;this.elementOptions.label&&s<this.elementOptions.scaling.label.drawThreshold-1||(s>=this.elementOptions.scaling.label.maxVisible&&(s=Number(this.elementOptions.scaling.label.maxVisible)/this.body.view.scale),this.calculateLabelSize(t,n,o,e,i,r),this._drawBackground(t),this._drawText(t,e,this.size.yLine,r,s))}}},{key:"_drawBackground",value:function(t){if(void 0!==this.fontOptions.background&&"none"!==this.fontOptions.background){t.fillStyle=this.fontOptions.background;var e=this.getSize();t.fillRect(e.left,e.top,e.width,e.height)}}},{key:"_drawText",value:function(t,e,i){var n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:"middle",o=arguments.length>4?arguments[4]:void 0,r=this._setAlignment(t,e,i,n),s=Kc(r,2);e=s[0],i=s[1],t.textAlign="left",e-=this.size.width/2,this.fontOptions.valign&&this.size.height>this.size.labelHeight&&("top"===this.fontOptions.valign&&(i-=(this.size.height-this.size.labelHeight)/2),"bottom"===this.fontOptions.valign&&(i+=(this.size.height-this.size.labelHeight)/2));for(var a=0;a<this.lineCount;a++){var h=this.lines[a];if(h&&h.blocks){var l=0;this.isEdgeLabel||"center"===this.fontOptions.align?l+=(this.size.width-h.width)/2:"right"===this.fontOptions.align&&(l+=this.size.width-h.width);for(var d=0;d<h.blocks.length;d++){var c=h.blocks[d];t.font=c.font;var u=this._getColor(c.color,o,c.strokeColor),f=Kc(u,2),p=f[0],v=f[1];c.strokeWidth>0&&(t.lineWidth=c.strokeWidth,t.strokeStyle=v,t.lineJoin="round"),t.fillStyle=p,c.strokeWidth>0&&t.strokeText(c.text,e+l,i+c.vadjust),t.fillText(c.text,e+l,i+c.vadjust),l+=c.width}i+=h.height}}}},{key:"_setAlignment",value:function(t,e,i,n){if(this.isEdgeLabel&&"horizontal"!==this.fontOptions.align&&!1===this.pointToSelf){e=0,i=0;"top"===this.fontOptions.align?(t.textBaseline="alphabetic",i-=4):"bottom"===this.fontOptions.align?(t.textBaseline="hanging",i+=4):t.textBaseline="middle"}else t.textBaseline=n;return[e,i]}},{key:"_getColor",value:function(t,e,i){var n=t||"#000000",o=i||"#ffffff";if(e<=this.elementOptions.scaling.label.drawThreshold){var r=Math.max(0,Math.min(1,1-(this.elementOptions.scaling.label.drawThreshold-e)));n=pm(n,r),o=pm(o,r)}return[n,o]}},{key:"getTextSize",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],i=arguments.length>2&&void 0!==arguments[2]&&arguments[2];return this._processLabel(t,e,i),{width:this.size.width,height:this.size.height,lineCount:this.lineCount}}},{key:"getSize",value:function(){var t=this.size.left,e=this.size.top-1;if(this.isEdgeLabel){var i=.5*-this.size.width;switch(this.fontOptions.align){case"middle":t=i,e=.5*-this.size.height;break;case"top":t=i,e=-(this.size.height+2);break;case"bottom":t=i,e=2}}return{left:t,top:e,width:this.size.width,height:this.size.height}}},{key:"calculateLabelSize",value:function(t,e,i){var n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:0,o=arguments.length>4&&void 0!==arguments[4]?arguments[4]:0,r=arguments.length>5&&void 0!==arguments[5]?arguments[5]:"middle";this._processLabel(t,e,i),this.size.left=n-.5*this.size.width,this.size.top=o-.5*this.size.height,this.size.yLine=o+.5*(1-this.lineCount)*this.fontOptions.size,"hanging"===r&&(this.size.top+=.5*this.fontOptions.size,this.size.top+=4,this.size.yLine+=4)}},{key:"getFormattingValues",value:function(t,e,i,n){var o=function(t,e,i){return"normal"===e?"mod"===i?"":t[i]:void 0!==t[e][i]?t[e][i]:t[i]},r={color:o(this.fontOptions,n,"color"),size:o(this.fontOptions,n,"size"),face:o(this.fontOptions,n,"face"),mod:o(this.fontOptions,n,"mod"),vadjust:o(this.fontOptions,n,"vadjust"),strokeWidth:this.fontOptions.strokeWidth,strokeColor:this.fontOptions.strokeColor};(e||i)&&("normal"===n&&!0===this.fontOptions.chooser&&this.elementOptions.labelHighlightBold?r.mod="bold":"function"==typeof this.fontOptions.chooser&&this.fontOptions.chooser(r,this.elementOptions.id,e,i));var s="";return void 0!==r.mod&&""!==r.mod&&(s+=r.mod+" "),s+=r.size+"px "+r.face,t.font=s.replace(/"/g,""),r.font=t.font,r.height=r.size,r}},{key:"differentState",value:function(t,e){return t!==this.selectedState||e!==this.hoverState}},{key:"_processLabelText",value:function(t,e,i,n){return new xE(t,this,e,i).process(n)}},{key:"_processLabel",value:function(t,e,i){if(!1!==this.labelDirty||this.differentState(e,i)){var n=this._processLabelText(t,e,i,this.elementOptions.label);this.fontOptions.minWdt>0&&n.width<this.fontOptions.minWdt&&(n.width=this.fontOptions.minWdt),this.size.labelHeight=n.height,this.fontOptions.minHgt>0&&n.height<this.fontOptions.minHgt&&(n.height=this.fontOptions.minHgt),this.lines=n.lines,this.lineCount=n.lines.length,this.size.width=n.width,this.size.height=n.height,this.selectedState=e,this.hoverState=i,this.labelDirty=!1}}},{key:"visible",value:function(){return 0!==this.size.width&&0!==this.size.height&&void 0!==this.elementOptions.label&&!(this.fontOptions.size*this.body.view.scale<this.elementOptions.scaling.label.drawThreshold-1)}}],[{key:"parseFontString",value:function(t,e){if(!e||"string"!=typeof e)return!1;var i=e.split(" ");return t.size=+i[0].replace("px",""),t.face=i[1],t.color=i[2],!0}}]),t}(),CE=function(){function t(e,i,n){Yd(this,t),this.body=i,this.labelModule=n,this.setOptions(e),this.top=void 0,this.left=void 0,this.height=void 0,this.width=void 0,this.radius=void 0,this.margin=void 0,this.refreshNeeded=!0,this.boundingBox={top:0,left:0,right:0,bottom:0}}return Kd(t,[{key:"setOptions",value:function(t){this.options=t}},{key:"_setMargins",value:function(t){this.margin={},this.options.margin&&("object"==Qc(this.options.margin)?(this.margin.top=this.options.margin.top,this.margin.right=this.options.margin.right,this.margin.bottom=this.options.margin.bottom,this.margin.left=this.options.margin.left):(this.margin.top=this.options.margin,this.margin.right=this.options.margin,this.margin.bottom=this.options.margin,this.margin.left=this.options.margin)),t.adjustSizes(this.margin)}},{key:"_distanceToBorder",value:function(t,e){var i=this.options.borderWidth;return t&&this.resize(t),Math.min(Math.abs(this.width/2/Math.cos(e)),Math.abs(this.height/2/Math.sin(e)))+i}},{key:"enableShadow",value:function(t,e){e.shadow&&(t.shadowColor=e.shadowColor,t.shadowBlur=e.shadowSize,t.shadowOffsetX=e.shadowX,t.shadowOffsetY=e.shadowY)}},{key:"disableShadow",value:function(t,e){e.shadow&&(t.shadowColor="rgba(0,0,0,0)",t.shadowBlur=0,t.shadowOffsetX=0,t.shadowOffsetY=0)}},{key:"enableBorderDashes",value:function(t,e){if(!1!==e.borderDashes)if(void 0!==t.setLineDash){var i=e.borderDashes;!0===i&&(i=[5,15]),t.setLineDash(i)}else console.warn("setLineDash is not supported in this browser. The dashed borders cannot be used."),this.options.shapeProperties.borderDashes=!1,e.borderDashes=!1}},{key:"disableBorderDashes",value:function(t,e){!1!==e.borderDashes&&(void 0!==t.setLineDash?t.setLineDash([0]):(console.warn("setLineDash is not supported in this browser. The dashed borders cannot be used."),this.options.shapeProperties.borderDashes=!1,e.borderDashes=!1))}},{key:"needsRefresh",value:function(t,e){return!0===this.refreshNeeded?(this.refreshNeeded=!1,!0):void 0===this.width||this.labelModule.differentState(t,e)}},{key:"initContextForDraw",value:function(t,e){var i=e.borderWidth/this.body.view.scale;t.lineWidth=Math.min(this.width,i),t.strokeStyle=e.borderColor,t.fillStyle=e.color}},{key:"performStroke",value:function(t,e){var i=e.borderWidth/this.body.view.scale;t.save(),i>0&&(this.enableBorderDashes(t,e),t.stroke(),this.disableBorderDashes(t,e)),t.restore()}},{key:"performFill",value:function(t,e){t.save(),t.fillStyle=e.color,this.enableShadow(t,e),jv(t).call(t),this.disableShadow(t,e),t.restore(),this.performStroke(t,e)}},{key:"_addBoundingBoxMargin",value:function(t){this.boundingBox.left-=t,this.boundingBox.top-=t,this.boundingBox.bottom+=t,this.boundingBox.right+=t}},{key:"_updateBoundingBox",value:function(t,e,i,n,o){void 0!==i&&this.resize(i,n,o),this.left=t-this.width/2,this.top=e-this.height/2,this.boundingBox.left=this.left,this.boundingBox.top=this.top,this.boundingBox.bottom=this.top+this.height,this.boundingBox.right=this.left+this.width}},{key:"updateBoundingBox",value:function(t,e,i,n,o){this._updateBoundingBox(t,e,i,n,o)}},{key:"getDimensionsFromLabel",value:function(t,e,i){this.textSize=this.labelModule.getTextSize(t,e,i);var n=this.textSize.width,o=this.textSize.height;return 0===n&&(n=14,o=14),{width:n,height:o}}}]),t}();function SE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var TE=function(t){zk(i,t);var e=SE(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o))._setMargins(o),r}return Kd(i,[{key:"resize",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.selected,i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.hover;if(this.needsRefresh(e,i)){var n=this.getDimensionsFromLabel(t,e,i);this.width=n.width+this.margin.right+this.margin.left,this.height=n.height+this.margin.top+this.margin.bottom,this.radius=this.width/2}}},{key:"draw",value:function(t,e,i,n,o,r){this.resize(t,n,o),this.left=e-this.width/2,this.top=i-this.height/2,this.initContextForDraw(t,r),Fn(t,this.left,this.top,this.width,this.height,r.borderRadius),this.performFill(t,r),this.updateBoundingBox(e,i,t,n,o),this.labelModule.draw(t,this.left+this.textSize.width/2+this.margin.left,this.top+this.textSize.height/2+this.margin.top,n,o)}},{key:"updateBoundingBox",value:function(t,e,i,n,o){this._updateBoundingBox(t,e,i,n,o);var r=this.options.shapeProperties.borderRadius;this._addBoundingBoxMargin(r)}},{key:"distanceToBorder",value:function(t,e){t&&this.resize(t);var i=this.options.borderWidth;return Math.min(Math.abs(this.width/2/Math.cos(e)),Math.abs(this.height/2/Math.sin(e)))+i}}]),i}(CE);function ME(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var PE=function(t){zk(i,t);var e=ME(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o)).labelOffset=0,r.selected=!1,r}return Kd(i,[{key:"setOptions",value:function(t,e,i){this.options=t,void 0===e&&void 0===i||this.setImages(e,i)}},{key:"setImages",value:function(t,e){e&&this.selected?(this.imageObj=e,this.imageObjAlt=t):(this.imageObj=t,this.imageObjAlt=e)}},{key:"switchImages",value:function(t){var e=t&&!this.selected||!t&&this.selected;if(this.selected=t,void 0!==this.imageObjAlt&&e){var i=this.imageObj;this.imageObj=this.imageObjAlt,this.imageObjAlt=i}}},{key:"_getImagePadding",value:function(){var t={top:0,right:0,bottom:0,left:0};if(this.options.imagePadding){var e=this.options.imagePadding;"object"==Qc(e)?(t.top=e.top,t.right=e.right,t.bottom=e.bottom,t.left=e.left):(t.top=e,t.right=e,t.bottom=e,t.left=e)}return t}},{key:"_resizeImage",value:function(){var t,e;if(!1===this.options.shapeProperties.useImageSize){var i=1,n=1;this.imageObj.width&&this.imageObj.height&&(this.imageObj.width>this.imageObj.height?i=this.imageObj.width/this.imageObj.height:n=this.imageObj.height/this.imageObj.width),t=2*this.options.size*i,e=2*this.options.size*n}else{var o=this._getImagePadding();t=this.imageObj.width+o.left+o.right,e=this.imageObj.height+o.top+o.bottom}this.width=t,this.height=e,this.radius=.5*this.width}},{key:"_drawRawCircle",value:function(t,e,i,n){this.initContextForDraw(t,n),Nn(t,e,i,n.size),this.performFill(t,n)}},{key:"_drawImageAtPosition",value:function(t,e){if(0!=this.imageObj.width){t.globalAlpha=void 0!==e.opacity?e.opacity:1,this.enableShadow(t,e);var i=1;!0===this.options.shapeProperties.interpolation&&(i=this.imageObj.width/this.width/this.body.view.scale);var n=this._getImagePadding(),o=this.left+n.left,r=this.top+n.top,s=this.width-n.left-n.right,a=this.height-n.top-n.bottom;this.imageObj.drawImageAtPosition(t,i,o,r,s,a),this.disableShadow(t,e)}}},{key:"_drawImageLabel",value:function(t,e,i,n,o){var r=0;if(void 0!==this.height){r=.5*this.height;var s=this.labelModule.getTextSize(t,n,o);s.lineCount>=1&&(r+=s.height/2)}var a=i+r;this.options.label&&(this.labelOffset=r),this.labelModule.draw(t,e,a,n,o,"hanging")}}]),i}(CE);function DE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var IE=function(t){zk(i,t);var e=DE(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o))._setMargins(o),r}return Kd(i,[{key:"resize",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.selected,i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.hover;if(this.needsRefresh(e,i)){var n=this.getDimensionsFromLabel(t,e,i),o=Math.max(n.width+this.margin.right+this.margin.left,n.height+this.margin.top+this.margin.bottom);this.options.size=o/2,this.width=o,this.height=o,this.radius=this.width/2}}},{key:"draw",value:function(t,e,i,n,o,r){this.resize(t,n,o),this.left=e-this.width/2,this.top=i-this.height/2,this._drawRawCircle(t,e,i,r),this.updateBoundingBox(e,i),this.labelModule.draw(t,this.left+this.textSize.width/2+this.margin.left,i,n,o)}},{key:"updateBoundingBox",value:function(t,e){this.boundingBox.top=e-this.options.size,this.boundingBox.left=t-this.options.size,this.boundingBox.right=t+this.options.size,this.boundingBox.bottom=e+this.options.size}},{key:"distanceToBorder",value:function(t){return t&&this.resize(t),.5*this.width}}]),i}(PE);function BE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var zE=function(t){zk(i,t);var e=BE(i);function i(t,n,o,r,s){var a;return Yd(this,i),(a=e.call(this,t,n,o)).setImages(r,s),a}return Kd(i,[{key:"resize",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.selected,i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.hover,n=void 0===this.imageObj.src||void 0===this.imageObj.width||void 0===this.imageObj.height;if(n){var o=2*this.options.size;return this.width=o,this.height=o,void(this.radius=.5*this.width)}this.needsRefresh(e,i)&&this._resizeImage()}},{key:"draw",value:function(t,e,i,n,o,r){this.switchImages(n),this.resize();var s=e,a=i;"top-left"===this.options.shapeProperties.coordinateOrigin?(this.left=e,this.top=i,s+=this.width/2,a+=this.height/2):(this.left=e-this.width/2,this.top=i-this.height/2),this._drawRawCircle(t,s,a,r),t.save(),t.clip(),this._drawImageAtPosition(t,r),t.restore(),this._drawImageLabel(t,s,a,n,o),this.updateBoundingBox(e,i)}},{key:"updateBoundingBox",value:function(t,e){"top-left"===this.options.shapeProperties.coordinateOrigin?(this.boundingBox.top=e,this.boundingBox.left=t,this.boundingBox.right=t+2*this.options.size,this.boundingBox.bottom=e+2*this.options.size):(this.boundingBox.top=e-this.options.size,this.boundingBox.left=t-this.options.size,this.boundingBox.right=t+this.options.size,this.boundingBox.bottom=e+this.options.size),this.boundingBox.left=Math.min(this.boundingBox.left,this.labelModule.size.left),this.boundingBox.right=Math.max(this.boundingBox.right,this.labelModule.size.left+this.labelModule.size.width),this.boundingBox.bottom=Math.max(this.boundingBox.bottom,this.boundingBox.bottom+this.labelOffset)}},{key:"distanceToBorder",value:function(t){return t&&this.resize(t),.5*this.width}}]),i}(PE);function NE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var FE=function(t){zk(i,t);var e=NE(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"resize",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.selected,i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.hover,n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{size:this.options.size};if(this.needsRefresh(e,i)){var o,r;this.labelModule.getTextSize(t,e,i);var s=2*n.size;this.width=null!==(o=this.customSizeWidth)&&void 0!==o?o:s,this.height=null!==(r=this.customSizeHeight)&&void 0!==r?r:s,this.radius=.5*this.width}}},{key:"_drawShape",value:function(t,e,i,n,o,r,s,a){var h,l=this;return this.resize(t,r,s,a),this.left=n-this.width/2,this.top=o-this.height/2,this.initContextForDraw(t,a),(h=e,Object.prototype.hasOwnProperty.call(Ln,h)?Ln[h]:function(t){for(var e=arguments.length,i=new Array(e>1?e-1:0),n=1;n<e;n++)i[n-1]=arguments[n];CanvasRenderingContext2D.prototype[h].call(t,i)})(t,n,o,a.size),this.performFill(t,a),void 0!==this.options.icon&&void 0!==this.options.icon.code&&(t.font=(r?"bold ":"")+this.height/2+"px "+(this.options.icon.face||"FontAwesome"),t.fillStyle=this.options.icon.color||"black",t.textAlign="center",t.textBaseline="middle",t.fillText(this.options.icon.code,n,o)),{drawExternalLabel:function(){if(void 0!==l.options.label){l.labelModule.calculateLabelSize(t,r,s,n,o,"hanging");var e=o+.5*l.height+.5*l.labelModule.size.height;l.labelModule.draw(t,n,e,r,s,"hanging")}l.updateBoundingBox(n,o)}}}},{key:"updateBoundingBox",value:function(t,e){this.boundingBox.top=e-this.options.size,this.boundingBox.left=t-this.options.size,this.boundingBox.right=t+this.options.size,this.boundingBox.bottom=e+this.options.size,void 0!==this.options.label&&this.labelModule.size.width>0&&(this.boundingBox.left=Math.min(this.boundingBox.left,this.labelModule.size.left),this.boundingBox.right=Math.max(this.boundingBox.right,this.labelModule.size.left+this.labelModule.size.width),this.boundingBox.bottom=Math.max(this.boundingBox.bottom,this.boundingBox.bottom+this.labelModule.size.height))}}]),i}(CE);function AE(t,e){var i=bu(t);if(hd){var n=hd(t);e&&(n=Xf(n).call(n,(function(e){return bd(t,e).enumerable}))),i.push.apply(i,n)}return i}function jE(t){for(var e=1;e<arguments.length;e++){var i,n,o=null!=arguments[e]?arguments[e]:{};e%2?Fu(i=AE(Object(o),!0)).call(i,(function(e){$d(t,e,o[e])})):Pd?Ad(t,Pd(o)):Fu(n=AE(Object(o))).call(n,(function(e){Ud(t,e,bd(o,e))}))}return t}function RE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var LE=function(t){zk(i,t);var e=RE(i);function i(t,n,o,r){var s;return Yd(this,i),(s=e.call(this,t,n,o,r)).ctxRenderer=r,s}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){this.resize(t,n,o,r),this.left=e-this.width/2,this.top=i-this.height/2,t.save();var s=this.ctxRenderer({ctx:t,id:this.options.id,x:e,y:i,state:{selected:n,hover:o},style:jE({},r),label:this.options.label});if(null!=s.drawNode&&s.drawNode(),t.restore(),s.drawExternalLabel){var a=s.drawExternalLabel;s.drawExternalLabel=function(){t.save(),a(),t.restore()}}return s.nodeDimensions&&(this.customSizeWidth=s.nodeDimensions.width,this.customSizeHeight=s.nodeDimensions.height),s}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(FE);function HE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var WE=function(t){zk(i,t);var e=HE(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o))._setMargins(o),r}return Kd(i,[{key:"resize",value:function(t,e,i){if(this.needsRefresh(e,i)){var n=this.getDimensionsFromLabel(t,e,i).width+this.margin.right+this.margin.left;this.width=n,this.height=n,this.radius=this.width/2}}},{key:"draw",value:function(t,e,i,n,o,r){this.resize(t,n,o),this.left=e-this.width/2,this.top=i-this.height/2,this.initContextForDraw(t,r),jn(t,e-this.width/2,i-this.height/2,this.width,this.height),this.performFill(t,r),this.updateBoundingBox(e,i,t,n,o),this.labelModule.draw(t,this.left+this.textSize.width/2+this.margin.left,this.top+this.textSize.height/2+this.margin.top,n,o)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(CE);function qE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var VE=function(t){zk(i,t);var e=qE(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){return this._drawShape(t,"diamond",4,e,i,n,o,r)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(FE);function UE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var YE=function(t){zk(i,t);var e=UE(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){return this._drawShape(t,"circle",2,e,i,n,o,r)}},{key:"distanceToBorder",value:function(t){return t&&this.resize(t),this.options.size}}]),i}(FE);function XE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var GE=function(t){zk(i,t);var e=XE(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"resize",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.selected,i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.hover;if(this.needsRefresh(e,i)){var n=this.getDimensionsFromLabel(t,e,i);this.height=2*n.height,this.width=n.width+n.height,this.radius=.5*this.width}}},{key:"draw",value:function(t,e,i,n,o,r){this.resize(t,n,o),this.left=e-.5*this.width,this.top=i-.5*this.height,this.initContextForDraw(t,r),An(t,this.left,this.top,this.width,this.height),this.performFill(t,r),this.updateBoundingBox(e,i,t,n,o),this.labelModule.draw(t,e,i,n,o)}},{key:"distanceToBorder",value:function(t,e){t&&this.resize(t);var i=.5*this.width,n=.5*this.height,o=Math.sin(e)*i,r=Math.cos(e)*n;return i*n/Math.sqrt(o*o+r*r)}}]),i}(CE);function KE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var $E=function(t){zk(i,t);var e=KE(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o))._setMargins(o),r}return Kd(i,[{key:"resize",value:function(t,e,i){this.needsRefresh(e,i)&&(this.iconSize={width:Number(this.options.icon.size),height:Number(this.options.icon.size)},this.width=this.iconSize.width+this.margin.right+this.margin.left,this.height=this.iconSize.height+this.margin.top+this.margin.bottom,this.radius=.5*this.width)}},{key:"draw",value:function(t,e,i,n,o,r){var s=this;return this.resize(t,n,o),this.options.icon.size=this.options.icon.size||50,this.left=e-this.width/2,this.top=i-this.height/2,this._icon(t,e,i,n,o,r),{drawExternalLabel:function(){if(void 0!==s.options.label){s.labelModule.draw(t,s.left+s.iconSize.width/2+s.margin.left,i+s.height/2+5,n)}s.updateBoundingBox(e,i)}}}},{key:"updateBoundingBox",value:function(t,e){if(this.boundingBox.top=e-.5*this.options.icon.size,this.boundingBox.left=t-.5*this.options.icon.size,this.boundingBox.right=t+.5*this.options.icon.size,this.boundingBox.bottom=e+.5*this.options.icon.size,void 0!==this.options.label&&this.labelModule.size.width>0){this.boundingBox.left=Math.min(this.boundingBox.left,this.labelModule.size.left),this.boundingBox.right=Math.max(this.boundingBox.right,this.labelModule.size.left+this.labelModule.size.width),this.boundingBox.bottom=Math.max(this.boundingBox.bottom,this.boundingBox.bottom+this.labelModule.size.height+5)}}},{key:"_icon",value:function(t,e,i,n,o,r){var s=Number(this.options.icon.size);void 0!==this.options.icon.code?(t.font=[null!=this.options.icon.weight?this.options.icon.weight:n?"bold":"",(null!=this.options.icon.weight&&n?5:0)+s+"px",this.options.icon.face].join(" "),t.fillStyle=this.options.icon.color||"black",t.textAlign="center",t.textBaseline="middle",this.enableShadow(t,r),t.fillText(this.options.icon.code,e,i),this.disableShadow(t,r)):console.error("When using the icon shape, you need to define the code in the icon options object. This can be done per node or globally.")}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(CE);function ZE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var QE=function(t){zk(i,t);var e=ZE(i);function i(t,n,o,r,s){var a;return Yd(this,i),(a=e.call(this,t,n,o)).setImages(r,s),a}return Kd(i,[{key:"resize",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.selected,i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.hover,n=void 0===this.imageObj.src||void 0===this.imageObj.width||void 0===this.imageObj.height;if(n){var o=2*this.options.size;return this.width=o,void(this.height=o)}this.needsRefresh(e,i)&&this._resizeImage()}},{key:"draw",value:function(t,e,i,n,o,r){t.save(),this.switchImages(n),this.resize();var s=e,a=i;if("top-left"===this.options.shapeProperties.coordinateOrigin?(this.left=e,this.top=i,s+=this.width/2,a+=this.height/2):(this.left=e-this.width/2,this.top=i-this.height/2),!0===this.options.shapeProperties.useBorderWithImage){var h=this.options.borderWidth,l=this.options.borderWidthSelected||2*this.options.borderWidth,d=(n?l:h)/this.body.view.scale;t.lineWidth=Math.min(this.width,d),t.beginPath();var c=n?this.options.color.highlight.border:o?this.options.color.hover.border:this.options.color.border,u=n?this.options.color.highlight.background:o?this.options.color.hover.background:this.options.color.background;void 0!==r.opacity&&(c=pm(c,r.opacity),u=pm(u,r.opacity)),t.strokeStyle=c,t.fillStyle=u,t.rect(this.left-.5*t.lineWidth,this.top-.5*t.lineWidth,this.width+t.lineWidth,this.height+t.lineWidth),jv(t).call(t),this.performStroke(t,r),t.closePath()}this._drawImageAtPosition(t,r),this._drawImageLabel(t,s,a,n,o),this.updateBoundingBox(e,i),t.restore()}},{key:"updateBoundingBox",value:function(t,e){this.resize(),"top-left"===this.options.shapeProperties.coordinateOrigin?(this.left=t,this.top=e):(this.left=t-this.width/2,this.top=e-this.height/2),this.boundingBox.left=this.left,this.boundingBox.top=this.top,this.boundingBox.bottom=this.top+this.height,this.boundingBox.right=this.left+this.width,void 0!==this.options.label&&this.labelModule.size.width>0&&(this.boundingBox.left=Math.min(this.boundingBox.left,this.labelModule.size.left),this.boundingBox.right=Math.max(this.boundingBox.right,this.labelModule.size.left+this.labelModule.size.width),this.boundingBox.bottom=Math.max(this.boundingBox.bottom,this.boundingBox.bottom+this.labelOffset))}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(PE);function JE(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var tO=function(t){zk(i,t);var e=JE(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){return this._drawShape(t,"square",2,e,i,n,o,r)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(FE);function eO(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var iO=function(t){zk(i,t);var e=eO(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){return this._drawShape(t,"hexagon",4,e,i,n,o,r)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(FE);function nO(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var oO=function(t){zk(i,t);var e=nO(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){return this._drawShape(t,"star",4,e,i,n,o,r)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(FE);function rO(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var sO=function(t){zk(i,t);var e=rO(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o))._setMargins(o),r}return Kd(i,[{key:"resize",value:function(t,e,i){this.needsRefresh(e,i)&&(this.textSize=this.labelModule.getTextSize(t,e,i),this.width=this.textSize.width+this.margin.right+this.margin.left,this.height=this.textSize.height+this.margin.top+this.margin.bottom,this.radius=.5*this.width)}},{key:"draw",value:function(t,e,i,n,o,r){this.resize(t,n,o),this.left=e-this.width/2,this.top=i-this.height/2,this.enableShadow(t,r),this.labelModule.draw(t,this.left+this.textSize.width/2+this.margin.left,this.top+this.textSize.height/2+this.margin.top,n,o),this.disableShadow(t,r),this.updateBoundingBox(e,i,t,n,o)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(CE);function aO(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var hO=function(t){zk(i,t);var e=aO(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){return this._drawShape(t,"triangle",3,e,i,n,o,r)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(FE);function lO(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var dO=function(t){zk(i,t);var e=lO(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"draw",value:function(t,e,i,n,o,r){return this._drawShape(t,"triangleDown",3,e,i,n,o,r)}},{key:"distanceToBorder",value:function(t,e){return this._distanceToBorder(t,e)}}]),i}(FE);function cO(t,e){var i=bu(t);if(hd){var n=hd(t);e&&(n=Xf(n).call(n,(function(e){return bd(t,e).enumerable}))),i.push.apply(i,n)}return i}function uO(t){for(var e=1;e<arguments.length;e++){var i,n,o=null!=arguments[e]?arguments[e]:{};e%2?Fu(i=cO(Object(o),!0)).call(i,(function(e){$d(t,e,o[e])})):Pd?Ad(t,Pd(o)):Fu(n=cO(Object(o))).call(n,(function(e){Ud(t,e,bd(o,e))}))}return t}var fO=function(){function t(e,i,n,o,r,s){Yd(this,t),this.options=Cm(r),this.globalOptions=r,this.defaultOptions=s,this.body=i,this.edges=[],this.id=void 0,this.imagelist=n,this.grouplist=o,this.x=void 0,this.y=void 0,this.baseSize=this.options.size,this.baseFontSize=this.options.font.size,this.predefinedPosition=!1,this.selected=!1,this.hover=!1,this.labelModule=new OE(this.body,this.options,!1),this.setOptions(e)}return Kd(t,[{key:"attachEdge",value:function(t){var e;-1===Fp(e=this.edges).call(e,t)&&this.edges.push(t)}},{key:"detachEdge",value:function(t){var e,i,n=Fp(e=this.edges).call(e,t);-1!=n&&ff(i=this.edges).call(i,n,1)}},{key:"setOptions",value:function(e){var i=this.options.shape;if(e){if(void 0!==e.color&&(this._localColor=e.color),void 0!==e.id&&(this.id=e.id),void 0===this.id)throw new Error("Node must have an id");t.checkMass(e,this.id),void 0!==e.x&&(null===e.x?(this.x=void 0,this.predefinedPosition=!1):(this.x=Ep(e.x),this.predefinedPosition=!0)),void 0!==e.y&&(null===e.y?(this.y=void 0,this.predefinedPosition=!1):(this.y=Ep(e.y),this.predefinedPosition=!0)),void 0!==e.size&&(this.baseSize=e.size),void 0!==e.value&&(e.value=lE(e.value)),t.parseOptions(this.options,e,!0,this.globalOptions,this.grouplist);var n=[e,this.options,this.defaultOptions];return this.chooser=gE("node",n),this._load_images(),this.updateLabelModule(e),void 0!==e.opacity&&t.checkOpacity(e.opacity)&&(this.options.opacity=e.opacity),this.updateShape(i),void 0!==e.hidden||void 0!==e.physics}}},{key:"_load_images",value:function(){if(("circularImage"===this.options.shape||"image"===this.options.shape)&&void 0===this.options.image)throw new Error("Option image must be defined for node type '"+this.options.shape+"'");if(void 0!==this.options.image){if(void 0===this.imagelist)throw new Error("Internal Error: No images provided");if("string"==typeof this.options.image)this.imageObj=this.imagelist.load(this.options.image,this.options.brokenImage,this.id);else{if(void 0===this.options.image.unselected)throw new Error("No unselected image provided");this.imageObj=this.imagelist.load(this.options.image.unselected,this.options.brokenImage,this.id),void 0!==this.options.image.selected?this.imageObjAlt=this.imagelist.load(this.options.image.selected,this.options.brokenImage,this.id):this.imageObjAlt=void 0}}}},{key:"getFormattingValues",value:function(){var t={color:this.options.color.background,opacity:this.options.opacity,borderWidth:this.options.borderWidth,borderColor:this.options.color.border,size:this.options.size,borderDashes:this.options.shapeProperties.borderDashes,borderRadius:this.options.shapeProperties.borderRadius,shadow:this.options.shadow.enabled,shadowColor:this.options.shadow.color,shadowSize:this.options.shadow.size,shadowX:this.options.shadow.x,shadowY:this.options.shadow.y};if(this.selected||this.hover?!0===this.chooser?this.selected?(null!=this.options.borderWidthSelected?t.borderWidth=this.options.borderWidthSelected:t.borderWidth*=2,t.color=this.options.color.highlight.background,t.borderColor=this.options.color.highlight.border,t.shadow=this.options.shadow.enabled):this.hover&&(t.color=this.options.color.hover.background,t.borderColor=this.options.color.hover.border,t.shadow=this.options.shadow.enabled):"function"==typeof this.chooser&&(this.chooser(t,this.options.id,this.selected,this.hover),!1===t.shadow&&(t.shadowColor===this.options.shadow.color&&t.shadowSize===this.options.shadow.size&&t.shadowX===this.options.shadow.x&&t.shadowY===this.options.shadow.y||(t.shadow=!0))):t.shadow=this.options.shadow.enabled,void 0!==this.options.opacity){var e=this.options.opacity;t.borderColor=pm(t.borderColor,e),t.color=pm(t.color,e),t.shadowColor=pm(t.shadowColor,e)}return t}},{key:"updateLabelModule",value:function(e){void 0!==this.options.label&&null!==this.options.label||(this.options.label=""),t.updateGroupOptions(this.options,uO(uO({},e),{},{color:e&&e.color||this._localColor||void 0}),this.grouplist);var i=this.grouplist.get(this.options.group,!1),n=[e,this.options,i,this.globalOptions,this.defaultOptions];this.labelModule.update(this.options,n),void 0!==this.labelModule.baseSize&&(this.baseFontSize=this.labelModule.baseSize)}},{key:"updateShape",value:function(t){if(t===this.options.shape&&this.shape)this.shape.setOptions(this.options,this.imageObj,this.imageObjAlt);else switch(this.options.shape){case"box":this.shape=new TE(this.options,this.body,this.labelModule);break;case"circle":this.shape=new IE(this.options,this.body,this.labelModule);break;case"circularImage":this.shape=new zE(this.options,this.body,this.labelModule,this.imageObj,this.imageObjAlt);break;case"custom":this.shape=new LE(this.options,this.body,this.labelModule,this.options.ctxRenderer);break;case"database":this.shape=new WE(this.options,this.body,this.labelModule);break;case"diamond":this.shape=new VE(this.options,this.body,this.labelModule);break;case"dot":this.shape=new YE(this.options,this.body,this.labelModule);break;case"ellipse":default:this.shape=new GE(this.options,this.body,this.labelModule);break;case"icon":this.shape=new $E(this.options,this.body,this.labelModule);break;case"image":this.shape=new QE(this.options,this.body,this.labelModule,this.imageObj,this.imageObjAlt);break;case"square":this.shape=new tO(this.options,this.body,this.labelModule);break;case"hexagon":this.shape=new iO(this.options,this.body,this.labelModule);break;case"star":this.shape=new oO(this.options,this.body,this.labelModule);break;case"text":this.shape=new sO(this.options,this.body,this.labelModule);break;case"triangle":this.shape=new hO(this.options,this.body,this.labelModule);break;case"triangleDown":this.shape=new dO(this.options,this.body,this.labelModule)}this.needsRefresh()}},{key:"select",value:function(){this.selected=!0,this.needsRefresh()}},{key:"unselect",value:function(){this.selected=!1,this.needsRefresh()}},{key:"needsRefresh",value:function(){this.shape.refreshNeeded=!0}},{key:"getTitle",value:function(){return this.options.title}},{key:"distanceToBorder",value:function(t,e){return this.shape.distanceToBorder(t,e)}},{key:"isFixed",value:function(){return this.options.fixed.x&&this.options.fixed.y}},{key:"isSelected",value:function(){return this.selected}},{key:"getValue",value:function(){return this.options.value}},{key:"getLabelSize",value:function(){return this.labelModule.size()}},{key:"setValueRange",value:function(t,e,i){if(void 0!==this.options.value){var n=this.options.scaling.customScalingFunction(t,e,i,this.options.value),o=this.options.scaling.max-this.options.scaling.min;if(!0===this.options.scaling.label.enabled){var r=this.options.scaling.label.max-this.options.scaling.label.min;this.options.font.size=this.options.scaling.label.min+n*r}this.options.size=this.options.scaling.min+n*o}else this.options.size=this.baseSize,this.options.font.size=this.baseFontSize;this.updateLabelModule()}},{key:"draw",value:function(t){var e=this.getFormattingValues();return this.shape.draw(t,this.x,this.y,this.selected,this.hover,e)||{}}},{key:"updateBoundingBox",value:function(t){this.shape.updateBoundingBox(this.x,this.y,t)}},{key:"resize",value:function(t){var e=this.getFormattingValues();this.shape.resize(t,this.selected,this.hover,e)}},{key:"getItemsOnPoint",value:function(t){var e=[];return this.labelModule.visible()&&yE(this.labelModule.getSize(),t)&&e.push({nodeId:this.id,labelId:0}),yE(this.shape.boundingBox,t)&&e.push({nodeId:this.id}),e}},{key:"isOverlappingWith",value:function(t){return this.shape.left<t.right&&this.shape.left+this.shape.width>t.left&&this.shape.top<t.bottom&&this.shape.top+this.shape.height>t.top}},{key:"isBoundingBoxOverlappingWith",value:function(t){return this.shape.boundingBox.left<t.right&&this.shape.boundingBox.right>t.left&&this.shape.boundingBox.top<t.bottom&&this.shape.boundingBox.bottom>t.top}}],[{key:"checkOpacity",value:function(t){return 0<=t&&t<=1}},{key:"checkCoordinateOrigin",value:function(t){return void 0===t||"center"===t||"top-left"===t}},{key:"updateGroupOptions",value:function(e,i,n){var o;if(void 0!==n){var r=e.group;if(void 0!==i&&void 0!==i.group&&r!==i.group)throw new Error("updateGroupOptions: group values in options don't match.");if("number"==typeof r||"string"==typeof r&&""!=r){var s=n.get(r);void 0!==s.opacity&&void 0===i.opacity&&(t.checkOpacity(s.opacity)||(console.error("Invalid option for node opacity. Value must be between 0 and 1, found: "+s.opacity),s.opacity=void 0));var a=Xf(o=vE(i)).call(o,(function(t){return null!=i[t]}));a.push("font"),im(a,e,s),e.color=gm(e.color)}}}},{key:"parseOptions",value:function(e,i){var n=arguments.length>2&&void 0!==arguments[2]&&arguments[2],o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{},r=arguments.length>4?arguments[4]:void 0,s=["color","fixed","shadow"];if(im(s,e,i,n),t.checkMass(i),void 0!==e.opacity&&(t.checkOpacity(e.opacity)||(console.error("Invalid option for node opacity. Value must be between 0 and 1, found: "+e.opacity),e.opacity=void 0)),void 0!==i.opacity&&(t.checkOpacity(i.opacity)||(console.error("Invalid option for node opacity. Value must be between 0 and 1, found: "+i.opacity),i.opacity=void 0)),i.shapeProperties&&!t.checkCoordinateOrigin(i.shapeProperties.coordinateOrigin)&&console.error("Invalid option for node coordinateOrigin, found: "+i.shapeProperties.coordinateOrigin),Sm(e,i,"shadow",o),void 0!==i.color&&null!==i.color){var a=gm(i.color);Jy(e.color,a)}else!0===n&&null===i.color&&(e.color=Cm(o.color));void 0!==i.fixed&&null!==i.fixed&&("boolean"==typeof i.fixed?(e.fixed.x=i.fixed,e.fixed.y=i.fixed):(void 0!==i.fixed.x&&"boolean"==typeof i.fixed.x&&(e.fixed.x=i.fixed.x),void 0!==i.fixed.y&&"boolean"==typeof i.fixed.y&&(e.fixed.y=i.fixed.y))),!0===n&&null===i.font&&(e.font=Cm(o.font)),t.updateGroupOptions(e,i,r),void 0!==i.scaling&&Sm(e.scaling,i.scaling,"label",o.scaling)}},{key:"checkMass",value:function(t,e){if(void 0!==t.mass&&t.mass<=0){var i="";void 0!==e&&(i=" in node id: "+e),console.error("%cNegative or zero mass disallowed"+i+", setting mass to 1.",Vm),t.mass=1}}}]),t}();function pO(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return vO(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return vO(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function vO(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}var gO=function(){function t(e,i,n,o){var r,s=this;if(Yd(this,t),this.body=e,this.images=i,this.groups=n,this.layoutEngine=o,this.body.functions.createNode=zn(r=this.create).call(r,this),this.nodesListeners={add:function(t,e){s.add(e.items)},update:function(t,e){s.update(e.items,e.data,e.oldData)},remove:function(t,e){s.remove(e.items)}},this.defaultOptions={borderWidth:1,borderWidthSelected:void 0,brokenImage:void 0,color:{border:"#2B7CE9",background:"#97C2FC",highlight:{border:"#2B7CE9",background:"#D2E5FF"},hover:{border:"#2B7CE9",background:"#D2E5FF"}},opacity:void 0,fixed:{x:!1,y:!1},font:{color:"#343434",size:14,face:"arial",background:"none",strokeWidth:0,strokeColor:"#ffffff",align:"center",vadjust:0,multi:!1,bold:{mod:"bold"},boldital:{mod:"bold italic"},ital:{mod:"italic"},mono:{mod:"",size:15,face:"monospace",vadjust:2}},group:void 0,hidden:!1,icon:{face:"FontAwesome",code:void 0,size:50,color:"#2B7CE9"},image:void 0,imagePadding:{top:0,right:0,bottom:0,left:0},label:void 0,labelHighlightBold:!0,level:void 0,margin:{top:5,right:5,bottom:5,left:5},mass:1,physics:!0,scaling:{min:10,max:30,label:{enabled:!1,min:14,max:30,maxVisible:30,drawThreshold:5},customScalingFunction:function(t,e,i,n){if(e===t)return.5;var o=1/(e-t);return Math.max(0,(n-t)*o)}},shadow:{enabled:!1,color:"rgba(0,0,0,0.5)",size:10,x:5,y:5},shape:"ellipse",shapeProperties:{borderDashes:!1,borderRadius:6,interpolation:!0,useImageSize:!1,useBorderWithImage:!1,coordinateOrigin:"center"},size:25,title:void 0,value:void 0,x:void 0,y:void 0},this.defaultOptions.mass<=0)throw"Internal error: mass in defaultOptions of NodesHandler may not be zero or negative";this.options=Cm(this.defaultOptions),this.bindEventListeners()}return Kd(t,[{key:"bindEventListeners",value:function(){var t,e,i=this;this.body.emitter.on("refreshNodes",zn(t=this.refresh).call(t,this)),this.body.emitter.on("refresh",zn(e=this.refresh).call(e,this)),this.body.emitter.on("destroy",(function(){hm(i.nodesListeners,(function(t,e){i.body.data.nodes&&i.body.data.nodes.off(e,t)})),delete i.body.functions.createNode,delete i.nodesListeners.add,delete i.nodesListeners.update,delete i.nodesListeners.remove,delete i.nodesListeners}))}},{key:"setOptions",value:function(t){if(void 0!==t){if(fO.parseOptions(this.options,t),void 0!==t.opacity&&(ek(t.opacity)||!ok(t.opacity)||t.opacity<0||t.opacity>1?console.error("Invalid option for node opacity. Value must be between 0 and 1, found: "+t.opacity):this.options.opacity=t.opacity),void 0!==t.shape)for(var e in this.body.nodes)Object.prototype.hasOwnProperty.call(this.body.nodes,e)&&this.body.nodes[e].updateShape();if(void 0!==t.font||void 0!==t.widthConstraint||void 0!==t.heightConstraint)for(var i=0,n=bu(this.body.nodes);i<n.length;i++){var o=n[i];this.body.nodes[o].updateLabelModule(),this.body.nodes[o].needsRefresh()}if(void 0!==t.size)for(var r in this.body.nodes)Object.prototype.hasOwnProperty.call(this.body.nodes,r)&&this.body.nodes[r].needsRefresh();void 0===t.hidden&&void 0===t.physics||this.body.emitter.emit("_dataChanged")}}},{key:"setData",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],i=this.body.data.nodes;if(Qx("id",t))this.body.data.nodes=t;else if(lu(t))this.body.data.nodes=new Kx,this.body.data.nodes.add(t);else{if(t)throw new TypeError("Array or DataSet expected");this.body.data.nodes=new Kx}if(i&&hm(this.nodesListeners,(function(t,e){i.off(e,t)})),this.body.nodes={},this.body.data.nodes){var n=this;hm(this.nodesListeners,(function(t,e){n.body.data.nodes.on(e,t)}));var o=this.body.data.nodes.getIds();this.add(o,!0)}!1===e&&this.body.emitter.emit("_dataChanged")}},{key:"add",value:function(t){for(var e,i=arguments.length>1&&void 0!==arguments[1]&&arguments[1],n=[],o=0;o<t.length;o++){e=t[o];var r=this.body.data.nodes.get(e),s=this.create(r);n.push(s),this.body.nodes[e]=s}this.layoutEngine.positionInitially(n),!1===i&&this.body.emitter.emit("_dataChanged")}},{key:"update",value:function(t,e,i){for(var n=this.body.nodes,o=!1,r=0;r<t.length;r++){var s=t[r],a=n[s],h=e[r];void 0!==a?a.setOptions(h)&&(o=!0):(o=!0,a=this.create(h),n[s]=a)}o||void 0===i||(o=ck(e).call(e,(function(t,e){var n=i[e];return n&&n.level!==t.level}))),!0===o?this.body.emitter.emit("_dataChanged"):this.body.emitter.emit("_dataUpdated")}},{key:"remove",value:function(t){for(var e=this.body.nodes,i=0;i<t.length;i++){delete e[t[i]]}this.body.emitter.emit("_dataChanged")}},{key:"create",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:fO;return new e(t,this.body,this.images,this.groups,this.options,this.defaultOptions)}},{key:"refresh",value:function(){var t=this,e=arguments.length>0&&void 0!==arguments[0]&&arguments[0];hm(this.body.nodes,(function(i,n){var o=t.body.data.nodes.get(n);void 0!==o&&(!0===e&&i.setOptions({x:null,y:null}),i.setOptions({fixed:!1}),i.setOptions(o))}))}},{key:"getPositions",value:function(t){var e={};if(void 0!==t){if(!0===lu(t)){for(var i=0;i<t.length;i++)if(void 0!==this.body.nodes[t[i]]){var n=this.body.nodes[t[i]];e[t[i]]={x:Math.round(n.x),y:Math.round(n.y)}}}else if(void 0!==this.body.nodes[t]){var o=this.body.nodes[t];e[t]={x:Math.round(o.x),y:Math.round(o.y)}}}else for(var r=0;r<this.body.nodeIndices.length;r++){var s=this.body.nodes[this.body.nodeIndices[r]];e[this.body.nodeIndices[r]]={x:Math.round(s.x),y:Math.round(s.y)}}return e}},{key:"getPosition",value:function(t){if(null==t)throw new TypeError("No id was specified for getPosition method.");if(null==this.body.nodes[t])throw new ReferenceError("NodeId provided for getPosition does not exist. Provided: ".concat(t));return{x:Math.round(this.body.nodes[t].x),y:Math.round(this.body.nodes[t].y)}}},{key:"storePositions",value:function(){var t,e=[],i=this.body.data.nodes.getDataSet(),n=pO(i.get());try{for(n.s();!(t=n.n()).done;){var o=t.value,r=o.id,s=this.body.nodes[r],a=Math.round(s.x),h=Math.round(s.y);o.x===a&&o.y===h||e.push({id:r,x:a,y:h})}}catch(t){n.e(t)}finally{n.f()}i.update(e)}},{key:"getBoundingBox",value:function(t){if(void 0!==this.body.nodes[t])return this.body.nodes[t].shape.boundingBox}},{key:"getConnectedNodes",value:function(t,e){var i=[];if(void 0!==this.body.nodes[t])for(var n=this.body.nodes[t],o={},r=0;r<n.edges.length;r++){var s=n.edges[r];"to"!==e&&s.toId==n.id?void 0===o[s.fromId]&&(i.push(s.fromId),o[s.fromId]=!0):"from"!==e&&s.fromId==n.id&&void 0===o[s.toId]&&(i.push(s.toId),o[s.toId]=!0)}return i}},{key:"getConnectedEdges",value:function(t){var e=[];if(void 0!==this.body.nodes[t])for(var i=this.body.nodes[t],n=0;n<i.edges.length;n++)e.push(i.edges[n].id);else console.error("NodeId provided for getConnectedEdges does not exist. Provided: ",t);return e}},{key:"moveNode",value:function(t,e,i){var n=this;void 0!==this.body.nodes[t]?(this.body.nodes[t].x=Number(e),this.body.nodes[t].y=Number(i),Sv((function(){n.body.emitter.emit("startSimulation")}),0)):console.error("Node id supplied to moveNode does not exist. Provided: ",t)}}]),t}(),yO=Wt,mO=_,bO=Y,wO=$e,kO=function(t){return void 0!==t&&(yO(t,"value")||yO(t,"writable"))},_O=m,xO=Pr;_i({target:"Reflect",stat:!0},{get:function t(e,i){var n,o,r=arguments.length<3?e:arguments[2];return wO(e)===r?e[i]:(n=_O.f(e,i))?kO(n)?n.value:void 0===n.get?void 0:mO(n.get,r):bO(o=xO(e))?t(o,i,r):void 0}});var EO=X.Reflect.get,OO=md;function CO(t,e){for(;!Object.prototype.hasOwnProperty.call(t,e)&&null!==(t=Ak(t)););return t}function SO(){return SO="undefined"!=typeof Reflect&&EO?EO:function(t,e,i){var n=CO(t,e);if(n){var o=OO(n,e);return o.get?o.get.call(arguments.length<3?t:i):o.value}},SO.apply(this,arguments)}var TO=_i,MO=Math.hypot,PO=Math.abs,DO=Math.sqrt;TO({target:"Math",stat:!0,forced:!!MO&&MO(1/0,NaN)!==1/0},{hypot:function(t,e){for(var i,n,o=0,r=0,s=arguments.length,a=0;r<s;)a<(i=PO(arguments[r++]))?(o=o*(n=a/i)*n+1,a=i):o+=i>0?(n=i/a)*n:i;return a===1/0?1/0:a*DO(o)}});var IO=X.Math.hypot;function BO(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var zO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"transform",value:function(t,e){lu(t)||(t=[t]);for(var i=e.point.x,n=e.point.y,o=e.angle,r=e.length,s=0;s<t.length;++s){var a=t[s],h=a.x*Math.cos(o)-a.y*Math.sin(o),l=a.x*Math.sin(o)+a.y*Math.cos(o);a.x=i+r*h,a.y=n+r*l}}},{key:"drawPath",value:function(t,e){t.beginPath(),t.moveTo(e[0].x,e[0].y);for(var i=1;i<e.length;++i)t.lineTo(e[i].x,e[i].y);t.closePath()}}]),t}(),NO=function(t){zk(i,t);var e=BO(i);function i(){return Yd(this,i),e.apply(this,arguments)}return Kd(i,null,[{key:"draw",value:function(t,e){if(e.image){t.save(),t.translate(e.point.x,e.point.y),t.rotate(Math.PI/2+e.angle);var i=null!=e.imageWidth?e.imageWidth:e.image.width,n=null!=e.imageHeight?e.imageHeight:e.image.height;e.image.drawImageAtPosition(t,1,-i/2,0,i,n),t.restore()}return!1}}]),i}(zO),FO=function(t){zk(i,t);var e=BO(i);function i(){return Yd(this,i),e.apply(this,arguments)}return Kd(i,null,[{key:"draw",value:function(t,e){var i=[{x:0,y:0},{x:-1,y:.3},{x:-.9,y:0},{x:-1,y:-.3}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),i}(zO),AO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i=[{x:-1,y:0},{x:0,y:.3},{x:-.4,y:0},{x:0,y:-.3}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),t}(),jO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i={x:-.4,y:0};zO.transform(i,e),t.strokeStyle=t.fillStyle,t.fillStyle="rgba(0, 0, 0, 0)";var n=Math.PI,o=e.angle-n/2,r=e.angle+n/2;return t.beginPath(),t.arc(i.x,i.y,.4*e.length,o,r,!1),t.stroke(),!0}}]),t}(),RO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i={x:-.3,y:0};zO.transform(i,e),t.strokeStyle=t.fillStyle,t.fillStyle="rgba(0, 0, 0, 0)";var n=Math.PI,o=e.angle+n/2,r=e.angle+3*n/2;return t.beginPath(),t.arc(i.x,i.y,.4*e.length,o,r,!1),t.stroke(),!0}}]),t}(),LO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i=[{x:.02,y:0},{x:-1,y:.3},{x:-1,y:-.3}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),t}(),HO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i=[{x:0,y:.3},{x:0,y:-.3},{x:-1,y:0}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),t}(),WO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i={x:-.4,y:0};return zO.transform(i,e),Nn(t,i.x,i.y,.4*e.length),!0}}]),t}(),qO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i=[{x:0,y:.5},{x:0,y:-.5},{x:-.15,y:-.5},{x:-.15,y:.5}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),t}(),VO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i=[{x:0,y:.3},{x:0,y:-.3},{x:-.6,y:-.3},{x:-.6,y:.3}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),t}(),UO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i=[{x:0,y:0},{x:-.5,y:-.3},{x:-1,y:0},{x:-.5,y:.3}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),t}(),YO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i=[{x:-1,y:.3},{x:-.5,y:0},{x:-1,y:-.3},{x:0,y:0}];return zO.transform(i,e),zO.drawPath(t,i),!0}}]),t}(),XO=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"draw",value:function(t,e){var i;switch(e.type&&(i=e.type.toLowerCase()),i){case"image":return NO.draw(t,e);case"circle":return WO.draw(t,e);case"box":return VO.draw(t,e);case"crow":return AO.draw(t,e);case"curve":return jO.draw(t,e);case"diamond":return UO.draw(t,e);case"inv_curve":return RO.draw(t,e);case"triangle":return LO.draw(t,e);case"inv_triangle":return HO.draw(t,e);case"bar":return qO.draw(t,e);case"vee":return YO.draw(t,e);default:return FO.draw(t,e)}}}]),t}();function GO(t,e){var i=bu(t);if(hd){var n=hd(t);e&&(n=Xf(n).call(n,(function(e){return bd(t,e).enumerable}))),i.push.apply(i,n)}return i}function KO(t){for(var e=1;e<arguments.length;e++){var i,n,o=null!=arguments[e]?arguments[e]:{};e%2?Fu(i=GO(Object(o),!0)).call(i,(function(e){$d(t,e,o[e])})):Pd?Ad(t,Pd(o)):Fu(n=GO(Object(o))).call(n,(function(e){Ud(t,e,bd(o,e))}))}return t}var $O=function(){function t(e,i,n){Yd(this,t),this._body=i,this._labelModule=n,this.color={},this.colorDirty=!0,this.hoverWidth=1.5,this.selectionWidth=2,this.setOptions(e),this.fromPoint=this.from,this.toPoint=this.to}return Kd(t,[{key:"connect",value:function(){this.from=this._body.nodes[this.options.from],this.to=this._body.nodes[this.options.to]}},{key:"cleanup",value:function(){return!1}},{key:"setOptions",value:function(t){this.options=t,this.from=this._body.nodes[this.options.from],this.to=this._body.nodes[this.options.to],this.id=this.options.id}},{key:"drawLine",value:function(t,e,i,n){var o=arguments.length>4&&void 0!==arguments[4]?arguments[4]:this.getViaNode();t.strokeStyle=this.getColor(t,e),t.lineWidth=e.width,!1!==e.dashes?this._drawDashedLine(t,e,o):this._drawLine(t,e,o)}},{key:"_drawLine",value:function(t,e,i,n,o){if(this.from!=this.to)this._line(t,e,i,n,o);else{var r=Kc(this._getCircleData(t),3),s=r[0],a=r[1],h=r[2];this._circle(t,e,s,a,h)}}},{key:"_drawDashedLine",value:function(t,e,i,n,o){t.lineCap="round";var r=lu(e.dashes)?e.dashes:[5,5];if(void 0!==t.setLineDash){if(t.save(),t.setLineDash(r),t.lineDashOffset=0,this.from!=this.to)this._line(t,e,i);else{var s=Kc(this._getCircleData(t),3),a=s[0],h=s[1],l=s[2];this._circle(t,e,a,h,l)}t.setLineDash([0]),t.lineDashOffset=0,t.restore()}else{if(this.from!=this.to)Rn(t,this.from.x,this.from.y,this.to.x,this.to.y,r);else{var d=Kc(this._getCircleData(t),3),c=d[0],u=d[1],f=d[2];this._circle(t,e,c,u,f)}this.enableShadow(t,e),t.stroke(),this.disableShadow(t,e)}}},{key:"findBorderPosition",value:function(t,e,i){return this.from!=this.to?this._findBorderPosition(t,e,i):this._findBorderPositionCircle(t,e,i)}},{key:"findBorderPositions",value:function(t){if(this.from!=this.to)return{from:this._findBorderPosition(this.from,t),to:this._findBorderPosition(this.to,t)};var e,i=Kc(au(e=this._getCircleData(t)).call(e,0,2),2),n=i[0],o=i[1];return{from:this._findBorderPositionCircle(this.from,t,{x:n,y:o,low:.25,high:.6,direction:-1}),to:this._findBorderPositionCircle(this.from,t,{x:n,y:o,low:.6,high:.8,direction:1})}}},{key:"_getCircleData",value:function(t){var e=this.options.selfReference.size;void 0!==t&&void 0===this.from.shape.width&&this.from.shape.resize(t);var i=bE(t,this.options.selfReference.angle,e,this.from);return[i.x,i.y,e]}},{key:"_pointOnCircle",value:function(t,e,i,n){var o=2*n*Math.PI;return{x:t+i*Math.cos(o),y:e-i*Math.sin(o)}}},{key:"_findBorderPositionCircle",value:function(t,e,i){var n,o=i.x,r=i.y,s=i.low,a=i.high,h=i.direction,l=this.options.selfReference.size,d=.5*(s+a),c=0;!0===this.options.arrowStrikethrough&&(-1===h?c=this.options.endPointOffset.from:1===h&&(c=this.options.endPointOffset.to));var u=0;do{d=.5*(s+a),n=this._pointOnCircle(o,r,l,d);var f=Math.atan2(t.y-n.y,t.x-n.x),p=t.distanceToBorder(e,f)+c-Math.sqrt(Math.pow(n.x-t.x,2)+Math.pow(n.y-t.y,2));if(Math.abs(p)<.05)break;p>0?h>0?s=d:a=d:h>0?a=d:s=d,++u}while(s<=a&&u<10);return KO(KO({},n),{},{t:d})}},{key:"getLineWidth",value:function(t,e){return!0===t?Math.max(this.selectionWidth,.3/this._body.view.scale):!0===e?Math.max(this.hoverWidth,.3/this._body.view.scale):Math.max(this.options.width,.3/this._body.view.scale)}},{key:"getColor",value:function(t,e){if(!1!==e.inheritsColor){if("both"===e.inheritsColor&&this.from.id!==this.to.id){var i=t.createLinearGradient(this.from.x,this.from.y,this.to.x,this.to.y),n=this.from.options.color.highlight.border,o=this.to.options.color.highlight.border;return!1===this.from.selected&&!1===this.to.selected?(n=pm(this.from.options.color.border,e.opacity),o=pm(this.to.options.color.border,e.opacity)):!0===this.from.selected&&!1===this.to.selected?o=this.to.options.color.border:!1===this.from.selected&&!0===this.to.selected&&(n=this.from.options.color.border),i.addColorStop(0,n),i.addColorStop(1,o),i}return"to"===e.inheritsColor?pm(this.to.options.color.border,e.opacity):pm(this.from.options.color.border,e.opacity)}return pm(e.color,e.opacity)}},{key:"_circle",value:function(t,e,i,n,o){this.enableShadow(t,e);var r=0,s=2*Math.PI;if(!this.options.selfReference.renderBehindTheNode){var a=this.options.selfReference.angle,h=this.options.selfReference.angle+Math.PI,l=this._findBorderPositionCircle(this.from,t,{x:i,y:n,low:a,high:h,direction:-1}),d=this._findBorderPositionCircle(this.from,t,{x:i,y:n,low:a,high:h,direction:1});r=Math.atan2(l.y-n,l.x-i),s=Math.atan2(d.y-n,d.x-i)}t.beginPath(),t.arc(i,n,o,r,s,!1),t.stroke(),this.disableShadow(t,e)}},{key:"getDistanceToEdge",value:function(t,e,i,n,o,r){if(this.from!=this.to)return this._getDistanceToEdge(t,e,i,n,o,r);var s=Kc(this._getCircleData(void 0),3),a=s[0],h=s[1],l=s[2],d=a-o,c=h-r;return Math.abs(Math.sqrt(d*d+c*c)-l)}},{key:"_getDistanceToLine",value:function(t,e,i,n,o,r){var s=i-t,a=n-e,h=((o-t)*s+(r-e)*a)/(s*s+a*a);h>1?h=1:h<0&&(h=0);var l=t+h*s-o,d=e+h*a-r;return Math.sqrt(l*l+d*d)}},{key:"getArrowData",value:function(t,e,i,n,o,r){var s,a,h,l,d,c,u,f=r.width;"from"===e?(h=this.from,l=this.to,d=r.fromArrowScale<0,c=Math.abs(r.fromArrowScale),u=r.fromArrowType):"to"===e?(h=this.to,l=this.from,d=r.toArrowScale<0,c=Math.abs(r.toArrowScale),u=r.toArrowType):(h=this.to,l=this.from,d=r.middleArrowScale<0,c=Math.abs(r.middleArrowScale),u=r.middleArrowType);var p=15*c+3*f;if(h!=l){var v=p/IO(h.x-l.x,h.y-l.y);if("middle"!==e)if(!0===this.options.smooth.enabled){var g=this._findBorderPosition(h,t,{via:i}),y=this.getPoint(g.t+v*("from"===e?1:-1),i);s=Math.atan2(g.y-y.y,g.x-y.x),a=g}else s=Math.atan2(h.y-l.y,h.x-l.x),a=this._findBorderPosition(h,t);else{var m=(d?-v:v)/2,b=this.getPoint(.5+m,i),w=this.getPoint(.5-m,i);s=Math.atan2(b.y-w.y,b.x-w.x),a=this.getPoint(.5,i)}}else{var k=Kc(this._getCircleData(t),3),_=k[0],x=k[1],E=k[2];if("from"===e){var O=this.options.selfReference.angle,C=this.options.selfReference.angle+Math.PI,S=this._findBorderPositionCircle(this.from,t,{x:_,y:x,low:O,high:C,direction:-1});s=-2*S.t*Math.PI+1.5*Math.PI+.1*Math.PI,a=S}else if("to"===e){var T=this.options.selfReference.angle,M=this.options.selfReference.angle+Math.PI,P=this._findBorderPositionCircle(this.from,t,{x:_,y:x,low:T,high:M,direction:1});s=-2*P.t*Math.PI+1.5*Math.PI-1.1*Math.PI,a=P}else{var D=this.options.selfReference.angle/(2*Math.PI);a=this._pointOnCircle(_,x,E,D),s=-2*D*Math.PI+1.5*Math.PI+.1*Math.PI}}return{point:a,core:{x:a.x-.9*p*Math.cos(s),y:a.y-.9*p*Math.sin(s)},angle:s,length:p,type:u}}},{key:"drawArrowHead",value:function(t,e,i,n,o){t.strokeStyle=this.getColor(t,e),t.fillStyle=t.strokeStyle,t.lineWidth=e.width,XO.draw(t,o)&&(this.enableShadow(t,e),jv(t).call(t),this.disableShadow(t,e))}},{key:"enableShadow",value:function(t,e){!0===e.shadow&&(t.shadowColor=e.shadowColor,t.shadowBlur=e.shadowSize,t.shadowOffsetX=e.shadowX,t.shadowOffsetY=e.shadowY)}},{key:"disableShadow",value:function(t,e){!0===e.shadow&&(t.shadowColor="rgba(0,0,0,0)",t.shadowBlur=0,t.shadowOffsetX=0,t.shadowOffsetY=0)}},{key:"drawBackground",value:function(t,e){if(!1!==e.background){var i={strokeStyle:t.strokeStyle,lineWidth:t.lineWidth,dashes:t.dashes};t.strokeStyle=e.backgroundColor,t.lineWidth=e.backgroundSize,this.setStrokeDashed(t,e.backgroundDashes),t.stroke(),t.strokeStyle=i.strokeStyle,t.lineWidth=i.lineWidth,t.dashes=i.dashes,this.setStrokeDashed(t,e.dashes)}}},{key:"setStrokeDashed",value:function(t,e){if(!1!==e)if(void 0!==t.setLineDash){var i=lu(e)?e:[5,5];t.setLineDash(i)}else console.warn("setLineDash is not supported in this browser. The dashed stroke cannot be used.");else void 0!==t.setLineDash?t.setLineDash([]):console.warn("setLineDash is not supported in this browser. The dashed stroke cannot be used.")}}]),t}();function ZO(t,e){var i=bu(t);if(hd){var n=hd(t);e&&(n=Xf(n).call(n,(function(e){return bd(t,e).enumerable}))),i.push.apply(i,n)}return i}function QO(t){for(var e=1;e<arguments.length;e++){var i,n,o=null!=arguments[e]?arguments[e]:{};e%2?Fu(i=ZO(Object(o),!0)).call(i,(function(e){$d(t,e,o[e])})):Pd?Ad(t,Pd(o)):Fu(n=ZO(Object(o))).call(n,(function(e){Ud(t,e,bd(o,e))}))}return t}function JO(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var tC=function(t){zk(i,t);var e=JO(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"_findBorderPositionBezier",value:function(t,e){var i,n,o=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this._getViaCoordinates(),r=10,s=.2,a=!1,h=1,l=0,d=this.to,c=this.options.endPointOffset?this.options.endPointOffset.to:0;t.id===this.from.id&&(d=this.from,a=!0,c=this.options.endPointOffset?this.options.endPointOffset.from:0),!1===this.options.arrowStrikethrough&&(c=0);var u=0;do{n=.5*(l+h),i=this.getPoint(n,o);var f=Math.atan2(d.y-i.y,d.x-i.x),p=d.distanceToBorder(e,f)+c,v=Math.sqrt(Math.pow(i.x-d.x,2)+Math.pow(i.y-d.y,2)),g=p-v;if(Math.abs(g)<s)break;g<0?!1===a?l=n:h=n:!1===a?h=n:l=n,++u}while(l<=h&&u<r);return QO(QO({},i),{},{t:n})}},{key:"_getDistanceToBezierEdge",value:function(t,e,i,n,o,r,s){var a,h,l,d,c,u=1e9,f=t,p=e;for(h=1;h<10;h++)l=.1*h,d=Math.pow(1-l,2)*t+2*l*(1-l)*s.x+Math.pow(l,2)*i,c=Math.pow(1-l,2)*e+2*l*(1-l)*s.y+Math.pow(l,2)*n,h>0&&(u=(a=this._getDistanceToLine(f,p,d,c,o,r))<u?a:u),f=d,p=c;return u}},{key:"_bezierCurve",value:function(t,e,i,n){t.beginPath(),t.moveTo(this.fromPoint.x,this.fromPoint.y),null!=i&&null!=i.x?null!=n&&null!=n.x?t.bezierCurveTo(i.x,i.y,n.x,n.y,this.toPoint.x,this.toPoint.y):t.quadraticCurveTo(i.x,i.y,this.toPoint.x,this.toPoint.y):t.lineTo(this.toPoint.x,this.toPoint.y),this.drawBackground(t,e),this.enableShadow(t,e),t.stroke(),this.disableShadow(t,e)}},{key:"getViaNode",value:function(){return this._getViaCoordinates()}}]),i}($O);function eC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var iC=function(t){zk(i,t);var e=eC(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o)).via=r.via,r._boundFunction=function(){r.positionBezierNode()},r._body.emitter.on("_repositionBezierNodes",r._boundFunction),r}return Kd(i,[{key:"setOptions",value:function(t){SO(Ak(i.prototype),"setOptions",this).call(this,t);var e=!1;this.options.physics!==t.physics&&(e=!0),this.options=t,this.id=this.options.id,this.from=this._body.nodes[this.options.from],this.to=this._body.nodes[this.options.to],this.setupSupportNode(),this.connect(),!0===e&&(this.via.setOptions({physics:this.options.physics}),this.positionBezierNode())}},{key:"connect",value:function(){this.from=this._body.nodes[this.options.from],this.to=this._body.nodes[this.options.to],void 0===this.from||void 0===this.to||!1===this.options.physics||this.from.id===this.to.id?this.via.setOptions({physics:!1}):this.via.setOptions({physics:!0})}},{key:"cleanup",value:function(){return this._body.emitter.off("_repositionBezierNodes",this._boundFunction),void 0!==this.via&&(delete this._body.nodes[this.via.id],this.via=void 0,!0)}},{key:"setupSupportNode",value:function(){if(void 0===this.via){var t="edgeId:"+this.id,e=this._body.functions.createNode({id:t,shape:"circle",physics:!0,hidden:!0});this._body.nodes[t]=e,this.via=e,this.via.parentEdgeId=this.id,this.positionBezierNode()}}},{key:"positionBezierNode",value:function(){void 0!==this.via&&void 0!==this.from&&void 0!==this.to?(this.via.x=.5*(this.from.x+this.to.x),this.via.y=.5*(this.from.y+this.to.y)):void 0!==this.via&&(this.via.x=0,this.via.y=0)}},{key:"_line",value:function(t,e,i){this._bezierCurve(t,e,i)}},{key:"_getViaCoordinates",value:function(){return this.via}},{key:"getViaNode",value:function(){return this.via}},{key:"getPoint",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.via;if(this.from===this.to){var i=this._getCircleData(),n=Kc(i,3),o=n[0],r=n[1],s=n[2],a=2*Math.PI*(1-t);return{x:o+s*Math.sin(a),y:r+s-s*(1-Math.cos(a))}}return{x:Math.pow(1-t,2)*this.fromPoint.x+2*t*(1-t)*e.x+Math.pow(t,2)*this.toPoint.x,y:Math.pow(1-t,2)*this.fromPoint.y+2*t*(1-t)*e.y+Math.pow(t,2)*this.toPoint.y}}},{key:"_findBorderPosition",value:function(t,e){return this._findBorderPositionBezier(t,e,this.via)}},{key:"_getDistanceToEdge",value:function(t,e,i,n,o,r){return this._getDistanceToBezierEdge(t,e,i,n,o,r,this.via)}}]),i}(tC);function nC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var oC=function(t){zk(i,t);var e=nC(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"_line",value:function(t,e,i){this._bezierCurve(t,e,i)}},{key:"getViaNode",value:function(){return this._getViaCoordinates()}},{key:"_getViaCoordinates",value:function(){var t,e,i=this.options.smooth.roundness,n=this.options.smooth.type,o=Math.abs(this.from.x-this.to.x),r=Math.abs(this.from.y-this.to.y);if("discrete"===n||"diagonalCross"===n){var s,a;s=a=o<=r?i*r:i*o,this.from.x>this.to.x&&(s=-s),this.from.y>=this.to.y&&(a=-a);var h=this.from.x+s,l=this.from.y+a;return"discrete"===n&&(o<=r?h=o<i*r?this.from.x:h:l=r<i*o?this.from.y:l),{x:h,y:l}}if("straightCross"===n){var d=(1-i)*o,c=(1-i)*r;return o<=r?(d=0,this.from.y<this.to.y&&(c=-c)):(this.from.x<this.to.x&&(d=-d),c=0),{x:this.to.x+d,y:this.to.y+c}}if("horizontal"===n){var u=(1-i)*o;return this.from.x<this.to.x&&(u=-u),{x:this.to.x+u,y:this.from.y}}if("vertical"===n){var f=(1-i)*r;return this.from.y<this.to.y&&(f=-f),{x:this.from.x,y:this.to.y+f}}if("curvedCW"===n){o=this.to.x-this.from.x,r=this.from.y-this.to.y;var p=Math.sqrt(o*o+r*r),v=Math.PI,g=(Math.atan2(r,o)+(.5*i+.5)*v)%(2*v);return{x:this.from.x+(.5*i+.5)*p*Math.sin(g),y:this.from.y+(.5*i+.5)*p*Math.cos(g)}}if("curvedCCW"===n){o=this.to.x-this.from.x,r=this.from.y-this.to.y;var y=Math.sqrt(o*o+r*r),m=Math.PI,b=(Math.atan2(r,o)+(.5*-i+.5)*m)%(2*m);return{x:this.from.x+(.5*i+.5)*y*Math.sin(b),y:this.from.y+(.5*i+.5)*y*Math.cos(b)}}t=e=o<=r?i*r:i*o,this.from.x>this.to.x&&(t=-t),this.from.y>=this.to.y&&(e=-e);var w=this.from.x+t,k=this.from.y+e;return o<=r?w=this.from.x<=this.to.x?this.to.x<w?this.to.x:w:this.to.x>w?this.to.x:w:k=this.from.y>=this.to.y?this.to.y>k?this.to.y:k:this.to.y<k?this.to.y:k,{x:w,y:k}}},{key:"_findBorderPosition",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};return this._findBorderPositionBezier(t,e,i.via)}},{key:"_getDistanceToEdge",value:function(t,e,i,n,o,r){var s=arguments.length>6&&void 0!==arguments[6]?arguments[6]:this._getViaCoordinates();return this._getDistanceToBezierEdge(t,e,i,n,o,r,s)}},{key:"getPoint",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this._getViaCoordinates(),i=t,n=Math.pow(1-i,2)*this.fromPoint.x+2*i*(1-i)*e.x+Math.pow(i,2)*this.toPoint.x,o=Math.pow(1-i,2)*this.fromPoint.y+2*i*(1-i)*e.y+Math.pow(i,2)*this.toPoint.y;return{x:n,y:o}}}]),i}(tC);function rC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var sC=function(t){zk(i,t);var e=rC(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"_getDistanceToBezierEdge2",value:function(t,e,i,n,o,r,s,a){for(var h=1e9,l=t,d=e,c=[0,0,0,0],u=1;u<10;u++){var f=.1*u;c[0]=Math.pow(1-f,3),c[1]=3*f*Math.pow(1-f,2),c[2]=3*Math.pow(f,2)*(1-f),c[3]=Math.pow(f,3);var p=c[0]*t+c[1]*s.x+c[2]*a.x+c[3]*i,v=c[0]*e+c[1]*s.y+c[2]*a.y+c[3]*n;if(u>0){var g=this._getDistanceToLine(l,d,p,v,o,r);h=g<h?g:h}l=p,d=v}return h}}]),i}(tC);function aC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var hC=function(t){zk(i,t);var e=aC(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"_line",value:function(t,e,i){var n=i[0],o=i[1];this._bezierCurve(t,e,n,o)}},{key:"_getViaCoordinates",value:function(){var t,e,i,n,o=this.from.x-this.to.x,r=this.from.y-this.to.y,s=this.options.smooth.roundness;return(Math.abs(o)>Math.abs(r)||!0===this.options.smooth.forceDirection||"horizontal"===this.options.smooth.forceDirection)&&"vertical"!==this.options.smooth.forceDirection?(e=this.from.y,n=this.to.y,t=this.from.x-s*o,i=this.to.x+s*o):(e=this.from.y-s*r,n=this.to.y+s*r,t=this.from.x,i=this.to.x),[{x:t,y:e},{x:i,y:n}]}},{key:"getViaNode",value:function(){return this._getViaCoordinates()}},{key:"_findBorderPosition",value:function(t,e){return this._findBorderPositionBezier(t,e)}},{key:"_getDistanceToEdge",value:function(t,e,i,n,o,r){var s=arguments.length>6&&void 0!==arguments[6]?arguments[6]:this._getViaCoordinates(),a=Kc(s,2),h=a[0],l=a[1];return this._getDistanceToBezierEdge2(t,e,i,n,o,r,h,l)}},{key:"getPoint",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this._getViaCoordinates(),i=Kc(e,2),n=i[0],o=i[1],r=t,s=[Math.pow(1-r,3),3*r*Math.pow(1-r,2),3*Math.pow(r,2)*(1-r),Math.pow(r,3)],a=s[0]*this.fromPoint.x+s[1]*n.x+s[2]*o.x+s[3]*this.toPoint.x,h=s[0]*this.fromPoint.y+s[1]*n.y+s[2]*o.y+s[3]*this.toPoint.y;return{x:a,y:h}}}]),i}(sC);function lC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var dC=function(t){zk(i,t);var e=lC(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"_line",value:function(t,e){t.beginPath(),t.moveTo(this.fromPoint.x,this.fromPoint.y),t.lineTo(this.toPoint.x,this.toPoint.y),this.enableShadow(t,e),t.stroke(),this.disableShadow(t,e)}},{key:"getViaNode",value:function(){}},{key:"getPoint",value:function(t){return{x:(1-t)*this.fromPoint.x+t*this.toPoint.x,y:(1-t)*this.fromPoint.y+t*this.toPoint.y}}},{key:"_findBorderPosition",value:function(t,e){var i=this.to,n=this.from;t.id===this.from.id&&(i=this.from,n=this.to);var o=Math.atan2(i.y-n.y,i.x-n.x),r=i.x-n.x,s=i.y-n.y,a=Math.sqrt(r*r+s*s),h=(a-t.distanceToBorder(e,o))/a;return{x:(1-h)*n.x+h*i.x,y:(1-h)*n.y+h*i.y,t:0}}},{key:"_getDistanceToEdge",value:function(t,e,i,n,o,r){return this._getDistanceToLine(t,e,i,n,o,r)}}]),i}($O),cC=function(){function t(e,i,n,o,r){if(Yd(this,t),void 0===i)throw new Error("No body provided");this.options=Cm(o),this.globalOptions=o,this.defaultOptions=r,this.body=i,this.imagelist=n,this.id=void 0,this.fromId=void 0,this.toId=void 0,this.selected=!1,this.hover=!1,this.labelDirty=!0,this.baseWidth=this.options.width,this.baseFontSize=this.options.font.size,this.from=void 0,this.to=void 0,this.edgeType=void 0,this.connected=!1,this.labelModule=new OE(this.body,this.options,!0),this.setOptions(e)}return Kd(t,[{key:"setOptions",value:function(e){if(e){var i=void 0!==e.physics&&this.options.physics!==e.physics||void 0!==e.hidden&&(this.options.hidden||!1)!==(e.hidden||!1)||void 0!==e.from&&this.options.from!==e.from||void 0!==e.to&&this.options.to!==e.to;t.parseOptions(this.options,e,!0,this.globalOptions),void 0!==e.id&&(this.id=e.id),void 0!==e.from&&(this.fromId=e.from),void 0!==e.to&&(this.toId=e.to),void 0!==e.title&&(this.title=e.title),void 0!==e.value&&(e.value=lE(e.value));var n=[e,this.options,this.defaultOptions];return this.chooser=gE("edge",n),this.updateLabelModule(e),i=this.updateEdgeType()||i,this._setInteractionWidths(),this.connect(),i}}},{key:"getFormattingValues",value:function(){var t=!0===this.options.arrows.to||!0===this.options.arrows.to.enabled,e=!0===this.options.arrows.from||!0===this.options.arrows.from.enabled,i=!0===this.options.arrows.middle||!0===this.options.arrows.middle.enabled,n=this.options.color.inherit,o={toArrow:t,toArrowScale:this.options.arrows.to.scaleFactor,toArrowType:this.options.arrows.to.type,toArrowSrc:this.options.arrows.to.src,toArrowImageWidth:this.options.arrows.to.imageWidth,toArrowImageHeight:this.options.arrows.to.imageHeight,middleArrow:i,middleArrowScale:this.options.arrows.middle.scaleFactor,middleArrowType:this.options.arrows.middle.type,middleArrowSrc:this.options.arrows.middle.src,middleArrowImageWidth:this.options.arrows.middle.imageWidth,middleArrowImageHeight:this.options.arrows.middle.imageHeight,fromArrow:e,fromArrowScale:this.options.arrows.from.scaleFactor,fromArrowType:this.options.arrows.from.type,fromArrowSrc:this.options.arrows.from.src,fromArrowImageWidth:this.options.arrows.from.imageWidth,fromArrowImageHeight:this.options.arrows.from.imageHeight,arrowStrikethrough:this.options.arrowStrikethrough,color:n?void 0:this.options.color.color,inheritsColor:n,opacity:this.options.color.opacity,hidden:this.options.hidden,length:this.options.length,shadow:this.options.shadow.enabled,shadowColor:this.options.shadow.color,shadowSize:this.options.shadow.size,shadowX:this.options.shadow.x,shadowY:this.options.shadow.y,dashes:this.options.dashes,width:this.options.width,background:this.options.background.enabled,backgroundColor:this.options.background.color,backgroundSize:this.options.background.size,backgroundDashes:this.options.background.dashes};if(this.selected||this.hover)if(!0===this.chooser){if(this.selected){var r=this.options.selectionWidth;"function"==typeof r?o.width=r(o.width):"number"==typeof r&&(o.width+=r),o.width=Math.max(o.width,.3/this.body.view.scale),o.color=this.options.color.highlight,o.shadow=this.options.shadow.enabled}else if(this.hover){var s=this.options.hoverWidth;"function"==typeof s?o.width=s(o.width):"number"==typeof s&&(o.width+=s),o.width=Math.max(o.width,.3/this.body.view.scale),o.color=this.options.color.hover,o.shadow=this.options.shadow.enabled}}else"function"==typeof this.chooser&&(this.chooser(o,this.options.id,this.selected,this.hover),void 0!==o.color&&(o.inheritsColor=!1),!1===o.shadow&&(o.shadowColor===this.options.shadow.color&&o.shadowSize===this.options.shadow.size&&o.shadowX===this.options.shadow.x&&o.shadowY===this.options.shadow.y||(o.shadow=!0)));else o.shadow=this.options.shadow.enabled,o.width=Math.max(o.width,.3/this.body.view.scale);return o}},{key:"updateLabelModule",value:function(t){var e=[t,this.options,this.globalOptions,this.defaultOptions];this.labelModule.update(this.options,e),void 0!==this.labelModule.baseSize&&(this.baseFontSize=this.labelModule.baseSize)}},{key:"updateEdgeType",value:function(){var t=this.options.smooth,e=!1,i=!0;return void 0!==this.edgeType&&((this.edgeType instanceof iC&&!0===t.enabled&&"dynamic"===t.type||this.edgeType instanceof hC&&!0===t.enabled&&"cubicBezier"===t.type||this.edgeType instanceof oC&&!0===t.enabled&&"dynamic"!==t.type&&"cubicBezier"!==t.type||this.edgeType instanceof dC&&!1===t.type.enabled)&&(i=!1),!0===i&&(e=this.cleanup())),!0===i?!0===t.enabled?"dynamic"===t.type?(e=!0,this.edgeType=new iC(this.options,this.body,this.labelModule)):"cubicBezier"===t.type?this.edgeType=new hC(this.options,this.body,this.labelModule):this.edgeType=new oC(this.options,this.body,this.labelModule):this.edgeType=new dC(this.options,this.body,this.labelModule):this.edgeType.setOptions(this.options),e}},{key:"connect",value:function(){this.disconnect(),this.from=this.body.nodes[this.fromId]||void 0,this.to=this.body.nodes[this.toId]||void 0,this.connected=void 0!==this.from&&void 0!==this.to,!0===this.connected?(this.from.attachEdge(this),this.to.attachEdge(this)):(this.from&&this.from.detachEdge(this),this.to&&this.to.detachEdge(this)),this.edgeType.connect()}},{key:"disconnect",value:function(){this.from&&(this.from.detachEdge(this),this.from=void 0),this.to&&(this.to.detachEdge(this),this.to=void 0),this.connected=!1}},{key:"getTitle",value:function(){return this.title}},{key:"isSelected",value:function(){return this.selected}},{key:"getValue",value:function(){return this.options.value}},{key:"setValueRange",value:function(t,e,i){if(void 0!==this.options.value){var n=this.options.scaling.customScalingFunction(t,e,i,this.options.value),o=this.options.scaling.max-this.options.scaling.min;if(!0===this.options.scaling.label.enabled){var r=this.options.scaling.label.max-this.options.scaling.label.min;this.options.font.size=this.options.scaling.label.min+n*r}this.options.width=this.options.scaling.min+n*o}else this.options.width=this.baseWidth,this.options.font.size=this.baseFontSize;this._setInteractionWidths(),this.updateLabelModule()}},{key:"_setInteractionWidths",value:function(){"function"==typeof this.options.hoverWidth?this.edgeType.hoverWidth=this.options.hoverWidth(this.options.width):this.edgeType.hoverWidth=this.options.hoverWidth+this.options.width,"function"==typeof this.options.selectionWidth?this.edgeType.selectionWidth=this.options.selectionWidth(this.options.width):this.edgeType.selectionWidth=this.options.selectionWidth+this.options.width}},{key:"draw",value:function(t){var e=this.getFormattingValues();if(!e.hidden){var i=this.edgeType.getViaNode();this.edgeType.drawLine(t,e,this.selected,this.hover,i),this.drawLabel(t,i)}}},{key:"drawArrows",value:function(t){var e=this.getFormattingValues();if(!e.hidden){var i=this.edgeType.getViaNode(),n={};this.edgeType.fromPoint=this.edgeType.from,this.edgeType.toPoint=this.edgeType.to,e.fromArrow&&(n.from=this.edgeType.getArrowData(t,"from",i,this.selected,this.hover,e),!1===e.arrowStrikethrough&&(this.edgeType.fromPoint=n.from.core),e.fromArrowSrc&&(n.from.image=this.imagelist.load(e.fromArrowSrc)),e.fromArrowImageWidth&&(n.from.imageWidth=e.fromArrowImageWidth),e.fromArrowImageHeight&&(n.from.imageHeight=e.fromArrowImageHeight)),e.toArrow&&(n.to=this.edgeType.getArrowData(t,"to",i,this.selected,this.hover,e),!1===e.arrowStrikethrough&&(this.edgeType.toPoint=n.to.core),e.toArrowSrc&&(n.to.image=this.imagelist.load(e.toArrowSrc)),e.toArrowImageWidth&&(n.to.imageWidth=e.toArrowImageWidth),e.toArrowImageHeight&&(n.to.imageHeight=e.toArrowImageHeight)),e.middleArrow&&(n.middle=this.edgeType.getArrowData(t,"middle",i,this.selected,this.hover,e),e.middleArrowSrc&&(n.middle.image=this.imagelist.load(e.middleArrowSrc)),e.middleArrowImageWidth&&(n.middle.imageWidth=e.middleArrowImageWidth),e.middleArrowImageHeight&&(n.middle.imageHeight=e.middleArrowImageHeight)),e.fromArrow&&this.edgeType.drawArrowHead(t,e,this.selected,this.hover,n.from),e.middleArrow&&this.edgeType.drawArrowHead(t,e,this.selected,this.hover,n.middle),e.toArrow&&this.edgeType.drawArrowHead(t,e,this.selected,this.hover,n.to)}}},{key:"drawLabel",value:function(t,e){if(void 0!==this.options.label){var i,n=this.from,o=this.to;if(this.labelModule.differentState(this.selected,this.hover)&&this.labelModule.getTextSize(t,this.selected,this.hover),n.id!=o.id){this.labelModule.pointToSelf=!1,i=this.edgeType.getPoint(.5,e),t.save();var r=this._getRotation(t);0!=r.angle&&(t.translate(r.x,r.y),t.rotate(r.angle)),this.labelModule.draw(t,i.x,i.y,this.selected,this.hover),t.restore()}else{this.labelModule.pointToSelf=!0;var s=bE(t,this.options.selfReference.angle,this.options.selfReference.size,n);i=this._pointOnCircle(s.x,s.y,this.options.selfReference.size,this.options.selfReference.angle),this.labelModule.draw(t,i.x,i.y,this.selected,this.hover)}}}},{key:"getItemsOnPoint",value:function(t){var e=[];if(this.labelModule.visible()){var i=this._getRotation();yE(this.labelModule.getSize(),t,i)&&e.push({edgeId:this.id,labelId:0})}var n={left:t.x,top:t.y};return this.isOverlappingWith(n)&&e.push({edgeId:this.id}),e}},{key:"isOverlappingWith",value:function(t){if(this.connected){var e=this.from.x,i=this.from.y,n=this.to.x,o=this.to.y,r=t.left,s=t.top;return this.edgeType.getDistanceToEdge(e,i,n,o,r,s)<10}return!1}},{key:"_getRotation",value:function(t){var e=this.edgeType.getViaNode(),i=this.edgeType.getPoint(.5,e);void 0!==t&&this.labelModule.calculateLabelSize(t,this.selected,this.hover,i.x,i.y);var n={x:i.x,y:this.labelModule.size.yLine,angle:0};if(!this.labelModule.visible())return n;if("horizontal"===this.options.font.align)return n;var o=this.from.y-this.to.y,r=this.from.x-this.to.x,s=Math.atan2(o,r);return(s<-1&&r<0||s>0&&r<0)&&(s+=Math.PI),n.angle=s,n}},{key:"_pointOnCircle",value:function(t,e,i,n){return{x:t+i*Math.cos(n),y:e-i*Math.sin(n)}}},{key:"select",value:function(){this.selected=!0}},{key:"unselect",value:function(){this.selected=!1}},{key:"cleanup",value:function(){return this.edgeType.cleanup()}},{key:"remove",value:function(){this.cleanup(),this.disconnect(),delete this.body.edges[this.id]}},{key:"endPointsValid",value:function(){return void 0!==this.body.nodes[this.fromId]&&void 0!==this.body.nodes[this.toId]}}],[{key:"parseOptions",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]&&arguments[2],n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{},o=arguments.length>4&&void 0!==arguments[4]&&arguments[4],r=["endPointOffset","arrowStrikethrough","id","from","hidden","hoverWidth","labelHighlightBold","length","line","opacity","physics","scaling","selectionWidth","selfReferenceSize","selfReference","to","title","value","width","font","chosen","widthConstraint"];if(em(r,t,e,i),void 0!==e.endPointOffset&&void 0!==e.endPointOffset.from&&(ok(e.endPointOffset.from)?t.endPointOffset.from=e.endPointOffset.from:(t.endPointOffset.from=void 0!==n.endPointOffset.from?n.endPointOffset.from:0,console.error("endPointOffset.from is not a valid number"))),void 0!==e.endPointOffset&&void 0!==e.endPointOffset.to&&(ok(e.endPointOffset.to)?t.endPointOffset.to=e.endPointOffset.to:(t.endPointOffset.to=void 0!==n.endPointOffset.to?n.endPointOffset.to:0,console.error("endPointOffset.to is not a valid number"))),mE(e.label)?t.label=e.label:mE(t.label)||(t.label=void 0),Sm(t,e,"smooth",n),Sm(t,e,"shadow",n),Sm(t,e,"background",n),void 0!==e.dashes&&null!==e.dashes?t.dashes=e.dashes:!0===i&&null===e.dashes&&(t.dashes=Kp(n.dashes)),void 0!==e.scaling&&null!==e.scaling?(void 0!==e.scaling.min&&(t.scaling.min=e.scaling.min),void 0!==e.scaling.max&&(t.scaling.max=e.scaling.max),Sm(t.scaling,e.scaling,"label",n.scaling)):!0===i&&null===e.scaling&&(t.scaling=Kp(n.scaling)),void 0!==e.arrows&&null!==e.arrows)if("string"==typeof e.arrows){var s=e.arrows.toLowerCase();t.arrows.to.enabled=-1!=Fp(s).call(s,"to"),t.arrows.middle.enabled=-1!=Fp(s).call(s,"middle"),t.arrows.from.enabled=-1!=Fp(s).call(s,"from")}else{if("object"!==Qc(e.arrows))throw new Error("The arrow newOptions can only be an object or a string. Refer to the documentation. You used:"+gv(e.arrows));Sm(t.arrows,e.arrows,"to",n.arrows),Sm(t.arrows,e.arrows,"middle",n.arrows),Sm(t.arrows,e.arrows,"from",n.arrows)}else!0===i&&null===e.arrows&&(t.arrows=Kp(n.arrows));if(void 0!==e.color&&null!==e.color){var a=$y(e.color)?{color:e.color,highlight:e.color,hover:e.color,inherit:!1,opacity:1}:e.color,h=t.color;if(o)nm(h,n.color,!1,i);else for(var l in h)Object.prototype.hasOwnProperty.call(h,l)&&delete h[l];if($y(h))h.color=h,h.highlight=h,h.hover=h,h.inherit=!1,void 0===a.opacity&&(h.opacity=1);else{var d=!1;void 0!==a.color&&(h.color=a.color,d=!0),void 0!==a.highlight&&(h.highlight=a.highlight,d=!0),void 0!==a.hover&&(h.hover=a.hover,d=!0),void 0!==a.inherit&&(h.inherit=a.inherit),void 0!==a.opacity&&(h.opacity=Math.min(1,Math.max(0,a.opacity))),!0===d?h.inherit=!1:void 0===h.inherit&&(h.inherit="from")}}else!0===i&&null===e.color&&(t.color=Cm(n.color));!0===i&&null===e.font&&(t.font=Cm(n.font)),Object.prototype.hasOwnProperty.call(e,"selfReferenceSize")&&(console.warn("The selfReferenceSize property has been deprecated. Please use selfReference property instead. The selfReference can be set like thise selfReference:{size:30, angle:Math.PI / 4}"),t.selfReference.size=e.selfReferenceSize)}}]),t}(),uC=function(){function t(e,i,n){var o,r=this;Yd(this,t),this.body=e,this.images=i,this.groups=n,this.body.functions.createEdge=zn(o=this.create).call(o,this),this.edgesListeners={add:function(t,e){r.add(e.items)},update:function(t,e){r.update(e.items)},remove:function(t,e){r.remove(e.items)}},this.options={},this.defaultOptions={arrows:{to:{enabled:!1,scaleFactor:1,type:"arrow"},middle:{enabled:!1,scaleFactor:1,type:"arrow"},from:{enabled:!1,scaleFactor:1,type:"arrow"}},endPointOffset:{from:0,to:0},arrowStrikethrough:!0,color:{color:"#848484",highlight:"#848484",hover:"#848484",inherit:"from",opacity:1},dashes:!1,font:{color:"#343434",size:14,face:"arial",background:"none",strokeWidth:2,strokeColor:"#ffffff",align:"horizontal",multi:!1,vadjust:0,bold:{mod:"bold"},boldital:{mod:"bold italic"},ital:{mod:"italic"},mono:{mod:"",size:15,face:"courier new",vadjust:2}},hidden:!1,hoverWidth:1.5,label:void 0,labelHighlightBold:!0,length:void 0,physics:!0,scaling:{min:1,max:15,label:{enabled:!0,min:14,max:30,maxVisible:30,drawThreshold:5},customScalingFunction:function(t,e,i,n){if(e===t)return.5;var o=1/(e-t);return Math.max(0,(n-t)*o)}},selectionWidth:1.5,selfReference:{size:20,angle:Math.PI/4,renderBehindTheNode:!0},shadow:{enabled:!1,color:"rgba(0,0,0,0.5)",size:10,x:5,y:5},background:{enabled:!1,color:"rgba(111,111,111,1)",size:10,dashes:!1},smooth:{enabled:!0,type:"dynamic",forceDirection:"none",roundness:.5},title:void 0,width:1,value:void 0},nm(this.options,this.defaultOptions),this.bindEventListeners()}return Kd(t,[{key:"bindEventListeners",value:function(){var t,e,i=this;this.body.emitter.on("_forceDisableDynamicCurves",(function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];"dynamic"===t&&(t="continuous");var n=!1;for(var o in i.body.edges)if(Object.prototype.hasOwnProperty.call(i.body.edges,o)){var r=i.body.edges[o],s=i.body.data.edges.get(o);if(null!=s){var a=s.smooth;void 0!==a&&!0===a.enabled&&"dynamic"===a.type&&(void 0===t?r.setOptions({smooth:!1}):r.setOptions({smooth:{type:t}}),n=!0)}}!0===e&&!0===n&&i.body.emitter.emit("_dataChanged")})),this.body.emitter.on("_dataUpdated",(function(){i.reconnectEdges()})),this.body.emitter.on("refreshEdges",zn(t=this.refresh).call(t,this)),this.body.emitter.on("refresh",zn(e=this.refresh).call(e,this)),this.body.emitter.on("destroy",(function(){hm(i.edgesListeners,(function(t,e){i.body.data.edges&&i.body.data.edges.off(e,t)})),delete i.body.functions.createEdge,delete i.edgesListeners.add,delete i.edgesListeners.update,delete i.edgesListeners.remove,delete i.edgesListeners}))}},{key:"setOptions",value:function(t){if(void 0!==t){cC.parseOptions(this.options,t,!0,this.defaultOptions,!0);var e=!1;if(void 0!==t.smooth)for(var i in this.body.edges)Object.prototype.hasOwnProperty.call(this.body.edges,i)&&(e=this.body.edges[i].updateEdgeType()||e);if(void 0!==t.font)for(var n in this.body.edges)Object.prototype.hasOwnProperty.call(this.body.edges,n)&&this.body.edges[n].updateLabelModule();void 0===t.hidden&&void 0===t.physics&&!0!==e||this.body.emitter.emit("_dataChanged")}}},{key:"setData",value:function(t){var e=this,i=arguments.length>1&&void 0!==arguments[1]&&arguments[1],n=this.body.data.edges;if(Qx("id",t))this.body.data.edges=t;else if(lu(t))this.body.data.edges=new Kx,this.body.data.edges.add(t);else{if(t)throw new TypeError("Array or DataSet expected");this.body.data.edges=new Kx}if(n&&hm(this.edgesListeners,(function(t,e){n.off(e,t)})),this.body.edges={},this.body.data.edges){hm(this.edgesListeners,(function(t,i){e.body.data.edges.on(i,t)}));var o=this.body.data.edges.getIds();this.add(o,!0)}this.body.emitter.emit("_adjustEdgesForHierarchicalLayout"),!1===i&&this.body.emitter.emit("_dataChanged")}},{key:"add",value:function(t){for(var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],i=this.body.edges,n=this.body.data.edges,o=0;o<t.length;o++){var r=t[o],s=i[r];s&&s.disconnect();var a=n.get(r,{showInternalIds:!0});i[r]=this.create(a)}this.body.emitter.emit("_adjustEdgesForHierarchicalLayout"),!1===e&&this.body.emitter.emit("_dataChanged")}},{key:"update",value:function(t){for(var e=this.body.edges,i=this.body.data.edges,n=!1,o=0;o<t.length;o++){var r=t[o],s=i.get(r),a=e[r];void 0!==a?(a.disconnect(),n=a.setOptions(s)||n,a.connect()):(this.body.edges[r]=this.create(s),n=!0)}!0===n?(this.body.emitter.emit("_adjustEdgesForHierarchicalLayout"),this.body.emitter.emit("_dataChanged")):this.body.emitter.emit("_dataUpdated")}},{key:"remove",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];if(0!==t.length){var i=this.body.edges;hm(t,(function(t){var e=i[t];void 0!==e&&e.remove()})),e&&this.body.emitter.emit("_dataChanged")}}},{key:"refresh",value:function(){var t=this;hm(this.body.edges,(function(e,i){var n=t.body.data.edges.get(i);void 0!==n&&e.setOptions(n)}))}},{key:"create",value:function(t){return new cC(t,this.body,this.images,this.options,this.defaultOptions)}},{key:"reconnectEdges",value:function(){var t,e=this.body.nodes,i=this.body.edges;for(t in e)Object.prototype.hasOwnProperty.call(e,t)&&(e[t].edges=[]);for(t in i)if(Object.prototype.hasOwnProperty.call(i,t)){var n=i[t];n.from=null,n.to=null,n.connect()}}},{key:"getConnectedNodes",value:function(t){var e=[];if(void 0!==this.body.edges[t]){var i=this.body.edges[t];void 0!==i.fromId&&e.push(i.fromId),void 0!==i.toId&&e.push(i.toId)}return e}},{key:"_updateState",value:function(){this._addMissingEdges(),this._removeInvalidEdges()}},{key:"_removeInvalidEdges",value:function(){var t=this,e=[];hm(this.body.edges,(function(i,n){var o=t.body.nodes[i.toId],r=t.body.nodes[i.fromId];void 0!==o&&!0===o.isCluster||void 0!==r&&!0===r.isCluster||void 0!==o&&void 0!==r||e.push(n)})),this.remove(e,!1)}},{key:"_addMissingEdges",value:function(){var t=this.body.data.edges;if(null!=t){var e=this.body.edges,i=[];Fu(t).call(t,(function(t,n){void 0===e[n]&&i.push(n)})),this.add(i,!0)}}}]),t}(),fC=function(){function t(e,i,n){Yd(this,t),this.body=e,this.physicsBody=i,this.barnesHutTree,this.setOptions(n),this._rng=jy("BARNES HUT SOLVER")}return Kd(t,[{key:"setOptions",value:function(t){this.options=t,this.thetaInversed=1/this.options.theta,this.overlapAvoidanceFactor=1-Math.max(0,Math.min(1,this.options.avoidOverlap))}},{key:"solve",value:function(){if(0!==this.options.gravitationalConstant&&this.physicsBody.physicsNodeIndices.length>0){var t,e=this.body.nodes,i=this.physicsBody.physicsNodeIndices,n=i.length,o=this._formBarnesHutTree(e,i);this.barnesHutTree=o;for(var r=0;r<n;r++)(t=e[i[r]]).options.mass>0&&this._getForceContributions(o.root,t)}}},{key:"_getForceContributions",value:function(t,e){this._getForceContribution(t.children.NW,e),this._getForceContribution(t.children.NE,e),this._getForceContribution(t.children.SW,e),this._getForceContribution(t.children.SE,e)}},{key:"_getForceContribution",value:function(t,e){if(t.childrenCount>0){var i=t.centerOfMass.x-e.x,n=t.centerOfMass.y-e.y,o=Math.sqrt(i*i+n*n);o*t.calcSize>this.thetaInversed?this._calculateForces(o,i,n,e,t):4===t.childrenCount?this._getForceContributions(t,e):t.children.data.id!=e.id&&this._calculateForces(o,i,n,e,t)}}},{key:"_calculateForces",value:function(t,e,i,n,o){0===t&&(e=t=.1),this.overlapAvoidanceFactor<1&&n.shape.radius&&(t=Math.max(.1+this.overlapAvoidanceFactor*n.shape.radius,t-n.shape.radius));var r=this.options.gravitationalConstant*o.mass*n.options.mass/Math.pow(t,3),s=e*r,a=i*r;this.physicsBody.forces[n.id].x+=s,this.physicsBody.forces[n.id].y+=a}},{key:"_formBarnesHutTree",value:function(t,e){for(var i,n=e.length,o=t[e[0]].x,r=t[e[0]].y,s=t[e[0]].x,a=t[e[0]].y,h=1;h<n;h++){var l=t[e[h]],d=l.x,c=l.y;l.options.mass>0&&(d<o&&(o=d),d>s&&(s=d),c<r&&(r=c),c>a&&(a=c))}var u=Math.abs(s-o)-Math.abs(a-r);u>0?(r-=.5*u,a+=.5*u):(o+=.5*u,s-=.5*u);var f=Math.max(1e-5,Math.abs(s-o)),p=.5*f,v=.5*(o+s),g=.5*(r+a),y={root:{centerOfMass:{x:0,y:0},mass:0,range:{minX:v-p,maxX:v+p,minY:g-p,maxY:g+p},size:f,calcSize:1/f,children:{data:null},maxWidth:0,level:0,childrenCount:4}};this._splitBranch(y.root);for(var m=0;m<n;m++)(i=t[e[m]]).options.mass>0&&this._placeInTree(y.root,i);return y}},{key:"_updateBranchMass",value:function(t,e){var i=t.centerOfMass,n=t.mass+e.options.mass,o=1/n;i.x=i.x*t.mass+e.x*e.options.mass,i.x*=o,i.y=i.y*t.mass+e.y*e.options.mass,i.y*=o,t.mass=n;var r=Math.max(Math.max(e.height,e.radius),e.width);t.maxWidth=t.maxWidth<r?r:t.maxWidth}},{key:"_placeInTree",value:function(t,e,i){1==i&&void 0!==i||this._updateBranchMass(t,e);var n,o=t.children.NW.range;n=o.maxX>e.x?o.maxY>e.y?"NW":"SW":o.maxY>e.y?"NE":"SE",this._placeInRegion(t,e,n)}},{key:"_placeInRegion",value:function(t,e,i){var n=t.children[i];switch(n.childrenCount){case 0:n.children.data=e,n.childrenCount=1,this._updateBranchMass(n,e);break;case 1:n.children.data.x===e.x&&n.children.data.y===e.y?(e.x+=this._rng(),e.y+=this._rng()):(this._splitBranch(n),this._placeInTree(n,e));break;case 4:this._placeInTree(n,e)}}},{key:"_splitBranch",value:function(t){var e=null;1===t.childrenCount&&(e=t.children.data,t.mass=0,t.centerOfMass.x=0,t.centerOfMass.y=0),t.childrenCount=4,t.children.data=null,this._insertRegion(t,"NW"),this._insertRegion(t,"NE"),this._insertRegion(t,"SW"),this._insertRegion(t,"SE"),null!=e&&this._placeInTree(t,e)}},{key:"_insertRegion",value:function(t,e){var i,n,o,r,s=.5*t.size;switch(e){case"NW":i=t.range.minX,n=t.range.minX+s,o=t.range.minY,r=t.range.minY+s;break;case"NE":i=t.range.minX+s,n=t.range.maxX,o=t.range.minY,r=t.range.minY+s;break;case"SW":i=t.range.minX,n=t.range.minX+s,o=t.range.minY+s,r=t.range.maxY;break;case"SE":i=t.range.minX+s,n=t.range.maxX,o=t.range.minY+s,r=t.range.maxY}t.children[e]={centerOfMass:{x:0,y:0},mass:0,range:{minX:i,maxX:n,minY:o,maxY:r},size:.5*t.size,calcSize:2*t.calcSize,children:{data:null},maxWidth:0,level:t.level+1,childrenCount:0}}},{key:"_debug",value:function(t,e){void 0!==this.barnesHutTree&&(t.lineWidth=1,this._drawBranch(this.barnesHutTree.root,t,e))}},{key:"_drawBranch",value:function(t,e,i){void 0===i&&(i="#FF0000"),4===t.childrenCount&&(this._drawBranch(t.children.NW,e),this._drawBranch(t.children.NE,e),this._drawBranch(t.children.SE,e),this._drawBranch(t.children.SW,e)),e.strokeStyle=i,e.beginPath(),e.moveTo(t.range.minX,t.range.minY),e.lineTo(t.range.maxX,t.range.minY),e.stroke(),e.beginPath(),e.moveTo(t.range.maxX,t.range.minY),e.lineTo(t.range.maxX,t.range.maxY),e.stroke(),e.beginPath(),e.moveTo(t.range.maxX,t.range.maxY),e.lineTo(t.range.minX,t.range.maxY),e.stroke(),e.beginPath(),e.moveTo(t.range.minX,t.range.maxY),e.lineTo(t.range.minX,t.range.minY),e.stroke()}}]),t}(),pC=function(){function t(e,i,n){Yd(this,t),this._rng=jy("REPULSION SOLVER"),this.body=e,this.physicsBody=i,this.setOptions(n)}return Kd(t,[{key:"setOptions",value:function(t){this.options=t}},{key:"solve",value:function(){for(var t,e,i,n,o,r,s,a,h=this.body.nodes,l=this.physicsBody.physicsNodeIndices,d=this.physicsBody.forces,c=this.options.nodeDistance,u=-2/3/c,f=0;f<l.length-1;f++){s=h[l[f]];for(var p=f+1;p<l.length;p++)t=(a=h[l[p]]).x-s.x,e=a.y-s.y,0===(i=Math.sqrt(t*t+e*e))&&(t=i=.1*this._rng()),i<2*c&&(r=i<.5*c?1:u*i+1.3333333333333333,n=t*(r/=i),o=e*r,d[s.id].x-=n,d[s.id].y-=o,d[a.id].x+=n,d[a.id].y+=o)}}}]),t}(),vC=function(){function t(e,i,n){Yd(this,t),this.body=e,this.physicsBody=i,this.setOptions(n)}return Kd(t,[{key:"setOptions",value:function(t){this.options=t,this.overlapAvoidanceFactor=Math.max(0,Math.min(1,this.options.avoidOverlap||0))}},{key:"solve",value:function(){for(var t=this.body.nodes,e=this.physicsBody.physicsNodeIndices,i=this.physicsBody.forces,n=this.options.nodeDistance,o=0;o<e.length-1;o++)for(var r=t[e[o]],s=o+1;s<e.length;s++){var a=t[e[s]];if(r.level===a.level){var h=n+this.overlapAvoidanceFactor*((r.shape.radius||0)/2+(a.shape.radius||0)/2),l=a.x-r.x,d=a.y-r.y,c=Math.sqrt(l*l+d*d),u=void 0;u=c<h?-Math.pow(.05*c,2)+Math.pow(.05*h,2):0,0!==c&&(u/=c);var f=l*u,p=d*u;i[r.id].x-=f,i[r.id].y-=p,i[a.id].x+=f,i[a.id].y+=p}}}}]),t}(),gC=function(){function t(e,i,n){Yd(this,t),this.body=e,this.physicsBody=i,this.setOptions(n)}return Kd(t,[{key:"setOptions",value:function(t){this.options=t}},{key:"solve",value:function(){for(var t,e,i,n,o,r=this.physicsBody.physicsEdgeIndices,s=this.body.edges,a=0;a<r.length;a++)!0===(e=s[r[a]]).connected&&e.toId!==e.fromId&&void 0!==this.body.nodes[e.toId]&&void 0!==this.body.nodes[e.fromId]&&(void 0!==e.edgeType.via?(t=void 0===e.options.length?this.options.springLength:e.options.length,i=e.to,n=e.edgeType.via,o=e.from,this._calculateSpringForce(i,n,.5*t),this._calculateSpringForce(n,o,.5*t)):(t=void 0===e.options.length?1.5*this.options.springLength:e.options.length,this._calculateSpringForce(e.from,e.to,t)))}},{key:"_calculateSpringForce",value:function(t,e,i){var n=t.x-e.x,o=t.y-e.y,r=Math.max(Math.sqrt(n*n+o*o),.01),s=this.options.springConstant*(i-r)/r,a=n*s,h=o*s;void 0!==this.physicsBody.forces[t.id]&&(this.physicsBody.forces[t.id].x+=a,this.physicsBody.forces[t.id].y+=h),void 0!==this.physicsBody.forces[e.id]&&(this.physicsBody.forces[e.id].x-=a,this.physicsBody.forces[e.id].y-=h)}}]),t}(),yC=function(){function t(e,i,n){Yd(this,t),this.body=e,this.physicsBody=i,this.setOptions(n)}return Kd(t,[{key:"setOptions",value:function(t){this.options=t}},{key:"solve",value:function(){for(var t,e,i,n,o,r,s,a,h,l,d=this.body.edges,c=.5,u=this.physicsBody.physicsEdgeIndices,f=this.physicsBody.physicsNodeIndices,p=this.physicsBody.forces,v=0;v<f.length;v++){var g=f[v];p[g].springFx=0,p[g].springFy=0}for(var y=0;y<u.length;y++)!0===(e=d[u[y]]).connected&&(t=void 0===e.options.length?this.options.springLength:e.options.length,i=e.from.x-e.to.x,n=e.from.y-e.to.y,a=0===(a=Math.sqrt(i*i+n*n))?.01:a,o=i*(s=this.options.springConstant*(t-a)/a),r=n*s,e.to.level!=e.from.level?(void 0!==p[e.toId]&&(p[e.toId].springFx-=o,p[e.toId].springFy-=r),void 0!==p[e.fromId]&&(p[e.fromId].springFx+=o,p[e.fromId].springFy+=r)):(void 0!==p[e.toId]&&(p[e.toId].x-=c*o,p[e.toId].y-=c*r),void 0!==p[e.fromId]&&(p[e.fromId].x+=c*o,p[e.fromId].y+=c*r)));s=1;for(var m=0;m<f.length;m++){var b=f[m];h=Math.min(s,Math.max(-s,p[b].springFx)),l=Math.min(s,Math.max(-s,p[b].springFy)),p[b].x+=h,p[b].y+=l}for(var w=0,k=0,_=0;_<f.length;_++){var x=f[_];w+=p[x].x,k+=p[x].y}for(var E=w/f.length,O=k/f.length,C=0;C<f.length;C++){var S=f[C];p[S].x-=E,p[S].y-=O}}}]),t}(),mC=function(){function t(e,i,n){Yd(this,t),this.body=e,this.physicsBody=i,this.setOptions(n)}return Kd(t,[{key:"setOptions",value:function(t){this.options=t}},{key:"solve",value:function(){for(var t,e,i,n,o=this.body.nodes,r=this.physicsBody.physicsNodeIndices,s=this.physicsBody.forces,a=0;a<r.length;a++){t=-(n=o[r[a]]).x,e=-n.y,i=Math.sqrt(t*t+e*e),this._calculateForces(i,t,e,s,n)}}},{key:"_calculateForces",value:function(t,e,i,n,o){var r=0===t?0:this.options.centralGravity/t;n[o.id].x=e*r,n[o.id].y=i*r}}]),t}();function bC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var wC=function(t){zk(i,t);var e=bC(i);function i(t,n,o){var r;return Yd(this,i),(r=e.call(this,t,n,o))._rng=jy("FORCE ATLAS 2 BASED REPULSION SOLVER"),r}return Kd(i,[{key:"_calculateForces",value:function(t,e,i,n,o){0===t&&(e=t=.1*this._rng()),this.overlapAvoidanceFactor<1&&n.shape.radius&&(t=Math.max(.1+this.overlapAvoidanceFactor*n.shape.radius,t-n.shape.radius));var r=n.edges.length+1,s=this.options.gravitationalConstant*o.mass*n.options.mass*r/Math.pow(t,2),a=e*s,h=i*s;this.physicsBody.forces[n.id].x+=a,this.physicsBody.forces[n.id].y+=h}}]),i}(fC);function kC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var _C=function(t){zk(i,t);var e=kC(i);function i(t,n,o){return Yd(this,i),e.call(this,t,n,o)}return Kd(i,[{key:"_calculateForces",value:function(t,e,i,n,o){if(t>0){var r=o.edges.length+1,s=this.options.centralGravity*r*o.options.mass;n[o.id].x=e*s,n[o.id].y=i*s}}}]),i}(mC),xC=function(){function t(e){Yd(this,t),this.body=e,this.physicsBody={physicsNodeIndices:[],physicsEdgeIndices:[],forces:{},velocities:{}},this.physicsEnabled=!0,this.simulationInterval=1e3/60,this.requiresTimeout=!0,this.previousStates={},this.referenceState={},this.freezeCache={},this.renderTimer=void 0,this.adaptiveTimestep=!1,this.adaptiveTimestepEnabled=!1,this.adaptiveCounter=0,this.adaptiveInterval=3,this.stabilized=!1,this.startedStabilization=!1,this.stabilizationIterations=0,this.ready=!1,this.options={},this.defaultOptions={enabled:!0,barnesHut:{theta:.5,gravitationalConstant:-2e3,centralGravity:.3,springLength:95,springConstant:.04,damping:.09,avoidOverlap:0},forceAtlas2Based:{theta:.5,gravitationalConstant:-50,centralGravity:.01,springConstant:.08,springLength:100,damping:.4,avoidOverlap:0},repulsion:{centralGravity:.2,springLength:200,springConstant:.05,nodeDistance:100,damping:.09,avoidOverlap:0},hierarchicalRepulsion:{centralGravity:0,springLength:100,springConstant:.01,nodeDistance:120,damping:.09},maxVelocity:50,minVelocity:.75,solver:"barnesHut",stabilization:{enabled:!0,iterations:1e3,updateInterval:50,onlyDynamicEdges:!1,fit:!0},timestep:.5,adaptiveTimestep:!0,wind:{x:0,y:0}},un(this.options,this.defaultOptions),this.timestep=.5,this.layoutFailed=!1,this.bindEventListeners()}return Kd(t,[{key:"bindEventListeners",value:function(){var t=this;this.body.emitter.on("initPhysics",(function(){t.initPhysics()})),this.body.emitter.on("_layoutFailed",(function(){t.layoutFailed=!0})),this.body.emitter.on("resetPhysics",(function(){t.stopSimulation(),t.ready=!1})),this.body.emitter.on("disablePhysics",(function(){t.physicsEnabled=!1,t.stopSimulation()})),this.body.emitter.on("restorePhysics",(function(){t.setOptions(t.options),!0===t.ready&&t.startSimulation()})),this.body.emitter.on("startSimulation",(function(){!0===t.ready&&t.startSimulation()})),this.body.emitter.on("stopSimulation",(function(){t.stopSimulation()})),this.body.emitter.on("destroy",(function(){t.stopSimulation(!1),t.body.emitter.off()})),this.body.emitter.on("_dataChanged",(function(){t.updatePhysicsData()}))}},{key:"setOptions",value:function(t){if(void 0!==t)if(!1===t)this.options.enabled=!1,this.physicsEnabled=!1,this.stopSimulation();else if(!0===t)this.options.enabled=!0,this.physicsEnabled=!0,this.startSimulation();else{this.physicsEnabled=!0,im(["stabilization"],this.options,t),Sm(this.options,t,"stabilization"),void 0===t.enabled&&(this.options.enabled=!0),!1===this.options.enabled&&(this.physicsEnabled=!1,this.stopSimulation());var e=this.options.wind;e&&(("number"!=typeof e.x||ek(e.x))&&(e.x=0),("number"!=typeof e.y||ek(e.y))&&(e.y=0)),this.timestep=this.options.timestep}this.init()}},{key:"init",value:function(){var t;"forceAtlas2Based"===this.options.solver?(t=this.options.forceAtlas2Based,this.nodesSolver=new wC(this.body,this.physicsBody,t),this.edgesSolver=new gC(this.body,this.physicsBody,t),this.gravitySolver=new _C(this.body,this.physicsBody,t)):"repulsion"===this.options.solver?(t=this.options.repulsion,this.nodesSolver=new pC(this.body,this.physicsBody,t),this.edgesSolver=new gC(this.body,this.physicsBody,t),this.gravitySolver=new mC(this.body,this.physicsBody,t)):"hierarchicalRepulsion"===this.options.solver?(t=this.options.hierarchicalRepulsion,this.nodesSolver=new vC(this.body,this.physicsBody,t),this.edgesSolver=new yC(this.body,this.physicsBody,t),this.gravitySolver=new mC(this.body,this.physicsBody,t)):(t=this.options.barnesHut,this.nodesSolver=new fC(this.body,this.physicsBody,t),this.edgesSolver=new gC(this.body,this.physicsBody,t),this.gravitySolver=new mC(this.body,this.physicsBody,t)),this.modelOptions=t}},{key:"initPhysics",value:function(){!0===this.physicsEnabled&&!0===this.options.enabled?!0===this.options.stabilization.enabled?this.stabilize():(this.stabilized=!1,this.ready=!0,this.body.emitter.emit("fit",{},this.layoutFailed),this.startSimulation()):(this.ready=!0,this.body.emitter.emit("fit"))}},{key:"startSimulation",value:function(){var t;!0===this.physicsEnabled&&!0===this.options.enabled?(this.stabilized=!1,this.adaptiveTimestep=!1,this.body.emitter.emit("_resizeNodes"),void 0===this.viewFunction&&(this.viewFunction=zn(t=this.simulationStep).call(t,this),this.body.emitter.on("initRedraw",this.viewFunction),this.body.emitter.emit("_startRendering"))):this.body.emitter.emit("_redraw")}},{key:"stopSimulation",value:function(){var t=!(arguments.length>0&&void 0!==arguments[0])||arguments[0];this.stabilized=!0,!0===t&&this._emitStabilized(),void 0!==this.viewFunction&&(this.body.emitter.off("initRedraw",this.viewFunction),this.viewFunction=void 0,!0===t&&this.body.emitter.emit("_stopRendering"))}},{key:"simulationStep",value:function(){var t=Eu();this.physicsTick(),(Eu()-t<.4*this.simulationInterval||!0===this.runDoubleSpeed)&&!1===this.stabilized&&(this.physicsTick(),this.runDoubleSpeed=!0),!0===this.stabilized&&this.stopSimulation()}},{key:"_emitStabilized",value:function(){var t=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.stabilizationIterations;(this.stabilizationIterations>1||!0===this.startedStabilization)&&Sv((function(){t.body.emitter.emit("stabilized",{iterations:e}),t.startedStabilization=!1,t.stabilizationIterations=0}),0)}},{key:"physicsStep",value:function(){this.gravitySolver.solve(),this.nodesSolver.solve(),this.edgesSolver.solve(),this.moveNodes()}},{key:"adjustTimeStep",value:function(){!0===this._evaluateStepQuality()?this.timestep=1.2*this.timestep:this.timestep/1.2<this.options.timestep?this.timestep=this.options.timestep:(this.adaptiveCounter=-1,this.timestep=Math.max(this.options.timestep,this.timestep/1.2))}},{key:"physicsTick",value:function(){if(this._startStabilizing(),!0!==this.stabilized){if(!0===this.adaptiveTimestep&&!0===this.adaptiveTimestepEnabled)this.adaptiveCounter%this.adaptiveInterval==0?(this.timestep=2*this.timestep,this.physicsStep(),this.revert(),this.timestep=.5*this.timestep,this.physicsStep(),this.physicsStep(),this.adjustTimeStep()):this.physicsStep(),this.adaptiveCounter+=1;else this.timestep=this.options.timestep,this.physicsStep();!0===this.stabilized&&this.revert(),this.stabilizationIterations++}}},{key:"updatePhysicsData",value:function(){this.physicsBody.forces={},this.physicsBody.physicsNodeIndices=[],this.physicsBody.physicsEdgeIndices=[];var t=this.body.nodes,e=this.body.edges;for(var i in t)Object.prototype.hasOwnProperty.call(t,i)&&!0===t[i].options.physics&&this.physicsBody.physicsNodeIndices.push(t[i].id);for(var n in e)Object.prototype.hasOwnProperty.call(e,n)&&!0===e[n].options.physics&&this.physicsBody.physicsEdgeIndices.push(e[n].id);for(var o=0;o<this.physicsBody.physicsNodeIndices.length;o++){var r=this.physicsBody.physicsNodeIndices[o];this.physicsBody.forces[r]={x:0,y:0},void 0===this.physicsBody.velocities[r]&&(this.physicsBody.velocities[r]={x:0,y:0})}for(var s in this.physicsBody.velocities)void 0===t[s]&&delete this.physicsBody.velocities[s]}},{key:"revert",value:function(){var t=bu(this.previousStates),e=this.body.nodes,i=this.physicsBody.velocities;this.referenceState={};for(var n=0;n<t.length;n++){var o=t[n];void 0!==e[o]?!0===e[o].options.physics&&(this.referenceState[o]={positions:{x:e[o].x,y:e[o].y}},i[o].x=this.previousStates[o].vx,i[o].y=this.previousStates[o].vy,e[o].x=this.previousStates[o].x,e[o].y=this.previousStates[o].y):delete this.previousStates[o]}}},{key:"_evaluateStepQuality",value:function(){var t,e,i=this.body.nodes,n=this.referenceState;for(var o in this.referenceState)if(Object.prototype.hasOwnProperty.call(this.referenceState,o)&&void 0!==i[o]&&(t=i[o].x-n[o].positions.x,e=i[o].y-n[o].positions.y,Math.sqrt(Math.pow(t,2)+Math.pow(e,2))>.3))return!1;return!0}},{key:"moveNodes",value:function(){for(var t=this.physicsBody.physicsNodeIndices,e=0,i=0,n=0;n<t.length;n++){var o=t[n],r=this._performStep(o);e=Math.max(e,r),i+=r}this.adaptiveTimestepEnabled=i/t.length<5,this.stabilized=e<this.options.minVelocity}},{key:"calculateComponentVelocity",value:function(t,e,i){t+=(e-this.modelOptions.damping*t)/i*this.timestep;var n=this.options.maxVelocity||1e9;return Math.abs(t)>n&&(t=t>0?n:-n),t}},{key:"_performStep",value:function(t){var e=this.body.nodes[t],i=this.physicsBody.forces[t];this.options.wind&&(i.x+=this.options.wind.x,i.y+=this.options.wind.y);var n=this.physicsBody.velocities[t];return this.previousStates[t]={x:e.x,y:e.y,vx:n.x,vy:n.y},!1===e.options.fixed.x?(n.x=this.calculateComponentVelocity(n.x,i.x,e.options.mass),e.x+=n.x*this.timestep):(i.x=0,n.x=0),!1===e.options.fixed.y?(n.y=this.calculateComponentVelocity(n.y,i.y,e.options.mass),e.y+=n.y*this.timestep):(i.y=0,n.y=0),Math.sqrt(Math.pow(n.x,2)+Math.pow(n.y,2))}},{key:"_freezeNodes",value:function(){var t=this.body.nodes;for(var e in t)if(Object.prototype.hasOwnProperty.call(t,e)&&t[e].x&&t[e].y){var i=t[e].options.fixed;this.freezeCache[e]={x:i.x,y:i.y},i.x=!0,i.y=!0}}},{key:"_restoreFrozenNodes",value:function(){var t=this.body.nodes;for(var e in t)Object.prototype.hasOwnProperty.call(t,e)&&void 0!==this.freezeCache[e]&&(t[e].options.fixed.x=this.freezeCache[e].x,t[e].options.fixed.y=this.freezeCache[e].y);this.freezeCache={}}},{key:"stabilize",value:function(){var t=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.stabilization.iterations;"number"!=typeof e&&(e=this.options.stabilization.iterations,console.error("The stabilize method needs a numeric amount of iterations. Switching to default: ",e)),0!==this.physicsBody.physicsNodeIndices.length?(this.adaptiveTimestep=this.options.adaptiveTimestep,this.body.emitter.emit("_resizeNodes"),this.stopSimulation(),this.stabilized=!1,this.body.emitter.emit("_blockRedraw"),this.targetIterations=e,!0===this.options.stabilization.onlyDynamicEdges&&this._freezeNodes(),this.stabilizationIterations=0,Sv((function(){return t._stabilizationBatch()}),0)):this.ready=!0}},{key:"_startStabilizing",value:function(){return!0!==this.startedStabilization&&(this.body.emitter.emit("startStabilizing"),this.startedStabilization=!0,!0)}},{key:"_stabilizationBatch",value:function(){var t=this,e=function(){return!1===t.stabilized&&t.stabilizationIterations<t.targetIterations},i=function(){t.body.emitter.emit("stabilizationProgress",{iterations:t.stabilizationIterations,total:t.targetIterations})};this._startStabilizing()&&i();for(var n,o=0;e()&&o<this.options.stabilization.updateInterval;)this.physicsTick(),o++;(i(),e())?Sv(zn(n=this._stabilizationBatch).call(n,this),0):this._finalizeStabilization()}},{key:"_finalizeStabilization",value:function(){this.body.emitter.emit("_allowRedraw"),!0===this.options.stabilization.fit&&this.body.emitter.emit("fit"),!0===this.options.stabilization.onlyDynamicEdges&&this._restoreFrozenNodes(),this.body.emitter.emit("stabilizationIterationsDone"),this.body.emitter.emit("_requestRedraw"),!0===this.stabilized?this._emitStabilized():this.startSimulation(),this.ready=!0}},{key:"_drawForces",value:function(t){for(var e=0;e<this.physicsBody.physicsNodeIndices.length;e++){var i=this.physicsBody.physicsNodeIndices[e],n=this.body.nodes[i],o=this.physicsBody.forces[i],r=Math.sqrt(Math.pow(o.x,2)+Math.pow(o.x,2)),s=Math.min(Math.max(5,r),15),a=3*s,h=km((180-180*Math.min(1,Math.max(0,.03*r)))/360,1,1),l={x:n.x+20*o.x,y:n.y+20*o.y};t.lineWidth=s,t.strokeStyle=h,t.beginPath(),t.moveTo(n.x,n.y),t.lineTo(l.x,l.y),t.stroke();var d=Math.atan2(o.y,o.x);t.fillStyle=h,XO.draw(t,{type:"arrow",point:l,angle:d,length:a}),jv(t).call(t)}}}]),t}(),EC=function(){function t(){Yd(this,t)}return Kd(t,null,[{key:"getRange",value:function(t){var e,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:[],n=1e9,o=-1e9,r=1e9,s=-1e9;if(i.length>0)for(var a=0;a<i.length;a++)r>(e=t[i[a]]).shape.boundingBox.left&&(r=e.shape.boundingBox.left),s<e.shape.boundingBox.right&&(s=e.shape.boundingBox.right),n>e.shape.boundingBox.top&&(n=e.shape.boundingBox.top),o<e.shape.boundingBox.bottom&&(o=e.shape.boundingBox.bottom);return 1e9===r&&-1e9===s&&1e9===n&&-1e9===o&&(n=0,o=0,r=0,s=0),{minX:r,maxX:s,minY:n,maxY:o}}},{key:"getRangeCore",value:function(t){var e,i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:[],n=1e9,o=-1e9,r=1e9,s=-1e9;if(i.length>0)for(var a=0;a<i.length;a++)r>(e=t[i[a]]).x&&(r=e.x),s<e.x&&(s=e.x),n>e.y&&(n=e.y),o<e.y&&(o=e.y);return 1e9===r&&-1e9===s&&1e9===n&&-1e9===o&&(n=0,o=0,r=0,s=0),{minX:r,maxX:s,minY:n,maxY:o}}},{key:"findCenter",value:function(t){return{x:.5*(t.maxX+t.minX),y:.5*(t.maxY+t.minY)}}},{key:"cloneOptions",value:function(t,e){var i={};return void 0===e||"node"===e?(nm(i,t.options,!0),i.x=t.x,i.y=t.y,i.amountOfConnections=t.edges.length):nm(i,t.options,!0),i}}]),t}();function OC(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var CC=function(t){zk(i,t);var e=OC(i);function i(t,n,o,r,s,a){var h;return Yd(this,i),(h=e.call(this,t,n,o,r,s,a)).isCluster=!0,h.containedNodes={},h.containedEdges={},h}return Kd(i,[{key:"_openChildCluster",value:function(t){var e=this,i=this.body.nodes[t];if(void 0===this.containedNodes[t])throw new Error("node with id: "+t+" not in current cluster");if(!i.isCluster)throw new Error("node with id: "+t+" is not a cluster");delete this.containedNodes[t],hm(i.edges,(function(t){delete e.containedEdges[t.id]})),hm(i.containedNodes,(function(t,i){e.containedNodes[i]=t})),i.containedNodes={},hm(i.containedEdges,(function(t,i){e.containedEdges[i]=t})),i.containedEdges={},hm(i.edges,(function(t){hm(e.edges,(function(i){var n,o,r=Fp(n=i.clusteringEdgeReplacingIds).call(n,t.id);-1!==r&&(hm(t.clusteringEdgeReplacingIds,(function(t){i.clusteringEdgeReplacingIds.push(t),e.body.edges[t].edgeReplacedById=i.id})),ff(o=i.clusteringEdgeReplacingIds).call(o,r,1))}))})),i.edges=[]}}]),i}(fO),SC=function(){function t(e){var i=this;Yd(this,t),this.body=e,this.clusteredNodes={},this.clusteredEdges={},this.options={},this.defaultOptions={},un(this.options,this.defaultOptions),this.body.emitter.on("_resetData",(function(){i.clusteredNodes={},i.clusteredEdges={}}))}return Kd(t,[{key:"clusterByHubsize",value:function(t,e){void 0===t?t=this._getHubSize():"object"===Qc(t)&&(e=this._checkOptions(t),t=this._getHubSize());for(var i=[],n=0;n<this.body.nodeIndices.length;n++){var o=this.body.nodes[this.body.nodeIndices[n]];o.edges.length>=t&&i.push(o.id)}for(var r=0;r<i.length;r++)this.clusterByConnection(i[r],e,!0);this.body.emitter.emit("_dataChanged")}},{key:"cluster",value:function(){var t=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},i=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];if(void 0===e.joinCondition)throw new Error("Cannot call clusterByNodeData without a joinCondition function in the options.");e=this._checkOptions(e);var n={},o={};hm(this.body.nodes,(function(i,r){i.options&&!0===e.joinCondition(i.options)&&(n[r]=i,hm(i.edges,(function(e){void 0===t.clusteredEdges[e.id]&&(o[e.id]=e)})))})),this._cluster(n,o,e,i)}},{key:"clusterByEdgeCount",value:function(t,e){var i=this,n=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];e=this._checkOptions(e);for(var o,r,s,a=[],h={},l=function(n){var l={},d={},c=i.body.nodeIndices[n],u=i.body.nodes[c];if(void 0===h[c]){s=0,r=[];for(var f=0;f<u.edges.length;f++)o=u.edges[f],void 0===i.clusteredEdges[o.id]&&(o.toId!==o.fromId&&s++,r.push(o));if(s===t){for(var p=function(t){if(void 0===e.joinCondition||null===e.joinCondition)return!0;var i=EC.cloneOptions(t);return e.joinCondition(i)},v=!0,g=0;g<r.length;g++){o=r[g];var y=i._getConnectedId(o,c);if(!p(u)){v=!1;break}d[o.id]=o,l[c]=u,l[y]=i.body.nodes[y],h[c]=!0}if(bu(l).length>0&&bu(d).length>0&&!0===v){var m=function(){for(var t=0;t<a.length;++t)for(var e in l)if(void 0!==a[t].nodes[e])return a[t]}();if(void 0!==m){for(var b in l)void 0===m.nodes[b]&&(m.nodes[b]=l[b]);for(var w in d)void 0===m.edges[w]&&(m.edges[w]=d[w])}else a.push({nodes:l,edges:d})}}}},d=0;d<this.body.nodeIndices.length;d++)l(d);for(var c=0;c<a.length;c++)this._cluster(a[c].nodes,a[c].edges,e,!1);!0===n&&this.body.emitter.emit("_dataChanged")}},{key:"clusterOutliers",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];this.clusterByEdgeCount(1,t,e)}},{key:"clusterBridges",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];this.clusterByEdgeCount(2,t,e)}},{key:"clusterByConnection",value:function(t,e){var i,n=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];if(void 0===t)throw new Error("No nodeId supplied to clusterByConnection!");if(void 0===this.body.nodes[t])throw new Error("The nodeId given to clusterByConnection does not exist!");var o=this.body.nodes[t];void 0===(e=this._checkOptions(e,o)).clusterNodeProperties.x&&(e.clusterNodeProperties.x=o.x),void 0===e.clusterNodeProperties.y&&(e.clusterNodeProperties.y=o.y),void 0===e.clusterNodeProperties.fixed&&(e.clusterNodeProperties.fixed={},e.clusterNodeProperties.fixed.x=o.options.fixed.x,e.clusterNodeProperties.fixed.y=o.options.fixed.y);var r={},s={},a=o.id,h=EC.cloneOptions(o);r[a]=o;for(var l=0;l<o.edges.length;l++){var d=o.edges[l];if(void 0===this.clusteredEdges[d.id]){var c=this._getConnectedId(d,a);if(void 0===this.clusteredNodes[c])if(c!==a)if(void 0===e.joinCondition)s[d.id]=d,r[c]=this.body.nodes[c];else{var u=EC.cloneOptions(this.body.nodes[c]);!0===e.joinCondition(h,u)&&(s[d.id]=d,r[c]=this.body.nodes[c])}else s[d.id]=d}}var f=gu(i=bu(r)).call(i,(function(t){return r[t].id}));for(var p in r)if(Object.prototype.hasOwnProperty.call(r,p))for(var v=r[p],g=0;g<v.edges.length;g++){var y=v.edges[g];Fp(f).call(f,this._getConnectedId(y,v.id))>-1&&(s[y.id]=y)}this._cluster(r,s,e,n)}},{key:"_createClusterEdges",value:function(t,e,i,n){for(var o,r,s,a,h,l,d=bu(t),c=[],u=0;u<d.length;u++){s=t[r=d[u]];for(var f=0;f<s.edges.length;f++)o=s.edges[f],void 0===this.clusteredEdges[o.id]&&(o.toId==o.fromId?e[o.id]=o:o.toId==r?(a=i.id,l=h=o.fromId):(a=o.toId,h=i.id,l=a),void 0===t[l]&&c.push({edge:o,fromId:h,toId:a}))}for(var p=[],v=function(t){for(var e=0;e<p.length;e++){var i=p[e],n=t.fromId===i.fromId&&t.toId===i.toId,o=t.fromId===i.toId&&t.toId===i.fromId;if(n||o)return i}return null},g=0;g<c.length;g++){var y=c[g],m=y.edge,b=v(y);null===b?(b=this._createClusteredEdge(y.fromId,y.toId,m,n),p.push(b)):b.clusteringEdgeReplacingIds.push(m.id),this.body.edges[m.id].edgeReplacedById=b.id,this._backupEdgeOptions(m),m.setOptions({physics:!1})}}},{key:"_checkOptions",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return void 0===t.clusterEdgeProperties&&(t.clusterEdgeProperties={}),void 0===t.clusterNodeProperties&&(t.clusterNodeProperties={}),t}},{key:"_cluster",value:function(t,e,i){var n=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],o=[];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&void 0!==this.clusteredNodes[r]&&o.push(r);for(var s=0;s<o.length;++s)delete t[o[s]];if(0!=bu(t).length&&(1!=bu(t).length||1==i.clusterNodeProperties.allowSingleNodeCluster)){var a=nm({},i.clusterNodeProperties);if(void 0!==i.processProperties){var h=[];for(var l in t)if(Object.prototype.hasOwnProperty.call(t,l)){var d=EC.cloneOptions(t[l]);h.push(d)}var c=[];for(var u in e)if(Object.prototype.hasOwnProperty.call(e,u)&&"clusterEdge:"!==u.substr(0,12)){var f=EC.cloneOptions(e[u],"edge");c.push(f)}if(!(a=i.processProperties(a,h,c)))throw new Error("The processProperties function does not return properties!")}void 0===a.id&&(a.id="cluster:"+Ax());var p=a.id;void 0===a.label&&(a.label="cluster");var v=void 0;void 0===a.x&&(v=this._getClusterPosition(t),a.x=v.x),void 0===a.y&&(void 0===v&&(v=this._getClusterPosition(t)),a.y=v.y),a.id=p;var g=this.body.functions.createNode(a,CC);g.containedNodes=t,g.containedEdges=e,g.clusterEdgeProperties=i.clusterEdgeProperties,this.body.nodes[a.id]=g,this._clusterEdges(t,e,a,i.clusterEdgeProperties),a.id=void 0,!0===n&&this.body.emitter.emit("_dataChanged")}}},{key:"_backupEdgeOptions",value:function(t){void 0===this.clusteredEdges[t.id]&&(this.clusteredEdges[t.id]={physics:t.options.physics})}},{key:"_restoreEdge",value:function(t){var e=this.clusteredEdges[t.id];void 0!==e&&(t.setOptions({physics:e.physics}),delete this.clusteredEdges[t.id])}},{key:"isCluster",value:function(t){return void 0!==this.body.nodes[t]?!0===this.body.nodes[t].isCluster:(console.error("Node does not exist."),!1)}},{key:"_getClusterPosition",value:function(t){for(var e,i=bu(t),n=t[i[0]].x,o=t[i[0]].x,r=t[i[0]].y,s=t[i[0]].y,a=1;a<i.length;a++)n=(e=t[i[a]]).x<n?e.x:n,o=e.x>o?e.x:o,r=e.y<r?e.y:r,s=e.y>s?e.y:s;return{x:.5*(n+o),y:.5*(r+s)}}},{key:"openCluster",value:function(t,e){var i=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];if(void 0===t)throw new Error("No clusterNodeId supplied to openCluster.");var n=this.body.nodes[t];if(void 0===n)throw new Error("The clusterNodeId supplied to openCluster does not exist.");if(!0!==n.isCluster||void 0===n.containedNodes||void 0===n.containedEdges)throw new Error("The node:"+t+" is not a valid cluster.");var o=this.findNode(t),r=Fp(o).call(o,t)-1;if(r>=0){var s=o[r],a=this.body.nodes[s];return a._openChildCluster(t),delete this.body.nodes[t],void(!0===i&&this.body.emitter.emit("_dataChanged"))}var h=n.containedNodes,l=n.containedEdges;if(void 0!==e&&void 0!==e.releaseFunction&&"function"==typeof e.releaseFunction){var d={},c={x:n.x,y:n.y};for(var u in h)if(Object.prototype.hasOwnProperty.call(h,u)){var f=this.body.nodes[u];d[u]={x:f.x,y:f.y}}var p=e.releaseFunction(c,d);for(var v in h)if(Object.prototype.hasOwnProperty.call(h,v)){var g=this.body.nodes[v];void 0!==p[v]&&(g.x=void 0===p[v].x?n.x:p[v].x,g.y=void 0===p[v].y?n.y:p[v].y)}}else hm(h,(function(t){!1===t.options.fixed.x&&(t.x=n.x),!1===t.options.fixed.y&&(t.y=n.y)}));for(var y in h)if(Object.prototype.hasOwnProperty.call(h,y)){var m=this.body.nodes[y];m.vx=n.vx,m.vy=n.vy,m.setOptions({physics:!0}),delete this.clusteredNodes[y]}for(var b=[],w=0;w<n.edges.length;w++)b.push(n.edges[w]);for(var k=0;k<b.length;k++){for(var _=b[k],x=this._getConnectedId(_,t),E=this.clusteredNodes[x],O=0;O<_.clusteringEdgeReplacingIds.length;O++){var C=_.clusteringEdgeReplacingIds[O],S=this.body.edges[C];if(void 0!==S)if(void 0!==E){var T=this.body.nodes[E.clusterId];T.containedEdges[S.id]=S,delete l[S.id];var M=S.fromId,P=S.toId;S.toId==x?P=E.clusterId:M=E.clusterId,this._createClusteredEdge(M,P,S,T.clusterEdgeProperties,{hidden:!1,physics:!0})}else this._restoreEdge(S)}_.remove()}for(var D in l)Object.prototype.hasOwnProperty.call(l,D)&&this._restoreEdge(l[D]);delete this.body.nodes[t],!0===i&&this.body.emitter.emit("_dataChanged")}},{key:"getNodesInCluster",value:function(t){var e=[];if(!0===this.isCluster(t)){var i=this.body.nodes[t].containedNodes;for(var n in i)Object.prototype.hasOwnProperty.call(i,n)&&e.push(this.body.nodes[n].id)}return e}},{key:"findNode",value:function(t){for(var e,i=[],n=0;void 0!==this.clusteredNodes[t]&&n<100;){if(void 0===(e=this.body.nodes[t]))return[];i.push(e.id),t=this.clusteredNodes[t].clusterId,n++}return void 0===(e=this.body.nodes[t])?[]:(i.push(e.id),Yu(i).call(i),i)}},{key:"updateClusteredNode",value:function(t,e){if(void 0===t)throw new Error("No clusteredNodeId supplied to updateClusteredNode.");if(void 0===e)throw new Error("No newOptions supplied to updateClusteredNode.");if(void 0===this.body.nodes[t])throw new Error("The clusteredNodeId supplied to updateClusteredNode does not exist.");this.body.nodes[t].setOptions(e),this.body.emitter.emit("_dataChanged")}},{key:"updateEdge",value:function(t,e){if(void 0===t)throw new Error("No startEdgeId supplied to updateEdge.");if(void 0===e)throw new Error("No newOptions supplied to updateEdge.");if(void 0===this.body.edges[t])throw new Error("The startEdgeId supplied to updateEdge does not exist.");for(var i=this.getClusteredEdges(t),n=0;n<i.length;n++){this.body.edges[i[n]].setOptions(e)}this.body.emitter.emit("_dataChanged")}},{key:"getClusteredEdges",value:function(t){for(var e=[],i=0;void 0!==t&&void 0!==this.body.edges[t]&&i<100;)e.push(this.body.edges[t].id),t=this.body.edges[t].edgeReplacedById,i++;return Yu(e).call(e),e}},{key:"getBaseEdge",value:function(t){return this.getBaseEdges(t)[0]}},{key:"getBaseEdges",value:function(t){for(var e=[t],i=[],n=[],o=0;e.length>0&&o<100;){var r=e.pop();if(void 0!==r){var s=this.body.edges[r];if(void 0!==s){o++;var a=s.clusteringEdgeReplacingIds;if(void 0===a)n.push(r);else for(var h=0;h<a.length;++h){var l=a[h];-1===Fp(e).call(e,a)&&-1===Fp(i).call(i,a)&&e.push(l)}i.push(r)}}}return n}},{key:"_getConnectedId",value:function(t,e){return t.toId!=e?t.toId:(t.fromId,t.fromId)}},{key:"_getHubSize",value:function(){for(var t=0,e=0,i=0,n=0,o=0;o<this.body.nodeIndices.length;o++){var r=this.body.nodes[this.body.nodeIndices[o]];r.edges.length>n&&(n=r.edges.length),t+=r.edges.length,e+=Math.pow(r.edges.length,2),i+=1}t/=i;var s=(e/=i)-Math.pow(t,2),a=Math.sqrt(s),h=Math.floor(t+2*a);return h>n&&(h=n),h}},{key:"_createClusteredEdge",value:function(t,e,i,n,o){var r=EC.cloneOptions(i,"edge");nm(r,n),r.from=t,r.to=e,r.id="clusterEdge:"+Ax(),void 0!==o&&nm(r,o);var s=this.body.functions.createEdge(r);return s.clusteringEdgeReplacingIds=[i.id],s.connect(),this.body.edges[s.id]=s,s}},{key:"_clusterEdges",value:function(t,e,i,n){if(e instanceof cC){var o=e,r={};r[o.id]=o,e=r}if(t instanceof fO){var s=t,a={};a[s.id]=s,t=a}if(null==i)throw new Error("_clusterEdges: parameter clusterNode required");for(var h in void 0===n&&(n=i.clusterEdgeProperties),this._createClusterEdges(t,e,i,n),e)if(Object.prototype.hasOwnProperty.call(e,h)&&void 0!==this.body.edges[h]){var l=this.body.edges[h];this._backupEdgeOptions(l),l.setOptions({physics:!1})}for(var d in t)Object.prototype.hasOwnProperty.call(t,d)&&(this.clusteredNodes[d]={clusterId:i.id,node:this.body.nodes[d]},this.body.nodes[d].setOptions({physics:!1}))}},{key:"_getClusterNodeForNode",value:function(t){if(void 0!==t){var e=this.clusteredNodes[t];if(void 0!==e){var i=e.clusterId;if(void 0!==i)return this.body.nodes[i]}}}},{key:"_filter",value:function(t,e){var i=[];return hm(t,(function(t){e(t)&&i.push(t)})),i}},{key:"_updateState",value:function(){var t,e=this,i=[],n={},o=function(t){hm(e.body.nodes,(function(e){!0===e.isCluster&&t(e)}))};for(t in this.clusteredNodes){if(Object.prototype.hasOwnProperty.call(this.clusteredNodes,t))void 0===this.body.nodes[t]&&i.push(t)}o((function(t){for(var e=0;e<i.length;e++)delete t.containedNodes[i[e]]}));for(var r=0;r<i.length;r++)delete this.clusteredNodes[i[r]];hm(this.clusteredEdges,(function(t){var i=e.body.edges[t];void 0!==i&&i.endPointsValid()||(n[t]=t)})),o((function(t){hm(t.containedEdges,(function(t,e){t.endPointsValid()||n[e]||(n[e]=e)}))})),hm(this.body.edges,(function(t,i){var o=!0,r=t.clusteringEdgeReplacingIds;if(void 0!==r){var s=0;hm(r,(function(t){var i=e.body.edges[t];void 0!==i&&i.endPointsValid()&&(s+=1)})),o=s>0}t.endPointsValid()&&o||(n[i]=i)})),o((function(t){hm(n,(function(i){delete t.containedEdges[i],hm(t.edges,(function(o,r){o.id!==i?o.clusteringEdgeReplacingIds=e._filter(o.clusteringEdgeReplacingIds,(function(t){return!n[t]})):t.edges[r]=null})),t.edges=e._filter(t.edges,(function(t){return null!==t}))}))})),hm(n,(function(t){delete e.clusteredEdges[t]})),hm(n,(function(t){delete e.body.edges[t]})),hm(bu(this.body.edges),(function(t){var i=e.body.edges[t],n=e._isClusteredNode(i.fromId)||e._isClusteredNode(i.toId);if(n!==e._isClusteredEdge(i.id))if(n){var o=e._getClusterNodeForNode(i.fromId);void 0!==o&&e._clusterEdges(e.body.nodes[i.fromId],i,o);var r=e._getClusterNodeForNode(i.toId);void 0!==r&&e._clusterEdges(e.body.nodes[i.toId],i,r)}else delete e._clusterEdges[t],e._restoreEdge(i)}));for(var s=!1,a=!0,h=function(){var t=[];o((function(e){var i=bu(e.containedNodes).length,n=!0===e.options.allowSingleNodeCluster;(n&&i<1||!n&&i<2)&&t.push(e.id)}));for(var i=0;i<t.length;++i)e.openCluster(t[i],{},!1);a=t.length>0,s=s||a};a;)h();s&&this._updateState()}},{key:"_isClusteredNode",value:function(t){return void 0!==this.clusteredNodes[t]}},{key:"_isClusteredEdge",value:function(t){return void 0!==this.clusteredEdges[t]}}]),t}();function TC(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return MC(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return MC(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function MC(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}var PC=function(){function t(e,i){var n;Yd(this,t),void 0!==window&&(n=window.requestAnimationFrame||window.mozRequestAnimationFrame||window.webkitRequestAnimationFrame||window.msRequestAnimationFrame),window.requestAnimationFrame=void 0===n?function(t){t()}:n,this.body=e,this.canvas=i,this.redrawRequested=!1,this.renderTimer=void 0,this.requiresTimeout=!0,this.renderingActive=!1,this.renderRequests=0,this.allowRedraw=!0,this.dragging=!1,this.zooming=!1,this.options={},this.defaultOptions={hideEdgesOnDrag:!1,hideEdgesOnZoom:!1,hideNodesOnDrag:!1},un(this.options,this.defaultOptions),this._determineBrowserMethod(),this.bindEventListeners()}return Kd(t,[{key:"bindEventListeners",value:function(){var t,e=this;this.body.emitter.on("dragStart",(function(){e.dragging=!0})),this.body.emitter.on("dragEnd",(function(){e.dragging=!1})),this.body.emitter.on("zoom",(function(){e.zooming=!0,window.clearTimeout(e.zoomTimeoutId),e.zoomTimeoutId=Sv((function(){var t;e.zooming=!1,zn(t=e._requestRedraw).call(t,e)()}),250)})),this.body.emitter.on("_resizeNodes",(function(){e._resizeNodes()})),this.body.emitter.on("_redraw",(function(){!1===e.renderingActive&&e._redraw()})),this.body.emitter.on("_blockRedraw",(function(){e.allowRedraw=!1})),this.body.emitter.on("_allowRedraw",(function(){e.allowRedraw=!0,e.redrawRequested=!1})),this.body.emitter.on("_requestRedraw",zn(t=this._requestRedraw).call(t,this)),this.body.emitter.on("_startRendering",(function(){e.renderRequests+=1,e.renderingActive=!0,e._startRendering()})),this.body.emitter.on("_stopRendering",(function(){e.renderRequests-=1,e.renderingActive=e.renderRequests>0,e.renderTimer=void 0})),this.body.emitter.on("destroy",(function(){e.renderRequests=0,e.allowRedraw=!1,e.renderingActive=!1,!0===e.requiresTimeout?clearTimeout(e.renderTimer):window.cancelAnimationFrame(e.renderTimer),e.body.emitter.off()}))}},{key:"setOptions",value:function(t){if(void 0!==t){em(["hideEdgesOnDrag","hideEdgesOnZoom","hideNodesOnDrag"],this.options,t)}}},{key:"_requestNextFrame",value:function(t,e){if("undefined"!=typeof window){var i,n=window;return!0===this.requiresTimeout?i=Sv(t,e):n.requestAnimationFrame&&(i=n.requestAnimationFrame(t)),i}}},{key:"_startRendering",value:function(){var t;!0===this.renderingActive&&(void 0===this.renderTimer&&(this.renderTimer=this._requestNextFrame(zn(t=this._renderStep).call(t,this),this.simulationInterval)))}},{key:"_renderStep",value:function(){!0===this.renderingActive&&(this.renderTimer=void 0,!0===this.requiresTimeout&&this._startRendering(),this._redraw(),!1===this.requiresTimeout&&this._startRendering())}},{key:"redraw",value:function(){this.body.emitter.emit("setSize"),this._redraw()}},{key:"_requestRedraw",value:function(){var t=this;!0!==this.redrawRequested&&!1===this.renderingActive&&!0===this.allowRedraw&&(this.redrawRequested=!0,this._requestNextFrame((function(){t._redraw(!1)}),0))}},{key:"_redraw",value:function(){var t=arguments.length>0&&void 0!==arguments[0]&&arguments[0];if(!0===this.allowRedraw){this.body.emitter.emit("initRedraw"),this.redrawRequested=!1;var e={drawExternalLabels:null};0!==this.canvas.frame.canvas.width&&0!==this.canvas.frame.canvas.height||this.canvas.setSize(),this.canvas.setTransform();var i=this.canvas.getContext(),n=this.canvas.frame.canvas.clientWidth,o=this.canvas.frame.canvas.clientHeight;if(i.clearRect(0,0,n,o),0===this.canvas.frame.clientWidth)return;if(i.save(),i.translate(this.body.view.translation.x,this.body.view.translation.y),i.scale(this.body.view.scale,this.body.view.scale),i.beginPath(),this.body.emitter.emit("beforeDrawing",i),i.closePath(),!1===t&&(!1===this.dragging||!0===this.dragging&&!1===this.options.hideEdgesOnDrag)&&(!1===this.zooming||!0===this.zooming&&!1===this.options.hideEdgesOnZoom)&&this._drawEdges(i),!1===this.dragging||!0===this.dragging&&!1===this.options.hideNodesOnDrag){var r=this._drawNodes(i,t),s=r.drawExternalLabels;e.drawExternalLabels=s}!1===t&&(!1===this.dragging||!0===this.dragging&&!1===this.options.hideEdgesOnDrag)&&(!1===this.zooming||!0===this.zooming&&!1===this.options.hideEdgesOnZoom)&&this._drawArrows(i),null!=e.drawExternalLabels&&e.drawExternalLabels(),!1===t&&this._drawSelectionBox(i),i.beginPath(),this.body.emitter.emit("afterDrawing",i),i.closePath(),i.restore(),!0===t&&i.clearRect(0,0,n,o)}}},{key:"_resizeNodes",value:function(){this.canvas.setTransform();var t=this.canvas.getContext();t.save(),t.translate(this.body.view.translation.x,this.body.view.translation.y),t.scale(this.body.view.scale,this.body.view.scale);var e,i=this.body.nodes;for(var n in i)Object.prototype.hasOwnProperty.call(i,n)&&((e=i[n]).resize(t),e.updateBoundingBox(t,e.selected));t.restore()}},{key:"_drawNodes",value:function(t){for(var e,i,n=arguments.length>1&&void 0!==arguments[1]&&arguments[1],o=this.body.nodes,r=this.body.nodeIndices,s=[],a=[],h=20,l=this.canvas.DOMtoCanvas({x:-h,y:-h}),d=this.canvas.DOMtoCanvas({x:this.canvas.frame.canvas.clientWidth+h,y:this.canvas.frame.canvas.clientHeight+h}),c={top:l.y,left:l.x,bottom:d.y,right:d.x},u=[],f=0;f<r.length;f++)if((e=o[r[f]]).hover)a.push(r[f]);else if(e.isSelected())s.push(r[f]);else if(!0===n){var p=e.draw(t);null!=p.drawExternalLabel&&u.push(p.drawExternalLabel)}else if(!0===e.isBoundingBoxOverlappingWith(c)){var v=e.draw(t);null!=v.drawExternalLabel&&u.push(v.drawExternalLabel)}else e.updateBoundingBox(t,e.selected);var g=s.length,y=a.length;for(i=0;i<g;i++){var m=(e=o[s[i]]).draw(t);null!=m.drawExternalLabel&&u.push(m.drawExternalLabel)}for(i=0;i<y;i++){var b=(e=o[a[i]]).draw(t);null!=b.drawExternalLabel&&u.push(b.drawExternalLabel)}return{drawExternalLabels:function(){var t,e=TC(u);try{for(e.s();!(t=e.n()).done;){(0,t.value)()}}catch(t){e.e(t)}finally{e.f()}}}}},{key:"_drawEdges",value:function(t){for(var e=this.body.edges,i=this.body.edgeIndices,n=0;n<i.length;n++){var o=e[i[n]];!0===o.connected&&o.draw(t)}}},{key:"_drawArrows",value:function(t){for(var e=this.body.edges,i=this.body.edgeIndices,n=0;n<i.length;n++){var o=e[i[n]];!0===o.connected&&o.drawArrows(t)}}},{key:"_determineBrowserMethod",value:function(){if("undefined"!=typeof window){var t=navigator.userAgent.toLowerCase();this.requiresTimeout=!1,(-1!=Fp(t).call(t,"msie 9.0")||-1!=Fp(t).call(t,"safari")&&Fp(t).call(t,"chrome")<=-1)&&(this.requiresTimeout=!0)}else this.requiresTimeout=!0}},{key:"_drawSelectionBox",value:function(t){if(this.body.selectionBox.show){t.beginPath();var e=this.body.selectionBox.position.end.x-this.body.selectionBox.position.start.x,i=this.body.selectionBox.position.end.y-this.body.selectionBox.position.start.y;t.rect(this.body.selectionBox.position.start.x,this.body.selectionBox.position.start.y,e,i),t.fillStyle="rgba(151, 194, 252, 0.2)",t.fillRect(this.body.selectionBox.position.start.x,this.body.selectionBox.position.start.y,e,i),t.strokeStyle="rgba(151, 194, 252, 1)",t.stroke()}else t.closePath()}}]),t}(),DC=X.setInterval;function IC(t,e){e.inputHandler=function(t){t.isFirst&&e(t)},t.on("hammer.input",e.inputHandler)}function BC(t,e){return e.inputHandler=function(t){t.isFinal&&e(t)},t.on("hammer.input",e.inputHandler)}var zC=function(){function t(e){Yd(this,t),this.body=e,this.pixelRatio=1,this.cameraState={},this.initialized=!1,this.canvasViewCenter={},this._cleanupCallbacks=[],this.options={},this.defaultOptions={autoResize:!0,height:"100%",width:"100%"},un(this.options,this.defaultOptions),this.bindEventListeners()}return Kd(t,[{key:"bindEventListeners",value:function(){var t,e=this;this.body.emitter.once("resize",(function(t){0!==t.width&&(e.body.view.translation.x=.5*t.width),0!==t.height&&(e.body.view.translation.y=.5*t.height)})),this.body.emitter.on("setSize",zn(t=this.setSize).call(t,this)),this.body.emitter.on("destroy",(function(){e.hammerFrame.destroy(),e.hammer.destroy(),e._cleanUp()}))}},{key:"setOptions",value:function(t){var e=this;if(void 0!==t){em(["width","height","autoResize"],this.options,t)}if(this._cleanUp(),!0===this.options.autoResize){var i;if(window.ResizeObserver){var n=new ResizeObserver((function(){!0===e.setSize()&&e.body.emitter.emit("_requestRedraw")})),o=this.frame;n.observe(o),this._cleanupCallbacks.push((function(){n.unobserve(o)}))}else{var r=DC((function(){!0===e.setSize()&&e.body.emitter.emit("_requestRedraw")}),1e3);this._cleanupCallbacks.push((function(){clearInterval(r)}))}var s=zn(i=this._onResize).call(i,this);dm(window,"resize",s),this._cleanupCallbacks.push((function(){cm(window,"resize",s)}))}}},{key:"_cleanUp",value:function(){var t,e,i;Fu(t=Yu(e=ff(i=this._cleanupCallbacks).call(i,0)).call(e)).call(t,(function(t){try{t()}catch(t){console.error(t)}}))}},{key:"_onResize",value:function(){this.setSize(),this.body.emitter.emit("_redraw")}},{key:"_getCameraState",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.pixelRatio;!0===this.initialized&&(this.cameraState.previousWidth=this.frame.canvas.width/t,this.cameraState.previousHeight=this.frame.canvas.height/t,this.cameraState.scale=this.body.view.scale,this.cameraState.position=this.DOMtoCanvas({x:.5*this.frame.canvas.width/t,y:.5*this.frame.canvas.height/t}))}},{key:"_setCameraState",value:function(){if(void 0!==this.cameraState.scale&&0!==this.frame.canvas.clientWidth&&0!==this.frame.canvas.clientHeight&&0!==this.pixelRatio&&this.cameraState.previousWidth>0&&this.cameraState.previousHeight>0){var t=this.frame.canvas.width/this.pixelRatio/this.cameraState.previousWidth,e=this.frame.canvas.height/this.pixelRatio/this.cameraState.previousHeight,i=this.cameraState.scale;1!=t&&1!=e?i=.5*this.cameraState.scale*(t+e):1!=t?i=this.cameraState.scale*t:1!=e&&(i=this.cameraState.scale*e),this.body.view.scale=i;var n=this.DOMtoCanvas({x:.5*this.frame.canvas.clientWidth,y:.5*this.frame.canvas.clientHeight}),o={x:n.x-this.cameraState.position.x,y:n.y-this.cameraState.position.y};this.body.view.translation.x+=o.x*this.body.view.scale,this.body.view.translation.y+=o.y*this.body.view.scale}}},{key:"_prepareValue",value:function(t){if("number"==typeof t)return t+"px";if("string"==typeof t){if(-1!==Fp(t).call(t,"%")||-1!==Fp(t).call(t,"px"))return t;if(-1===Fp(t).call(t,"%"))return t+"px"}throw new Error("Could not use the value supplied for width or height:"+t)}},{key:"_create",value:function(){for(;this.body.container.hasChildNodes();)this.body.container.removeChild(this.body.container.firstChild);if(this.frame=document.createElement("div"),this.frame.className="vis-network",this.frame.style.position="relative",this.frame.style.overflow="hidden",this.frame.tabIndex=0,this.frame.canvas=document.createElement("canvas"),this.frame.canvas.style.position="relative",this.frame.appendChild(this.frame.canvas),this.frame.canvas.getContext)this._setPixelRatio(),this.setTransform();else{var t=document.createElement("DIV");t.style.color="red",t.style.fontWeight="bold",t.style.padding="10px",t.innerText="Error: your browser does not support HTML canvas",this.frame.canvas.appendChild(t)}this.body.container.appendChild(this.frame),this.body.view.scale=1,this.body.view.translation={x:.5*this.frame.canvas.clientWidth,y:.5*this.frame.canvas.clientHeight},this._bindHammer()}},{key:"_bindHammer",value:function(){var t=this;void 0!==this.hammer&&this.hammer.destroy(),this.drag={},this.pinch={},this.hammer=new Wm(this.frame.canvas),this.hammer.get("pinch").set({enable:!0}),this.hammer.get("pan").set({threshold:5,direction:Wm.DIRECTION_ALL}),IC(this.hammer,(function(e){t.body.eventListeners.onTouch(e)})),this.hammer.on("tap",(function(e){t.body.eventListeners.onTap(e)})),this.hammer.on("doubletap",(function(e){t.body.eventListeners.onDoubleTap(e)})),this.hammer.on("press",(function(e){t.body.eventListeners.onHold(e)})),this.hammer.on("panstart",(function(e){t.body.eventListeners.onDragStart(e)})),this.hammer.on("panmove",(function(e){t.body.eventListeners.onDrag(e)})),this.hammer.on("panend",(function(e){t.body.eventListeners.onDragEnd(e)})),this.hammer.on("pinch",(function(e){t.body.eventListeners.onPinch(e)})),this.frame.canvas.addEventListener("wheel",(function(e){t.body.eventListeners.onMouseWheel(e)})),this.frame.canvas.addEventListener("mousemove",(function(e){t.body.eventListeners.onMouseMove(e)})),this.frame.canvas.addEventListener("contextmenu",(function(e){t.body.eventListeners.onContext(e)})),this.hammerFrame=new Wm(this.frame),BC(this.hammerFrame,(function(e){t.body.eventListeners.onRelease(e)}))}},{key:"setSize",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.width,e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.height;t=this._prepareValue(t),e=this._prepareValue(e);var i=!1,n=this.frame.canvas.width,o=this.frame.canvas.height,r=this.pixelRatio;if(this._setPixelRatio(),t!=this.options.width||e!=this.options.height||this.frame.style.width!=t||this.frame.style.height!=e)this._getCameraState(r),this.frame.style.width=t,this.frame.style.height=e,this.frame.canvas.style.width="100%",this.frame.canvas.style.height="100%",this.frame.canvas.width=Math.round(this.frame.canvas.clientWidth*this.pixelRatio),this.frame.canvas.height=Math.round(this.frame.canvas.clientHeight*this.pixelRatio),this.options.width=t,this.options.height=e,this.canvasViewCenter={x:.5*this.frame.clientWidth,y:.5*this.frame.clientHeight},i=!0;else{var s=Math.round(this.frame.canvas.clientWidth*this.pixelRatio),a=Math.round(this.frame.canvas.clientHeight*this.pixelRatio);this.frame.canvas.width===s&&this.frame.canvas.height===a||this._getCameraState(r),this.frame.canvas.width!==s&&(this.frame.canvas.width=s,i=!0),this.frame.canvas.height!==a&&(this.frame.canvas.height=a,i=!0)}return!0===i&&(this.body.emitter.emit("resize",{width:Math.round(this.frame.canvas.width/this.pixelRatio),height:Math.round(this.frame.canvas.height/this.pixelRatio),oldWidth:Math.round(n/this.pixelRatio),oldHeight:Math.round(o/this.pixelRatio)}),this._setCameraState()),this.initialized=!0,i}},{key:"getContext",value:function(){return this.frame.canvas.getContext("2d")}},{key:"_determinePixelRatio",value:function(){var t=this.getContext();if(void 0===t)throw new Error("Could not get canvax context");var e=1;return"undefined"!=typeof window&&(e=window.devicePixelRatio||1),e/(t.webkitBackingStorePixelRatio||t.mozBackingStorePixelRatio||t.msBackingStorePixelRatio||t.oBackingStorePixelRatio||t.backingStorePixelRatio||1)}},{key:"_setPixelRatio",value:function(){this.pixelRatio=this._determinePixelRatio()}},{key:"setTransform",value:function(){var t=this.getContext();if(void 0===t)throw new Error("Could not get canvax context");t.setTransform(this.pixelRatio,0,0,this.pixelRatio,0,0)}},{key:"_XconvertDOMtoCanvas",value:function(t){return(t-this.body.view.translation.x)/this.body.view.scale}},{key:"_XconvertCanvasToDOM",value:function(t){return t*this.body.view.scale+this.body.view.translation.x}},{key:"_YconvertDOMtoCanvas",value:function(t){return(t-this.body.view.translation.y)/this.body.view.scale}},{key:"_YconvertCanvasToDOM",value:function(t){return t*this.body.view.scale+this.body.view.translation.y}},{key:"canvasToDOM",value:function(t){return{x:this._XconvertCanvasToDOM(t.x),y:this._YconvertCanvasToDOM(t.y)}}},{key:"DOMtoCanvas",value:function(t){return{x:this._XconvertDOMtoCanvas(t.x),y:this._YconvertDOMtoCanvas(t.y)}}}]),t}();function NC(t,e){var i=un({nodes:e,minZoomLevel:Number.MIN_VALUE,maxZoomLevel:1},null!=t?t:{});if(!lu(i.nodes))throw new TypeError("Nodes has to be an array of ids.");if(0===i.nodes.length&&(i.nodes=e),!("number"==typeof i.minZoomLevel&&i.minZoomLevel>0))throw new TypeError("Min zoom level has to be a number higher than zero.");if(!("number"==typeof i.maxZoomLevel&&i.minZoomLevel<=i.maxZoomLevel))throw new TypeError("Max zoom level has to be a number higher than min zoom level.");return i}var FC=function(){function t(e,i){var n,o,r=this;Yd(this,t),this.body=e,this.canvas=i,this.animationSpeed=1/this.renderRefreshRate,this.animationEasingFunction="easeInOutQuint",this.easingTime=0,this.sourceScale=0,this.targetScale=0,this.sourceTranslation=0,this.targetTranslation=0,this.lockedOnNodeId=void 0,this.lockedOnNodeOffset=void 0,this.touchTime=0,this.viewFunction=void 0,this.body.emitter.on("fit",zn(n=this.fit).call(n,this)),this.body.emitter.on("animationFinished",(function(){r.body.emitter.emit("_stopRendering")})),this.body.emitter.on("unlockNode",zn(o=this.releaseNode).call(o,this))}return Kd(t,[{key:"setOptions",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};this.options=t}},{key:"fit",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1];t=NC(t,this.body.nodeIndices);var i,n,o=this.canvas.frame.canvas.clientWidth,r=this.canvas.frame.canvas.clientHeight;if(0===o||0===r)n=1,i=EC.getRange(this.body.nodes,t.nodes);else if(!0===e){var s=0;for(var a in this.body.nodes)if(Object.prototype.hasOwnProperty.call(this.body.nodes,a)){var h=this.body.nodes[a];!0===h.predefinedPosition&&(s+=1)}if(s>.5*this.body.nodeIndices.length)return void this.fit(t,!1);i=EC.getRange(this.body.nodes,t.nodes);var l=this.body.nodeIndices.length;n=12.662/(l+7.4147)+.0964822;var d=Math.min(o/600,r/600);n*=d}else{this.body.emitter.emit("_resizeNodes"),i=EC.getRange(this.body.nodes,t.nodes);var c=1.1*Math.abs(i.maxX-i.minX),u=1.1*Math.abs(i.maxY-i.minY),f=o/c,p=r/u;n=f<=p?f:p}n>t.maxZoomLevel?n=t.maxZoomLevel:n<t.minZoomLevel&&(n=t.minZoomLevel);var v=EC.findCenter(i),g={position:v,scale:n,animation:t.animation};this.moveTo(g)}},{key:"focus",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};if(void 0!==this.body.nodes[t]){var i={x:this.body.nodes[t].x,y:this.body.nodes[t].y};e.position=i,e.lockedOnNode=t,this.moveTo(e)}else console.error("Node: "+t+" cannot be found.")}},{key:"moveTo",value:function(t){if(void 0!==t){if(null!=t.offset){if(null!=t.offset.x){if(t.offset.x=+t.offset.x,!ok(t.offset.x))throw new TypeError('The option "offset.x" has to be a finite number.')}else t.offset.x=0;if(null!=t.offset.y){if(t.offset.y=+t.offset.y,!ok(t.offset.y))throw new TypeError('The option "offset.y" has to be a finite number.')}else t.offset.x=0}else t.offset={x:0,y:0};if(null!=t.position){if(null!=t.position.x){if(t.position.x=+t.position.x,!ok(t.position.x))throw new TypeError('The option "position.x" has to be a finite number.')}else t.position.x=0;if(null!=t.position.y){if(t.position.y=+t.position.y,!ok(t.position.y))throw new TypeError('The option "position.y" has to be a finite number.')}else t.position.x=0}else t.position=this.getViewPosition();if(null!=t.scale){if(t.scale=+t.scale,!(t.scale>0))throw new TypeError('The option "scale" has to be a number greater than zero.')}else t.scale=this.body.view.scale;void 0===t.animation&&(t.animation={duration:0}),!1===t.animation&&(t.animation={duration:0}),!0===t.animation&&(t.animation={}),void 0===t.animation.duration&&(t.animation.duration=1e3),void 0===t.animation.easingFunction&&(t.animation.easingFunction="easeInOutQuad"),this.animateView(t)}else t={}}},{key:"animateView",value:function(t){if(void 0!==t){this.animationEasingFunction=t.animation.easingFunction,this.releaseNode(),!0===t.locked&&(this.lockedOnNodeId=t.lockedOnNode,this.lockedOnNodeOffset=t.offset),0!=this.easingTime&&this._transitionRedraw(!0),this.sourceScale=this.body.view.scale,this.sourceTranslation=this.body.view.translation,this.targetScale=t.scale,this.body.view.scale=this.targetScale;var e,i,n=this.canvas.DOMtoCanvas({x:.5*this.canvas.frame.canvas.clientWidth,y:.5*this.canvas.frame.canvas.clientHeight}),o=n.x-t.position.x,r=n.y-t.position.y;if(this.targetTranslation={x:this.sourceTranslation.x+o*this.targetScale+t.offset.x,y:this.sourceTranslation.y+r*this.targetScale+t.offset.y},0===t.animation.duration)if(null!=this.lockedOnNodeId)this.viewFunction=zn(e=this._lockedRedraw).call(e,this),this.body.emitter.on("initRedraw",this.viewFunction);else this.body.view.scale=this.targetScale,this.body.view.translation=this.targetTranslation,this.body.emitter.emit("_requestRedraw");else this.animationSpeed=1/(60*t.animation.duration*.001)||1/60,this.animationEasingFunction=t.animation.easingFunction,this.viewFunction=zn(i=this._transitionRedraw).call(i,this),this.body.emitter.on("initRedraw",this.viewFunction),this.body.emitter.emit("_startRendering")}}},{key:"_lockedRedraw",value:function(){var t=this.body.nodes[this.lockedOnNodeId].x,e=this.body.nodes[this.lockedOnNodeId].y,i=this.canvas.DOMtoCanvas({x:.5*this.canvas.frame.canvas.clientWidth,y:.5*this.canvas.frame.canvas.clientHeight}),n=i.x-t,o=i.y-e,r=this.body.view.translation,s={x:r.x+n*this.body.view.scale+this.lockedOnNodeOffset.x,y:r.y+o*this.body.view.scale+this.lockedOnNodeOffset.y};this.body.view.translation=s}},{key:"releaseNode",value:function(){void 0!==this.lockedOnNodeId&&void 0!==this.viewFunction&&(this.body.emitter.off("initRedraw",this.viewFunction),this.lockedOnNodeId=void 0,this.lockedOnNodeOffset=void 0)}},{key:"_transitionRedraw",value:function(){var t=arguments.length>0&&void 0!==arguments[0]&&arguments[0];this.easingTime+=this.animationSpeed,this.easingTime=!0===t?1:this.easingTime;var e=Tm[this.animationEasingFunction](this.easingTime);if(this.body.view.scale=this.sourceScale+(this.targetScale-this.sourceScale)*e,this.body.view.translation={x:this.sourceTranslation.x+(this.targetTranslation.x-this.sourceTranslation.x)*e,y:this.sourceTranslation.y+(this.targetTranslation.y-this.sourceTranslation.y)*e},this.easingTime>=1){var i;if(this.body.emitter.off("initRedraw",this.viewFunction),this.easingTime=0,null!=this.lockedOnNodeId)this.viewFunction=zn(i=this._lockedRedraw).call(i,this),this.body.emitter.on("initRedraw",this.viewFunction);this.body.emitter.emit("animationFinished")}}},{key:"getScale",value:function(){return this.body.view.scale}},{key:"getViewPosition",value:function(){return this.canvas.DOMtoCanvas({x:.5*this.canvas.frame.canvas.clientWidth,y:.5*this.canvas.frame.canvas.clientHeight})}}]),t}();function AC(t){var e,i=t&&t.preventDefault||!1,n=t&&t.container||window,o={},r={keydown:{},keyup:{}},s={};for(e=97;e<=122;e++)s[String.fromCharCode(e)]={code:e-97+65,shift:!1};for(e=65;e<=90;e++)s[String.fromCharCode(e)]={code:e,shift:!0};for(e=0;e<=9;e++)s[""+e]={code:48+e,shift:!1};for(e=1;e<=12;e++)s["F"+e]={code:111+e,shift:!1};for(e=0;e<=9;e++)s["num"+e]={code:96+e,shift:!1};s["num*"]={code:106,shift:!1},s["num+"]={code:107,shift:!1},s["num-"]={code:109,shift:!1},s["num/"]={code:111,shift:!1},s["num."]={code:110,shift:!1},s.left={code:37,shift:!1},s.up={code:38,shift:!1},s.right={code:39,shift:!1},s.down={code:40,shift:!1},s.space={code:32,shift:!1},s.enter={code:13,shift:!1},s.shift={code:16,shift:void 0},s.esc={code:27,shift:!1},s.backspace={code:8,shift:!1},s.tab={code:9,shift:!1},s.ctrl={code:17,shift:!1},s.alt={code:18,shift:!1},s.delete={code:46,shift:!1},s.pageup={code:33,shift:!1},s.pagedown={code:34,shift:!1},s["="]={code:187,shift:!1},s["-"]={code:189,shift:!1},s["]"]={code:221,shift:!1},s["["]={code:219,shift:!1};var a=function(t){l(t,"keydown")},h=function(t){l(t,"keyup")},l=function(t,e){if(void 0!==r[e][t.keyCode]){for(var n=r[e][t.keyCode],o=0;o<n.length;o++)(void 0===n[o].shift||1==n[o].shift&&1==t.shiftKey||0==n[o].shift&&0==t.shiftKey)&&n[o].fn(t);1==i&&t.preventDefault()}};return o.bind=function(t,e,i){if(void 0===i&&(i="keydown"),void 0===s[t])throw new Error("unsupported key: "+t);void 0===r[i][s[t].code]&&(r[i][s[t].code]=[]),r[i][s[t].code].push({fn:e,shift:s[t].shift})},o.bindAll=function(t,e){for(var i in void 0===e&&(e="keydown"),s)s.hasOwnProperty(i)&&o.bind(i,t,e)},o.getKey=function(t){for(var e in s)if(s.hasOwnProperty(e)){if(1==t.shiftKey&&1==s[e].shift&&t.keyCode==s[e].code)return e;if(0==t.shiftKey&&0==s[e].shift&&t.keyCode==s[e].code)return e;if(t.keyCode==s[e].code&&"shift"==e)return e}return"unknown key, currently not supported"},o.unbind=function(t,e,i){if(void 0===i&&(i="keydown"),void 0===s[t])throw new Error("unsupported key: "+t);if(void 0!==e){var n=[],o=r[i][s[t].code];if(void 0!==o)for(var a=0;a<o.length;a++)o[a].fn==e&&o[a].shift==s[t].shift||n.push(r[i][s[t].code][a]);r[i][s[t].code]=n}else r[i][s[t].code]=[]},o.reset=function(){r={keydown:{},keyup:{}}},o.destroy=function(){r={keydown:{},keyup:{}},n.removeEventListener("keydown",a,!0),n.removeEventListener("keyup",h,!0)},n.addEventListener("keydown",a,!0),n.addEventListener("keyup",h,!0),o}var jC=Object.freeze({__proto__:null,default:AC}),RC=function(){function t(e,i){var n=this;Yd(this,t),this.body=e,this.canvas=i,this.iconsCreated=!1,this.navigationHammers=[],this.boundFunctions={},this.touchTime=0,this.activated=!1,this.body.emitter.on("activate",(function(){n.activated=!0,n.configureKeyboardBindings()})),this.body.emitter.on("deactivate",(function(){n.activated=!1,n.configureKeyboardBindings()})),this.body.emitter.on("destroy",(function(){void 0!==n.keycharm&&n.keycharm.destroy()})),this.options={}}return Kd(t,[{key:"setOptions",value:function(t){void 0!==t&&(this.options=t,this.create())}},{key:"create",value:function(){!0===this.options.navigationButtons?!1===this.iconsCreated&&this.loadNavigationElements():!0===this.iconsCreated&&this.cleanNavigation(),this.configureKeyboardBindings()}},{key:"cleanNavigation",value:function(){if(0!=this.navigationHammers.length){for(var t=0;t<this.navigationHammers.length;t++)this.navigationHammers[t].destroy();this.navigationHammers=[]}this.navigationDOM&&this.navigationDOM.wrapper&&this.navigationDOM.wrapper.parentNode&&this.navigationDOM.wrapper.parentNode.removeChild(this.navigationDOM.wrapper),this.iconsCreated=!1}},{key:"loadNavigationElements",value:function(){var t=this;this.cleanNavigation(),this.navigationDOM={};var e=["up","down","left","right","zoomIn","zoomOut","zoomExtends"],i=["_moveUp","_moveDown","_moveLeft","_moveRight","_zoomIn","_zoomOut","_fit"];this.navigationDOM.wrapper=document.createElement("div"),this.navigationDOM.wrapper.className="vis-navigation",this.canvas.frame.appendChild(this.navigationDOM.wrapper);for(var n=0;n<e.length;n++){this.navigationDOM[e[n]]=document.createElement("div"),this.navigationDOM[e[n]].className="vis-button vis-"+e[n],this.navigationDOM.wrapper.appendChild(this.navigationDOM[e[n]]);var o,r,s=new Wm(this.navigationDOM[e[n]]);if("_fit"===i[n])IC(s,zn(o=this._fit).call(o,this));else IC(s,zn(r=this.bindToRedraw).call(r,this,i[n]));this.navigationHammers.push(s)}var a=new Wm(this.canvas.frame);BC(a,(function(){t._stopMovement()})),this.navigationHammers.push(a),this.iconsCreated=!0}},{key:"bindToRedraw",value:function(t){var e;void 0===this.boundFunctions[t]&&(this.boundFunctions[t]=zn(e=this[t]).call(e,this),this.body.emitter.on("initRedraw",this.boundFunctions[t]),this.body.emitter.emit("_startRendering"))}},{key:"unbindFromRedraw",value:function(t){void 0!==this.boundFunctions[t]&&(this.body.emitter.off("initRedraw",this.boundFunctions[t]),this.body.emitter.emit("_stopRendering"),delete this.boundFunctions[t])}},{key:"_fit",value:function(){(new Date).valueOf()-this.touchTime>700&&(this.body.emitter.emit("fit",{duration:700}),this.touchTime=(new Date).valueOf())}},{key:"_stopMovement",value:function(){for(var t in this.boundFunctions)Object.prototype.hasOwnProperty.call(this.boundFunctions,t)&&(this.body.emitter.off("initRedraw",this.boundFunctions[t]),this.body.emitter.emit("_stopRendering"));this.boundFunctions={}}},{key:"_moveUp",value:function(){this.body.view.translation.y+=this.options.keyboard.speed.y}},{key:"_moveDown",value:function(){this.body.view.translation.y-=this.options.keyboard.speed.y}},{key:"_moveLeft",value:function(){this.body.view.translation.x+=this.options.keyboard.speed.x}},{key:"_moveRight",value:function(){this.body.view.translation.x-=this.options.keyboard.speed.x}},{key:"_zoomIn",value:function(){var t=this.body.view.scale,e=this.body.view.scale*(1+this.options.keyboard.speed.zoom),i=this.body.view.translation,n=e/t,o=(1-n)*this.canvas.canvasViewCenter.x+i.x*n,r=(1-n)*this.canvas.canvasViewCenter.y+i.y*n;this.body.view.scale=e,this.body.view.translation={x:o,y:r},this.body.emitter.emit("zoom",{direction:"+",scale:this.body.view.scale,pointer:null})}},{key:"_zoomOut",value:function(){var t=this.body.view.scale,e=this.body.view.scale/(1+this.options.keyboard.speed.zoom),i=this.body.view.translation,n=e/t,o=(1-n)*this.canvas.canvasViewCenter.x+i.x*n,r=(1-n)*this.canvas.canvasViewCenter.y+i.y*n;this.body.view.scale=e,this.body.view.translation={x:o,y:r},this.body.emitter.emit("zoom",{direction:"-",scale:this.body.view.scale,pointer:null})}},{key:"configureKeyboardBindings",value:function(){var t,e,i,n,o,r,s,a,h,l,d,c,u,f,p,v,g,y,m,b,w,k,_,x,E=this;(void 0!==this.keycharm&&this.keycharm.destroy(),!0===this.options.keyboard.enabled)&&(!0===this.options.keyboard.bindToWindow?this.keycharm=AC({container:window,preventDefault:!0}):this.keycharm=AC({container:this.canvas.frame,preventDefault:!0}),this.keycharm.reset(),!0===this.activated&&(zn(t=this.keycharm).call(t,"up",(function(){E.bindToRedraw("_moveUp")}),"keydown"),zn(e=this.keycharm).call(e,"down",(function(){E.bindToRedraw("_moveDown")}),"keydown"),zn(i=this.keycharm).call(i,"left",(function(){E.bindToRedraw("_moveLeft")}),"keydown"),zn(n=this.keycharm).call(n,"right",(function(){E.bindToRedraw("_moveRight")}),"keydown"),zn(o=this.keycharm).call(o,"=",(function(){E.bindToRedraw("_zoomIn")}),"keydown"),zn(r=this.keycharm).call(r,"num+",(function(){E.bindToRedraw("_zoomIn")}),"keydown"),zn(s=this.keycharm).call(s,"num-",(function(){E.bindToRedraw("_zoomOut")}),"keydown"),zn(a=this.keycharm).call(a,"-",(function(){E.bindToRedraw("_zoomOut")}),"keydown"),zn(h=this.keycharm).call(h,"[",(function(){E.bindToRedraw("_zoomOut")}),"keydown"),zn(l=this.keycharm).call(l,"]",(function(){E.bindToRedraw("_zoomIn")}),"keydown"),zn(d=this.keycharm).call(d,"pageup",(function(){E.bindToRedraw("_zoomIn")}),"keydown"),zn(c=this.keycharm).call(c,"pagedown",(function(){E.bindToRedraw("_zoomOut")}),"keydown"),zn(u=this.keycharm).call(u,"up",(function(){E.unbindFromRedraw("_moveUp")}),"keyup"),zn(f=this.keycharm).call(f,"down",(function(){E.unbindFromRedraw("_moveDown")}),"keyup"),zn(p=this.keycharm).call(p,"left",(function(){E.unbindFromRedraw("_moveLeft")}),"keyup"),zn(v=this.keycharm).call(v,"right",(function(){E.unbindFromRedraw("_moveRight")}),"keyup"),zn(g=this.keycharm).call(g,"=",(function(){E.unbindFromRedraw("_zoomIn")}),"keyup"),zn(y=this.keycharm).call(y,"num+",(function(){E.unbindFromRedraw("_zoomIn")}),"keyup"),zn(m=this.keycharm).call(m,"num-",(function(){E.unbindFromRedraw("_zoomOut")}),"keyup"),zn(b=this.keycharm).call(b,"-",(function(){E.unbindFromRedraw("_zoomOut")}),"keyup"),zn(w=this.keycharm).call(w,"[",(function(){E.unbindFromRedraw("_zoomOut")}),"keyup"),zn(k=this.keycharm).call(k,"]",(function(){E.unbindFromRedraw("_zoomIn")}),"keyup"),zn(_=this.keycharm).call(_,"pageup",(function(){E.unbindFromRedraw("_zoomIn")}),"keyup"),zn(x=this.keycharm).call(x,"pagedown",(function(){E.unbindFromRedraw("_zoomOut")}),"keyup")))}}]),t}();function LC(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return HC(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return HC(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function HC(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}var WC=function(){function t(e,i,n){var o,r,s,a,h,l,d,c,u,f,p,v,g;Yd(this,t),this.body=e,this.canvas=i,this.selectionHandler=n,this.navigationHandler=new RC(e,i),this.body.eventListeners.onTap=zn(o=this.onTap).call(o,this),this.body.eventListeners.onTouch=zn(r=this.onTouch).call(r,this),this.body.eventListeners.onDoubleTap=zn(s=this.onDoubleTap).call(s,this),this.body.eventListeners.onHold=zn(a=this.onHold).call(a,this),this.body.eventListeners.onDragStart=zn(h=this.onDragStart).call(h,this),this.body.eventListeners.onDrag=zn(l=this.onDrag).call(l,this),this.body.eventListeners.onDragEnd=zn(d=this.onDragEnd).call(d,this),this.body.eventListeners.onMouseWheel=zn(c=this.onMouseWheel).call(c,this),this.body.eventListeners.onPinch=zn(u=this.onPinch).call(u,this),this.body.eventListeners.onMouseMove=zn(f=this.onMouseMove).call(f,this),this.body.eventListeners.onRelease=zn(p=this.onRelease).call(p,this),this.body.eventListeners.onContext=zn(v=this.onContext).call(v,this),this.touchTime=0,this.drag={},this.pinch={},this.popup=void 0,this.popupObj=void 0,this.popupTimer=void 0,this.body.functions.getPointer=zn(g=this.getPointer).call(g,this),this.options={},this.defaultOptions={dragNodes:!0,dragView:!0,hover:!1,keyboard:{enabled:!1,speed:{x:10,y:10,zoom:.02},bindToWindow:!0,autoFocus:!0},navigationButtons:!1,tooltipDelay:300,zoomView:!0,zoomSpeed:1},un(this.options,this.defaultOptions),this.bindEventListeners()}return Kd(t,[{key:"bindEventListeners",value:function(){var t=this;this.body.emitter.on("destroy",(function(){clearTimeout(t.popupTimer),delete t.body.functions.getPointer}))}},{key:"setOptions",value:function(t){if(void 0!==t){im(["hideEdgesOnDrag","hideEdgesOnZoom","hideNodesOnDrag","keyboard","multiselect","selectable","selectConnectedEdges"],this.options,t),Sm(this.options,t,"keyboard"),t.tooltip&&(un(this.options.tooltip,t.tooltip),t.tooltip.color&&(this.options.tooltip.color=gm(t.tooltip.color)))}this.navigationHandler.setOptions(this.options)}},{key:"getPointer",value:function(t){return{x:t.x-sm(this.canvas.frame.canvas),y:t.y-am(this.canvas.frame.canvas)}}},{key:"onTouch",value:function(t){(new Date).valueOf()-this.touchTime>50&&(this.drag.pointer=this.getPointer(t.center),this.drag.pinched=!1,this.pinch.scale=this.body.view.scale,this.touchTime=(new Date).valueOf())}},{key:"onTap",value:function(t){var e=this.getPointer(t.center),i=this.selectionHandler.options.multiselect&&(t.changedPointers[0].ctrlKey||t.changedPointers[0].metaKey);this.checkSelectionChanges(e,i),this.selectionHandler.commitAndEmit(e,t),this.selectionHandler.generateClickEvent("click",t,e)}},{key:"onDoubleTap",value:function(t){var e=this.getPointer(t.center);this.selectionHandler.generateClickEvent("doubleClick",t,e)}},{key:"onHold",value:function(t){var e=this.getPointer(t.center),i=this.selectionHandler.options.multiselect;this.checkSelectionChanges(e,i),this.selectionHandler.commitAndEmit(e,t),this.selectionHandler.generateClickEvent("click",t,e),this.selectionHandler.generateClickEvent("hold",t,e)}},{key:"onRelease",value:function(t){if((new Date).valueOf()-this.touchTime>10){var e=this.getPointer(t.center);this.selectionHandler.generateClickEvent("release",t,e),this.touchTime=(new Date).valueOf()}}},{key:"onContext",value:function(t){var e=this.getPointer({x:t.clientX,y:t.clientY});this.selectionHandler.generateClickEvent("oncontext",t,e)}},{key:"checkSelectionChanges",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1];!0===e?this.selectionHandler.selectAdditionalOnPoint(t):this.selectionHandler.selectOnPoint(t)}},{key:"_determineDifference",value:function(t,e){var i=function(t,e){for(var i=[],n=0;n<t.length;n++){var o=t[n];-1===Fp(e).call(e,o)&&i.push(o)}return i};return{nodes:i(t.nodes,e.nodes),edges:i(t.edges,e.edges)}}},{key:"onDragStart",value:function(t){if(!this.drag.dragging){void 0===this.drag.pointer&&this.onTouch(t);var e=this.selectionHandler.getNodeAt(this.drag.pointer);if(this.drag.dragging=!0,this.drag.selection=[],this.drag.translation=un({},this.body.view.translation),this.drag.nodeId=void 0,t.srcEvent.shiftKey){this.body.selectionBox.show=!0;var i=this.getPointer(t.center);this.body.selectionBox.position.start={x:this.canvas._XconvertDOMtoCanvas(i.x),y:this.canvas._YconvertDOMtoCanvas(i.y)},this.body.selectionBox.position.end={x:this.canvas._XconvertDOMtoCanvas(i.x),y:this.canvas._YconvertDOMtoCanvas(i.y)}}if(void 0!==e&&!0===this.options.dragNodes){this.drag.nodeId=e.id,!1===e.isSelected()&&this.selectionHandler.setSelection({nodes:[e.id]}),this.selectionHandler.generateClickEvent("dragStart",t,this.drag.pointer);var n,o=LC(this.selectionHandler.getSelectedNodes());try{for(o.s();!(n=o.n()).done;){var r=n.value,s={id:r.id,node:r,x:r.x,y:r.y,xFixed:r.options.fixed.x,yFixed:r.options.fixed.y};r.options.fixed.x=!0,r.options.fixed.y=!0,this.drag.selection.push(s)}}catch(t){o.e(t)}finally{o.f()}}else this.selectionHandler.generateClickEvent("dragStart",t,this.drag.pointer,void 0,!0)}}},{key:"onDrag",value:function(t){var e=this;if(!0!==this.drag.pinched){this.body.emitter.emit("unlockNode");var i=this.getPointer(t.center),n=this.drag.selection;if(n&&n.length&&!0===this.options.dragNodes){this.selectionHandler.generateClickEvent("dragging",t,i);var o=i.x-this.drag.pointer.x,r=i.y-this.drag.pointer.y;Fu(n).call(n,(function(t){var i=t.node;!1===t.xFixed&&(i.x=e.canvas._XconvertDOMtoCanvas(e.canvas._XconvertCanvasToDOM(t.x)+o)),!1===t.yFixed&&(i.y=e.canvas._YconvertDOMtoCanvas(e.canvas._YconvertCanvasToDOM(t.y)+r))})),this.body.emitter.emit("startSimulation")}else{if(t.srcEvent.shiftKey){if(this.selectionHandler.generateClickEvent("dragging",t,i,void 0,!0),void 0===this.drag.pointer)return void this.onDragStart(t);this.body.selectionBox.position.end={x:this.canvas._XconvertDOMtoCanvas(i.x),y:this.canvas._YconvertDOMtoCanvas(i.y)},this.body.emitter.emit("_requestRedraw")}if(!0===this.options.dragView&&!t.srcEvent.shiftKey){if(this.selectionHandler.generateClickEvent("dragging",t,i,void 0,!0),void 0===this.drag.pointer)return void this.onDragStart(t);var s=i.x-this.drag.pointer.x,a=i.y-this.drag.pointer.y;this.body.view.translation={x:this.drag.translation.x+s,y:this.drag.translation.y+a},this.body.emitter.emit("_requestRedraw")}}}}},{key:"onDragEnd",value:function(t){var e=this;if(this.drag.dragging=!1,this.body.selectionBox.show){var i;this.body.selectionBox.show=!1;var n=this.body.selectionBox.position,o={minX:Math.min(n.start.x,n.end.x),minY:Math.min(n.start.y,n.end.y),maxX:Math.max(n.start.x,n.end.x),maxY:Math.max(n.start.y,n.end.y)},r=Xf(i=this.body.nodeIndices).call(i,(function(t){var i=e.body.nodes[t];return i.x>=o.minX&&i.x<=o.maxX&&i.y>=o.minY&&i.y<=o.maxY}));Fu(r).call(r,(function(t){return e.selectionHandler.selectObject(e.body.nodes[t])}));var s=this.getPointer(t.center);this.selectionHandler.commitAndEmit(s,t),this.selectionHandler.generateClickEvent("dragEnd",t,this.getPointer(t.center),void 0,!0),this.body.emitter.emit("_requestRedraw")}else{var a=this.drag.selection;a&&a.length?(Fu(a).call(a,(function(t){t.node.options.fixed.x=t.xFixed,t.node.options.fixed.y=t.yFixed})),this.selectionHandler.generateClickEvent("dragEnd",t,this.getPointer(t.center)),this.body.emitter.emit("startSimulation")):(this.selectionHandler.generateClickEvent("dragEnd",t,this.getPointer(t.center),void 0,!0),this.body.emitter.emit("_requestRedraw"))}}},{key:"onPinch",value:function(t){var e=this.getPointer(t.center);this.drag.pinched=!0,void 0===this.pinch.scale&&(this.pinch.scale=1);var i=this.pinch.scale*t.scale;this.zoom(i,e)}},{key:"zoom",value:function(t,e){if(!0===this.options.zoomView){var i=this.body.view.scale;t<1e-5&&(t=1e-5),t>10&&(t=10);var n=void 0;void 0!==this.drag&&!0===this.drag.dragging&&(n=this.canvas.DOMtoCanvas(this.drag.pointer));var o=this.body.view.translation,r=t/i,s=(1-r)*e.x+o.x*r,a=(1-r)*e.y+o.y*r;if(this.body.view.scale=t,this.body.view.translation={x:s,y:a},null!=n){var h=this.canvas.canvasToDOM(n);this.drag.pointer.x=h.x,this.drag.pointer.y=h.y}this.body.emitter.emit("_requestRedraw"),i<t?this.body.emitter.emit("zoom",{direction:"+",scale:this.body.view.scale,pointer:e}):this.body.emitter.emit("zoom",{direction:"-",scale:this.body.view.scale,pointer:e})}}},{key:"onMouseWheel",value:function(t){if(!0===this.options.zoomView){if(0!==t.deltaY){var e=this.body.view.scale;e*=1+(t.deltaY<0?1:-1)*(.1*this.options.zoomSpeed);var i=this.getPointer({x:t.clientX,y:t.clientY});this.zoom(e,i)}t.preventDefault()}}},{key:"onMouseMove",value:function(t){var e=this,i=this.getPointer({x:t.clientX,y:t.clientY}),n=!1;void 0!==this.popup&&(!1===this.popup.hidden&&this._checkHidePopup(i),!1===this.popup.hidden&&(n=!0,this.popup.setPosition(i.x+3,i.y-5),this.popup.show())),this.options.keyboard.autoFocus&&!1===this.options.keyboard.bindToWindow&&!0===this.options.keyboard.enabled&&this.canvas.frame.focus(),!1===n&&(void 0!==this.popupTimer&&(clearInterval(this.popupTimer),this.popupTimer=void 0),this.drag.dragging||(this.popupTimer=Sv((function(){return e._checkShowPopup(i)}),this.options.tooltipDelay))),!0===this.options.hover&&this.selectionHandler.hoverObject(t,i)}},{key:"_checkShowPopup",value:function(t){var e=this.canvas._XconvertDOMtoCanvas(t.x),i=this.canvas._YconvertDOMtoCanvas(t.y),n={left:e,top:i,right:e,bottom:i},o=void 0===this.popupObj?void 0:this.popupObj.id,r=!1,s="node";if(void 0===this.popupObj){for(var a,h=this.body.nodeIndices,l=this.body.nodes,d=[],c=0;c<h.length;c++)!0===(a=l[h[c]]).isOverlappingWith(n)&&(r=!0,void 0!==a.getTitle()&&d.push(h[c]));d.length>0&&(this.popupObj=l[d[d.length-1]],r=!0)}if(void 0===this.popupObj&&!1===r){for(var u,f=this.body.edgeIndices,p=this.body.edges,v=[],g=0;g<f.length;g++)!0===(u=p[f[g]]).isOverlappingWith(n)&&!0===u.connected&&void 0!==u.getTitle()&&v.push(f[g]);v.length>0&&(this.popupObj=p[v[v.length-1]],s="edge")}void 0!==this.popupObj?this.popupObj.id!==o&&(void 0===this.popup&&(this.popup=new qm(this.canvas.frame)),this.popup.popupTargetType=s,this.popup.popupTargetId=this.popupObj.id,this.popup.setPosition(t.x+3,t.y-5),this.popup.setText(this.popupObj.getTitle()),this.popup.show(),this.body.emitter.emit("showPopup",this.popupObj.id)):void 0!==this.popup&&(this.popup.hide(),this.body.emitter.emit("hidePopup"))}},{key:"_checkHidePopup",value:function(t){var e=this.selectionHandler._pointerToPositionObject(t),i=!1;if("node"===this.popup.popupTargetType){if(void 0!==this.body.nodes[this.popup.popupTargetId]&&!0===(i=this.body.nodes[this.popup.popupTargetId].isOverlappingWith(e))){var n=this.selectionHandler.getNodeAt(t);i=void 0!==n&&n.id===this.popup.popupTargetId}}else void 0===this.selectionHandler.getNodeAt(t)&&void 0!==this.body.edges[this.popup.popupTargetId]&&(i=this.body.edges[this.popup.popupTargetId].isOverlappingWith(e));!1===i&&(this.popupObj=void 0,this.popup.hide(),this.body.emitter.emit("hidePopup"))}}]),t}(),qC=g,VC=Nw,UC=Db.exports.getWeakData,YC=$e,XC=Y,GC=yw,KC=pw,$C=Wt,ZC=Vo.set,QC=Vo.getterFor,JC=Wh.find,tS=Wh.findIndex,eS=qC([].splice),iS=0,nS=function(t){return t.frozen||(t.frozen=new oS)},oS=function(){this.entries=[]},rS=function(t,e){return JC(t.entries,(function(t){return t[0]===e}))};oS.prototype={get:function(t){var e=rS(this,t);if(e)return e[1]},has:function(t){return!!rS(this,t)},set:function(t,e){var i=rS(this,t);i?i[1]=e:this.entries.push([t,e])},delete:function(t){var e=tS(this.entries,(function(e){return e[0]===t}));return~e&&eS(this.entries,e,1),!!~e}};var sS,aS={getConstructor:function(t,e,i,n){var o=t((function(t,o){GC(t,r),ZC(t,{type:e,id:iS++,frozen:void 0}),null!=o&&KC(o,t[n],{that:t,AS_ENTRIES:i})})),r=o.prototype,s=QC(e),a=function(t,e,i){var n=s(t),o=UC(YC(e),!0);return!0===o?nS(n).set(e,i):o[n.id]=i,t};return VC(r,{delete:function(t){var e=s(this);if(!XC(t))return!1;var i=UC(t);return!0===i?nS(e).delete(t):i&&$C(i,e.id)&&delete i[e.id]},has:function(t){var e=s(this);if(!XC(t))return!1;var i=UC(t);return!0===i?nS(e).has(t):i&&$C(i,e.id)}}),VC(r,i?{get:function(t){var e=s(this);if(XC(t)){var i=UC(t);return!0===i?nS(e).get(t):i?i[e.id]:void 0}},set:function(t,e){return a(this,t,e)}}:{add:function(t){return a(this,t,!0)}}),o}},hS=n,lS=g,dS=Nw,cS=Db.exports,uS=Bw,fS=aS,pS=Y,vS=jb,gS=Vo.enforce,yS=_o,mS=!hS.ActiveXObject&&"ActiveXObject"in hS,bS=function(t){return function(){return t(this,arguments.length?arguments[0]:void 0)}},wS=uS("WeakMap",bS,fS);if(yS&&mS){sS=fS.getConstructor(bS,"WeakMap",!0),cS.enable();var kS=wS.prototype,_S=lS(kS.delete),xS=lS(kS.has),ES=lS(kS.get),OS=lS(kS.set);dS(kS,{delete:function(t){if(pS(t)&&!vS(t)){var e=gS(this);return e.frozen||(e.frozen=new sS),_S(this,t)||e.frozen.delete(t)}return _S(this,t)},has:function(t){if(pS(t)&&!vS(t)){var e=gS(this);return e.frozen||(e.frozen=new sS),xS(this,t)||e.frozen.has(t)}return xS(this,t)},get:function(t){if(pS(t)&&!vS(t)){var e=gS(this);return e.frozen||(e.frozen=new sS),xS(this,t)?ES(this,t):e.frozen.get(t)}return ES(this,t)},set:function(t,e){if(pS(t)&&!vS(t)){var i=gS(this);i.frozen||(i.frozen=new sS),xS(this,t)?OS(this,t,e):i.frozen.set(t,e)}else OS(this,t,e);return this}})}var CS,SS,TS,MS,PS,DS=X.WeakMap;function IS(t,e,i,n){if("a"===i&&!n)throw new TypeError("Private accessor was defined without a getter");if("function"==typeof e?t!==e||!n:!e.has(t))throw new TypeError("Cannot read private member from an object whose class did not declare it");return"m"===i?n:"a"===i?n.call(t):n?n.value:e.get(t)}function BS(t,e,i,n,o){if("m"===n)throw new TypeError("Private method is not writable");if("a"===n&&!o)throw new TypeError("Private accessor was defined without a setter");if("function"==typeof e?t!==e||!o:!e.has(t))throw new TypeError("Cannot write private member to an object whose class did not declare it");return"a"===n?o.call(t,i):o?o.value=i:e.set(t,i),i}function zS(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return NS(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return NS(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function NS(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}function FS(t,e){var i,n=new b_,o=zS(e);try{for(o.s();!(i=o.n()).done;){var r=i.value;t.has(r)||n.add(r)}}catch(t){o.e(t)}finally{o.f()}return n}var AS=function(){function t(){Yd(this,t),CS.set(this,new b_),SS.set(this,new b_)}return Kd(t,[{key:"size",get:function(){return IS(this,SS,"f").size}},{key:"add",value:function(){for(var t=arguments.length,e=new Array(t),i=0;i<t;i++)e[i]=arguments[i];for(var n=0,o=e;n<o.length;n++){var r=o[n];IS(this,SS,"f").add(r)}}},{key:"delete",value:function(){for(var t=arguments.length,e=new Array(t),i=0;i<t;i++)e[i]=arguments[i];for(var n=0,o=e;n<o.length;n++){var r=o[n];IS(this,SS,"f").delete(r)}}},{key:"clear",value:function(){IS(this,SS,"f").clear()}},{key:"getSelection",value:function(){return Jc(IS(this,SS,"f"))}},{key:"getChanges",value:function(){return{added:Jc(FS(IS(this,CS,"f"),IS(this,SS,"f"))),deleted:Jc(FS(IS(this,SS,"f"),IS(this,CS,"f"))),previous:Jc(new b_(IS(this,CS,"f"))),current:Jc(new b_(IS(this,SS,"f")))}}},{key:"commit",value:function(){var t=this.getChanges();BS(this,CS,IS(this,SS,"f"),"f"),BS(this,SS,new b_(IS(this,CS,"f")),"f");var e,i=zS(t.added);try{for(i.s();!(e=i.n()).done;){e.value.select()}}catch(t){i.e(t)}finally{i.f()}var n,o=zS(t.deleted);try{for(o.s();!(n=o.n()).done;){n.value.unselect()}}catch(t){o.e(t)}finally{o.f()}return t}}]),t}();CS=new DS,SS=new DS;var jS=function(){function t(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:function(){};Yd(this,t),TS.set(this,new AS),MS.set(this,new AS),PS.set(this,void 0),BS(this,PS,e,"f")}return Kd(t,[{key:"sizeNodes",get:function(){return IS(this,TS,"f").size}},{key:"sizeEdges",get:function(){return IS(this,MS,"f").size}},{key:"getNodes",value:function(){return IS(this,TS,"f").getSelection()}},{key:"getEdges",value:function(){return IS(this,MS,"f").getSelection()}},{key:"addNodes",value:function(){var t;(t=IS(this,TS,"f")).add.apply(t,arguments)}},{key:"addEdges",value:function(){var t;(t=IS(this,MS,"f")).add.apply(t,arguments)}},{key:"deleteNodes",value:function(t){IS(this,TS,"f").delete(t)}},{key:"deleteEdges",value:function(t){IS(this,MS,"f").delete(t)}},{key:"clear",value:function(){IS(this,TS,"f").clear(),IS(this,MS,"f").clear()}},{key:"commit",value:function(){for(var t,e,i={nodes:IS(this,TS,"f").commit(),edges:IS(this,MS,"f").commit()},n=arguments.length,o=new Array(n),r=0;r<n;r++)o[r]=arguments[r];return(t=IS(this,PS,"f")).call.apply(t,su(e=[this,i]).call(e,o)),i}}]),t}();function RS(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return LS(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return LS(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function LS(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}TS=new DS,MS=new DS,PS=new DS;var HS=function(){function t(e,i){var n=this;Yd(this,t),this.body=e,this.canvas=i,this._selectionAccumulator=new jS,this.hoverObj={nodes:{},edges:{}},this.options={},this.defaultOptions={multiselect:!1,selectable:!0,selectConnectedEdges:!0,hoverConnectedEdges:!0},un(this.options,this.defaultOptions),this.body.emitter.on("_dataChanged",(function(){n.updateSelection()}))}return Kd(t,[{key:"setOptions",value:function(t){if(void 0!==t){em(["multiselect","hoverConnectedEdges","selectable","selectConnectedEdges"],this.options,t)}}},{key:"selectOnPoint",value:function(t){var e=!1;if(!0===this.options.selectable){var i=this.getNodeAt(t)||this.getEdgeAt(t);this.unselectAll(),void 0!==i&&(e=this.selectObject(i)),this.body.emitter.emit("_requestRedraw")}return e}},{key:"selectAdditionalOnPoint",value:function(t){var e=!1;if(!0===this.options.selectable){var i=this.getNodeAt(t)||this.getEdgeAt(t);void 0!==i&&(e=!0,!0===i.isSelected()?this.deselectObject(i):this.selectObject(i),this.body.emitter.emit("_requestRedraw"))}return e}},{key:"_initBaseEvent",value:function(t,e){var i={};return i.pointer={DOM:{x:e.x,y:e.y},canvas:this.canvas.DOMtoCanvas(e)},i.event=t,i}},{key:"generateClickEvent",value:function(t,e,i,n){var o=arguments.length>4&&void 0!==arguments[4]&&arguments[4],r=this._initBaseEvent(e,i);if(!0===o)r.nodes=[],r.edges=[];else{var s=this.getSelection();r.nodes=s.nodes,r.edges=s.edges}void 0!==n&&(r.previousSelection=n),"click"==t&&(r.items=this.getClickedItems(i)),void 0!==e.controlEdge&&(r.controlEdge=e.controlEdge),this.body.emitter.emit(t,r)}},{key:"selectObject",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.selectConnectedEdges;if(void 0!==t){if(t instanceof fO){var i;if(!0===e)(i=this._selectionAccumulator).addEdges.apply(i,Jc(t.edges));this._selectionAccumulator.addNodes(t)}else this._selectionAccumulator.addEdges(t);return!0}return!1}},{key:"deselectObject",value:function(t){!0===t.isSelected()&&(t.selected=!1,this._removeFromSelection(t))}},{key:"_getAllNodesOverlappingWith",value:function(t){for(var e=[],i=this.body.nodes,n=0;n<this.body.nodeIndices.length;n++){var o=this.body.nodeIndices[n];i[o].isOverlappingWith(t)&&e.push(o)}return e}},{key:"_pointerToPositionObject",value:function(t){var e=this.canvas.DOMtoCanvas(t);return{left:e.x-1,top:e.y+1,right:e.x+1,bottom:e.y-1}}},{key:"getNodeAt",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1],i=this._pointerToPositionObject(t),n=this._getAllNodesOverlappingWith(i);return n.length>0?!0===e?this.body.nodes[n[n.length-1]]:n[n.length-1]:void 0}},{key:"_getEdgesOverlappingWith",value:function(t,e){for(var i=this.body.edges,n=0;n<this.body.edgeIndices.length;n++){var o=this.body.edgeIndices[n];i[o].isOverlappingWith(t)&&e.push(o)}}},{key:"_getAllEdgesOverlappingWith",value:function(t){var e=[];return this._getEdgesOverlappingWith(t,e),e}},{key:"getEdgeAt",value:function(t){for(var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1],i=this.canvas.DOMtoCanvas(t),n=10,o=null,r=this.body.edges,s=0;s<this.body.edgeIndices.length;s++){var a=this.body.edgeIndices[s],h=r[a];if(h.connected){var l=h.from.x,d=h.from.y,c=h.to.x,u=h.to.y,f=h.edgeType.getDistanceToEdge(l,d,c,u,i.x,i.y);f<n&&(o=a,n=f)}}return null!==o?!0===e?this.body.edges[o]:o:void 0}},{key:"_addToHover",value:function(t){t instanceof fO?this.hoverObj.nodes[t.id]=t:this.hoverObj.edges[t.id]=t}},{key:"_removeFromSelection",value:function(t){var e;t instanceof fO?(this._selectionAccumulator.deleteNodes(t),(e=this._selectionAccumulator).deleteEdges.apply(e,Jc(t.edges))):this._selectionAccumulator.deleteEdges(t)}},{key:"unselectAll",value:function(){this._selectionAccumulator.clear()}},{key:"getSelectedNodeCount",value:function(){return this._selectionAccumulator.sizeNodes}},{key:"getSelectedEdgeCount",value:function(){return this._selectionAccumulator.sizeEdges}},{key:"_hoverConnectedEdges",value:function(t){for(var e=0;e<t.edges.length;e++){var i=t.edges[e];i.hover=!0,this._addToHover(i)}}},{key:"emitBlurEvent",value:function(t,e,i){var n=this._initBaseEvent(t,e);!0===i.hover&&(i.hover=!1,i instanceof fO?(n.node=i.id,this.body.emitter.emit("blurNode",n)):(n.edge=i.id,this.body.emitter.emit("blurEdge",n)))}},{key:"emitHoverEvent",value:function(t,e,i){var n=this._initBaseEvent(t,e),o=!1;return!1===i.hover&&(i.hover=!0,this._addToHover(i),o=!0,i instanceof fO?(n.node=i.id,this.body.emitter.emit("hoverNode",n)):(n.edge=i.id,this.body.emitter.emit("hoverEdge",n))),o}},{key:"hoverObject",value:function(t,e){var i=this.getNodeAt(e);void 0===i&&(i=this.getEdgeAt(e));var n=!1;for(var o in this.hoverObj.nodes)Object.prototype.hasOwnProperty.call(this.hoverObj.nodes,o)&&(void 0===i||i instanceof fO&&i.id!=o||i instanceof cC)&&(this.emitBlurEvent(t,e,this.hoverObj.nodes[o]),delete this.hoverObj.nodes[o],n=!0);for(var r in this.hoverObj.edges)Object.prototype.hasOwnProperty.call(this.hoverObj.edges,r)&&(!0===n?(this.hoverObj.edges[r].hover=!1,delete this.hoverObj.edges[r]):(void 0===i||i instanceof cC&&i.id!=r||i instanceof fO&&!i.hover)&&(this.emitBlurEvent(t,e,this.hoverObj.edges[r]),delete this.hoverObj.edges[r],n=!0));if(void 0!==i){var s=bu(this.hoverObj.edges).length,a=bu(this.hoverObj.nodes).length;(n||i instanceof cC&&0===s&&0===a||i instanceof fO&&0===s&&0===a)&&(n=this.emitHoverEvent(t,e,i)),i instanceof fO&&!0===this.options.hoverConnectedEdges&&this._hoverConnectedEdges(i)}!0===n&&this.body.emitter.emit("_requestRedraw")}},{key:"commitWithoutEmitting",value:function(){this._selectionAccumulator.commit()}},{key:"commitAndEmit",value:function(t,e){var i=!1,n=this._selectionAccumulator.commit(),o={nodes:n.nodes.previous,edges:n.edges.previous};n.edges.deleted.length>0&&(this.generateClickEvent("deselectEdge",e,t,o),i=!0),n.nodes.deleted.length>0&&(this.generateClickEvent("deselectNode",e,t,o),i=!0),n.nodes.added.length>0&&(this.generateClickEvent("selectNode",e,t),i=!0),n.edges.added.length>0&&(this.generateClickEvent("selectEdge",e,t),i=!0),!0===i&&this.generateClickEvent("select",e,t)}},{key:"getSelection",value:function(){return{nodes:this.getSelectedNodeIds(),edges:this.getSelectedEdgeIds()}}},{key:"getSelectedNodes",value:function(){return this._selectionAccumulator.getNodes()}},{key:"getSelectedEdges",value:function(){return this._selectionAccumulator.getEdges()}},{key:"getSelectedNodeIds",value:function(){var t;return gu(t=this._selectionAccumulator.getNodes()).call(t,(function(t){return t.id}))}},{key:"getSelectedEdgeIds",value:function(){var t;return gu(t=this._selectionAccumulator.getEdges()).call(t,(function(t){return t.id}))}},{key:"setSelection",value:function(t){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};if(!t||!t.nodes&&!t.edges)throw new TypeError("Selection must be an object with nodes and/or edges properties");if((e.unselectAll||void 0===e.unselectAll)&&this.unselectAll(),t.nodes){var i,n=RS(t.nodes);try{for(n.s();!(i=n.n()).done;){var o=i.value,r=this.body.nodes[o];if(!r)throw new RangeError('Node with id "'+o+'" not found');this.selectObject(r,e.highlightEdges)}}catch(t){n.e(t)}finally{n.f()}}if(t.edges){var s,a=RS(t.edges);try{for(a.s();!(s=a.n()).done;){var h=s.value,l=this.body.edges[h];if(!l)throw new RangeError('Edge with id "'+h+'" not found');this.selectObject(l)}}catch(t){a.e(t)}finally{a.f()}}this.body.emitter.emit("_requestRedraw"),this._selectionAccumulator.commit()}},{key:"selectNodes",value:function(t){var e=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];if(!t||void 0===t.length)throw"Selection must be an array with ids";this.setSelection({nodes:t},{highlightEdges:e})}},{key:"selectEdges",value:function(t){if(!t||void 0===t.length)throw"Selection must be an array with ids";this.setSelection({edges:t})}},{key:"updateSelection",value:function(){for(var t in this._selectionAccumulator.getNodes())Object.prototype.hasOwnProperty.call(this.body.nodes,t.id)||this._selectionAccumulator.deleteNodes(t);for(var e in this._selectionAccumulator.getEdges())Object.prototype.hasOwnProperty.call(this.body.edges,e.id)||this._selectionAccumulator.deleteEdges(e)}},{key:"getClickedItems",value:function(t){for(var e=this.canvas.DOMtoCanvas(t),i=[],n=this.body.nodeIndices,o=this.body.nodes,r=n.length-1;r>=0;r--){var s=o[n[r]].getItemsOnPoint(e);i.push.apply(i,s)}for(var a=this.body.edgeIndices,h=this.body.edges,l=a.length-1;l>=0;l--){var d=h[a[l]].getItemsOnPoint(e);i.push.apply(i,d)}return i}}]),t}(),WS={};!function(t){!function(t){function e(t,e){if(!(t instanceof e))throw new TypeError("Cannot call a class as a function")}t.__esModule=!0,t.sort=v;var i=32,n=7,o=256,r=[1,10,100,1e3,1e4,1e5,1e6,1e7,1e8,1e9];function s(t){return t<1e5?t<100?t<10?0:1:t<1e4?t<1e3?2:3:4:t<1e7?t<1e6?5:6:t<1e9?t<1e8?7:8:9}function a(t,e){if(t===e)return 0;if(~~t===t&&~~e===e){if(0===t||0===e)return t<e?-1:1;if(t<0||e<0){if(e>=0)return-1;if(t>=0)return 1;t=-t,e=-e}var i=s(t),n=s(e),o=0;return i<n?(t*=r[n-i-1],e/=10,o=-1):i>n&&(e*=r[i-n-1],t/=10,o=1),t===e?o:t<e?-1:1}var a=String(t),h=String(e);return a===h?0:a<h?-1:1}function h(t){for(var e=0;t>=i;)e|=1&t,t>>=1;return t+e}function l(t,e,i,n){var o=e+1;if(o===i)return 1;if(n(t[o++],t[e])<0){for(;o<i&&n(t[o],t[o-1])<0;)o++;d(t,e,o)}else for(;o<i&&n(t[o],t[o-1])>=0;)o++;return o-e}function d(t,e,i){for(i--;e<i;){var n=t[e];t[e++]=t[i],t[i--]=n}}function c(t,e,i,n,o){for(n===e&&n++;n<i;n++){for(var r=t[n],s=e,a=n;s<a;){var h=s+a>>>1;o(r,t[h])<0?a=h:s=h+1}var l=n-s;switch(l){case 3:t[s+3]=t[s+2];case 2:t[s+2]=t[s+1];case 1:t[s+1]=t[s];break;default:for(;l>0;)t[s+l]=t[s+l-1],l--}t[s]=r}}function u(t,e,i,n,o,r){var s=0,a=0,h=1;if(r(t,e[i+o])>0){for(a=n-o;h<a&&r(t,e[i+o+h])>0;)s=h,(h=1+(h<<1))<=0&&(h=a);h>a&&(h=a),s+=o,h+=o}else{for(a=o+1;h<a&&r(t,e[i+o-h])<=0;)s=h,(h=1+(h<<1))<=0&&(h=a);h>a&&(h=a);var l=s;s=o-h,h=o-l}for(s++;s<h;){var d=s+(h-s>>>1);r(t,e[i+d])>0?s=d+1:h=d}return h}function f(t,e,i,n,o,r){var s=0,a=0,h=1;if(r(t,e[i+o])<0){for(a=o+1;h<a&&r(t,e[i+o-h])<0;)s=h,(h=1+(h<<1))<=0&&(h=a);h>a&&(h=a);var l=s;s=o-h,h=o-l}else{for(a=n-o;h<a&&r(t,e[i+o+h])>=0;)s=h,(h=1+(h<<1))<=0&&(h=a);h>a&&(h=a),s+=o,h+=o}for(s++;s<h;){var d=s+(h-s>>>1);r(t,e[i+d])<0?h=d:s=d+1}return h}var p=function(){function t(i,r){e(this,t),this.array=null,this.compare=null,this.minGallop=n,this.length=0,this.tmpStorageLength=o,this.stackLength=0,this.runStart=null,this.runLength=null,this.stackSize=0,this.array=i,this.compare=r,this.length=i.length,this.length<2*o&&(this.tmpStorageLength=this.length>>>1),this.tmp=new Array(this.tmpStorageLength),this.stackLength=this.length<120?5:this.length<1542?10:this.length<119151?19:40,this.runStart=new Array(this.stackLength),this.runLength=new Array(this.stackLength)}return t.prototype.pushRun=function(t,e){this.runStart[this.stackSize]=t,this.runLength[this.stackSize]=e,this.stackSize+=1},t.prototype.mergeRuns=function(){for(;this.stackSize>1;){var t=this.stackSize-2;if(t>=1&&this.runLength[t-1]<=this.runLength[t]+this.runLength[t+1]||t>=2&&this.runLength[t-2]<=this.runLength[t]+this.runLength[t-1])this.runLength[t-1]<this.runLength[t+1]&&t--;else if(this.runLength[t]>this.runLength[t+1])break;this.mergeAt(t)}},t.prototype.forceMergeRuns=function(){for(;this.stackSize>1;){var t=this.stackSize-2;t>0&&this.runLength[t-1]<this.runLength[t+1]&&t--,this.mergeAt(t)}},t.prototype.mergeAt=function(t){var e=this.compare,i=this.array,n=this.runStart[t],o=this.runLength[t],r=this.runStart[t+1],s=this.runLength[t+1];this.runLength[t]=o+s,t===this.stackSize-3&&(this.runStart[t+1]=this.runStart[t+2],this.runLength[t+1]=this.runLength[t+2]),this.stackSize--;var a=f(i[r],i,n,o,0,e);n+=a,0!=(o-=a)&&0!==(s=u(i[n+o-1],i,r,s,s-1,e))&&(o<=s?this.mergeLow(n,o,r,s):this.mergeHigh(n,o,r,s))},t.prototype.mergeLow=function(t,e,i,o){var r=this.compare,s=this.array,a=this.tmp,h=0;for(h=0;h<e;h++)a[h]=s[t+h];var l=0,d=i,c=t;if(s[c++]=s[d++],0!=--o)if(1!==e){for(var p=this.minGallop;;){var v=0,g=0,y=!1;do{if(r(s[d],a[l])<0){if(s[c++]=s[d++],g++,v=0,0==--o){y=!0;break}}else if(s[c++]=a[l++],v++,g=0,1==--e){y=!0;break}}while((v|g)<p);if(y)break;do{if(0!==(v=f(s[d],a,l,e,0,r))){for(h=0;h<v;h++)s[c+h]=a[l+h];if(c+=v,l+=v,(e-=v)<=1){y=!0;break}}if(s[c++]=s[d++],0==--o){y=!0;break}if(0!==(g=u(a[l],s,d,o,0,r))){for(h=0;h<g;h++)s[c+h]=s[d+h];if(c+=g,d+=g,0==(o-=g)){y=!0;break}}if(s[c++]=a[l++],1==--e){y=!0;break}p--}while(v>=n||g>=n);if(y)break;p<0&&(p=0),p+=2}if(this.minGallop=p,p<1&&(this.minGallop=1),1===e){for(h=0;h<o;h++)s[c+h]=s[d+h];s[c+o]=a[l]}else{if(0===e)throw new Error("mergeLow preconditions were not respected");for(h=0;h<e;h++)s[c+h]=a[l+h]}}else{for(h=0;h<o;h++)s[c+h]=s[d+h];s[c+o]=a[l]}else for(h=0;h<e;h++)s[c+h]=a[l+h]},t.prototype.mergeHigh=function(t,e,i,o){var r=this.compare,s=this.array,a=this.tmp,h=0;for(h=0;h<o;h++)a[h]=s[i+h];var l=t+e-1,d=o-1,c=i+o-1,p=0,v=0;if(s[c--]=s[l--],0!=--e)if(1!==o){for(var g=this.minGallop;;){var y=0,m=0,b=!1;do{if(r(a[d],s[l])<0){if(s[c--]=s[l--],y++,m=0,0==--e){b=!0;break}}else if(s[c--]=a[d--],m++,y=0,1==--o){b=!0;break}}while((y|m)<g);if(b)break;do{if(0!=(y=e-f(a[d],s,t,e,e-1,r))){for(e-=y,v=1+(c-=y),p=1+(l-=y),h=y-1;h>=0;h--)s[v+h]=s[p+h];if(0===e){b=!0;break}}if(s[c--]=a[d--],1==--o){b=!0;break}if(0!=(m=o-u(s[l],a,0,o,o-1,r))){for(o-=m,v=1+(c-=m),p=1+(d-=m),h=0;h<m;h++)s[v+h]=a[p+h];if(o<=1){b=!0;break}}if(s[c--]=s[l--],0==--e){b=!0;break}g--}while(y>=n||m>=n);if(b)break;g<0&&(g=0),g+=2}if(this.minGallop=g,g<1&&(this.minGallop=1),1===o){for(v=1+(c-=e),p=1+(l-=e),h=e-1;h>=0;h--)s[v+h]=s[p+h];s[c]=a[d]}else{if(0===o)throw new Error("mergeHigh preconditions were not respected");for(p=c-(o-1),h=0;h<o;h++)s[p+h]=a[h]}}else{for(v=1+(c-=e),p=1+(l-=e),h=e-1;h>=0;h--)s[v+h]=s[p+h];s[c]=a[d]}else for(p=c-(o-1),h=0;h<o;h++)s[p+h]=a[h]},t}();function v(t,e,n,o){if(!Array.isArray(t))throw new TypeError("Can only sort arrays");e?"function"!=typeof e&&(o=n,n=e,e=a):e=a,n||(n=0),o||(o=t.length);var r=o-n;if(!(r<2)){var s=0;if(r<i)c(t,n,o,n+(s=l(t,n,o,e)),e);else{var d=new p(t,e),u=h(r);do{if((s=l(t,n,o,e))<u){var f=r;f>u&&(f=u),c(t,n,n+f,n+s,e),s=f}d.pushRun(n,s),d.mergeRuns(),r-=s,n+=s}while(0!==r);d.forceMergeRuns()}}}}(t)}(WS);var qS=WS;function VS(t){var e=function(){if("undefined"==typeof Reflect||!Mk)return!1;if(Mk.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Mk(Boolean,[],(function(){}))),!0}catch(t){return!1}}();return function(){var i,n=Ak(t);if(e){var o=Ak(this).constructor;i=Mk(n,arguments,o)}else i=n.apply(this,arguments);return Nk(this,i)}}var US=function(){function t(){Yd(this,t)}return Kd(t,[{key:"abstract",value:function(){throw new Error("Can't instantiate abstract class!")}},{key:"fake_use",value:function(){}},{key:"curveType",value:function(){return this.abstract()}},{key:"getPosition",value:function(t){return this.fake_use(t),this.abstract()}},{key:"setPosition",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:void 0;this.fake_use(t,e,i),this.abstract()}},{key:"getTreeSize",value:function(t){return this.fake_use(t),this.abstract()}},{key:"sort",value:function(t){this.fake_use(t),this.abstract()}},{key:"fix",value:function(t,e){this.fake_use(t,e),this.abstract()}},{key:"shift",value:function(t,e){this.fake_use(t,e),this.abstract()}}]),t}(),YS=function(t){zk(i,t);var e=VS(i);function i(t){var n;return Yd(this,i),(n=e.call(this)).layout=t,n}return Kd(i,[{key:"curveType",value:function(){return"horizontal"}},{key:"getPosition",value:function(t){return t.x}},{key:"setPosition",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:void 0;void 0!==i&&this.layout.hierarchical.addToOrdering(t,i),t.x=e}},{key:"getTreeSize",value:function(t){var e=this.layout.hierarchical.getTreeSize(this.layout.body.nodes,t);return{min:e.min_x,max:e.max_x}}},{key:"sort",value:function(t){qS.sort(t,(function(t,e){return t.x-e.x}))}},{key:"fix",value:function(t,e){t.y=this.layout.options.hierarchical.levelSeparation*e,t.options.fixed.y=!0}},{key:"shift",value:function(t,e){this.layout.body.nodes[t].x+=e}}]),i}(US),XS=function(t){zk(i,t);var e=VS(i);function i(t){var n;return Yd(this,i),(n=e.call(this)).layout=t,n}return Kd(i,[{key:"curveType",value:function(){return"vertical"}},{key:"getPosition",value:function(t){return t.y}},{key:"setPosition",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:void 0;void 0!==i&&this.layout.hierarchical.addToOrdering(t,i),t.y=e}},{key:"getTreeSize",value:function(t){var e=this.layout.hierarchical.getTreeSize(this.layout.body.nodes,t);return{min:e.min_y,max:e.max_y}}},{key:"sort",value:function(t){qS.sort(t,(function(t,e){return t.y-e.y}))}},{key:"fix",value:function(t,e){t.x=this.layout.options.hierarchical.levelSeparation*e,t.options.fixed.x=!0}},{key:"shift",value:function(t,e){this.layout.body.nodes[t].y+=e}}]),i}(US),GS=Wh.every;_i({target:"Array",proto:!0,forced:!Cu("every")},{every:function(t){return GS(this,t,arguments.length>1?arguments[1]:void 0)}});var KS=Tn("Array").every,$S=J,ZS=KS,QS=Array.prototype,JS=function(t){var e=t.every;return t===QS||$S(QS,t)&&e===QS.every?ZS:e},tT=JS;function eT(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return iT(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return iT(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function iT(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}function nT(t,e){var i=new b_;return Fu(t).call(t,(function(t){var e;Fu(e=t.edges).call(e,(function(t){t.connected&&i.add(t)}))})),Fu(i).call(i,(function(t){var i=t.from.id,n=t.to.id;null==e[i]&&(e[i]=0),(null==e[n]||e[i]>=e[n])&&(e[n]=e[i]+1)})),e}function oT(t,e,i,n){var o,r,s=Kp(null),a=i_(o=Jc(kx(n).call(n))).call(o,(function(t,e){return t+1+e.edges.length}),0),h=i+"Id",l="to"===i?1:-1,d=eT(n);try{var c=function(){var o=Kc(r.value,2),d=o[0],c=o[1];if(!n.has(d)||!t(c))return"continue";s[d]=0;for(var u=[c],f=0,p=void 0,v=function(){var t,o;if(!n.has(d))return"continue";var r=s[p.id]+l;if(Fu(t=Xf(o=p.edges).call(o,(function(t){return t.connected&&t.to!==t.from&&t[i]!==p&&n.has(t.toId)&&n.has(t.fromId)}))).call(t,(function(t){var n=t[h],o=s[n];(null==o||e(r,o))&&(s[n]=r,u.push(t[i]))})),f>a)return{v:{v:nT(n,s)}};++f};p=u.pop();){var g=v();if("continue"!==g&&"object"===Qc(g))return g.v}};for(d.s();!(r=d.n()).done;){var u=c();if("continue"!==u&&"object"===Qc(u))return u.v}}catch(t){d.e(t)}finally{d.f()}return s}var rT=function(){function t(){Yd(this,t),this.childrenReference={},this.parentReference={},this.trees={},this.distributionOrdering={},this.levels={},this.distributionIndex={},this.isTree=!1,this.treeIndex=-1}return Kd(t,[{key:"addRelation",value:function(t,e){void 0===this.childrenReference[t]&&(this.childrenReference[t]=[]),this.childrenReference[t].push(e),void 0===this.parentReference[e]&&(this.parentReference[e]=[]),this.parentReference[e].push(t)}},{key:"checkIfTree",value:function(){for(var t in this.parentReference)if(this.parentReference[t].length>1)return void(this.isTree=!1);this.isTree=!0}},{key:"numTrees",value:function(){return this.treeIndex+1}},{key:"setTreeIndex",value:function(t,e){void 0!==e&&void 0===this.trees[t.id]&&(this.trees[t.id]=e,this.treeIndex=Math.max(e,this.treeIndex))}},{key:"ensureLevel",value:function(t){void 0===this.levels[t]&&(this.levels[t]=0)}},{key:"getMaxLevel",value:function(t){var e=this,i={};return function t(n){if(void 0!==i[n])return i[n];var o=e.levels[n];if(e.childrenReference[n]){var r=e.childrenReference[n];if(r.length>0)for(var s=0;s<r.length;s++)o=Math.max(o,t(r[s]))}return i[n]=o,o}(t)}},{key:"levelDownstream",value:function(t,e){void 0===this.levels[e.id]&&(void 0===this.levels[t.id]&&(this.levels[t.id]=0),this.levels[e.id]=this.levels[t.id]+1)}},{key:"setMinLevelToZero",value:function(t){var e=1e9;for(var i in t)Object.prototype.hasOwnProperty.call(t,i)&&void 0!==this.levels[i]&&(e=Math.min(this.levels[i],e));for(var n in t)Object.prototype.hasOwnProperty.call(t,n)&&void 0!==this.levels[n]&&(this.levels[n]-=e)}},{key:"getTreeSize",value:function(t,e){var i=1e9,n=-1e9,o=1e9,r=-1e9;for(var s in this.trees)if(Object.prototype.hasOwnProperty.call(this.trees,s)&&this.trees[s]===e){var a=t[s];i=Math.min(a.x,i),n=Math.max(a.x,n),o=Math.min(a.y,o),r=Math.max(a.y,r)}return{min_x:i,max_x:n,min_y:o,max_y:r}}},{key:"hasSameParent",value:function(t,e){var i=this.parentReference[t.id],n=this.parentReference[e.id];if(void 0===i||void 0===n)return!1;for(var o=0;o<i.length;o++)for(var r=0;r<n.length;r++)if(i[o]==n[r])return!0;return!1}},{key:"inSameSubNetwork",value:function(t,e){return this.trees[t.id]===this.trees[e.id]}},{key:"getLevels",value:function(){return bu(this.distributionOrdering)}},{key:"addToOrdering",value:function(t,e){void 0===this.distributionOrdering[e]&&(this.distributionOrdering[e]=[]);var i=!1,n=this.distributionOrdering[e];for(var o in n)if(n[o]===t){i=!0;break}i||(this.distributionOrdering[e].push(t),this.distributionIndex[t.id]=this.distributionOrdering[e].length-1)}}]),t}(),sT=function(){function t(e){Yd(this,t),this.body=e,this._resetRNG(Math.random()+":"+Eu()),this.setPhysics=!1,this.options={},this.optionsBackup={physics:{}},this.defaultOptions={randomSeed:void 0,improvedLayout:!0,clusterThreshold:150,hierarchical:{enabled:!1,levelSeparation:150,nodeSpacing:100,treeSpacing:200,blockShifting:!0,edgeMinimization:!0,parentCentralization:!0,direction:"UD",sortMethod:"hubsize"}},un(this.options,this.defaultOptions),this.bindEventListeners()}return Kd(t,[{key:"bindEventListeners",value:function(){var t=this;this.body.emitter.on("_dataChanged",(function(){t.setupHierarchicalLayout()})),this.body.emitter.on("_dataLoaded",(function(){t.layoutNetwork()})),this.body.emitter.on("_resetHierarchicalLayout",(function(){t.setupHierarchicalLayout()})),this.body.emitter.on("_adjustEdgesForHierarchicalLayout",(function(){if(!0===t.options.hierarchical.enabled){var e=t.direction.curveType();t.body.emitter.emit("_forceDisableDynamicCurves",e,!1)}}))}},{key:"setOptions",value:function(t,e){if(void 0!==t){var i=this.options.hierarchical,n=i.enabled;if(em(["randomSeed","improvedLayout","clusterThreshold"],this.options,t),Sm(this.options,t,"hierarchical"),void 0!==t.randomSeed&&this._resetRNG(t.randomSeed),!0===i.enabled)return!0===n&&this.body.emitter.emit("refresh",!0),"RL"===i.direction||"DU"===i.direction?i.levelSeparation>0&&(i.levelSeparation*=-1):i.levelSeparation<0&&(i.levelSeparation*=-1),this.setDirectionStrategy(),this.body.emitter.emit("_resetHierarchicalLayout"),this.adaptAllOptionsForHierarchicalLayout(e);if(!0===n)return this.body.emitter.emit("refresh"),nm(e,this.optionsBackup)}return e}},{key:"_resetRNG",value:function(t){this.initialRandomSeed=t,this._rng=jy(this.initialRandomSeed)}},{key:"adaptAllOptionsForHierarchicalLayout",value:function(t){if(!0===this.options.hierarchical.enabled){var e=this.optionsBackup.physics;void 0===t.physics||!0===t.physics?(t.physics={enabled:void 0===e.enabled||e.enabled,solver:"hierarchicalRepulsion"},e.enabled=void 0===e.enabled||e.enabled,e.solver=e.solver||"barnesHut"):"object"===Qc(t.physics)?(e.enabled=void 0===t.physics.enabled||t.physics.enabled,e.solver=t.physics.solver||"barnesHut",t.physics.solver="hierarchicalRepulsion"):!1!==t.physics&&(e.solver="barnesHut",t.physics={solver:"hierarchicalRepulsion"});var i=this.direction.curveType();if(void 0===t.edges)this.optionsBackup.edges={smooth:{enabled:!0,type:"dynamic"}},t.edges={smooth:!1};else if(void 0===t.edges.smooth)this.optionsBackup.edges={smooth:{enabled:!0,type:"dynamic"}},t.edges.smooth=!1;else if("boolean"==typeof t.edges.smooth)this.optionsBackup.edges={smooth:t.edges.smooth},t.edges.smooth={enabled:t.edges.smooth,type:i};else{var n=t.edges.smooth;void 0!==n.type&&"dynamic"!==n.type&&(i=n.type),this.optionsBackup.edges={smooth:{enabled:void 0===n.enabled||n.enabled,type:void 0===n.type?"dynamic":n.type,roundness:void 0===n.roundness?.5:n.roundness,forceDirection:void 0!==n.forceDirection&&n.forceDirection}},t.edges.smooth={enabled:void 0===n.enabled||n.enabled,type:i,roundness:void 0===n.roundness?.5:n.roundness,forceDirection:void 0!==n.forceDirection&&n.forceDirection}}this.body.emitter.emit("_forceDisableDynamicCurves",i)}return t}},{key:"positionInitially",value:function(t){if(!0!==this.options.hierarchical.enabled){this._resetRNG(this.initialRandomSeed);for(var e=t.length+50,i=0;i<t.length;i++){var n=t[i],o=2*Math.PI*this._rng();void 0===n.x&&(n.x=e*Math.cos(o)),void 0===n.y&&(n.y=e*Math.sin(o))}}}},{key:"layoutNetwork",value:function(){if(!0!==this.options.hierarchical.enabled&&!0===this.options.improvedLayout){for(var t=this.body.nodeIndices,e=0,i=0;i<t.length;i++){!0===this.body.nodes[t[i]].predefinedPosition&&(e+=1)}if(e<.5*t.length){var n=0,o=this.options.clusterThreshold,r={clusterNodeProperties:{shape:"ellipse",label:"",group:"",font:{multi:!1}},clusterEdgeProperties:{label:"",font:{multi:!1},smooth:{enabled:!1}}};if(t.length>o){for(var s=t.length;t.length>o&&n<=10;){n+=1;var a=t.length;if(n%3==0?this.body.modules.clustering.clusterBridges(r):this.body.modules.clustering.clusterOutliers(r),a==t.length&&n%3!=0)return this._declusterAll(),this.body.emitter.emit("_layoutFailed"),void console.info("This network could not be positioned by this version of the improved layout algorithm. Please disable improvedLayout for better performance.")}this.body.modules.kamadaKawai.setOptions({springLength:Math.max(150,2*s)})}n>10&&console.info("The clustering didn't succeed within the amount of interations allowed, progressing with partial result."),this.body.modules.kamadaKawai.solve(t,this.body.edgeIndices,!0),this._shiftToCenter();for(var h=0;h<t.length;h++){var l=this.body.nodes[t[h]];!1===l.predefinedPosition&&(l.x+=70*(.5-this._rng()),l.y+=70*(.5-this._rng()))}this._declusterAll(),this.body.emitter.emit("_repositionBezierNodes")}}}},{key:"_shiftToCenter",value:function(){for(var t=EC.getRangeCore(this.body.nodes,this.body.nodeIndices),e=EC.findCenter(t),i=0;i<this.body.nodeIndices.length;i++){var n=this.body.nodes[this.body.nodeIndices[i]];n.x-=e.x,n.y-=e.y}}},{key:"_declusterAll",value:function(){for(var t=!0;!0===t;){t=!1;for(var e=0;e<this.body.nodeIndices.length;e++)!0===this.body.nodes[this.body.nodeIndices[e]].isCluster&&(t=!0,this.body.modules.clustering.openCluster(this.body.nodeIndices[e],{},!1));!0===t&&this.body.emitter.emit("_dataChanged")}}},{key:"getSeed",value:function(){return this.initialRandomSeed}},{key:"setupHierarchicalLayout",value:function(){if(!0===this.options.hierarchical.enabled&&this.body.nodeIndices.length>0){var t,e,i=!1,n=!1;for(e in this.lastNodeOnLevel={},this.hierarchical=new rT,this.body.nodes)Object.prototype.hasOwnProperty.call(this.body.nodes,e)&&(void 0!==(t=this.body.nodes[e]).options.level?(i=!0,this.hierarchical.levels[e]=t.options.level):n=!0);if(!0===n&&!0===i)throw new Error("To use the hierarchical layout, nodes require either no predefined levels or levels have to be defined for all nodes.");if(!0===n){var o=this.options.hierarchical.sortMethod;"hubsize"===o?this._determineLevelsByHubsize():"directed"===o?this._determineLevelsDirected():"custom"===o&&this._determineLevelsCustomCallback()}for(var r in this.body.nodes)Object.prototype.hasOwnProperty.call(this.body.nodes,r)&&this.hierarchical.ensureLevel(r);var s=this._getDistribution();this._generateMap(),this._placeNodesByHierarchy(s),this._condenseHierarchy(),this._shiftToCenter()}}},{key:"_condenseHierarchy",value:function(){var t=this,e=!1,i={},n=function(e,i){var n=t.hierarchical.trees;for(var o in n)Object.prototype.hasOwnProperty.call(n,o)&&n[o]===e&&t.direction.shift(o,i)},o=function(){for(var e=[],i=0;i<t.hierarchical.numTrees();i++)e.push(t.direction.getTreeSize(i));return e},r=function e(i,n){if(!n[i.id]&&(n[i.id]=!0,t.hierarchical.childrenReference[i.id])){var o=t.hierarchical.childrenReference[i.id];if(o.length>0)for(var r=0;r<o.length;r++)e(t.body.nodes[o[r]],n)}},s=function(e){var i=arguments.length>1&&void 0!==arguments[1]?arguments[1]:1e9,n=1e9,o=1e9,r=1e9,s=-1e9;for(var a in e)if(Object.prototype.hasOwnProperty.call(e,a)){var h=t.body.nodes[a],l=t.hierarchical.levels[h.id],d=t.direction.getPosition(h),c=t._getSpaceAroundNode(h,e),u=Kc(c,2),f=u[0],p=u[1];n=Math.min(f,n),o=Math.min(p,o),l<=i&&(r=Math.min(d,r),s=Math.max(d,s))}return[r,s,n,o]},a=function(e,i){var n=t.hierarchical.getMaxLevel(e.id),o=t.hierarchical.getMaxLevel(i.id);return Math.min(n,o)},h=function(e,i,n){for(var o=t.hierarchical,r=0;r<i.length;r++){var s=i[r],a=o.distributionOrdering[s];if(a.length>1)for(var h=0;h<a.length-1;h++){var l=a[h],d=a[h+1];o.hasSameParent(l,d)&&o.inSameSubNetwork(l,d)&&e(l,d,n)}}},l=function(i,n){var o=arguments.length>2&&void 0!==arguments[2]&&arguments[2],h=t.direction.getPosition(i),l=t.direction.getPosition(n),d=Math.abs(l-h),c=t.options.hierarchical.nodeSpacing;if(d>c){var u={},f={};r(i,u),r(n,f);var p=a(i,n),v=s(u,p),g=s(f,p),y=v[1],m=g[0],b=g[2],w=Math.abs(y-m);if(w>c){var k=y-m+c;k<-b+c&&(k=-b+c),k<0&&(t._shiftBlock(n.id,k),e=!0,!0===o&&t._centerParent(n))}}},d=function(n,o){for(var a=o.id,h=o.edges,l=t.hierarchical.levels[o.id],d=t.options.hierarchical.levelSeparation*t.options.hierarchical.levelSeparation,c={},u=[],f=0;f<h.length;f++){var p=h[f];if(p.toId!=p.fromId){var v=p.toId==a?p.from:p.to;c[h[f].id]=v,t.hierarchical.levels[v.id]<l&&u.push(p)}}var g=function(e,i){for(var n=0,o=0;o<i.length;o++)if(void 0!==c[i[o].id]){var r=t.direction.getPosition(c[i[o].id])-e;n+=r/Math.sqrt(r*r+d)}return n},y=function(e,i){for(var n=0,o=0;o<i.length;o++)if(void 0!==c[i[o].id]){var r=t.direction.getPosition(c[i[o].id])-e;n-=d*Math.pow(r*r+d,-1.5)}return n},m=function(e,i){for(var n=t.direction.getPosition(o),r={},s=0;s<e;s++){var a=g(n,i),h=y(n,i);if(void 0!==r[n-=Math.max(-40,Math.min(40,Math.round(a/h)))])break;r[n]=s}return n},b=m(n,u);!function(n){var a=t.direction.getPosition(o);if(void 0===i[o.id]){var h={};r(o,h),i[o.id]=h}var l=s(i[o.id]),d=l[2],c=l[3],u=n-a,f=0;u>0?f=Math.min(u,c-t.options.hierarchical.nodeSpacing):u<0&&(f=-Math.min(-u,d-t.options.hierarchical.nodeSpacing)),0!=f&&(t._shiftBlock(o.id,f),e=!0)}(b),function(i){var n=t.direction.getPosition(o),r=Kc(t._getSpaceAroundNode(o),2),s=r[0],a=r[1],h=i-n,l=n;h>0?l=Math.min(n+(a-t.options.hierarchical.nodeSpacing),i):h<0&&(l=Math.max(n-(s-t.options.hierarchical.nodeSpacing),i)),l!==n&&(t.direction.setPosition(o,l),e=!0)}(b=m(n,h))};!0===this.options.hierarchical.blockShifting&&(function(i){var n=t.hierarchical.getLevels();n=Yu(n).call(n);for(var o=0;o<i&&(e=!1,h(l,n,!0),!0===e);o++);}(5),function(){for(var e in t.body.nodes)Object.prototype.hasOwnProperty.call(t.body.nodes,e)&&t._centerParent(t.body.nodes[e])}()),!0===this.options.hierarchical.edgeMinimization&&function(i){var n=t.hierarchical.getLevels();n=Yu(n).call(n);for(var o=0;o<i;o++){e=!1;for(var r=0;r<n.length;r++)for(var s=n[r],a=t.hierarchical.distributionOrdering[s],h=0;h<a.length;h++)d(1e3,a[h]);if(!0!==e)break}}(20),!0===this.options.hierarchical.parentCentralization&&function(){var e=t.hierarchical.getLevels();e=Yu(e).call(e);for(var i=0;i<e.length;i++)for(var n=e[i],o=t.hierarchical.distributionOrdering[n],r=0;r<o.length;r++)t._centerParent(o[r])}(),function(){for(var e=o(),i=0,r=0;r<e.length-1;r++){i+=e[r].max-e[r+1].min+t.options.hierarchical.treeSpacing,n(r+1,i)}}()}},{key:"_getSpaceAroundNode",value:function(t,e){var i=!0;void 0===e&&(i=!1);var n=this.hierarchical.levels[t.id];if(void 0!==n){var o=this.hierarchical.distributionIndex[t.id],r=this.direction.getPosition(t),s=this.hierarchical.distributionOrdering[n],a=1e9,h=1e9;if(0!==o){var l=s[o-1];if(!0===i&&void 0===e[l.id]||!1===i)a=r-this.direction.getPosition(l)}if(o!=s.length-1){var d=s[o+1];if(!0===i&&void 0===e[d.id]||!1===i){var c=this.direction.getPosition(d);h=Math.min(h,c-r)}}return[a,h]}return[0,0]}},{key:"_centerParent",value:function(t){if(this.hierarchical.parentReference[t.id])for(var e=this.hierarchical.parentReference[t.id],i=0;i<e.length;i++){var n=e[i],o=this.body.nodes[n],r=this.hierarchical.childrenReference[n];if(void 0!==r){var s=this._getCenterPosition(r),a=this.direction.getPosition(o),h=Kc(this._getSpaceAroundNode(o),2),l=h[0],d=h[1],c=a-s;(c<0&&Math.abs(c)<d-this.options.hierarchical.nodeSpacing||c>0&&Math.abs(c)<l-this.options.hierarchical.nodeSpacing)&&this.direction.setPosition(o,s)}}}},{key:"_placeNodesByHierarchy",value:function(t){for(var e in this.positionedNodes={},t)if(Object.prototype.hasOwnProperty.call(t,e)){var i,n=bu(t[e]);n=this._indexArrayToNodes(n),rx(i=this.direction).call(i,n);for(var o=0,r=0;r<n.length;r++){var s=n[r];if(void 0===this.positionedNodes[s.id]){var a=this.options.hierarchical.nodeSpacing,h=a*o;o>0&&(h=this.direction.getPosition(n[r-1])+a),this.direction.setPosition(s,h,e),this._validatePositionAndContinue(s,e,h),o++}}}}},{key:"_placeBranchNodes",value:function(t,e){var i,n=this.hierarchical.childrenReference[t];if(void 0!==n){for(var o=[],r=0;r<n.length;r++)o.push(this.body.nodes[n[r]]);rx(i=this.direction).call(i,o);for(var s=0;s<o.length;s++){var a=o[s],h=this.hierarchical.levels[a.id];if(!(h>e&&void 0===this.positionedNodes[a.id]))return;var l=this.options.hierarchical.nodeSpacing,d=void 0;d=0===s?this.direction.getPosition(this.body.nodes[t]):this.direction.getPosition(o[s-1])+l,this.direction.setPosition(a,d,h),this._validatePositionAndContinue(a,h,d)}var c=this._getCenterPosition(o);this.direction.setPosition(this.body.nodes[t],c,e)}}},{key:"_validatePositionAndContinue",value:function(t,e,i){if(this.hierarchical.isTree){if(void 0!==this.lastNodeOnLevel[e]){var n=this.direction.getPosition(this.body.nodes[this.lastNodeOnLevel[e]]);if(i-n<this.options.hierarchical.nodeSpacing){var o=n+this.options.hierarchical.nodeSpacing-i,r=this._findCommonParent(this.lastNodeOnLevel[e],t.id);this._shiftBlock(r.withChild,o)}}this.lastNodeOnLevel[e]=t.id,this.positionedNodes[t.id]=!0,this._placeBranchNodes(t.id,e)}}},{key:"_indexArrayToNodes",value:function(t){for(var e=[],i=0;i<t.length;i++)e.push(this.body.nodes[t[i]]);return e}},{key:"_getDistribution",value:function(){var t,e,i={};for(t in this.body.nodes)if(Object.prototype.hasOwnProperty.call(this.body.nodes,t)){e=this.body.nodes[t];var n=void 0===this.hierarchical.levels[t]?0:this.hierarchical.levels[t];this.direction.fix(e,n),void 0===i[n]&&(i[n]={}),i[n][t]=e}return i}},{key:"_getActiveEdges",value:function(t){var e=this,i=[];return hm(t.edges,(function(t){var n;-1!==Fp(n=e.body.edgeIndices).call(n,t.id)&&i.push(t)})),i}},{key:"_getHubSizes",value:function(){var t=this,e={};hm(this.body.nodeIndices,(function(i){var n=t.body.nodes[i],o=t._getActiveEdges(n).length;e[o]=!0}));var i=[];return hm(e,(function(t){i.push(Number(t))})),rx(qS).call(qS,i,(function(t,e){return e-t})),i}},{key:"_determineLevelsByHubsize",value:function(){for(var t=this,e=function(e,i){t.hierarchical.levelDownstream(e,i)},i=this._getHubSizes(),n=function(n){var o=i[n];if(0===o)return"break";hm(t.body.nodeIndices,(function(i){var n=t.body.nodes[i];o===t._getActiveEdges(n).length&&t._crawlNetwork(e,i)}))},o=0;o<i.length;++o){if("break"===n(o))break}}},{key:"_determineLevelsCustomCallback",value:function(){var t=this;this._crawlNetwork((function(e,i,n){var o=t.hierarchical.levels[e.id];void 0===o&&(o=t.hierarchical.levels[e.id]=1e5);var r=(EC.cloneOptions(e,"node"),EC.cloneOptions(i,"node"),void EC.cloneOptions(n,"edge"));t.hierarchical.levels[i.id]=o+r})),this.hierarchical.setMinLevelToZero(this.body.nodes)}},{key:"_determineLevelsDirected",value:function(){var t,e=this,i=i_(t=this.body.nodeIndices).call(t,(function(t,i){return t.set(i,e.body.nodes[i]),t}),new Jw);"roots"===this.options.hierarchical.shakeTowards?this.hierarchical.levels=function(t){return oT((function(e){var i,n;return tT(i=Xf(n=e.edges).call(n,(function(e){return t.has(e.toId)}))).call(i,(function(t){return t.from===e}))}),(function(t,e){return e<t}),"to",t)}(i):this.hierarchical.levels=function(t){return oT((function(e){var i,n;return tT(i=Xf(n=e.edges).call(n,(function(e){return t.has(e.toId)}))).call(i,(function(t){return t.to===e}))}),(function(t,e){return e>t}),"from",t)}(i),this.hierarchical.setMinLevelToZero(this.body.nodes)}},{key:"_generateMap",value:function(){var t=this;this._crawlNetwork((function(e,i){t.hierarchical.levels[i.id]>t.hierarchical.levels[e.id]&&t.hierarchical.addRelation(e.id,i.id)})),this.hierarchical.checkIfTree()}},{key:"_crawlNetwork",value:function(){var t=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:function(){},i=arguments.length>1?arguments[1]:void 0,n={},o=function i(o,r){if(void 0===n[o.id]){var s;t.hierarchical.setTreeIndex(o,r),n[o.id]=!0;for(var a=t._getActiveEdges(o),h=0;h<a.length;h++){var l=a[h];!0===l.connected&&(s=l.toId==o.id?l.from:l.to,o.id!=s.id&&(e(o,s,l),i(s,r)))}}};if(void 0===i)for(var r=0,s=0;s<this.body.nodeIndices.length;s++){var a=this.body.nodeIndices[s];if(void 0===n[a]){var h=this.body.nodes[a];o(h,r),r+=1}}else{var l=this.body.nodes[i];if(void 0===l)return void console.error("Node not found:",i);o(l)}}},{key:"_shiftBlock",value:function(t,e){var i=this,n={};!function t(o){if(!n[o]){n[o]=!0,i.direction.shift(o,e);var r=i.hierarchical.childrenReference[o];if(void 0!==r)for(var s=0;s<r.length;s++)t(r[s])}}(t)}},{key:"_findCommonParent",value:function(t,e){var i=this,n={};return function t(e,n){var o=i.hierarchical.parentReference[n];if(void 0!==o)for(var r=0;r<o.length;r++){var s=o[r];e[s]=!0,t(e,s)}}(n,t),function t(e,n){var o=i.hierarchical.parentReference[n];if(void 0!==o)for(var r=0;r<o.length;r++){var s=o[r];if(void 0!==e[s])return{foundParent:s,withChild:n};var a=t(e,s);if(null!==a.foundParent)return a}return{foundParent:null,withChild:n}}(n,e)}},{key:"setDirectionStrategy",value:function(){var t="UD"===this.options.hierarchical.direction||"DU"===this.options.hierarchical.direction;this.direction=t?new YS(this):new XS(this)}},{key:"_getCenterPosition",value:function(t){for(var e=1e9,i=-1e9,n=0;n<t.length;n++){var o=void 0;if(void 0!==t[n].id)o=t[n];else{var r=t[n];o=this.body.nodes[r]}var s=this.direction.getPosition(o);e=Math.min(e,s),i=Math.max(i,s)}return.5*(e+i)}}]),t}();function aT(t,e){var i=void 0!==tu&&ih(t)||t["@@iterator"];if(!i){if(lu(t)||(i=function(t,e){var i;if(!t)return;if("string"==typeof t)return hT(t,e);var n=au(i=Object.prototype.toString.call(t)).call(i,8,-1);"Object"===n&&t.constructor&&(n=t.constructor.name);if("Map"===n||"Set"===n)return ja(t);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return hT(t,e)}(t))||e&&t&&"number"==typeof t.length){i&&(t=i);var n=0,o=function(){};return{s:o,n:function(){return n>=t.length?{done:!0}:{done:!1,value:t[n++]}},e:function(t){throw t},f:o}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var r,s=!0,a=!1;return{s:function(){i=i.call(t)},n:function(){var t=i.next();return s=t.done,t},e:function(t){a=!0,r=t},f:function(){try{s||null==i.return||i.return()}finally{if(a)throw r}}}}function hT(t,e){(null==e||e>t.length)&&(e=t.length);for(var i=0,n=new Array(e);i<e;i++)n[i]=t[i];return n}var lT=function(){function t(e,i,n,o){var r,s,a=this;Yd(this,t),this.body=e,this.canvas=i,this.selectionHandler=n,this.interactionHandler=o,this.editMode=!1,this.manipulationDiv=void 0,this.editModeDiv=void 0,this.closeDiv=void 0,this._domEventListenerCleanupQueue=[],this.temporaryUIFunctions={},this.temporaryEventFunctions=[],this.touchTime=0,this.temporaryIds={nodes:[],edges:[]},this.guiEnabled=!1,this.inMode=!1,this.selectedControlNode=void 0,this.options={},this.defaultOptions={enabled:!1,initiallyActive:!1,addNode:!0,addEdge:!0,editNode:void 0,editEdge:!0,deleteNode:!0,deleteEdge:!0,controlNodeStyle:{shape:"dot",size:6,color:{background:"#ff0000",border:"#3c3c3c",highlight:{background:"#07f968",border:"#3c3c3c"}},borderWidth:2,borderWidthSelected:2}},un(this.options,this.defaultOptions),this.body.emitter.on("destroy",(function(){a._clean()})),this.body.emitter.on("_dataChanged",zn(r=this._restore).call(r,this)),this.body.emitter.on("_resetData",zn(s=this._restore).call(s,this))}return Kd(t,[{key:"_restore",value:function(){!1!==this.inMode&&(!0===this.options.initiallyActive?this.enableEditMode():this.disableEditMode())}},{key:"setOptions",value:function(t,e,i){void 0!==e&&(void 0!==e.locale?this.options.locale=e.locale:this.options.locale=i.locale,void 0!==e.locales?this.options.locales=e.locales:this.options.locales=i.locales),void 0!==t&&("boolean"==typeof t?this.options.enabled=t:(this.options.enabled=!0,nm(this.options,t)),!0===this.options.initiallyActive&&(this.editMode=!0),this._setup())}},{key:"toggleEditMode",value:function(){!0===this.editMode?this.disableEditMode():this.enableEditMode()}},{key:"enableEditMode",value:function(){this.editMode=!0,this._clean(),!0===this.guiEnabled&&(this.manipulationDiv.style.display="block",this.closeDiv.style.display="block",this.editModeDiv.style.display="none",this.showManipulatorToolbar())}},{key:"disableEditMode",value:function(){this.editMode=!1,this._clean(),!0===this.guiEnabled&&(this.manipulationDiv.style.display="none",this.closeDiv.style.display="none",this.editModeDiv.style.display="block",this._createEditButton())}},{key:"showManipulatorToolbar",value:function(){if(this._clean(),this.manipulationDOM={},!0===this.guiEnabled){var t,e;this.editMode=!0,this.manipulationDiv.style.display="block",this.closeDiv.style.display="block";var i=this.selectionHandler.getSelectedNodeCount(),n=this.selectionHandler.getSelectedEdgeCount(),o=i+n,r=this.options.locales[this.options.locale],s=!1;!1!==this.options.addNode&&(this._createAddNodeButton(r),s=!0),!1!==this.options.addEdge&&(!0===s?this._createSeperator(1):s=!0,this._createAddEdgeButton(r)),1===i&&"function"==typeof this.options.editNode?(!0===s?this._createSeperator(2):s=!0,this._createEditNodeButton(r)):1===n&&0===i&&!1!==this.options.editEdge&&(!0===s?this._createSeperator(3):s=!0,this._createEditEdgeButton(r)),0!==o&&(i>0&&!1!==this.options.deleteNode||0===i&&!1!==this.options.deleteEdge)&&(!0===s&&this._createSeperator(4),this._createDeleteButton(r)),this._bindElementEvents(this.closeDiv,zn(t=this.toggleEditMode).call(t,this)),this._temporaryBindEvent("select",zn(e=this.showManipulatorToolbar).call(e,this))}this.body.emitter.emit("_redraw")}},{key:"addNodeMode",value:function(){var t;if(!0!==this.editMode&&this.enableEditMode(),this._clean(),this.inMode="addNode",!0===this.guiEnabled){var e,i=this.options.locales[this.options.locale];this.manipulationDOM={},this._createBackButton(i),this._createSeperator(),this._createDescription(i.addDescription||this.options.locales.en.addDescription),this._bindElementEvents(this.closeDiv,zn(e=this.toggleEditMode).call(e,this))}this._temporaryBindEvent("click",zn(t=this._performAddNode).call(t,this))}},{key:"editNode",value:function(){var t=this;!0!==this.editMode&&this.enableEditMode(),this._clean();var e=this.selectionHandler.getSelectedNodes()[0];if(void 0!==e){if(this.inMode="editNode","function"!=typeof this.options.editNode)throw new Error("No function has been configured to handle the editing of nodes.");if(!0!==e.isCluster){var i=nm({},e.options,!1);if(i.x=e.x,i.y=e.y,2!==this.options.editNode.length)throw new Error("The function for edit does not support two arguments (data, callback)");this.options.editNode(i,(function(e){null!=e&&"editNode"===t.inMode&&t.body.data.nodes.getDataSet().update(e),t.showManipulatorToolbar()}))}else alert(this.options.locales[this.options.locale].editClusterError||this.options.locales.en.editClusterError)}else this.showManipulatorToolbar()}},{key:"addEdgeMode",value:function(){var t,e,i,n,o;if(!0!==this.editMode&&this.enableEditMode(),this._clean(),this.inMode="addEdge",!0===this.guiEnabled){var r,s=this.options.locales[this.options.locale];this.manipulationDOM={},this._createBackButton(s),this._createSeperator(),this._createDescription(s.edgeDescription||this.options.locales.en.edgeDescription),this._bindElementEvents(this.closeDiv,zn(r=this.toggleEditMode).call(r,this))}this._temporaryBindUI("onTouch",zn(t=this._handleConnect).call(t,this)),this._temporaryBindUI("onDragEnd",zn(e=this._finishConnect).call(e,this)),this._temporaryBindUI("onDrag",zn(i=this._dragControlNode).call(i,this)),this._temporaryBindUI("onRelease",zn(n=this._finishConnect).call(n,this)),this._temporaryBindUI("onDragStart",zn(o=this._dragStartEdge).call(o,this)),this._temporaryBindUI("onHold",(function(){}))}},{key:"editEdgeMode",value:function(){if(!0!==this.editMode&&this.enableEditMode(),this._clean(),this.inMode="editEdge","object"!==Qc(this.options.editEdge)||"function"!=typeof this.options.editEdge.editWithoutDrag||(this.edgeBeingEditedId=this.selectionHandler.getSelectedEdgeIds()[0],void 0===this.edgeBeingEditedId)){if(!0===this.guiEnabled){var t,e=this.options.locales[this.options.locale];this.manipulationDOM={},this._createBackButton(e),this._createSeperator(),this._createDescription(e.editEdgeDescription||this.options.locales.en.editEdgeDescription),this._bindElementEvents(this.closeDiv,zn(t=this.toggleEditMode).call(t,this))}if(this.edgeBeingEditedId=this.selectionHandler.getSelectedEdgeIds()[0],void 0!==this.edgeBeingEditedId){var i,n,o,r,s=this.body.edges[this.edgeBeingEditedId],a=this._getNewTargetNode(s.from.x,s.from.y),h=this._getNewTargetNode(s.to.x,s.to.y);this.temporaryIds.nodes.push(a.id),this.temporaryIds.nodes.push(h.id),this.body.nodes[a.id]=a,this.body.nodeIndices.push(a.id),this.body.nodes[h.id]=h,this.body.nodeIndices.push(h.id),this._temporaryBindUI("onTouch",zn(i=this._controlNodeTouch).call(i,this)),this._temporaryBindUI("onTap",(function(){})),this._temporaryBindUI("onHold",(function(){})),this._temporaryBindUI("onDragStart",zn(n=this._controlNodeDragStart).call(n,this)),this._temporaryBindUI("onDrag",zn(o=this._controlNodeDrag).call(o,this)),this._temporaryBindUI("onDragEnd",zn(r=this._controlNodeDragEnd).call(r,this)),this._temporaryBindUI("onMouseMove",(function(){})),this._temporaryBindEvent("beforeDrawing",(function(t){var e=s.edgeType.findBorderPositions(t);!1===a.selected&&(a.x=e.from.x,a.y=e.from.y),!1===h.selected&&(h.x=e.to.x,h.y=e.to.y)})),this.body.emitter.emit("_redraw")}else this.showManipulatorToolbar()}else{var l=this.body.edges[this.edgeBeingEditedId];this._performEditEdge(l.from.id,l.to.id)}}},{key:"deleteSelected",value:function(){var t=this;!0!==this.editMode&&this.enableEditMode(),this._clean(),this.inMode="delete";var e=this.selectionHandler.getSelectedNodeIds(),i=this.selectionHandler.getSelectedEdgeIds(),n=void 0;if(e.length>0){for(var o=0;o<e.length;o++)if(!0===this.body.nodes[e[o]].isCluster)return void alert(this.options.locales[this.options.locale].deleteClusterError||this.options.locales.en.deleteClusterError);"function"==typeof this.options.deleteNode&&(n=this.options.deleteNode)}else i.length>0&&"function"==typeof this.options.deleteEdge&&(n=this.options.deleteEdge);if("function"==typeof n){var r={nodes:e,edges:i};if(2!==n.length)throw new Error("The function for delete does not support two arguments (data, callback)");n(r,(function(e){null!=e&&"delete"===t.inMode?(t.body.data.edges.getDataSet().remove(e.edges),t.body.data.nodes.getDataSet().remove(e.nodes),t.body.emitter.emit("startSimulation"),t.showManipulatorToolbar()):(t.body.emitter.emit("startSimulation"),t.showManipulatorToolbar())}))}else this.body.data.edges.getDataSet().remove(i),this.body.data.nodes.getDataSet().remove(e),this.body.emitter.emit("startSimulation"),this.showManipulatorToolbar()}},{key:"_setup",value:function(){!0===this.options.enabled?(this.guiEnabled=!0,this._createWrappers(),!1===this.editMode?this._createEditButton():this.showManipulatorToolbar()):(this._removeManipulationDOM(),this.guiEnabled=!1)}},{key:"_createWrappers",value:function(){var t,e;(void 0===this.manipulationDiv&&(this.manipulationDiv=document.createElement("div"),this.manipulationDiv.className="vis-manipulation",!0===this.editMode?this.manipulationDiv.style.display="block":this.manipulationDiv.style.display="none",this.canvas.frame.appendChild(this.manipulationDiv)),void 0===this.editModeDiv&&(this.editModeDiv=document.createElement("div"),this.editModeDiv.className="vis-edit-mode",!0===this.editMode?this.editModeDiv.style.display="none":this.editModeDiv.style.display="block",this.canvas.frame.appendChild(this.editModeDiv)),void 0===this.closeDiv)&&(this.closeDiv=document.createElement("button"),this.closeDiv.className="vis-close",this.closeDiv.setAttribute("aria-label",null!==(t=null===(e=this.options.locales[this.options.locale])||void 0===e?void 0:e.close)&&void 0!==t?t:this.options.locales.en.close),this.closeDiv.style.display=this.manipulationDiv.style.display,this.canvas.frame.appendChild(this.closeDiv))}},{key:"_getNewTargetNode",value:function(t,e){var i=nm({},this.options.controlNodeStyle);i.id="targetNode"+Ax(),i.hidden=!1,i.physics=!1,i.x=t,i.y=e;var n=this.body.functions.createNode(i);return n.shape.boundingBox={left:t,right:t,top:e,bottom:e},n}},{key:"_createEditButton",value:function(){var t;this._clean(),this.manipulationDOM={},Ky(this.editModeDiv);var e=this.options.locales[this.options.locale],i=this._createButton("editMode","vis-edit vis-edit-mode",e.edit||this.options.locales.en.edit);this.editModeDiv.appendChild(i),this._bindElementEvents(i,zn(t=this.toggleEditMode).call(t,this))}},{key:"_clean",value:function(){this.inMode=!1,!0===this.guiEnabled&&(Ky(this.editModeDiv),Ky(this.manipulationDiv),this._cleanupDOMEventListeners()),this._cleanupTemporaryNodesAndEdges(),this._unbindTemporaryUIs(),this._unbindTemporaryEvents(),this.body.emitter.emit("restorePhysics")}},{key:"_cleanupDOMEventListeners",value:function(){var t,e,i=aT(ff(t=this._domEventListenerCleanupQueue).call(t,0));try{for(i.s();!(e=i.n()).done;){(0,e.value)()}}catch(t){i.e(t)}finally{i.f()}}},{key:"_removeManipulationDOM",value:function(){this._clean(),Ky(this.manipulationDiv),Ky(this.editModeDiv),Ky(this.closeDiv),this.manipulationDiv&&this.canvas.frame.removeChild(this.manipulationDiv),this.editModeDiv&&this.canvas.frame.removeChild(this.editModeDiv),this.closeDiv&&this.canvas.frame.removeChild(this.closeDiv),this.manipulationDiv=void 0,this.editModeDiv=void 0,this.closeDiv=void 0}},{key:"_createSeperator",value:function(){var t=arguments.length>0&&void 0!==arguments[0]?arguments[0]:1;this.manipulationDOM["seperatorLineDiv"+t]=document.createElement("div"),this.manipulationDOM["seperatorLineDiv"+t].className="vis-separator-line",this.manipulationDiv.appendChild(this.manipulationDOM["seperatorLineDiv"+t])}},{key:"_createAddNodeButton",value:function(t){var e,i=this._createButton("addNode","vis-add",t.addNode||this.options.locales.en.addNode);this.manipulationDiv.appendChild(i),this._bindElementEvents(i,zn(e=this.addNodeMode).call(e,this))}},{key:"_createAddEdgeButton",value:function(t){var e,i=this._createButton("addEdge","vis-connect",t.addEdge||this.options.locales.en.addEdge);this.manipulationDiv.appendChild(i),this._bindElementEvents(i,zn(e=this.addEdgeMode).call(e,this))}},{key:"_createEditNodeButton",value:function(t){var e,i=this._createButton("editNode","vis-edit",t.editNode||this.options.locales.en.editNode);this.manipulationDiv.appendChild(i),this._bindElementEvents(i,zn(e=this.editNode).call(e,this))}},{key:"_createEditEdgeButton",value:function(t){var e,i=this._createButton("editEdge","vis-edit",t.editEdge||this.options.locales.en.editEdge);this.manipulationDiv.appendChild(i),this._bindElementEvents(i,zn(e=this.editEdgeMode).call(e,this))}},{key:"_createDeleteButton",value:function(t){var e,i;i=this.options.rtl?"vis-delete-rtl":"vis-delete";var n=this._createButton("delete",i,t.del||this.options.locales.en.del);this.manipulationDiv.appendChild(n),this._bindElementEvents(n,zn(e=this.deleteSelected).call(e,this))}},{key:"_createBackButton",value:function(t){var e,i=this._createButton("back","vis-back",t.back||this.options.locales.en.back);this.manipulationDiv.appendChild(i),this._bindElementEvents(i,zn(e=this.showManipulatorToolbar).call(e,this))}},{key:"_createButton",value:function(t,e,i){var n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:"vis-label";return this.manipulationDOM[t+"Div"]=document.createElement("button"),this.manipulationDOM[t+"Div"].className="vis-button "+e,this.manipulationDOM[t+"Label"]=document.createElement("div"),this.manipulationDOM[t+"Label"].className=n,this.manipulationDOM[t+"Label"].innerText=i,this.manipulationDOM[t+"Div"].appendChild(this.manipulationDOM[t+"Label"]),this.manipulationDOM[t+"Div"]}},{key:"_createDescription",value:function(t){this.manipulationDOM.descriptionLabel=document.createElement("div"),this.manipulationDOM.descriptionLabel.className="vis-none",this.manipulationDOM.descriptionLabel.innerText=t,this.manipulationDiv.appendChild(this.manipulationDOM.descriptionLabel)}},{key:"_temporaryBindEvent",value:function(t,e){this.temporaryEventFunctions.push({event:t,boundFunction:e}),this.body.emitter.on(t,e)}},{key:"_temporaryBindUI",value:function(t,e){if(void 0===this.body.eventListeners[t])throw new Error("This UI function does not exist. Typo? You tried: "+t+" possible are: "+gv(bu(this.body.eventListeners)));this.temporaryUIFunctions[t]=this.body.eventListeners[t],this.body.eventListeners[t]=e}},{key:"_unbindTemporaryUIs",value:function(){for(var t in this.temporaryUIFunctions)Object.prototype.hasOwnProperty.call(this.temporaryUIFunctions,t)&&(this.body.eventListeners[t]=this.temporaryUIFunctions[t],delete this.temporaryUIFunctions[t]);this.temporaryUIFunctions={}}},{key:"_unbindTemporaryEvents",value:function(){for(var t=0;t<this.temporaryEventFunctions.length;t++){var e=this.temporaryEventFunctions[t].event,i=this.temporaryEventFunctions[t].boundFunction;this.body.emitter.off(e,i)}this.temporaryEventFunctions=[]}},{key:"_bindElementEvents",value:function(t,e){var i=new Wm(t,{});IC(i,e),this._domEventListenerCleanupQueue.push((function(){i.destroy()}));var n=function(t){var i=t.keyCode,n=t.key;"Enter"!==n&&" "!==n&&13!==i&&32!==i||e()};t.addEventListener("keyup",n,!1),this._domEventListenerCleanupQueue.push((function(){t.removeEventListener("keyup",n,!1)}))}},{key:"_cleanupTemporaryNodesAndEdges",value:function(){for(var t=0;t<this.temporaryIds.edges.length;t++){var e;this.body.edges[this.temporaryIds.edges[t]].disconnect(),delete this.body.edges[this.temporaryIds.edges[t]];var i,n=Fp(e=this.body.edgeIndices).call(e,this.temporaryIds.edges[t]);if(-1!==n)ff(i=this.body.edgeIndices).call(i,n,1)}for(var o=0;o<this.temporaryIds.nodes.length;o++){var r;delete this.body.nodes[this.temporaryIds.nodes[o]];var s,a=Fp(r=this.body.nodeIndices).call(r,this.temporaryIds.nodes[o]);if(-1!==a)ff(s=this.body.nodeIndices).call(s,a,1)}this.temporaryIds={nodes:[],edges:[]}}},{key:"_controlNodeTouch",value:function(t){this.selectionHandler.unselectAll(),this.lastTouch=this.body.functions.getPointer(t.center),this.lastTouch.translation=un({},this.body.view.translation)}},{key:"_controlNodeDragStart",value:function(){var t=this.lastTouch,e=this.selectionHandler._pointerToPositionObject(t),i=this.body.nodes[this.temporaryIds.nodes[0]],n=this.body.nodes[this.temporaryIds.nodes[1]],o=this.body.edges[this.edgeBeingEditedId];this.selectedControlNode=void 0;var r=i.isOverlappingWith(e),s=n.isOverlappingWith(e);!0===r?(this.selectedControlNode=i,o.edgeType.from=i):!0===s&&(this.selectedControlNode=n,o.edgeType.to=n),void 0!==this.selectedControlNode&&this.selectionHandler.selectObject(this.selectedControlNode),this.body.emitter.emit("_redraw")}},{key:"_controlNodeDrag",value:function(t){this.body.emitter.emit("disablePhysics");var e=this.body.functions.getPointer(t.center),i=this.canvas.DOMtoCanvas(e);void 0!==this.selectedControlNode?(this.selectedControlNode.x=i.x,this.selectedControlNode.y=i.y):this.interactionHandler.onDrag(t),this.body.emitter.emit("_redraw")}},{key:"_controlNodeDragEnd",value:function(t){var e=this.body.functions.getPointer(t.center),i=this.selectionHandler._pointerToPositionObject(e),n=this.body.edges[this.edgeBeingEditedId];if(void 0!==this.selectedControlNode){this.selectionHandler.unselectAll();for(var o=this.selectionHandler._getAllNodesOverlappingWith(i),r=void 0,s=o.length-1;s>=0;s--)if(o[s]!==this.selectedControlNode.id){r=this.body.nodes[o[s]];break}if(void 0!==r&&void 0!==this.selectedControlNode)if(!0===r.isCluster)alert(this.options.locales[this.options.locale].createEdgeError||this.options.locales.en.createEdgeError);else{var a=this.body.nodes[this.temporaryIds.nodes[0]];this.selectedControlNode.id===a.id?this._performEditEdge(r.id,n.to.id):this._performEditEdge(n.from.id,r.id)}else n.updateEdgeType(),this.body.emitter.emit("restorePhysics");this.body.emitter.emit("_redraw")}}},{key:"_handleConnect",value:function(t){if((new Date).valueOf()-this.touchTime>100){this.lastTouch=this.body.functions.getPointer(t.center),this.lastTouch.translation=un({},this.body.view.translation),this.interactionHandler.drag.pointer=this.lastTouch,this.interactionHandler.drag.translation=this.lastTouch.translation;var e=this.lastTouch,i=this.selectionHandler.getNodeAt(e);if(void 0!==i)if(!0===i.isCluster)alert(this.options.locales[this.options.locale].createEdgeError||this.options.locales.en.createEdgeError);else{var n=this._getNewTargetNode(i.x,i.y);this.body.nodes[n.id]=n,this.body.nodeIndices.push(n.id);var o=this.body.functions.createEdge({id:"connectionEdge"+Ax(),from:i.id,to:n.id,physics:!1,smooth:{enabled:!0,type:"continuous",roundness:.5}});this.body.edges[o.id]=o,this.body.edgeIndices.push(o.id),this.temporaryIds.nodes.push(n.id),this.temporaryIds.edges.push(o.id)}this.touchTime=(new Date).valueOf()}}},{key:"_dragControlNode",value:function(t){var e=this.body.functions.getPointer(t.center),i=this.selectionHandler._pointerToPositionObject(e),n=void 0;void 0!==this.temporaryIds.edges[0]&&(n=this.body.edges[this.temporaryIds.edges[0]].fromId);for(var o=this.selectionHandler._getAllNodesOverlappingWith(i),r=void 0,s=o.length-1;s>=0;s--){var a;if(-1===Fp(a=this.temporaryIds.nodes).call(a,o[s])){r=this.body.nodes[o[s]];break}}if(t.controlEdge={from:n,to:r?r.id:void 0},this.selectionHandler.generateClickEvent("controlNodeDragging",t,e),void 0!==this.temporaryIds.nodes[0]){var h=this.body.nodes[this.temporaryIds.nodes[0]];h.x=this.canvas._XconvertDOMtoCanvas(e.x),h.y=this.canvas._YconvertDOMtoCanvas(e.y),this.body.emitter.emit("_redraw")}else this.interactionHandler.onDrag(t)}},{key:"_finishConnect",value:function(t){var e=this.body.functions.getPointer(t.center),i=this.selectionHandler._pointerToPositionObject(e),n=void 0;void 0!==this.temporaryIds.edges[0]&&(n=this.body.edges[this.temporaryIds.edges[0]].fromId);for(var o=this.selectionHandler._getAllNodesOverlappingWith(i),r=void 0,s=o.length-1;s>=0;s--){var a;if(-1===Fp(a=this.temporaryIds.nodes).call(a,o[s])){r=this.body.nodes[o[s]];break}}this._cleanupTemporaryNodesAndEdges(),void 0!==r&&(!0===r.isCluster?alert(this.options.locales[this.options.locale].createEdgeError||this.options.locales.en.createEdgeError):void 0!==this.body.nodes[n]&&void 0!==this.body.nodes[r.id]&&this._performAddEdge(n,r.id)),t.controlEdge={from:n,to:r?r.id:void 0},this.selectionHandler.generateClickEvent("controlNodeDragEnd",t,e),this.body.emitter.emit("_redraw")}},{key:"_dragStartEdge",value:function(t){var e=this.lastTouch;this.selectionHandler.generateClickEvent("dragStart",t,e,void 0,!0)}},{key:"_performAddNode",value:function(t){var e=this,i={id:Ax(),x:t.pointer.canvas.x,y:t.pointer.canvas.y,label:"new"};if("function"==typeof this.options.addNode){if(2!==this.options.addNode.length)throw this.showManipulatorToolbar(),new Error("The function for add does not support two arguments (data,callback)");this.options.addNode(i,(function(t){null!=t&&"addNode"===e.inMode&&e.body.data.nodes.getDataSet().add(t),e.showManipulatorToolbar()}))}else this.body.data.nodes.getDataSet().add(i),this.showManipulatorToolbar()}},{key:"_performAddEdge",value:function(t,e){var i=this,n={from:t,to:e};if("function"==typeof this.options.addEdge){if(2!==this.options.addEdge.length)throw new Error("The function for connect does not support two arguments (data,callback)");this.options.addEdge(n,(function(t){null!=t&&"addEdge"===i.inMode&&(i.body.data.edges.getDataSet().add(t),i.selectionHandler.unselectAll(),i.showManipulatorToolbar())}))}else this.body.data.edges.getDataSet().add(n),this.selectionHandler.unselectAll(),this.showManipulatorToolbar()}},{key:"_performEditEdge",value:function(t,e){var i=this,n={id:this.edgeBeingEditedId,from:t,to:e,label:this.body.data.edges.get(this.edgeBeingEditedId).label},o=this.options.editEdge;if("object"===Qc(o)&&(o=o.editWithoutDrag),"function"==typeof o){if(2!==o.length)throw new Error("The function for edit does not support two arguments (data, callback)");o(n,(function(t){null==t||"editEdge"!==i.inMode?(i.body.edges[n.id].updateEdgeType(),i.body.emitter.emit("_redraw"),i.showManipulatorToolbar()):(i.body.data.edges.getDataSet().update(t),i.selectionHandler.unselectAll(),i.showManipulatorToolbar())}))}else this.body.data.edges.getDataSet().update(n),this.selectionHandler.unselectAll(),this.showManipulatorToolbar()}}]),t}(),dT="string",cT="boolean",uT="number",fT="array",pT="object",vT=["arrow","bar","box","circle","crow","curve","diamond","image","inv_curve","inv_triangle","triangle","vee"],gT={borderWidth:{number:uT},borderWidthSelected:{number:uT,undefined:"undefined"},brokenImage:{string:dT,undefined:"undefined"},chosen:{label:{boolean:cT,function:"function"},node:{boolean:cT,function:"function"},__type__:{object:pT,boolean:cT}},color:{border:{string:dT},background:{string:dT},highlight:{border:{string:dT},background:{string:dT},__type__:{object:pT,string:dT}},hover:{border:{string:dT},background:{string:dT},__type__:{object:pT,string:dT}},__type__:{object:pT,string:dT}},opacity:{number:uT,undefined:"undefined"},fixed:{x:{boolean:cT},y:{boolean:cT},__type__:{object:pT,boolean:cT}},font:{align:{string:dT},color:{string:dT},size:{number:uT},face:{string:dT},background:{string:dT},strokeWidth:{number:uT},strokeColor:{string:dT},vadjust:{number:uT},multi:{boolean:cT,string:dT},bold:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},boldital:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},ital:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},mono:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},__type__:{object:pT,string:dT}},group:{string:dT,number:uT,undefined:"undefined"},heightConstraint:{minimum:{number:uT},valign:{string:dT},__type__:{object:pT,boolean:cT,number:uT}},hidden:{boolean:cT},icon:{face:{string:dT},code:{string:dT},size:{number:uT},color:{string:dT},weight:{string:dT,number:uT},__type__:{object:pT}},id:{string:dT,number:uT},image:{selected:{string:dT,undefined:"undefined"},unselected:{string:dT,undefined:"undefined"},__type__:{object:pT,string:dT}},imagePadding:{top:{number:uT},right:{number:uT},bottom:{number:uT},left:{number:uT},__type__:{object:pT,number:uT}},label:{string:dT,undefined:"undefined"},labelHighlightBold:{boolean:cT},level:{number:uT,undefined:"undefined"},margin:{top:{number:uT},right:{number:uT},bottom:{number:uT},left:{number:uT},__type__:{object:pT,number:uT}},mass:{number:uT},physics:{boolean:cT},scaling:{min:{number:uT},max:{number:uT},label:{enabled:{boolean:cT},min:{number:uT},max:{number:uT},maxVisible:{number:uT},drawThreshold:{number:uT},__type__:{object:pT,boolean:cT}},customScalingFunction:{function:"function"},__type__:{object:pT}},shadow:{enabled:{boolean:cT},color:{string:dT},size:{number:uT},x:{number:uT},y:{number:uT},__type__:{object:pT,boolean:cT}},shape:{string:["custom","ellipse","circle","database","box","text","image","circularImage","diamond","dot","star","triangle","triangleDown","square","icon","hexagon"]},ctxRenderer:{function:"function"},shapeProperties:{borderDashes:{boolean:cT,array:fT},borderRadius:{number:uT},interpolation:{boolean:cT},useImageSize:{boolean:cT},useBorderWithImage:{boolean:cT},coordinateOrigin:{string:["center","top-left"]},__type__:{object:pT}},size:{number:uT},title:{string:dT,dom:"dom",undefined:"undefined"},value:{number:uT,undefined:"undefined"},widthConstraint:{minimum:{number:uT},maximum:{number:uT},__type__:{object:pT,boolean:cT,number:uT}},x:{number:uT},y:{number:uT},__type__:{object:pT}},yT={configure:{enabled:{boolean:cT},filter:{boolean:cT,string:dT,array:fT,function:"function"},container:{dom:"dom"},showButton:{boolean:cT},__type__:{object:pT,boolean:cT,string:dT,array:fT,function:"function"}},edges:{arrows:{to:{enabled:{boolean:cT},scaleFactor:{number:uT},type:{string:vT},imageHeight:{number:uT},imageWidth:{number:uT},src:{string:dT},__type__:{object:pT,boolean:cT}},middle:{enabled:{boolean:cT},scaleFactor:{number:uT},type:{string:vT},imageWidth:{number:uT},imageHeight:{number:uT},src:{string:dT},__type__:{object:pT,boolean:cT}},from:{enabled:{boolean:cT},scaleFactor:{number:uT},type:{string:vT},imageWidth:{number:uT},imageHeight:{number:uT},src:{string:dT},__type__:{object:pT,boolean:cT}},__type__:{string:["from","to","middle"],object:pT}},endPointOffset:{from:{number:uT},to:{number:uT},__type__:{object:pT,number:uT}},arrowStrikethrough:{boolean:cT},background:{enabled:{boolean:cT},color:{string:dT},size:{number:uT},dashes:{boolean:cT,array:fT},__type__:{object:pT,boolean:cT}},chosen:{label:{boolean:cT,function:"function"},edge:{boolean:cT,function:"function"},__type__:{object:pT,boolean:cT}},color:{color:{string:dT},highlight:{string:dT},hover:{string:dT},inherit:{string:["from","to","both"],boolean:cT},opacity:{number:uT},__type__:{object:pT,string:dT}},dashes:{boolean:cT,array:fT},font:{color:{string:dT},size:{number:uT},face:{string:dT},background:{string:dT},strokeWidth:{number:uT},strokeColor:{string:dT},align:{string:["horizontal","top","middle","bottom"]},vadjust:{number:uT},multi:{boolean:cT,string:dT},bold:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},boldital:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},ital:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},mono:{color:{string:dT},size:{number:uT},face:{string:dT},mod:{string:dT},vadjust:{number:uT},__type__:{object:pT,string:dT}},__type__:{object:pT,string:dT}},hidden:{boolean:cT},hoverWidth:{function:"function",number:uT},label:{string:dT,undefined:"undefined"},labelHighlightBold:{boolean:cT},length:{number:uT,undefined:"undefined"},physics:{boolean:cT},scaling:{min:{number:uT},max:{number:uT},label:{enabled:{boolean:cT},min:{number:uT},max:{number:uT},maxVisible:{number:uT},drawThreshold:{number:uT},__type__:{object:pT,boolean:cT}},customScalingFunction:{function:"function"},__type__:{object:pT}},selectionWidth:{function:"function",number:uT},selfReferenceSize:{number:uT},selfReference:{size:{number:uT},angle:{number:uT},renderBehindTheNode:{boolean:cT},__type__:{object:pT}},shadow:{enabled:{boolean:cT},color:{string:dT},size:{number:uT},x:{number:uT},y:{number:uT},__type__:{object:pT,boolean:cT}},smooth:{enabled:{boolean:cT},type:{string:["dynamic","continuous","discrete","diagonalCross","straightCross","horizontal","vertical","curvedCW","curvedCCW","cubicBezier"]},roundness:{number:uT},forceDirection:{string:["horizontal","vertical","none"],boolean:cT},__type__:{object:pT,boolean:cT}},title:{string:dT,undefined:"undefined"},width:{number:uT},widthConstraint:{maximum:{number:uT},__type__:{object:pT,boolean:cT,number:uT}},value:{number:uT,undefined:"undefined"},__type__:{object:pT}},groups:{useDefaultGroups:{boolean:cT},__any__:gT,__type__:{object:pT}},interaction:{dragNodes:{boolean:cT},dragView:{boolean:cT},hideEdgesOnDrag:{boolean:cT},hideEdgesOnZoom:{boolean:cT},hideNodesOnDrag:{boolean:cT},hover:{boolean:cT},keyboard:{enabled:{boolean:cT},speed:{x:{number:uT},y:{number:uT},zoom:{number:uT},__type__:{object:pT}},bindToWindow:{boolean:cT},autoFocus:{boolean:cT},__type__:{object:pT,boolean:cT}},multiselect:{boolean:cT},navigationButtons:{boolean:cT},selectable:{boolean:cT},selectConnectedEdges:{boolean:cT},hoverConnectedEdges:{boolean:cT},tooltipDelay:{number:uT},zoomView:{boolean:cT},zoomSpeed:{number:uT},__type__:{object:pT}},layout:{randomSeed:{undefined:"undefined",number:uT,string:dT},improvedLayout:{boolean:cT},clusterThreshold:{number:uT},hierarchical:{enabled:{boolean:cT},levelSeparation:{number:uT},nodeSpacing:{number:uT},treeSpacing:{number:uT},blockShifting:{boolean:cT},edgeMinimization:{boolean:cT},parentCentralization:{boolean:cT},direction:{string:["UD","DU","LR","RL"]},sortMethod:{string:["hubsize","directed"]},shakeTowards:{string:["leaves","roots"]},__type__:{object:pT,boolean:cT}},__type__:{object:pT}},manipulation:{enabled:{boolean:cT},initiallyActive:{boolean:cT},addNode:{boolean:cT,function:"function"},addEdge:{boolean:cT,function:"function"},editNode:{function:"function"},editEdge:{editWithoutDrag:{function:"function"},__type__:{object:pT,boolean:cT,function:"function"}},deleteNode:{boolean:cT,function:"function"},deleteEdge:{boolean:cT,function:"function"},controlNodeStyle:gT,__type__:{object:pT,boolean:cT}},nodes:gT,physics:{enabled:{boolean:cT},barnesHut:{theta:{number:uT},gravitationalConstant:{number:uT},centralGravity:{number:uT},springLength:{number:uT},springConstant:{number:uT},damping:{number:uT},avoidOverlap:{number:uT},__type__:{object:pT}},forceAtlas2Based:{theta:{number:uT},gravitationalConstant:{number:uT},centralGravity:{number:uT},springLength:{number:uT},springConstant:{number:uT},damping:{number:uT},avoidOverlap:{number:uT},__type__:{object:pT}},repulsion:{centralGravity:{number:uT},springLength:{number:uT},springConstant:{number:uT},nodeDistance:{number:uT},damping:{number:uT},__type__:{object:pT}},hierarchicalRepulsion:{centralGravity:{number:uT},springLength:{number:uT},springConstant:{number:uT},nodeDistance:{number:uT},damping:{number:uT},avoidOverlap:{number:uT},__type__:{object:pT}},maxVelocity:{number:uT},minVelocity:{number:uT},solver:{string:["barnesHut","repulsion","hierarchicalRepulsion","forceAtlas2Based"]},stabilization:{enabled:{boolean:cT},iterations:{number:uT},updateInterval:{number:uT},onlyDynamicEdges:{boolean:cT},fit:{boolean:cT},__type__:{object:pT,boolean:cT}},timestep:{number:uT},adaptiveTimestep:{boolean:cT},wind:{x:{number:uT},y:{number:uT},__type__:{object:pT}},__type__:{object:pT,boolean:cT}},autoResize:{boolean:cT},clickToUse:{boolean:cT},locale:{string:dT},locales:{__any__:{any:"any"},__type__:{object:pT}},height:{string:dT},width:{string:dT},__type__:{object:pT}},mT={nodes:{borderWidth:[1,0,10,1],borderWidthSelected:[2,0,10,1],color:{border:["color","#2B7CE9"],background:["color","#97C2FC"],highlight:{border:["color","#2B7CE9"],background:["color","#D2E5FF"]},hover:{border:["color","#2B7CE9"],background:["color","#D2E5FF"]}},opacity:[0,0,1,.1],fixed:{x:!1,y:!1},font:{color:["color","#343434"],size:[14,0,100,1],face:["arial","verdana","tahoma"],background:["color","none"],strokeWidth:[0,0,50,1],strokeColor:["color","#ffffff"]},hidden:!1,labelHighlightBold:!0,physics:!0,scaling:{min:[10,0,200,1],max:[30,0,200,1],label:{enabled:!1,min:[14,0,200,1],max:[30,0,200,1],maxVisible:[30,0,200,1],drawThreshold:[5,0,20,1]}},shadow:{enabled:!1,color:"rgba(0,0,0,0.5)",size:[10,0,20,1],x:[5,-30,30,1],y:[5,-30,30,1]},shape:["ellipse","box","circle","database","diamond","dot","square","star","text","triangle","triangleDown","hexagon"],shapeProperties:{borderDashes:!1,borderRadius:[6,0,20,1],interpolation:!0,useImageSize:!1},size:[25,0,200,1]},edges:{arrows:{to:{enabled:!1,scaleFactor:[1,0,3,.05],type:"arrow"},middle:{enabled:!1,scaleFactor:[1,0,3,.05],type:"arrow"},from:{enabled:!1,scaleFactor:[1,0,3,.05],type:"arrow"}},endPointOffset:{from:[0,-10,10,1],to:[0,-10,10,1]},arrowStrikethrough:!0,color:{color:["color","#848484"],highlight:["color","#848484"],hover:["color","#848484"],inherit:["from","to","both",!0,!1],opacity:[1,0,1,.05]},dashes:!1,font:{color:["color","#343434"],size:[14,0,100,1],face:["arial","verdana","tahoma"],background:["color","none"],strokeWidth:[2,0,50,1],strokeColor:["color","#ffffff"],align:["horizontal","top","middle","bottom"]},hidden:!1,hoverWidth:[1.5,0,5,.1],labelHighlightBold:!0,physics:!0,scaling:{min:[1,0,100,1],max:[15,0,100,1],label:{enabled:!0,min:[14,0,200,1],max:[30,0,200,1],maxVisible:[30,0,200,1],drawThreshold:[5,0,20,1]}},selectionWidth:[1.5,0,5,.1],selfReferenceSize:[20,0,200,1],selfReference:{size:[20,0,200,1],angle:[Math.PI/2,-6*Math.PI,6*Math.PI,Math.PI/8],renderBehindTheNode:!0},shadow:{enabled:!1,color:"rgba(0,0,0,0.5)",size:[10,0,20,1],x:[5,-30,30,1],y:[5,-30,30,1]},smooth:{enabled:!0,type:["dynamic","continuous","discrete","diagonalCross","straightCross","horizontal","vertical","curvedCW","curvedCCW","cubicBezier"],forceDirection:["horizontal","vertical","none"],roundness:[.5,0,1,.05]},width:[1,0,30,1]},layout:{hierarchical:{enabled:!1,levelSeparation:[150,20,500,5],nodeSpacing:[100,20,500,5],treeSpacing:[200,20,500,5],blockShifting:!0,edgeMinimization:!0,parentCentralization:!0,direction:["UD","DU","LR","RL"],sortMethod:["hubsize","directed"],shakeTowards:["leaves","roots"]}},interaction:{dragNodes:!0,dragView:!0,hideEdgesOnDrag:!1,hideEdgesOnZoom:!1,hideNodesOnDrag:!1,hover:!1,keyboard:{enabled:!1,speed:{x:[10,0,40,1],y:[10,0,40,1],zoom:[.02,0,.1,.005]},bindToWindow:!0,autoFocus:!0},multiselect:!1,navigationButtons:!1,selectable:!0,selectConnectedEdges:!0,hoverConnectedEdges:!0,tooltipDelay:[300,0,1e3,25],zoomView:!0,zoomSpeed:[1,.1,2,.1]},manipulation:{enabled:!1,initiallyActive:!1},physics:{enabled:!0,barnesHut:{theta:[.5,.1,1,.05],gravitationalConstant:[-2e3,-3e4,0,50],centralGravity:[.3,0,10,.05],springLength:[95,0,500,5],springConstant:[.04,0,1.2,.005],damping:[.09,0,1,.01],avoidOverlap:[0,0,1,.01]},forceAtlas2Based:{theta:[.5,.1,1,.05],gravitationalConstant:[-50,-500,0,1],centralGravity:[.01,0,1,.005],springLength:[95,0,500,5],springConstant:[.08,0,1.2,.005],damping:[.4,0,1,.01],avoidOverlap:[0,0,1,.01]},repulsion:{centralGravity:[.2,0,10,.05],springLength:[200,0,500,5],springConstant:[.05,0,1.2,.005],nodeDistance:[100,0,500,5],damping:[.09,0,1,.01]},hierarchicalRepulsion:{centralGravity:[.2,0,10,.05],springLength:[100,0,500,5],springConstant:[.01,0,1.2,.005],nodeDistance:[120,0,500,5],damping:[.09,0,1,.01],avoidOverlap:[0,0,1,.01]},maxVelocity:[50,0,150,1],minVelocity:[.1,.01,.5,.01],solver:["barnesHut","forceAtlas2Based","repulsion","hierarchicalRepulsion"],timestep:[.5,.01,1,.01],wind:{x:[0,-10,10,.1],y:[0,-10,10,.1]}}},bT=function(t,e,i){var n;return!(!Nf(t).call(t,"physics")||!Nf(n=mT.physics.solver).call(n,e)||i.physics.solver===e||"wind"===e)},wT=Object.freeze({__proto__:null,configuratorHideOption:bT,allOptions:yT,configureOptions:mT}),kT=function(){function t(){Yd(this,t)}return Kd(t,[{key:"getDistances",value:function(t,e,i){for(var n={},o=t.edges,r=0;r<e.length;r++){var s={};n[e[r]]=s;for(var a=0;a<e.length;a++)s[e[a]]=r==a?0:1e9}for(var h=0;h<i.length;h++){var l=o[i[h]];!0===l.connected&&void 0!==n[l.fromId]&&void 0!==n[l.toId]&&(n[l.fromId][l.toId]=1,n[l.toId][l.fromId]=1)}for(var d=e.length,c=0;c<d;c++)for(var u=e[c],f=n[u],p=0;p<d-1;p++)for(var v=e[p],g=n[v],y=p+1;y<d;y++){var m=e[y],b=n[m],w=Math.min(g[m],g[u]+f[m]);g[m]=w,b[v]=w}return n}}]),t}(),_T=function(){function t(e,i,n){Yd(this,t),this.body=e,this.springLength=i,this.springConstant=n,this.distanceSolver=new kT}return Kd(t,[{key:"setOptions",value:function(t){t&&(t.springLength&&(this.springLength=t.springLength),t.springConstant&&(this.springConstant=t.springConstant))}},{key:"solve",value:function(t,e){var i=arguments.length>2&&void 0!==arguments[2]&&arguments[2],n=this.distanceSolver.getDistances(this.body,t,e);this._createL_matrix(n),this._createK_matrix(n),this._createE_matrix();for(var o=.01,r=1,s=0,a=Math.max(1e3,Math.min(10*this.body.nodeIndices.length,6e3)),h=5,l=1e9,d=0,c=0,u=0,f=0,p=0;l>o&&s<a;){s+=1;var v=this._getHighestEnergyNode(i),g=Kc(v,4);for(d=g[0],l=g[1],c=g[2],u=g[3],f=l,p=0;f>r&&p<h;){p+=1,this._moveNode(d,c,u);var y=this._getEnergy(d),m=Kc(y,3);f=m[0],c=m[1],u=m[2]}}}},{key:"_getHighestEnergyNode",value:function(t){for(var e=this.body.nodeIndices,i=this.body.nodes,n=0,o=e[0],r=0,s=0,a=0;a<e.length;a++){var h=e[a];if(!0!==i[h].predefinedPosition||!0===i[h].isCluster&&!0===t||!0!==i[h].options.fixed.x||!0!==i[h].options.fixed.y){var l=Kc(this._getEnergy(h),3),d=l[0],c=l[1],u=l[2];n<d&&(n=d,o=h,r=c,s=u)}}return[o,n,r,s]}},{key:"_getEnergy",value:function(t){var e=Kc(this.E_sums[t],2),i=e[0],n=e[1];return[Math.sqrt(Math.pow(i,2)+Math.pow(n,2)),i,n]}},{key:"_moveNode",value:function(t,e,i){for(var n=this.body.nodeIndices,o=this.body.nodes,r=0,s=0,a=0,h=o[t].x,l=o[t].y,d=this.K_matrix[t],c=this.L_matrix[t],u=0;u<n.length;u++){var f=n[u];if(f!==t){var p=o[f].x,v=o[f].y,g=d[f],y=c[f],m=1/Math.pow(Math.pow(h-p,2)+Math.pow(l-v,2),1.5);r+=g*(1-y*Math.pow(l-v,2)*m),s+=g*(y*(h-p)*(l-v)*m),a+=g*(1-y*Math.pow(h-p,2)*m)}}var b=(e/r+i/s)/(s/r-a/s),w=-(s*b+e)/r;o[t].x+=w,o[t].y+=b,this._updateE_matrix(t)}},{key:"_createL_matrix",value:function(t){var e=this.body.nodeIndices,i=this.springLength;this.L_matrix=[];for(var n=0;n<e.length;n++){this.L_matrix[e[n]]={};for(var o=0;o<e.length;o++)this.L_matrix[e[n]][e[o]]=i*t[e[n]][e[o]]}}},{key:"_createK_matrix",value:function(t){var e=this.body.nodeIndices,i=this.springConstant;this.K_matrix=[];for(var n=0;n<e.length;n++){this.K_matrix[e[n]]={};for(var o=0;o<e.length;o++)this.K_matrix[e[n]][e[o]]=i*Math.pow(t[e[n]][e[o]],-2)}}},{key:"_createE_matrix",value:function(){var t=this.body.nodeIndices,e=this.body.nodes;this.E_matrix={},this.E_sums={};for(var i=0;i<t.length;i++)this.E_matrix[t[i]]=[];for(var n=0;n<t.length;n++){for(var o=t[n],r=e[o].x,s=e[o].y,a=0,h=0,l=n;l<t.length;l++){var d=t[l];if(d!==o){var c=e[d].x,u=e[d].y,f=1/Math.sqrt(Math.pow(r-c,2)+Math.pow(s-u,2));this.E_matrix[o][l]=[this.K_matrix[o][d]*(r-c-this.L_matrix[o][d]*(r-c)*f),this.K_matrix[o][d]*(s-u-this.L_matrix[o][d]*(s-u)*f)],this.E_matrix[d][n]=this.E_matrix[o][l],a+=this.E_matrix[o][l][0],h+=this.E_matrix[o][l][1]}}this.E_sums[o]=[a,h]}}},{key:"_updateE_matrix",value:function(t){for(var e=this.body.nodeIndices,i=this.body.nodes,n=this.E_matrix[t],o=this.K_matrix[t],r=this.L_matrix[t],s=i[t].x,a=i[t].y,h=0,l=0,d=0;d<e.length;d++){var c=e[d];if(c!==t){var u=n[d],f=u[0],p=u[1],v=i[c].x,g=i[c].y,y=1/Math.sqrt(Math.pow(s-v,2)+Math.pow(a-g,2)),m=o[c]*(s-v-r[c]*(s-v)*y),b=o[c]*(a-g-r[c]*(a-g)*y);n[d]=[m,b],h+=m,l+=b;var w=this.E_sums[c];w[0]+=m-f,w[1]+=b-p}}this.E_sums[t]=[h,l]}}]),t}();function xT(t,e,i){var n,o,r,s,a=this;if(!(this instanceof xT))throw new SyntaxError("Constructor must be called with the new operator");this.options={},this.defaultOptions={locale:"en",locales:Tb,clickToUse:!1},un(this.options,this.defaultOptions),this.body={container:t,nodes:{},nodeIndices:[],edges:{},edgeIndices:[],emitter:{on:zn(n=this.on).call(n,this),off:zn(o=this.off).call(o,this),emit:zn(r=this.emit).call(r,this),once:zn(s=this.once).call(s,this)},eventListeners:{onTap:function(){},onTouch:function(){},onDoubleTap:function(){},onHold:function(){},onDragStart:function(){},onDrag:function(){},onDragEnd:function(){},onMouseWheel:function(){},onPinch:function(){},onMouseMove:function(){},onRelease:function(){},onContext:function(){}},data:{nodes:null,edges:null},functions:{createNode:function(){},createEdge:function(){},getPointer:function(){}},modules:{},view:{scale:1,translation:{x:0,y:0}},selectionBox:{show:!1,position:{start:{x:0,y:0},end:{x:0,y:0}}}},this.bindEventListeners(),this.images=new Pb((function(){return a.body.emitter.emit("_requestRedraw")})),this.groups=new tk,this.canvas=new zC(this.body),this.selectionHandler=new HS(this.body,this.canvas),this.interactionHandler=new WC(this.body,this.canvas,this.selectionHandler),this.view=new FC(this.body,this.canvas),this.renderer=new PC(this.body,this.canvas),this.physics=new xC(this.body),this.layoutEngine=new sT(this.body),this.clustering=new SC(this.body),this.manipulation=new lT(this.body,this.canvas,this.selectionHandler,this.interactionHandler),this.nodesHandler=new gO(this.body,this.images,this.groups,this.layoutEngine),this.edgesHandler=new uC(this.body,this.images,this.groups),this.body.modules.kamadaKawai=new _T(this.body,150,.05),this.body.modules.clustering=this.clustering,this.canvas._create(),this.setOptions(i),this.setData(e)}function ET(t){for(var e in t)Object.prototype.hasOwnProperty.call(t,e)&&(t[e].redundant=t[e].used,t[e].used=[])}function OT(t){for(var e in t)if(Object.prototype.hasOwnProperty.call(t,e)&&t[e].redundant){for(var i=0;i<t[e].redundant.length;i++)t[e].redundant[i].parentNode.removeChild(t[e].redundant[i]);t[e].redundant=[]}}function CT(t,e,i){var n;return Object.prototype.hasOwnProperty.call(e,t)?e[t].redundant.length>0?(n=e[t].redundant[0],e[t].redundant.shift()):(n=document.createElementNS("http://www.w3.org/2000/svg",t),i.appendChild(n)):(n=document.createElementNS("http://www.w3.org/2000/svg",t),e[t]={used:[],redundant:[]},i.appendChild(n)),e[t].used.push(n),n}Wn(xT.prototype),xT.prototype.setOptions=function(t){var e=this;if(null===t&&(t=void 0),void 0!==t){!0===Um.validate(t,yT)&&console.error("%cErrors have been found in the supplied options object.",Vm);if(em(["locale","locales","clickToUse"],this.options,t),void 0!==t.locale&&(t.locale=function(t,e){try{var i=Kc(e.split(/[-_ /]/,2),2),n=i[0],o=i[1],r=null!=n?n.toLowerCase():null,s=null!=o?o.toUpperCase():null;if(r&&s){var a,h=r+"-"+s;if(Object.prototype.hasOwnProperty.call(t,h))return h;console.warn(su(a="Unknown variant ".concat(s," of language ")).call(a,r,"."))}if(r){var l=r;if(Object.prototype.hasOwnProperty.call(t,l))return l;console.warn("Unknown language ".concat(r))}return console.warn("Unknown locale ".concat(e,", falling back to English.")),"en"}catch(t){return console.error(t),console.warn("Unexpected error while normalizing locale ".concat(e,", falling back to English.")),"en"}}(t.locales||this.options.locales,t.locale)),t=this.layoutEngine.setOptions(t.layout,t),this.canvas.setOptions(t),this.groups.setOptions(t.groups),this.nodesHandler.setOptions(t.nodes),this.edgesHandler.setOptions(t.edges),this.physics.setOptions(t.physics),this.manipulation.setOptions(t.manipulation,t,this.options),this.interactionHandler.setOptions(t.interaction),this.renderer.setOptions(t.interaction),this.selectionHandler.setOptions(t.interaction),void 0!==t.groups&&this.body.emitter.emit("refreshNodes"),"configure"in t&&(this.configurator||(this.configurator=new Hm(this,this.body.container,mT,this.canvas.pixelRatio,bT)),this.configurator.setOptions(t.configure)),this.configurator&&!0===this.configurator.options.enabled){var i={nodes:{},edges:{},layout:{},interaction:{},manipulation:{},physics:{},global:{}};nm(i.nodes,this.nodesHandler.options),nm(i.edges,this.edgesHandler.options),nm(i.layout,this.layoutEngine.options),nm(i.interaction,this.selectionHandler.options),nm(i.interaction,this.renderer.options),nm(i.interaction,this.interactionHandler.options),nm(i.manipulation,this.manipulation.options),nm(i.physics,this.physics.options),nm(i.global,this.canvas.options),nm(i.global,this.options),this.configurator.setModuleOptions(i)}void 0!==t.clickToUse?!0===t.clickToUse?void 0===this.activator&&(this.activator=new Rm(this.canvas.frame),this.activator.on("change",(function(){e.body.emitter.emit("activate")}))):(void 0!==this.activator&&(this.activator.destroy(),delete this.activator),this.body.emitter.emit("activate")):this.body.emitter.emit("activate"),this.canvas.setSize(),this.body.emitter.emit("startSimulation")}},xT.prototype._updateVisibleIndices=function(){var t=this.body.nodes,e=this.body.edges;for(var i in this.body.nodeIndices=[],this.body.edgeIndices=[],t)Object.prototype.hasOwnProperty.call(t,i)&&(this.clustering._isClusteredNode(i)||!1!==t[i].options.hidden||this.body.nodeIndices.push(t[i].id));for(var n in e)if(Object.prototype.hasOwnProperty.call(e,n)){var o=e[n],r=t[o.fromId],s=t[o.toId],a=void 0!==r&&void 0!==s;!this.clustering._isClusteredEdge(n)&&!1===o.options.hidden&&a&&!1===r.options.hidden&&!1===s.options.hidden&&this.body.edgeIndices.push(o.id)}},xT.prototype.bindEventListeners=function(){var t=this;this.body.emitter.on("_dataChanged",(function(){t.edgesHandler._updateState(),t.body.emitter.emit("_dataUpdated")})),this.body.emitter.on("_dataUpdated",(function(){t.clustering._updateState(),t._updateVisibleIndices(),t._updateValueRange(t.body.nodes),t._updateValueRange(t.body.edges),t.body.emitter.emit("startSimulation"),t.body.emitter.emit("_requestRedraw")}))},xT.prototype.setData=function(t){if(this.body.emitter.emit("resetPhysics"),this.body.emitter.emit("_resetData"),this.selectionHandler.unselectAll(),t&&t.dot&&(t.nodes||t.edges))throw new SyntaxError('Data must contain either parameter "dot" or  parameter pair "nodes" and "edges", but not both.');if(this.setOptions(t&&t.options),t&&t.dot){console.warn("The dot property has been deprecated. Please use the static convertDot method to convert DOT into vis.network format and use the normal data format with nodes and edges. This converter is used like this: var data = vis.network.convertDot(dotString);");var e=Eb(t.dot);this.setData(e)}else if(t&&t.gephi){console.warn("The gephi property has been deprecated. Please use the static convertGephi method to convert gephi into vis.network format and use the normal data format with nodes and edges. This converter is used like this: var data = vis.network.convertGephi(gephiJson);");var i=Cb(t.gephi);this.setData(i)}else this.nodesHandler.setData(t&&t.nodes,!0),this.edgesHandler.setData(t&&t.edges,!0),this.body.emitter.emit("_dataChanged"),this.body.emitter.emit("_dataLoaded"),this.body.emitter.emit("initPhysics")},xT.prototype.destroy=function(){for(var t in this.body.emitter.emit("destroy"),this.body.emitter.off(),this.off(),delete this.groups,delete this.canvas,delete this.selectionHandler,delete this.interactionHandler,delete this.view,delete this.renderer,delete this.physics,delete this.layoutEngine,delete this.clustering,delete this.manipulation,delete this.nodesHandler,delete this.edgesHandler,delete this.configurator,delete this.images,this.body.nodes)Object.prototype.hasOwnProperty.call(this.body.nodes,t)&&delete this.body.nodes[t];for(var e in this.body.edges)Object.prototype.hasOwnProperty.call(this.body.edges,e)&&delete this.body.edges[e];Ky(this.body.container)},xT.prototype._updateValueRange=function(t){var e,i=void 0,n=void 0,o=0;for(e in t)if(Object.prototype.hasOwnProperty.call(t,e)){var r=t[e].getValue();void 0!==r&&(i=void 0===i?r:Math.min(r,i),n=void 0===n?r:Math.max(r,n),o+=r)}if(void 0!==i&&void 0!==n)for(e in t)Object.prototype.hasOwnProperty.call(t,e)&&t[e].setValueRange(i,n,o)},xT.prototype.isActive=function(){return!this.activator||this.activator.active},xT.prototype.setSize=function(){return this.canvas.setSize.apply(this.canvas,arguments)},xT.prototype.canvasToDOM=function(){return this.canvas.canvasToDOM.apply(this.canvas,arguments)},xT.prototype.DOMtoCanvas=function(){return this.canvas.DOMtoCanvas.apply(this.canvas,arguments)},xT.prototype.findNode=function(){return this.clustering.findNode.apply(this.clustering,arguments)},xT.prototype.isCluster=function(){return this.clustering.isCluster.apply(this.clustering,arguments)},xT.prototype.openCluster=function(){return this.clustering.openCluster.apply(this.clustering,arguments)},xT.prototype.cluster=function(){return this.clustering.cluster.apply(this.clustering,arguments)},xT.prototype.getNodesInCluster=function(){return this.clustering.getNodesInCluster.apply(this.clustering,arguments)},xT.prototype.clusterByConnection=function(){return this.clustering.clusterByConnection.apply(this.clustering,arguments)},xT.prototype.clusterByHubsize=function(){return this.clustering.clusterByHubsize.apply(this.clustering,arguments)},xT.prototype.updateClusteredNode=function(){return this.clustering.updateClusteredNode.apply(this.clustering,arguments)},xT.prototype.getClusteredEdges=function(){return this.clustering.getClusteredEdges.apply(this.clustering,arguments)},xT.prototype.getBaseEdge=function(){return this.clustering.getBaseEdge.apply(this.clustering,arguments)},xT.prototype.getBaseEdges=function(){return this.clustering.getBaseEdges.apply(this.clustering,arguments)},xT.prototype.updateEdge=function(){return this.clustering.updateEdge.apply(this.clustering,arguments)},xT.prototype.clusterOutliers=function(){return this.clustering.clusterOutliers.apply(this.clustering,arguments)},xT.prototype.getSeed=function(){return this.layoutEngine.getSeed.apply(this.layoutEngine,arguments)},xT.prototype.enableEditMode=function(){return this.manipulation.enableEditMode.apply(this.manipulation,arguments)},xT.prototype.disableEditMode=function(){return this.manipulation.disableEditMode.apply(this.manipulation,arguments)},xT.prototype.addNodeMode=function(){return this.manipulation.addNodeMode.apply(this.manipulation,arguments)},xT.prototype.editNode=function(){return this.manipulation.editNode.apply(this.manipulation,arguments)},xT.prototype.editNodeMode=function(){return console.warn("Deprecated: Please use editNode instead of editNodeMode."),this.manipulation.editNode.apply(this.manipulation,arguments)},xT.prototype.addEdgeMode=function(){return this.manipulation.addEdgeMode.apply(this.manipulation,arguments)},xT.prototype.editEdgeMode=function(){return this.manipulation.editEdgeMode.apply(this.manipulation,arguments)},xT.prototype.deleteSelected=function(){return this.manipulation.deleteSelected.apply(this.manipulation,arguments)},xT.prototype.getPositions=function(){return this.nodesHandler.getPositions.apply(this.nodesHandler,arguments)},xT.prototype.getPosition=function(){return this.nodesHandler.getPosition.apply(this.nodesHandler,arguments)},xT.prototype.storePositions=function(){return this.nodesHandler.storePositions.apply(this.nodesHandler,arguments)},xT.prototype.moveNode=function(){return this.nodesHandler.moveNode.apply(this.nodesHandler,arguments)},xT.prototype.getBoundingBox=function(){return this.nodesHandler.getBoundingBox.apply(this.nodesHandler,arguments)},xT.prototype.getConnectedNodes=function(t){return void 0!==this.body.nodes[t]?this.nodesHandler.getConnectedNodes.apply(this.nodesHandler,arguments):this.edgesHandler.getConnectedNodes.apply(this.edgesHandler,arguments)},xT.prototype.getConnectedEdges=function(){return this.nodesHandler.getConnectedEdges.apply(this.nodesHandler,arguments)},xT.prototype.startSimulation=function(){return this.physics.startSimulation.apply(this.physics,arguments)},xT.prototype.stopSimulation=function(){return this.physics.stopSimulation.apply(this.physics,arguments)},xT.prototype.stabilize=function(){return this.physics.stabilize.apply(this.physics,arguments)},xT.prototype.getSelection=function(){return this.selectionHandler.getSelection.apply(this.selectionHandler,arguments)},xT.prototype.setSelection=function(){return this.selectionHandler.setSelection.apply(this.selectionHandler,arguments)},xT.prototype.getSelectedNodes=function(){return this.selectionHandler.getSelectedNodeIds.apply(this.selectionHandler,arguments)},xT.prototype.getSelectedEdges=function(){return this.selectionHandler.getSelectedEdgeIds.apply(this.selectionHandler,arguments)},xT.prototype.getNodeAt=function(){var t=this.selectionHandler.getNodeAt.apply(this.selectionHandler,arguments);return void 0!==t&&void 0!==t.id?t.id:t},xT.prototype.getEdgeAt=function(){var t=this.selectionHandler.getEdgeAt.apply(this.selectionHandler,arguments);return void 0!==t&&void 0!==t.id?t.id:t},xT.prototype.selectNodes=function(){return this.selectionHandler.selectNodes.apply(this.selectionHandler,arguments)},xT.prototype.selectEdges=function(){return this.selectionHandler.selectEdges.apply(this.selectionHandler,arguments)},xT.prototype.unselectAll=function(){this.selectionHandler.unselectAll.apply(this.selectionHandler,arguments),this.selectionHandler.commitWithoutEmitting.apply(this.selectionHandler),this.redraw()},xT.prototype.redraw=function(){return this.renderer.redraw.apply(this.renderer,arguments)},xT.prototype.getScale=function(){return this.view.getScale.apply(this.view,arguments)},xT.prototype.getViewPosition=function(){return this.view.getViewPosition.apply(this.view,arguments)},xT.prototype.fit=function(){return this.view.fit.apply(this.view,arguments)},xT.prototype.moveTo=function(){return this.view.moveTo.apply(this.view,arguments)},xT.prototype.focus=function(){return this.view.focus.apply(this.view,arguments)},xT.prototype.releaseNode=function(){return this.view.releaseNode.apply(this.view,arguments)},xT.prototype.getOptionsFromConfigurator=function(){var t={};return this.configurator&&(t=this.configurator.getOptions.apply(this.configurator)),t};var ST=Object.freeze({__proto__:null,prepareElements:ET,cleanupElements:OT,resetElements:function(t){ET(t),OT(t),ET(t)},getSVGElement:CT,getDOMElement:function(t,e,i,n){var o;return Object.prototype.hasOwnProperty.call(e,t)?e[t].redundant.length>0?(o=e[t].redundant[0],e[t].redundant.shift()):(o=document.createElement(t),void 0!==n?i.insertBefore(o,n):i.appendChild(o)):(o=document.createElement(t),e[t]={used:[],redundant:[]},void 0!==n?i.insertBefore(o,n):i.appendChild(o)),e[t].used.push(o),o},drawPoint:function(t,e,i,n,o,r){var s;if("circle"==i.style?((s=CT("circle",n,o)).setAttributeNS(null,"cx",t),s.setAttributeNS(null,"cy",e),s.setAttributeNS(null,"r",.5*i.size)):((s=CT("rect",n,o)).setAttributeNS(null,"x",t-.5*i.size),s.setAttributeNS(null,"y",e-.5*i.size),s.setAttributeNS(null,"width",i.size),s.setAttributeNS(null,"height",i.size)),void 0!==i.styles&&s.setAttributeNS(null,"style",i.styles),s.setAttributeNS(null,"class",i.className+" vis-point"),r){var a=CT("text",n,o);r.xOffset&&(t+=r.xOffset),r.yOffset&&(e+=r.yOffset),r.content&&(a.textContent=r.content),r.className&&a.setAttributeNS(null,"class",r.className+" vis-label"),a.setAttributeNS(null,"x",t),a.setAttributeNS(null,"y",e)}return s},drawBar:function(t,e,i,n,o,r,s,a){if(0!=n){n<0&&(e-=n*=-1);var h=CT("rect",r,s);h.setAttributeNS(null,"x",t-.5*i),h.setAttributeNS(null,"y",e),h.setAttributeNS(null,"width",i),h.setAttributeNS(null,"height",n),h.setAttributeNS(null,"class",o),a&&h.setAttributeNS(null,"style",a)}}}),TT={Images:Pb,dotparser:Ob,gephiParser:Sb,allOptions:wT,convertDot:Eb,convertGephi:Cb},MT=Object.freeze({__proto__:null,network:TT,DOMutil:ST,util:Ym,data:Jx,Hammer:Wm,keycharm:jC,DataSet:Kx,DataView:$x,Queue:Yx,Network:xT});t.DOMutil=ST,t.DataSet=Kx,t.DataView=$x,t.Hammer=Wm,t.Network=xT,t.Queue=Yx,t.data=Jx,t.default=MT,t.keycharm=jC,t.network=TT,t.util=Ym,Object.defineProperty(t,"__esModule",{value:!0})}));
//# sourceMappingURL=vis-network.min.js.map</script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 800px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 800px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#6FA8DC", "id": "Saurabh Singh", "label": "Saurabh Singh", "shape": "dot", "size": 10.267857142857142, "title": "Saurabh Singh"}, {"color": "#6FA8DC", "id": "Learning a Sequential Search for Landmarks", "label": "Learning a Sequential Search for Landmarks", "shape": "dot", "size": 10.892857142857142, "title": "Learning a Sequential Search for Landmarks"}, {"color": "#6FA8DC", "id": "Derek Hoiem", "label": "Derek Hoiem", "shape": "dot", "size": 10.446428571428571, "title": "Derek Hoiem"}, {"color": "#6FA8DC", "id": "David Forsyth", "label": "David Forsyth", "shape": "dot", "size": 10.267857142857142, "title": "David Forsyth"}, {"color": "#6FA8DC", "id": "CVPR", "label": "CVPR", "shape": "dot", "size": 23.303571428571427, "title": "CVPR"}, {"color": "#6FA8DC", "id": "2015", "label": "2015", "shape": "dot", "size": 11.517857142857142, "title": "2015"}, {"color": "#6FA8DC", "id": "Glaucoma", "label": "Glaucoma", "shape": "dot", "size": 10.267857142857142, "title": "Glaucoma"}, {"color": "#6FA8DC", "id": "Sequential Search", "label": "Sequential Search", "shape": "dot", "size": 10.089285714285714, "title": "Sequential Search"}, {"color": "#6FA8DC", "id": "Landmarks", "label": "Landmarks", "shape": "dot", "size": 10.089285714285714, "title": "Landmarks"}, {"color": "#6FA8DC", "id": "Ollama", "label": "Ollama", "shape": "dot", "size": 10.089285714285714, "title": "Ollama"}, {"color": "#6FA8DC", "id": "method", "label": "method", "shape": "dot", "size": 25.0, "title": "method"}, {"color": "#6FA8DC", "id": "landmarks", "label": "landmarks", "shape": "dot", "size": 10.267857142857142, "title": "landmarks"}, {"color": "#6FA8DC", "id": "images of objects", "label": "images of objects", "shape": "dot", "size": 10.089285714285714, "title": "images of objects"}, {"color": "#6FA8DC", "id": "appearance", "label": "appearance", "shape": "dot", "size": 10.267857142857142, "title": "appearance"}, {"color": "#6FA8DC", "id": "parsing human body layouts", "label": "parsing human body layouts", "shape": "dot", "size": 10.089285714285714, "title": "parsing human body layouts"}, {"color": "#6FA8DC", "id": "finding landmarks in images of birds", "label": "finding landmarks in images of birds", "shape": "dot", "size": 10.089285714285714, "title": "finding landmarks in images of birds"}, {"color": "#6FA8DC", "id": "sequential search", "label": "sequential search", "shape": "dot", "size": 10.178571428571429, "title": "sequential search"}, {"color": "#6FA8DC", "id": "landmark addition", "label": "landmark addition", "shape": "dot", "size": 10.089285714285714, "title": "landmark addition"}, {"color": "#6FA8DC", "id": "image", "label": "image", "shape": "dot", "size": 10.714285714285714, "title": "image"}, {"color": "#6FA8DC", "id": "groups", "label": "groups", "shape": "dot", "size": 10.089285714285714, "title": "groups"}, {"color": "#6FA8DC", "id": "learned function", "label": "learned function", "shape": "dot", "size": 10.267857142857142, "title": "learned function"}, {"color": "#6FA8DC", "id": "landmark group", "label": "landmark group", "shape": "dot", "size": 10.178571428571429, "title": "landmark group"}, {"color": "#6FA8DC", "id": "expand groups", "label": "expand groups", "shape": "dot", "size": 10.089285714285714, "title": "expand groups"}, {"color": "#6FA8DC", "id": "scoring function", "label": "scoring function", "shape": "dot", "size": 10.178571428571429, "title": "scoring function"}, {"color": "#6FA8DC", "id": "data labelled with landmarks", "label": "data labelled with landmarks", "shape": "dot", "size": 10.089285714285714, "title": "data labelled with landmarks"}, {"color": "#6FA8DC", "id": "spatial model", "label": "spatial model", "shape": "dot", "size": 10.267857142857142, "title": "spatial model"}, {"color": "#6FA8DC", "id": "kinematics of landmark groups", "label": "kinematics of landmark groups", "shape": "dot", "size": 10.089285714285714, "title": "kinematics of landmark groups"}, {"color": "#6FA8DC", "id": "strong performance", "label": "strong performance", "shape": "dot", "size": 10.178571428571429, "title": "strong performance"}, {"color": "#6FA8DC", "id": "landmark", "label": "landmark", "shape": "dot", "size": 10.089285714285714, "title": "landmark"}, {"color": "#6FA8DC", "id": "initial landmark", "label": "initial landmark", "shape": "dot", "size": 10.089285714285714, "title": "initial landmark"}, {"color": "#6FA8DC", "id": "data", "label": "data", "shape": "dot", "size": 10.357142857142858, "title": "data"}, {"color": "#6FA8DC", "id": "model problems", "label": "model problems", "shape": "dot", "size": 10.089285714285714, "title": "model problems"}, {"color": "#6FA8DC", "id": "Method", "label": "Method", "shape": "dot", "size": 12.857142857142858, "title": "Method"}, {"color": "#6FA8DC", "id": "Andriluka et al. (2009)", "label": "Andriluka et al. (2009)", "shape": "dot", "size": 10.178571428571429, "title": "Andriluka et al. (2009)"}, {"color": "#6FA8DC", "id": "People detection", "label": "People detection", "shape": "dot", "size": 10.089285714285714, "title": "People detection"}, {"color": "#6FA8DC", "id": "articulated pose estimation", "label": "articulated pose estimation", "shape": "dot", "size": 10.178571428571429, "title": "articulated pose estimation"}, {"color": "#6FA8DC", "id": "Barto (1998)", "label": "Barto (1998)", "shape": "dot", "size": 10.089285714285714, "title": "Barto (1998)"}, {"color": "#6FA8DC", "id": "Reinforcement learning", "label": "Reinforcement learning", "shape": "dot", "size": 10.089285714285714, "title": "Reinforcement learning"}, {"color": "#6FA8DC", "id": "Felzenszwalb and Huttenlocher (2005)", "label": "Felzenszwalb and Huttenlocher (2005)", "shape": "dot", "size": 10.089285714285714, "title": "Felzenszwalb and Huttenlocher (2005)"}, {"color": "#6FA8DC", "id": "Pictorial structures", "label": "Pictorial structures", "shape": "dot", "size": 10.089285714285714, "title": "Pictorial structures"}, {"color": "#6FA8DC", "id": "Fergus et al. (2003)", "label": "Fergus et al. (2003)", "shape": "dot", "size": 10.089285714285714, "title": "Fergus et al. (2003)"}, {"color": "#6FA8DC", "id": "Unsupervised scale-invariant learning", "label": "Unsupervised scale-invariant learning", "shape": "dot", "size": 10.089285714285714, "title": "Unsupervised scale-invariant learning"}, {"color": "#6FA8DC", "id": "Doll\u00b4ar et al. (2009)", "label": "Doll\u00b4ar et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Doll\u00b4ar et al. (2009)"}, {"color": "#6FA8DC", "id": "Integral channel features", "label": "Integral channel features", "shape": "dot", "size": 10.178571428571429, "title": "Integral channel features"}, {"color": "#6FA8DC", "id": "Eichner and Ferrari (2012)", "label": "Eichner and Ferrari (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Eichner and Ferrari (2012)"}, {"color": "#6FA8DC", "id": "collective human pose estimation", "label": "collective human pose estimation", "shape": "dot", "size": 10.089285714285714, "title": "collective human pose estimation"}, {"color": "#6FA8DC", "id": "Doll\u00e1r, P.", "label": "Doll\u00e1r, P.", "shape": "dot", "size": 10.178571428571429, "title": "Doll\u00e1r, P."}, {"color": "#6FA8DC", "id": "Eichner, M.", "label": "Eichner, M.", "shape": "dot", "size": 10.089285714285714, "title": "Eichner, M."}, {"color": "#6FA8DC", "id": "Appearance sharing", "label": "Appearance sharing", "shape": "dot", "size": 10.089285714285714, "title": "Appearance sharing"}, {"color": "#6FA8DC", "id": "Fei-Fei, L.", "label": "Fei-Fei, L.", "shape": "dot", "size": 10.178571428571429, "title": "Fei-Fei, L."}, {"color": "#6FA8DC", "id": "One-shot learning", "label": "One-shot learning", "shape": "dot", "size": 10.089285714285714, "title": "One-shot learning"}, {"color": "#6FA8DC", "id": "Felzenszwalb, P. F.", "label": "Felzenszwalb, P. F.", "shape": "dot", "size": 10.535714285714286, "title": "Felzenszwalb, P. F."}, {"color": "#6FA8DC", "id": "Cascade object detection", "label": "Cascade object detection", "shape": "dot", "size": 10.089285714285714, "title": "Cascade object detection"}, {"color": "#6FA8DC", "id": "Fergus, R.", "label": "Fergus, R.", "shape": "dot", "size": 10.178571428571429, "title": "Fergus, R."}, {"color": "#6FA8DC", "id": "Sparse object category model", "label": "Sparse object category model", "shape": "dot", "size": 10.089285714285714, "title": "Sparse object category model"}, {"color": "#6FA8DC", "id": "Wang, Y.", "label": "Wang, Y.", "shape": "dot", "size": 10.178571428571429, "title": "Wang, Y."}, {"color": "#6FA8DC", "id": "Multiple tree models", "label": "Multiple tree models", "shape": "dot", "size": 10.089285714285714, "title": "Multiple tree models"}, {"color": "#6FA8DC", "id": "BMVC", "label": "BMVC", "shape": "dot", "size": 10.357142857142858, "title": "BMVC"}, {"color": "#6FA8DC", "id": "ECCV", "label": "ECCV", "shape": "dot", "size": 11.607142857142858, "title": "ECCV"}, {"color": "#6FA8DC", "id": "University of Illinois, Urbana-Champaign", "label": "University of Illinois, Urbana-Champaign", "shape": "dot", "size": 10.267857142857142, "title": "University of Illinois, Urbana-Champaign"}, {"color": "#6FA8DC", "id": "University of Indiana", "label": "University of Indiana", "shape": "dot", "size": 10.267857142857142, "title": "University of Indiana"}, {"color": "#6FA8DC", "id": "Gedas Bertasius", "label": "Gedas Bertasius", "shape": "dot", "size": 10.178571428571429, "title": "Gedas Bertasius"}, {"color": "#6FA8DC", "id": "DeepEdge", "label": "DeepEdge", "shape": "dot", "size": 10.714285714285714, "title": "DeepEdge"}, {"color": "#6FA8DC", "id": "Lorenzo Torresani", "label": "Lorenzo Torresani", "shape": "dot", "size": 10.178571428571429, "title": "Lorenzo Torresani"}, {"color": "#6FA8DC", "id": "Deep Network", "label": "Deep Network", "shape": "dot", "size": 10.089285714285714, "title": "Deep Network"}, {"color": "#6FA8DC", "id": "Contour Detection", "label": "Contour Detection", "shape": "dot", "size": 10.089285714285714, "title": "Contour Detection"}, {"color": "#6FA8DC", "id": "Top-Down Contour Detection", "label": "Top-Down Contour Detection", "shape": "dot", "size": 10.089285714285714, "title": "Top-Down Contour Detection"}, {"color": "#6FA8DC", "id": "Bifurcated Deep Network", "label": "Bifurcated Deep Network", "shape": "dot", "size": 10.089285714285714, "title": "Bifurcated Deep Network"}, {"color": "#6FA8DC", "id": "Contour detection", "label": "Contour detection", "shape": "dot", "size": 10.089285714285714, "title": "Contour detection"}, {"color": "#6FA8DC", "id": "low-level features", "label": "low-level features", "shape": "dot", "size": 10.267857142857142, "title": "low-level features"}, {"color": "#6FA8DC", "id": "novel method", "label": "novel method", "shape": "dot", "size": 10.714285714285714, "title": "novel method"}, {"color": "#6FA8DC", "id": "state-of-the-art results", "label": "state-of-the-art results", "shape": "dot", "size": 10.892857142857142, "title": "state-of-the-art results"}, {"color": "#6FA8DC", "id": "contour detection", "label": "contour detection", "shape": "dot", "size": 10.267857142857142, "title": "contour detection"}, {"color": "#6FA8DC", "id": "object recognition", "label": "object recognition", "shape": "dot", "size": 10.714285714285714, "title": "object recognition"}, {"color": "#6FA8DC", "id": "feature engineering", "label": "feature engineering", "shape": "dot", "size": 10.089285714285714, "title": "feature engineering"}, {"color": "#6FA8DC", "id": "Arbel\u00e1ez et al. (2011)", "label": "Arbel\u00e1ez et al. (2011)", "shape": "dot", "size": 10.178571428571429, "title": "Arbel\u00e1ez et al. (2011)"}, {"color": "#6FA8DC", "id": "Contour detection and hierarchical image segmentation", "label": "Contour detection and hierarchical image segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Contour detection and hierarchical image segmentation"}, {"color": "#6FA8DC", "id": "Lim et al. (2013)", "label": "Lim et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Lim et al. (2013)"}, {"color": "#6FA8DC", "id": "Sketch tokens", "label": "Sketch tokens", "shape": "dot", "size": 10.178571428571429, "title": "Sketch tokens"}, {"color": "#6FA8DC", "id": "Long et al. (2014)", "label": "Long et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Long et al. (2014)"}, {"color": "#6FA8DC", "id": "Fully convolutional networks", "label": "Fully convolutional networks", "shape": "dot", "size": 10.178571428571429, "title": "Fully convolutional networks"}, {"color": "#6FA8DC", "id": "Malik et al. (2001)", "label": "Malik et al. (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Malik et al. (2001)"}, {"color": "#6FA8DC", "id": "Contour and texture analysis", "label": "Contour and texture analysis", "shape": "dot", "size": 10.089285714285714, "title": "Contour and texture analysis"}, {"color": "#6FA8DC", "id": "semantic segmentation", "label": "semantic segmentation", "shape": "dot", "size": 10.625, "title": "semantic segmentation"}, {"color": "#6FA8DC", "id": "Girshick", "label": "Girshick", "shape": "dot", "size": 10.357142857142858, "title": "Girshick"}, {"color": "#6FA8DC", "id": "Rich feature hierarchies", "label": "Rich feature hierarchies", "shape": "dot", "size": 11.160714285714286, "title": "Rich feature hierarchies"}, {"color": "#6FA8DC", "id": "Donahue", "label": "Donahue", "shape": "dot", "size": 10.089285714285714, "title": "Donahue"}, {"color": "#6FA8DC", "id": "Darrell", "label": "Darrell", "shape": "dot", "size": 10.089285714285714, "title": "Darrell"}, {"color": "#6FA8DC", "id": "Hariharan", "label": "Hariharan", "shape": "dot", "size": 10.178571428571429, "title": "Hariharan"}, {"color": "#6FA8DC", "id": "Hypercolumns", "label": "Hypercolumns", "shape": "dot", "size": 10.267857142857142, "title": "Hypercolumns"}, {"color": "#6FA8DC", "id": "Arbel\u00e1ez", "label": "Arbel\u00e1ez", "shape": "dot", "size": 10.267857142857142, "title": "Arbel\u00e1ez"}, {"color": "#6FA8DC", "id": "Iandola", "label": "Iandola", "shape": "dot", "size": 10.089285714285714, "title": "Iandola"}, {"color": "#6FA8DC", "id": "Densenet", "label": "Densenet", "shape": "dot", "size": 10.089285714285714, "title": "Densenet"}, {"color": "#6FA8DC", "id": "Jia", "label": "Jia", "shape": "dot", "size": 10.178571428571429, "title": "Jia"}, {"color": "#6FA8DC", "id": "Caffe", "label": "Caffe", "shape": "dot", "size": 10.714285714285714, "title": "Caffe"}, {"color": "#6FA8DC", "id": "Convolutional architecture", "label": "Convolutional architecture", "shape": "dot", "size": 10.089285714285714, "title": "Convolutional architecture"}, {"color": "#6FA8DC", "id": "Girshik", "label": "Girshik", "shape": "dot", "size": 10.089285714285714, "title": "Girshik"}, {"color": "#6FA8DC", "id": "Object detection", "label": "Object detection", "shape": "dot", "size": 10.357142857142858, "title": "Object detection"}, {"color": "#6FA8DC", "id": "Shelhamer et al.", "label": "Shelhamer et al.", "shape": "dot", "size": 10.089285714285714, "title": "Shelhamer et al."}, {"color": "#6FA8DC", "id": "Ren et al.", "label": "Ren et al.", "shape": "dot", "size": 10.089285714285714, "title": "Ren et al."}, {"color": "#6FA8DC", "id": "Scale-invariant contour completion", "label": "Scale-invariant contour completion", "shape": "dot", "size": 10.178571428571429, "title": "Scale-invariant contour completion"}, {"color": "#6FA8DC", "id": "Condition random fields", "label": "Condition random fields", "shape": "dot", "size": 10.089285714285714, "title": "Condition random fields"}, {"color": "#6FA8DC", "id": "University of Pennsylvania", "label": "University of Pennsylvania", "shape": "dot", "size": 10.267857142857142, "title": "University of Pennsylvania"}, {"color": "#6FA8DC", "id": "Jianbo Shi", "label": "Jianbo Shi", "shape": "dot", "size": 10.089285714285714, "title": "Jianbo Shi"}, {"color": "#6FA8DC", "id": "Dartmouth College", "label": "Dartmouth College", "shape": "dot", "size": 10.089285714285714, "title": "Dartmouth College"}, {"color": "#6FA8DC", "id": "Wen Wang", "label": "Wen Wang", "shape": "dot", "size": 10.357142857142858, "title": "Wen Wang"}, {"color": "#6FA8DC", "id": "Discrimi nant Analysis", "label": "Discrimi nant Analysis", "shape": "dot", "size": 10.357142857142858, "title": "Discrimi nant Analysis"}, {"color": "#6FA8DC", "id": "Ruiping Wang", "label": "Ruiping Wang", "shape": "dot", "size": 10.446428571428571, "title": "Ruiping Wang"}, {"color": "#6FA8DC", "id": "Gaussian Distributions", "label": "Gaussian Distributions", "shape": "dot", "size": 10.089285714285714, "title": "Gaussian Distributions"}, {"color": "#6FA8DC", "id": "Face Recognition", "label": "Face Recognition", "shape": "dot", "size": 11.607142857142858, "title": "Face Recognition"}, {"color": "#6FA8DC", "id": "Wang_Discriminant_Analysis_on_2015_CVPR_paper", "label": "Wang_Discriminant_Analysis_on_2015_CVPR_paper", "shape": "dot", "size": 10.267857142857142, "title": "Wang_Discriminant_Analysis_on_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Zhiwu Huang", "label": "Zhiwu Huang", "shape": "dot", "size": 10.267857142857142, "title": "Zhiwu Huang"}, {"color": "#6FA8DC", "id": "Wang_Discribminant_Analysis_on_2015_CVPR_paper", "label": "Wang_Discribminant_Analysis_on_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Wang_Discribminant_Analysis_on_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Shiguan Shan", "label": "Shiguan Shan", "shape": "dot", "size": 10.267857142857142, "title": "Shiguan Shan"}, {"color": "#6FA8DC", "id": "Xilin Chen", "label": "Xilin Chen", "shape": "dot", "size": 10.357142857142858, "title": "Xilin Chen"}, {"color": "#6FA8DC", "id": "DARG", "label": "DARG", "shape": "dot", "size": 10.357142857142858, "title": "DARG"}, {"color": "#6FA8DC", "id": "face recognition problem", "label": "face recognition problem", "shape": "dot", "size": 10.089285714285714, "title": "face recognition problem"}, {"color": "#6FA8DC", "id": "image sets", "label": "image sets", "shape": "dot", "size": 10.178571428571429, "title": "image sets"}, {"color": "#6FA8DC", "id": "Gaussian Mixture Models", "label": "Gaussian Mixture Models", "shape": "dot", "size": 10.178571428571429, "title": "Gaussian Mixture Models"}, {"color": "#6FA8DC", "id": "Gaussian distributions", "label": "Gaussian distributions", "shape": "dot", "size": 10.089285714285714, "title": "Gaussian distributions"}, {"color": "#6FA8DC", "id": "Riemannian manifold", "label": "Riemannian manifold", "shape": "dot", "size": 10.089285714285714, "title": "Riemannian manifold"}, {"color": "#6FA8DC", "id": "Kernel Discrimiant Analysis", "label": "Kernel Discrimiant Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Kernel Discrimiant Analysis"}, {"color": "#6FA8DC", "id": "probabilistic kernels", "label": "probabilistic kernels", "shape": "dot", "size": 10.178571428571429, "title": "probabilistic kernels"}, {"color": "#6FA8DC", "id": "geometry", "label": "geometry", "shape": "dot", "size": 10.357142857142858, "title": "geometry"}, {"color": "#6FA8DC", "id": "Gaussian components", "label": "Gaussian components", "shape": "dot", "size": 10.089285714285714, "title": "Gaussian components"}, {"color": "#6FA8DC", "id": "proposed method", "label": "proposed method", "shape": "dot", "size": 10.892857142857142, "title": "proposed method"}, {"color": "#6FA8DC", "id": "face recognition databases", "label": "face recognition databases", "shape": "dot", "size": 10.178571428571429, "title": "face recognition databases"}, {"color": "#6FA8DC", "id": "superior performance", "label": "superior performance", "shape": "dot", "size": 10.625, "title": "superior performance"}, {"color": "#6FA8DC", "id": "state-of-the-art approaches", "label": "state-of-the-art approaches", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art approaches"}, {"color": "#6FA8DC", "id": "Russian components", "label": "Russian components", "shape": "dot", "size": 10.178571428571429, "title": "Russian components"}, {"color": "#6FA8DC", "id": "different subjects", "label": "different subjects", "shape": "dot", "size": 10.089285714285714, "title": "different subjects"}, {"color": "#6FA8DC", "id": "prior probabilities", "label": "prior probabilities", "shape": "dot", "size": 10.089285714285714, "title": "prior probabilities"}, {"color": "#6FA8DC", "id": "challenging", "label": "challenging", "shape": "dot", "size": 10.267857142857142, "title": "challenging"}, {"color": "#6FA8DC", "id": "Riemannian Manifold", "label": "Riemannian Manifold", "shape": "dot", "size": 10.089285714285714, "title": "Riemannian Manifold"}, {"color": "#6FA8DC", "id": "Discriminant Analysis", "label": "Discriminant Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Discriminant Analysis"}, {"color": "#6FA8DC", "id": "Kernel Methods", "label": "Kernel Methods", "shape": "dot", "size": 10.178571428571429, "title": "Kernel Methods"}, {"color": "#6FA8DC", "id": "Aranndi et al. (2005)", "label": "Aranndi et al. (2005)", "shape": "dot", "size": 10.089285714285714, "title": "Aranndi et al. (2005)"}, {"color": "#6FA8DC", "id": "Face recognition with image sets using manifold density divergence", "label": "Face recognition with image sets using manifold density divergence", "shape": "dot", "size": 10.178571428571429, "title": "Face recognition with image sets using manifold density divergence"}, {"color": "#6FA8DC", "id": "Amar \u0026 Nagaoka (2000)", "label": "Amar \u0026 Nagaoka (2000)", "shape": "dot", "size": 10.089285714285714, "title": "Amar \u0026 Nagaoka (2000)"}, {"color": "#6FA8DC", "id": "Methods of Information Geometry", "label": "Methods of Information Geometry", "shape": "dot", "size": 10.178571428571429, "title": "Methods of Information Geometry"}, {"color": "#6FA8DC", "id": "Information Geometry", "label": "Information Geometry", "shape": "dot", "size": 10.089285714285714, "title": "Information Geometry"}, {"color": "#6FA8DC", "id": "Chan et al. (2004)", "label": "Chan et al. (2004)", "shape": "dot", "size": 10.089285714285714, "title": "Chan et al. (2004)"}, {"color": "#6FA8DC", "id": "Probabilistic Kernels", "label": "Probabilistic Kernels", "shape": "dot", "size": 10.357142857142858, "title": "Probabilistic Kernels"}, {"color": "#6FA8DC", "id": "Probabilistic KernELS", "label": "Probabilistic KernELS", "shape": "dot", "size": 10.089285714285714, "title": "Probabilistic KernELS"}, {"color": "#6FA8DC", "id": "Information Divergence", "label": "Information Divergence", "shape": "dot", "size": 10.178571428571429, "title": "Information Divergence"}, {"color": "#6FA8DC", "id": "Chan, A. B.", "label": "Chan, A. B.", "shape": "dot", "size": 10.178571428571429, "title": "Chan, A. B."}, {"color": "#6FA8DC", "id": "Moreno, P. J.", "label": "Moreno, P. J.", "shape": "dot", "size": 10.089285714285714, "title": "Moreno, P. J."}, {"color": "#6FA8DC", "id": "Image Sets", "label": "Image Sets", "shape": "dot", "size": 10.089285714285714, "title": "Image Sets"}, {"color": "#6FA8DC", "id": "Cevikalp, H.", "label": "Cevikalp, H.", "shape": "dot", "size": 10.089285714285714, "title": "Cevikalp, H."}, {"color": "#6FA8DC", "id": "Triggs, B.", "label": "Triggs, B.", "shape": "dot", "size": 10.089285714285714, "title": "Triggs, B."}, {"color": "#6FA8DC", "id": "Image Sets Alignment", "label": "Image Sets Alignment", "shape": "dot", "size": 10.178571428571429, "title": "Image Sets Alignment"}, {"color": "#6FA8DC", "id": "Video-based Face Recognition", "label": "Video-based Face Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Video-based Face Recognition"}, {"color": "#6FA8DC", "id": "Cui, Z.", "label": "Cui, Z.", "shape": "dot", "size": 10.089285714285714, "title": "Cui, Z."}, {"color": "#6FA8DC", "id": "Grassmann Discriminant Analysis", "label": "Grassmann Discriminant Analysis", "shape": "dot", "size": 10.267857142857142, "title": "Grassmann Discriminant Analysis"}, {"color": "#6FA8DC", "id": "Subspace-based Learning", "label": "Subspace-based Learning", "shape": "dot", "size": 10.089285714285714, "title": "Subspace-based Learning"}, {"color": "#6FA8DC", "id": "Hamm, J.", "label": "Hamm, J.", "shape": "dot", "size": 10.089285714285714, "title": "Hamm, J."}, {"color": "#6FA8DC", "id": "Lee, D. D.", "label": "Lee, D. D.", "shape": "dot", "size": 10.089285714285714, "title": "Lee, D. D."}, {"color": "#6FA8DC", "id": "Sparse Approximated Nearest Points", "label": "Sparse Approximated Nearest Points", "shape": "dot", "size": 10.178571428571429, "title": "Sparse Approximated Nearest Points"}, {"color": "#6FA8DC", "id": "Image Set Classification", "label": "Image Set Classification", "shape": "dot", "size": 10.089285714285714, "title": "Image Set Classification"}, {"color": "#6FA8DC", "id": "Hu, Y.", "label": "Hu, Y.", "shape": "dot", "size": 10.267857142857142, "title": "Hu, Y."}, {"color": "#6FA8DC", "id": "Sparse approximated nearest points", "label": "Sparse approximated nearest points", "shape": "dot", "size": 10.089285714285714, "title": "Sparse approximated nearest points"}, {"color": "#6FA8DC", "id": "IEEE International Conference on Computer Vision and Pattern Recognized (CVPR)", "label": "IEEE International Conference on Computer Vision and Pattern Recognized (CVPR)", "shape": "dot", "size": 10.089285714285714, "title": "IEEE International Conference on Computer Vision and Pattern Recognized (CVPR)"}, {"color": "#6FA8DC", "id": "Harandi, M. T.", "label": "Harandi, M. T.", "shape": "dot", "size": 10.089285714285714, "title": "Harandi, M. T."}, {"color": "#6FA8DC", "id": "Grasmannian kernels", "label": "Grasmannian kernels", "shape": "dot", "size": 10.089285714285714, "title": "Grasmannian kernels"}, {"color": "#6FA8DC", "id": "Jayasumana, S.", "label": "Jayasumana, S.", "shape": "dot", "size": 10.089285714285714, "title": "Jayasumana, S."}, {"color": "#6FA8DC", "id": "IEEE Computer Society on Computer Vision and Pattern Recognition (CVPR)", "label": "IEEE Computer Society on Computer Vision and Pattern Recognition (CVPR)", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Computer Society on Computer Vision and Pattern Recognition (CVPR)"}, {"color": "#6FA8DC", "id": "Kim, M.", "label": "Kim, M.", "shape": "dot", "size": 10.178571428571429, "title": "Kim, M."}, {"color": "#6FA8DC", "id": "Face tracking and recognition", "label": "Face tracking and recognition", "shape": "dot", "size": 10.089285714285714, "title": "Face tracking and recognition"}, {"color": "#6FA8DC", "id": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)", "label": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)"}, {"color": "#6FA8DC", "id": "Key Laboratory of Intelligent Information Processing", "label": "Key Laboratory of Intelligent Information Processing", "shape": "dot", "size": 10.446428571428571, "title": "Key Laboratory of Intelligent Information Processing"}, {"color": "#6FA8DC", "id": "Chinese Academy of Sciences", "label": "Chinese Academy of Sciences", "shape": "dot", "size": 10.982142857142858, "title": "Chinese Academy of Sciences"}, {"color": "#6FA8DC", "id": "Institute of Computing Technology", "label": "Institute of Computing Technology", "shape": "dot", "size": 10.625, "title": "Institute of Computing Technology"}, {"color": "#6FA8DC", "id": "wen.wang@vipl.ict.ac.cn", "label": "wen.wang@vipl.ict.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "wen.wang@vipl.ict.ac.cn"}, {"color": "#6FA8DC", "id": "wangruiping@ict.ac.cn", "label": "wangruiping@ict.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "wangruiping@ict.ac.cn"}, {"color": "#6FA8DC", "id": "zhiwu.huang@vipl.ict.ac.cn", "label": "zhiwu.huang@vipl.ict.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "zhiwu.huang@vipl.ict.ac.cn"}, {"color": "#6FA8DC", "id": "sgshan@ict.ac.cn", "label": "sgshan@ict.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "sgshan@ict.ac.cn"}, {"color": "#6FA8DC", "id": "xlchen@ict.ac.cn", "label": "xlchen@ict.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "xlchen@ict.ac.cn"}, {"color": "#6FA8DC", "id": "Super-resolution Person Re-identi\ufb01cation", "label": "Super-resolution Person Re-identi\ufb01cation", "shape": "dot", "size": 10.892857142857142, "title": "Super-resolution Person Re-identi\ufb01cation"}, {"color": "#6FA8DC", "id": "Xiao-Yuan Jing", "label": "Xiao-Yuan Jing", "shape": "dot", "size": 10.178571428571429, "title": "Xiao-Yuan Jing"}, {"color": "#6FA8DC", "id": "Xiaoke Zhu", "label": "Xiaoke Zhu", "shape": "dot", "size": 10.178571428571429, "title": "Xiaoke Zhu"}, {"color": "#6FA8DC", "id": "Fei Wu", "label": "Fei Wu", "shape": "dot", "size": 10.178571428571429, "title": "Fei Wu"}, {"color": "#6FA8DC", "id": "Xinge You", "label": "Xinge You", "shape": "dot", "size": 10.178571428571429, "title": "Xinge You"}, {"color": "#6FA8DC", "id": "Qinglong Liu", "label": "Qinglong Liu", "shape": "dot", "size": 10.178571428571429, "title": "Qinglong Liu"}, {"color": "#6FA8DC", "id": "Dong Yue", "label": "Dong Yue", "shape": "dot", "size": 10.178571428571429, "title": "Dong Yue"}, {"color": "#6FA8DC", "id": "Ruimin Hu", "label": "Ruimin Hu", "shape": "dot", "size": 10.178571428571429, "title": "Ruimin Hu"}, {"color": "#6FA8DC", "id": "Baowen Xu", "label": "Baowen Xu", "shape": "dot", "size": 10.267857142857142, "title": "Baowen Xu"}, {"color": "#6FA8DC", "id": "Jing_Super-Resolution_Person_Re-Identification_2015_CVPR_paper.pdf", "label": "Jing_Super-Resolution_Person_Re-Identification_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Jing_Super-Resolution_Person_Re-Identification_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Person re-identification", "label": "Person re-identification", "shape": "dot", "size": 10.357142857142858, "title": "Person re-identification"}, {"color": "#6FA8DC", "id": "surveillance applications", "label": "surveillance applications", "shape": "dot", "size": 10.089285714285714, "title": "surveillance applications"}, {"color": "#6FA8DC", "id": "forensics applications", "label": "forensics applications", "shape": "dot", "size": 10.089285714285714, "title": "forensics applications"}, {"color": "#6FA8DC", "id": "SLD2L", "label": "SLD2L", "shape": "dot", "size": 10.267857142857142, "title": "SLD2L"}, {"color": "#6FA8DC", "id": "converting LR probe image features", "label": "converting LR probe image features", "shape": "dot", "size": 10.089285714285714, "title": "converting LR probe image features"}, {"color": "#6FA8DC", "id": "effectiveness", "label": "effectiveness", "shape": "dot", "size": 11.160714285714286, "title": "effectiveness"}, {"color": "#6FA8DC", "id": "discriminant term", "label": "discriminant term", "shape": "dot", "size": 10.089285714285714, "title": "discriminant term"}, {"color": "#6FA8DC", "id": "converted features are far from different-person HR gallery features", "label": "converted features are far from different-person HR gallery features", "shape": "dot", "size": 10.089285714285714, "title": "converted features are far from different-person HR gallery features"}, {"color": "#6FA8DC", "id": "low-rank regularization", "label": "low-rank regularization", "shape": "dot", "size": 10.357142857142858, "title": "low-rank regularization"}, {"color": "#6FA8DC", "id": "intrinsic feature space", "label": "intrinsic feature space", "shape": "dot", "size": 10.089285714285714, "title": "intrinsic feature space"}, {"color": "#6FA8DC", "id": "HR images", "label": "HR images", "shape": "dot", "size": 10.178571428571429, "title": "HR images"}, {"color": "#6FA8DC", "id": "LR images", "label": "LR images", "shape": "dot", "size": 10.178571428571429, "title": "LR images"}, {"color": "#6FA8DC", "id": "HR gallery images", "label": "HR gallery images", "shape": "dot", "size": 10.089285714285714, "title": "HR gallery images"}, {"color": "#6FA8DC", "id": "features", "label": "features", "shape": "dot", "size": 10.535714285714286, "title": "features"}, {"color": "#6FA8DC", "id": "LR probe images", "label": "LR probe images", "shape": "dot", "size": 10.089285714285714, "title": "LR probe images"}, {"color": "#6FA8DC", "id": "public datasets", "label": "public datasets", "shape": "dot", "size": 10.357142857142858, "title": "public datasets"}, {"color": "#6FA8DC", "id": "HR gallery", "label": "HR gallery", "shape": "dot", "size": 10.089285714285714, "title": "HR gallery"}, {"color": "#6FA8DC", "id": "Super-resolution person re-identification", "label": "Super-resolution person re-identification", "shape": "dot", "size": 10.089285714285714, "title": "Super-resolution person re-identification"}, {"color": "#6FA8DC", "id": "research", "label": "research", "shape": "dot", "size": 10.535714285714286, "title": "research"}, {"color": "#6FA8DC", "id": "Low-rank discriminant dictionary learning", "label": "Low-rank discriminant dictionary learning", "shape": "dot", "size": 10.089285714285714, "title": "Low-rank discriminant dictionary learning"}, {"color": "#6FA8DC", "id": "machine learning", "label": "machine learning", "shape": "dot", "size": 10.446428571428571, "title": "machine learning"}, {"color": "#6FA8DC", "id": "Semi-coupled dictionaries", "label": "Semi-coupled dictionaries", "shape": "dot", "size": 10.089285714285714, "title": "Semi-coupled dictionaries"}, {"color": "#6FA8DC", "id": "person re-identification", "label": "person re-identification", "shape": "dot", "size": 10.982142857142858, "title": "person re-identification"}, {"color": "#6FA8DC", "id": "Feature representation learning", "label": "Feature representation learning", "shape": "dot", "size": 10.089285714285714, "title": "Feature representation learning"}, {"color": "#6FA8DC", "id": "semi-coupled dictionaries", "label": "semi-coupled dictionaries", "shape": "dot", "size": 10.089285714285714, "title": "semi-coupled dictionaries"}, {"color": "#6FA8DC", "id": "Bak et al. (2010)", "label": "Bak et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Bak et al. (2010)"}, {"color": "#6FA8DC", "id": "Bedagkar-Gala \u0026 Shah (2014)", "label": "Bedagkar-Gala \u0026 Shah (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Bedagkar-Gala \u0026 Shah (2014)"}, {"color": "#6FA8DC", "id": "person re-identi\ufb01cation approaches", "label": "person re-identi\ufb01cation approaches", "shape": "dot", "size": 10.089285714285714, "title": "person re-identi\ufb01cation approaches"}, {"color": "#6FA8DC", "id": "Liu et al. (2014)", "label": "Liu et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Liu et al. (2014)"}, {"color": "#6FA8DC", "id": "semi-supervised coupled dictionary learning", "label": "semi-supervised coupled dictionary learning", "shape": "dot", "size": 10.089285714285714, "title": "semi-supervised coupled dictionary learning"}, {"color": "#6FA8DC", "id": "Liu, X.", "label": "Liu, X.", "shape": "dot", "size": 10.089285714285714, "title": "Liu, X."}, {"color": "#6FA8DC", "id": "Semi-supervised coupled dictionary learning for person re-identi\ufb01cation", "label": "Semi-supervised coupled dictionary learning for person re-identi\ufb01cation", "shape": "dot", "size": 10.178571428571429, "title": "Semi-supervised coupled dictionary learning for person re-identi\ufb01cation"}, {"color": "#6FA8DC", "id": "CVPR, IEEE Conference on", "label": "CVPR, IEEE Conference on", "shape": "dot", "size": 10.089285714285714, "title": "CVPR, IEEE Conference on"}, {"color": "#6FA8DC", "id": "Ma, L.", "label": "Ma, L.", "shape": "dot", "size": 10.267857142857142, "title": "Ma, L."}, {"color": "#6FA8DC", "id": "Sparse representation for face recognition based on discriminative low-rank dictionary learning", "label": "Sparse representation for face recognition based on discriminative low-rank dictionary learning", "shape": "dot", "size": 10.089285714285714, "title": "Sparse representation for face recognition based on discriminative low-rank dictionary learning"}, {"color": "#6FA8DC", "id": "Gray, D.", "label": "Gray, D.", "shape": "dot", "size": 10.267857142857142, "title": "Gray, D."}, {"color": "#6FA8DC", "id": "Evaluating appearance models for recognition, reacquisition, and tracking", "label": "Evaluating appearance models for recognition, reacquisition, and tracking", "shape": "dot", "size": 10.178571428571429, "title": "Evaluating appearance models for recognition, reacquisition, and tracking"}, {"color": "#6FA8DC", "id": "Performance Evaluation of Tracking and Surveillance, IEEE workshop on", "label": "Performance Evaluation of Tracking and Surveillance, IEEE workshop on", "shape": "dot", "size": 10.089285714285714, "title": "Performance Evaluation of Tracking and Surveillance, IEEE workshop on"}, {"color": "#6FA8DC", "id": "Viewpoint invariant pedestrian recognition with an ensemble of localized features", "label": "Viewpoint invariant pedestrian recognition with an ensemble of localized features", "shape": "dot", "size": 10.178571428571429, "title": "Viewpoint invariant pedestrian recognition with an ensemble of localized features"}, {"color": "#6FA8DC", "id": "Person re-identi\ufb01cation over camera networks using multi-task distance metric learning", "label": "Person re-identi\ufb01cation over camera networks using multi-task distance metric learning", "shape": "dot", "size": 10.178571428571429, "title": "Person re-identi\ufb01cation over camera networks using multi-task distance metric learning"}, {"color": "#6FA8DC", "id": "Image Processing, IEEE Transactions on", "label": "Image Processing, IEEE Transactions on", "shape": "dot", "size": 10.267857142857142, "title": "Image Processing, IEEE Transactions on"}, {"color": "#6FA8DC", "id": "Person re-identi\ufb01cation over camera networks", "label": "Person re-identi\ufb01cation over camera networks", "shape": "dot", "size": 10.178571428571429, "title": "Person re-identi\ufb01cation over camera networks"}, {"color": "#6FA8DC", "id": "Hirzer, M.", "label": "Hirzer, M.", "shape": "dot", "size": 10.089285714285714, "title": "Hirzer, M."}, {"color": "#6FA8DC", "id": "Person re-identi\ufb01cation by descriptive and discriminative classification", "label": "Person re-identi\ufb01cation by descriptive and discriminative classification", "shape": "dot", "size": 10.178571428571429, "title": "Person re-identi\ufb01cation by descriptive and discriminative classification"}, {"color": "#6FA8DC", "id": "Zheng, W.-S.", "label": "Zheng, W.-S.", "shape": "dot", "size": 10.089285714285714, "title": "Zheng, W.-S."}, {"color": "#6FA8DC", "id": "Reidenti\ufb01cation by relative distance comparison", "label": "Reidenti\ufb01cation by relative distance comparison", "shape": "dot", "size": 10.178571428571429, "title": "Reidenti\ufb01cation by relative distance comparison"}, {"color": "#6FA8DC", "id": "State Key Laboratory of Software Engineering", "label": "State Key Laboratory of Software Engineering", "shape": "dot", "size": 10.535714285714286, "title": "State Key Laboratory of Software Engineering"}, {"color": "#6FA8DC", "id": "Image super-resolution via sparse representation", "label": "Image super-resolution via sparse representation", "shape": "dot", "size": 10.089285714285714, "title": "Image super-resolution via sparse representation"}, {"color": "#6FA8DC", "id": "Image Analysis", "label": "Image Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Image Analysis"}, {"color": "#6FA8DC", "id": "Pattern Analysis and Machine Intelligence, IEEE Transactions on", "label": "Pattern Analysis and Machine Intelligence, IEEE Transactions on", "shape": "dot", "size": 10.178571428571429, "title": "Pattern Analysis and Machine Intelligence, IEEE Transactions on"}, {"color": "#6FA8DC", "id": "re Engineering", "label": "re Engineering", "shape": "dot", "size": 10.089285714285714, "title": "re Engineering"}, {"color": "#6FA8DC", "id": "School of Computer", "label": "School of Computer", "shape": "dot", "size": 10.535714285714286, "title": "School of Computer"}, {"color": "#6FA8DC", "id": "Wuhan University", "label": "Wuhan University", "shape": "dot", "size": 10.178571428571429, "title": "Wuhan University"}, {"color": "#6FA8DC", "id": "China", "label": "China", "shape": "dot", "size": 10.178571428571429, "title": "China"}, {"color": "#6FA8DC", "id": "Huazhong University of Science and Technology", "label": "Huazhong University of Science and Technology", "shape": "dot", "size": 10.178571428571429, "title": "Huazhong University of Science and Technology"}, {"color": "#6FA8DC", "id": "School of Electronic Information and Communications", "label": "School of Electronic Information and Communications", "shape": "dot", "size": 10.089285714285714, "title": "School of Electronic Information and Communications"}, {"color": "#6FA8DC", "id": "Nanjing University of Posts and Telecommunications", "label": "Nanjing University of Posts and Telecommunications", "shape": "dot", "size": 10.089285714285714, "title": "Nanjing University of Posts and Telecommunications"}, {"color": "#6FA8DC", "id": "National Engineering Research Center for Multimedia Software", "label": "National Engineering Research Center for Multimedia Software", "shape": "dot", "size": 10.178571428571429, "title": "National Engineering Research Center for Multimedia Software"}, {"color": "#6FA8DC", "id": "Ronan Collobert", "label": "Ronan Collobert", "shape": "dot", "size": 10.357142857142858, "title": "Ronan Collobert"}, {"color": "#6FA8DC", "id": "From Image-level to Pixel-level Labeling", "label": "From Image-level to Pixel-level Labeling", "shape": "dot", "size": 10.178571428571429, "title": "From Image-level to Pixel-level Labeling"}, {"color": "#6FA8DC", "id": "Multimedia Software", "label": "Multimedia Software", "shape": "dot", "size": 10.089285714285714, "title": "Multimedia Software"}, {"color": "#6FA8DC", "id": "We", "label": "We", "shape": "dot", "size": 10.089285714285714, "title": "We"}, {"color": "#6FA8DC", "id": "object segmentation", "label": "object segmentation", "shape": "dot", "size": 10.625, "title": "object segmentation"}, {"color": "#6FA8DC", "id": "object class information", "label": "object class information", "shape": "dot", "size": 10.089285714285714, "title": "object class information"}, {"color": "#6FA8DC", "id": "weakly supervised segmentation task", "label": "weakly supervised segmentation task", "shape": "dot", "size": 10.089285714285714, "title": "weakly supervised segmentation task"}, {"color": "#6FA8DC", "id": "Multiple Instance Learning (MIL) framework", "label": "Multiple Instance Learning (MIL) framework", "shape": "dot", "size": 10.089285714285714, "title": "Multiple Instance Learning (MIL) framework"}, {"color": "#6FA8DC", "id": "training image", "label": "training image", "shape": "dot", "size": 10.089285714285714, "title": "training image"}, {"color": "#6FA8DC", "id": "pixel corresponding to image class label", "label": "pixel corresponding to image class label", "shape": "dot", "size": 10.089285714285714, "title": "pixel corresponding to image class label"}, {"color": "#6FA8DC", "id": "segmentation task", "label": "segmentation task", "shape": "dot", "size": 10.089285714285714, "title": "segmentation task"}, {"color": "#6FA8DC", "id": "inferring pixels belonging to class of object", "label": "inferring pixels belonging to class of object", "shape": "dot", "size": 10.089285714285714, "title": "inferring pixels belonging to class of object"}, {"color": "#6FA8DC", "id": "model", "label": "model", "shape": "dot", "size": 12.589285714285715, "title": "model"}, {"color": "#6FA8DC", "id": "Convolutional Neural Network", "label": "Convolutional Neural Network", "shape": "dot", "size": 10.178571428571429, "title": "Convolutional Neural Network"}, {"color": "#6FA8DC", "id": "training", "label": "training", "shape": "dot", "size": 10.535714285714286, "title": "training"}, {"color": "#6FA8DC", "id": "pixels important for image classification", "label": "pixels important for image classification", "shape": "dot", "size": 10.089285714285714, "title": "pixels important for image classification"}, {"color": "#6FA8DC", "id": "pixels", "label": "pixels", "shape": "dot", "size": 10.178571428571429, "title": "pixels"}, {"color": "#6FA8DC", "id": "network-based model", "label": "network-based model", "shape": "dot", "size": 10.178571428571429, "title": "network-based model"}, {"color": "#6FA8DC", "id": "important pixels", "label": "important pixels", "shape": "dot", "size": 10.089285714285714, "title": "important pixels"}, {"color": "#6FA8DC", "id": "right pixels", "label": "right pixels", "shape": "dot", "size": 10.089285714285714, "title": "right pixels"}, {"color": "#6FA8DC", "id": "system", "label": "system", "shape": "dot", "size": 12.589285714285715, "title": "system"}, {"color": "#6FA8DC", "id": "Imaginet dataset", "label": "Imaginet dataset", "shape": "dot", "size": 10.089285714285714, "title": "Imaginet dataset"}, {"color": "#6FA8DC", "id": "segmentation experiments", "label": "segmentation experiments", "shape": "dot", "size": 10.089285714285714, "title": "segmentation experiments"}, {"color": "#6FA8DC", "id": "Pascal VOC dataset", "label": "Pascal VOC dataset", "shape": "dot", "size": 10.089285714285714, "title": "Pascal VOC dataset"}, {"color": "#6FA8DC", "id": "state of the art results", "label": "state of the art results", "shape": "dot", "size": 10.178571428571429, "title": "state of the art results"}, {"color": "#6FA8DC", "id": "weakly supervised object segmentation task", "label": "weakly supervised object segmentation task", "shape": "dot", "size": 10.089285714285714, "title": "weakly supervised object segmentation task"}, {"color": "#6FA8DC", "id": "fully-supervised segmentation approaches", "label": "fully-supervised segmentation approaches", "shape": "dot", "size": 10.178571428571429, "title": "fully-supervised segmentation approaches"}, {"color": "#6FA8DC", "id": "Model", "label": "Model", "shape": "dot", "size": 10.625, "title": "Model"}, {"color": "#6FA8DC", "id": "Object Segmentation", "label": "Object Segmentation", "shape": "dot", "size": 10.535714285714286, "title": "Object Segmentation"}, {"color": "#6FA8DC", "id": "task", "label": "task", "shape": "dot", "size": 10.089285714285714, "title": "task"}, {"color": "#6FA8DC", "id": "Weakly Supervised Segmentation", "label": "Weakly Supervised Segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Weakly Supervised Segmentation"}, {"color": "#6FA8DC", "id": "approach", "label": "approach", "shape": "dot", "size": 20.535714285714285, "title": "approach"}, {"color": "#6FA8DC", "id": "Convolutional Neural Networks", "label": "Convolutional Neural Networks", "shape": "dot", "size": 10.625, "title": "Convolutional Neural Networks"}, {"color": "#6FA8DC", "id": "network type", "label": "network type", "shape": "dot", "size": 10.089285714285714, "title": "network type"}, {"color": "#6FA8DC", "id": "Multiple Instance Learning", "label": "Multiple Instance Learning", "shape": "dot", "size": 10.089285714285714, "title": "Multiple Instance Learning"}, {"color": "#6FA8DC", "id": "Image-level Training", "label": "Image-level Training", "shape": "dot", "size": 10.089285714285714, "title": "Image-level Training"}, {"color": "#6FA8DC", "id": "training method", "label": "training method", "shape": "dot", "size": 10.446428571428571, "title": "training method"}, {"color": "#6FA8DC", "id": "Arbel\u00e1ez et al. (2009)", "label": "Arbel\u00e1ez et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Arbel\u00e1ez et al. (2009)"}, {"color": "#6FA8DC", "id": "Multiscale combinatorial grouping", "label": "Multiscale combinatorial grouping", "shape": "dot", "size": 10.178571428571429, "title": "Multiscale combinatorial grouping"}, {"color": "#6FA8DC", "id": "Boyd \u0026 Vandenberghe (2004)", "label": "Boyd \u0026 Vandenberghe (2004)", "shape": "dot", "size": 10.089285714285714, "title": "Boyd \u0026 Vandenberghe (2004)"}, {"color": "#6FA8DC", "id": "Convex optimization", "label": "Convex optimization", "shape": "dot", "size": 10.178571428571429, "title": "Convex optimization"}, {"color": "#6FA8DC", "id": "Bridle (1990)", "label": "Bridle (1990)", "shape": "dot", "size": 10.089285714285714, "title": "Bridle (1990)"}, {"color": "#6FA8DC", "id": "Probabilistic interpretation of feedforward classification network outputs", "label": "Probabilistic interpretation of feedforward classification network outputs", "shape": "dot", "size": 10.089285714285714, "title": "Probabilistic interpretation of feedforward classification network outputs"}, {"color": "#6FA8DC", "id": "Probabilistic interpretation", "label": "Probabilistic interpretation", "shape": "dot", "size": 10.178571428571429, "title": "Probabilistic interpretation"}, {"color": "#6FA8DC", "id": "Statistical pattern recognition", "label": "Statistical pattern recognition", "shape": "dot", "size": 10.089285714285714, "title": "Statistical pattern recognition"}, {"color": "#6FA8DC", "id": "Feedforward classification network outputs", "label": "Feedforward classification network outputs", "shape": "dot", "size": 10.089285714285714, "title": "Feedforward classification network outputs"}, {"color": "#6FA8DC", "id": "Efficient graph-based image segmentation", "label": "Efficient graph-based image segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Efficient graph-based image segmentation"}, {"color": "#6FA8DC", "id": "International Journal of Computer Vision (IJCV)", "label": "International Journal of Computer Vision (IJCV)", "shape": "dot", "size": 10.089285714285714, "title": "International Journal of Computer Vision (IJCV)"}, {"color": "#6FA8DC", "id": "Semantic segmentation", "label": "Semantic segmentation", "shape": "dot", "size": 10.357142857142858, "title": "Semantic segmentation"}, {"color": "#6FA8DC", "id": "Simultaneous detection and segmentation", "label": "Simultaneous detection and segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Simultaneous detection and segmentation"}, {"color": "#6FA8DC", "id": "European Conference on Computer Vision (ECCV)", "label": "European Conference on Computer Vision (ECCV)", "shape": "dot", "size": 10.089285714285714, "title": "European Conference on Computer Vision (ECCV)"}, {"color": "#6FA8DC", "id": "Graph-based image segmentation", "label": "Graph-based image segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Graph-based image segmentation"}, {"color": "#6FA8DC", "id": "Image segmentation", "label": "Image segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Image segmentation"}, {"color": "#6FA8DC", "id": "Hariharan et al.", "label": "Hariharan et al.", "shape": "dot", "size": 10.267857142857142, "title": "Hariharan et al."}, {"color": "#6FA8DC", "id": "Krizhevsky et al.", "label": "Krizhevsky et al.", "shape": "dot", "size": 10.178571428571429, "title": "Krizhevsky et al."}, {"color": "#6FA8DC", "id": "NIPS", "label": "NIPS", "shape": "dot", "size": 11.517857142857142, "title": "NIPS"}, {"color": "#6FA8DC", "id": "LeCun et al.", "label": "LeCun et al.", "shape": "dot", "size": 10.089285714285714, "title": "LeCun et al."}, {"color": "#6FA8DC", "id": "Proceedings of the IEEE", "label": "Proceedings of the IEEE", "shape": "dot", "size": 10.089285714285714, "title": "Proceedings of the IEEE"}, {"color": "#6FA8DC", "id": "Maron \u0026 Lozano-P\u00e9rez", "label": "Maron \u0026 Lozano-P\u00e9rez", "shape": "dot", "size": 10.089285714285714, "title": "Maron \u0026 Lozano-P\u00e9rez"}, {"color": "#6FA8DC", "id": "Pedro O. Pinheiro", "label": "Pedro O. Pinheiro", "shape": "dot", "size": 10.089285714285714, "title": "Pedro O. Pinheiro"}, {"color": "#6FA8DC", "id": "Idiap Research Institute", "label": "Idiap Research Institute", "shape": "dot", "size": 10.089285714285714, "title": "Idiap Research Institute"}, {"color": "#6FA8DC", "id": "Facebook AI Research", "label": "Facebook AI Research", "shape": "dot", "size": 10.446428571428571, "title": "Facebook AI Research"}, {"color": "#6FA8DC", "id": "ronan@coltobert.com", "label": "ronan@coltobert.com", "shape": "dot", "size": 10.089285714285714, "title": "ronan@coltobert.com"}, {"color": "#6FA8DC", "id": "Yeqing Li", "label": "Yeqing Li", "shape": "dot", "size": 10.178571428571429, "title": "Yeqing Li"}, {"color": "#6FA8DC", "id": "Deep Sparse Representation", "label": "Deep Sparse Representation", "shape": "dot", "size": 10.625, "title": "Deep Sparse Representation"}, {"color": "#6FA8DC", "id": "Chen Chen", "label": "Chen Chen", "shape": "dot", "size": 10.178571428571429, "title": "Chen Chen"}, {"color": "#6FA8DC", "id": "Fei Yang", "label": "Fei Yang", "shape": "dot", "size": 10.089285714285714, "title": "Fei Yang"}, {"color": "#6FA8DC", "id": "Junzhou Huang", "label": "Junzhou Huang", "shape": "dot", "size": 10.267857142857142, "title": "Junzhou Huang"}, {"color": "#6FA8DC", "id": "Menlo Park", "label": "Menlo Park", "shape": "dot", "size": 10.178571428571429, "title": "Menlo Park"}, {"color": "#6FA8DC", "id": "USA", "label": "USA", "shape": "dot", "size": 10.178571428571429, "title": "USA"}, {"color": "#6FA8DC", "id": "Deep Sparse representation", "label": "Deep Sparse representation", "shape": "dot", "size": 10.089285714285714, "title": "Deep Sparse representation"}, {"color": "#6FA8DC", "id": "image registration technique", "label": "image registration technique", "shape": "dot", "size": 10.089285714285714, "title": "image registration technique"}, {"color": "#6FA8DC", "id": "Li_Deep_Sparse_Representation_2015_CVPR_paper.pdf", "label": "Li_Deep_Sparse_Representation_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Li_Deep_Sparse_Representation_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "paper", "label": "paper", "shape": "dot", "size": 20.982142857142854, "title": "paper"}, {"color": "#6FA8DC", "id": "similarity measure", "label": "similarity measure", "shape": "dot", "size": 10.267857142857142, "title": "similarity measure"}, {"color": "#6FA8DC", "id": "deep sparse representation", "label": "deep sparse representation", "shape": "dot", "size": 10.089285714285714, "title": "deep sparse representation"}, {"color": "#6FA8DC", "id": "subpixel-level accuracy", "label": "subpixel-level accuracy", "shape": "dot", "size": 10.089285714285714, "title": "subpixel-level accuracy"}, {"color": "#6FA8DC", "id": "robustness", "label": "robustness", "shape": "dot", "size": 10.446428571428571, "title": "robustness"}, {"color": "#6FA8DC", "id": "images", "label": "images", "shape": "dot", "size": 10.803571428571429, "title": "images"}, {"color": "#6FA8DC", "id": "gradient domain", "label": "gradient domain", "shape": "dot", "size": 10.089285714285714, "title": "gradient domain"}, {"color": "#6FA8DC", "id": "frequency domain", "label": "frequency domain", "shape": "dot", "size": 10.089285714285714, "title": "frequency domain"}, {"color": "#6FA8DC", "id": "sparse error tensors", "label": "sparse error tensors", "shape": "dot", "size": 10.089285714285714, "title": "sparse error tensors"}, {"color": "#6FA8DC", "id": "limitations", "label": "limitations", "shape": "dot", "size": 10.267857142857142, "title": "limitations"}, {"color": "#6FA8DC", "id": "spatially-varying intensity distortions", "label": "spatially-varying intensity distortions", "shape": "dot", "size": 10.178571428571429, "title": "spatially-varying intensity distortions"}, {"color": "#6FA8DC", "id": "traditional methods", "label": "traditional methods", "shape": "dot", "size": 10.089285714285714, "title": "traditional methods"}, {"color": "#6FA8DC", "id": "state-of-the-art methods", "label": "state-of-the-art methods", "shape": "dot", "size": 10.892857142857142, "title": "state-of-the-art methods"}, {"color": "#6FA8DC", "id": "RASL", "label": "RASL", "shape": "dot", "size": 10.535714285714286, "title": "RASL"}, {"color": "#6FA8DC", "id": "accuracy", "label": "accuracy", "shape": "dot", "size": 10.803571428571429, "title": "accuracy"}, {"color": "#6FA8DC", "id": "efficiency", "label": "efficiency", "shape": "dot", "size": 10.267857142857142, "title": "efficiency"}, {"color": "#6FA8DC", "id": "Deformable medical image registration", "label": "Deformable medical image registration", "shape": "dot", "size": 10.089285714285714, "title": "Deformable medical image registration"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Medical Imaging", "label": "IEEE Transactions on Medical Imaging", "shape": "dot", "size": 10.357142857142858, "title": "IEEE Transactions on Medical Imaging"}, {"color": "#6FA8DC", "id": "sparse decomposition", "label": "sparse decomposition", "shape": "dot", "size": 10.089285714285714, "title": "sparse decomposition"}, {"color": "#6FA8DC", "id": "low-rank decomposition", "label": "low-rank decomposition", "shape": "dot", "size": 10.089285714285714, "title": "low-rank decomposition"}, {"color": "#6FA8DC", "id": "Robust principal component analysis", "label": "Robust principal component analysis", "shape": "dot", "size": 10.089285714285714, "title": "Robust principal component analysis"}, {"color": "#6FA8DC", "id": "Journal of the ACM", "label": "Journal of the ACM", "shape": "dot", "size": 10.357142857142858, "title": "Journal of the ACM"}, {"color": "#6FA8DC", "id": "Deep sparse representation", "label": "Deep sparse representation", "shape": "dot", "size": 10.089285714285714, "title": "Deep sparse representation"}, {"color": "#6FA8DC", "id": "Deep Learning", "label": "Deep Learning", "shape": "dot", "size": 10.535714285714286, "title": "Deep Learning"}, {"color": "#6FA8DC", "id": "Intensity Distortions", "label": "Intensity Distortions", "shape": "dot", "size": 10.089285714285714, "title": "Intensity Distortions"}, {"color": "#6FA8DC", "id": "existing approaches", "label": "existing approaches", "shape": "dot", "size": 10.982142857142858, "title": "existing approaches"}, {"color": "#6FA8DC", "id": "journal", "label": "journal", "shape": "dot", "size": 10.714285714285714, "title": "journal"}, {"color": "#6FA8DC", "id": "32", "label": "32", "shape": "dot", "size": 10.089285714285714, "title": "32"}, {"color": "#6FA8DC", "id": "7", "label": "7", "shape": "dot", "size": 10.089285714285714, "title": "7"}, {"color": "#6FA8DC", "id": "58", "label": "58", "shape": "dot", "size": 10.089285714285714, "title": "58"}, {"color": "#6FA8DC", "id": "3", "label": "3", "shape": "dot", "size": 10.089285714285714, "title": "3"}, {"color": "#6FA8DC", "id": "Pattern Recognition", "label": "Pattern Recognition", "shape": "dot", "size": 10.446428571428571, "title": "Pattern Recognition"}, {"color": "#6FA8DC", "id": "35", "label": "35", "shape": "dot", "size": 10.089285714285714, "title": "35"}, {"color": "#6FA8DC", "id": "2", "label": "2", "shape": "dot", "size": 10.089285714285714, "title": "2"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Geoscience and Remote Sensing", "label": "IEEE Transactions on Geoscience and Remote Sensing", "shape": "dot", "size": 10.357142857142858, "title": "IEEE Transactions on Geoscience and Remote Sensing"}, {"color": "#6FA8DC", "id": "46", "label": "46", "shape": "dot", "size": 10.089285714285714, "title": "46"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Geoscientific and Remote Sensing", "label": "IEEE Transactions on Geoscientific and Remote Sensing", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Transactions on Geoscientific and Remote Sensing"}, {"color": "#6FA8DC", "id": "5", "label": "5", "shape": "dot", "size": 10.089285714285714, "title": "5"}, {"color": "#6FA8DC", "id": "Medical image analysis", "label": "Medical image analysis", "shape": "dot", "size": 10.267857142857142, "title": "Medical image analysis"}, {"color": "#6FA8DC", "id": "18", "label": "18", "shape": "dot", "size": 10.089285714285714, "title": "18"}, {"color": "#6FA8DC", "id": "6", "label": "6", "shape": "dot", "size": 10.089285714285714, "title": "6"}, {"color": "#6FA8DC", "id": "H", "label": "H", "shape": "dot", "size": 10.089285714285714, "title": "H"}, {"color": "#6FA8DC", "id": "Landmark matching based retinal image alignment", "label": "Landmark matching based retinal image alignment", "shape": "dot", "size": 10.267857142857142, "title": "Landmark matching based retinal image alignment"}, {"color": "#6FA8DC", "id": "Maguire", "label": "Maguire", "shape": "dot", "size": 10.089285714285714, "title": "Maguire"}, {"color": "#6FA8DC", "id": "Brainard", "label": "Brainard", "shape": "dot", "size": 10.089285714285714, "title": "Brainard"}, {"color": "#6FA8DC", "id": "Tzimiropouulos", "label": "Tzimiropouulos", "shape": "dot", "size": 10.089285714285714, "title": "Tzimiropouulos"}, {"color": "#6FA8DC", "id": "Robust FFT-based scale-invariant image registration", "label": "Robust FFT-based scale-invariant image registration", "shape": "dot", "size": 10.357142857142858, "title": "Robust FFT-based scale-invariant image registration"}, {"color": "#6FA8DC", "id": "Argyriou", "label": "Argyriou", "shape": "dot", "size": 10.089285714285714, "title": "Argyriou"}, {"color": "#6FA8DC", "id": "Zafeiriou", "label": "Zafeiriou", "shape": "dot", "size": 10.178571428571429, "title": "Zafeiriou"}, {"color": "#6FA8DC", "id": "Stathaki", "label": "Stathaki", "shape": "dot", "size": 10.089285714285714, "title": "Stathaki"}, {"color": "#6FA8DC", "id": "Viola", "label": "Viola", "shape": "dot", "size": 10.178571428571429, "title": "Viola"}, {"color": "#6FA8DC", "id": "Alignment by maximization of mutual information", "label": "Alignment by maximization of mutual information", "shape": "dot", "size": 10.178571428571429, "title": "Alignment by maximization of mutual information"}, {"color": "#6FA8DC", "id": "Wells III", "label": "Wells III", "shape": "dot", "size": 10.089285714285714, "title": "Wells III"}, {"color": "#6FA8DC", "id": "Gross", "label": "Gross", "shape": "dot", "size": 10.089285714285714, "title": "Gross"}, {"color": "#6FA8DC", "id": "Multi-pie", "label": "Multi-pie", "shape": "dot", "size": 10.446428571428571, "title": "Multi-pie"}, {"color": "#6FA8DC", "id": "Matthews", "label": "Matthews", "shape": "dot", "size": 10.089285714285714, "title": "Matthews"}, {"color": "#6FA8DC", "id": "Cohn", "label": "Cohn", "shape": "dot", "size": 10.089285714285714, "title": "Cohn"}, {"color": "#6FA8DC", "id": "Kanade", "label": "Kanade", "shape": "dot", "size": 10.089285714285714, "title": "Kanade"}, {"color": "#6FA8DC", "id": "Baker", "label": "Baker", "shape": "dot", "size": 10.089285714285714, "title": "Baker"}, {"color": "#6FA8DC", "id": "Zitova", "label": "Zitova", "shape": "dot", "size": 10.089285714285714, "title": "Zitova"}, {"color": "#6FA8DC", "id": "Image registration methods", "label": "Image registration methods", "shape": "dot", "size": 10.178571428571429, "title": "Image registration methods"}, {"color": "#6FA8DC", "id": "Flusser", "label": "Flusser", "shape": "dot", "size": 10.089285714285714, "title": "Flusser"}, {"color": "#6FA8DC", "id": "University of Texas at Arlington", "label": "University of Texas at Arlington", "shape": "dot", "size": 10.267857142857142, "title": "University of Texas at Arlington"}, {"color": "#6FA8DC", "id": "Tsung-Yi Lin", "label": "Tsung-Yi Lin", "shape": "dot", "size": 10.178571428571429, "title": "Tsung-Yi Lin"}, {"color": "#6FA8DC", "id": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "label": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "shape": "dot", "size": 10.625, "title": "Lin_Learning_Deep_Representations_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Yin Cui", "label": "Yin Cui", "shape": "dot", "size": 10.178571428571429, "title": "Yin Cui"}, {"color": "#6FA8DC", "id": "Serge Belongie", "label": "Serge Belongie", "shape": "dot", "size": 10.267857142857142, "title": "Serge Belongie"}, {"color": "#6FA8DC", "id": "James Hays", "label": "James Hays", "shape": "dot", "size": 10.178571428571429, "title": "James Hays"}, {"color": "#6FA8DC", "id": "Image and vision computing", "label": "Image and vision computing", "shape": "dot", "size": 10.089285714285714, "title": "Image and vision computing"}, {"color": "#6FA8DC", "id": "21", "label": "21", "shape": "dot", "size": 10.089285714285714, "title": "21"}, {"color": "#6FA8DC", "id": "977\u20131000", "label": "977\u20131000", "shape": "dot", "size": 10.089285714285714, "title": "977\u20131000"}, {"color": "#6FA8DC", "id": "geo-tagged images", "label": "geo-tagged images", "shape": "dot", "size": 10.089285714285714, "title": "geo-tagged images"}, {"color": "#6FA8DC", "id": "image-based geolocalization algorithms", "label": "image-based geolocalization algorithms", "shape": "dot", "size": 10.178571428571429, "title": "image-based geolocalization algorithms"}, {"color": "#6FA8DC", "id": "ground-level images", "label": "ground-level images", "shape": "dot", "size": 10.089285714285714, "title": "ground-level images"}, {"color": "#6FA8DC", "id": "limitation", "label": "limitation", "shape": "dot", "size": 10.178571428571429, "title": "limitation"}, {"color": "#6FA8DC", "id": "ground-level query images", "label": "ground-level query images", "shape": "dot", "size": 10.089285714285714, "title": "ground-level query images"}, {"color": "#6FA8DC", "id": "aerial imagery", "label": "aerial imagery", "shape": "dot", "size": 10.089285714285714, "title": "aerial imagery"}, {"color": "#6FA8DC", "id": "Where-CNN", "label": "Where-CNN", "shape": "dot", "size": 10.178571428571429, "title": "Where-CNN"}, {"color": "#6FA8DC", "id": "deep learning approach", "label": "deep learning approach", "shape": "dot", "size": 10.178571428571429, "title": "deep learning approach"}, {"color": "#6FA8DC", "id": "face verification", "label": "face verification", "shape": "dot", "size": 10.357142857142858, "title": "face verification"}, {"color": "#6FA8DC", "id": "dataset", "label": "dataset", "shape": "dot", "size": 12.232142857142858, "title": "dataset"}, {"color": "#6FA8DC", "id": "78K aligned cross-view image pairs", "label": "78K aligned cross-view image pairs", "shape": "dot", "size": 10.089285714285714, "title": "78K aligned cross-view image pairs"}, {"color": "#6FA8DC", "id": "feature representation", "label": "feature representation", "shape": "dot", "size": 10.178571428571429, "title": "feature representation"}, {"color": "#6FA8DC", "id": "matching views", "label": "matching views", "shape": "dot", "size": 10.089285714285714, "title": "matching views"}, {"color": "#6FA8DC", "id": "close", "label": "close", "shape": "dot", "size": 10.089285714285714, "title": "close"}, {"color": "#6FA8DC", "id": "mismatched views", "label": "mismatched views", "shape": "dot", "size": 10.089285714285714, "title": "mismatched views"}, {"color": "#6FA8DC", "id": "far apart", "label": "far apart", "shape": "dot", "size": 10.089285714285714, "title": "far apart"}, {"color": "#6FA8DC", "id": "Geolocalization", "label": "Geolocalization", "shape": "dot", "size": 10.089285714285714, "title": "Geolocalization"}, {"color": "#6FA8DC", "id": "Aerial Imagery", "label": "Aerial Imagery", "shape": "dot", "size": 10.089285714285714, "title": "Aerial Imagery"}, {"color": "#6FA8DC", "id": "Cross-View Matching", "label": "Cross-View Matching", "shape": "dot", "size": 10.178571428571429, "title": "Cross-View Matching"}, {"color": "#6FA8DC", "id": "Feature Representation", "label": "Feature Representation", "shape": "dot", "size": 10.089285714285714, "title": "Feature Representation"}, {"color": "#6FA8DC", "id": "Deep Convolutional Neural Networks", "label": "Deep Convolutional Neural Networks", "shape": "dot", "size": 10.267857142857142, "title": "Deep Convolutional Neural Networks"}, {"color": "#6FA8DC", "id": "Image Classification", "label": "Image Classification", "shape": "dot", "size": 10.267857142857142, "title": "Image Classification"}, {"color": "#6FA8DC", "id": "Google Street View", "label": "Google Street View", "shape": "dot", "size": 10.089285714285714, "title": "Google Street View"}, {"color": "#6FA8DC", "id": "World", "label": "World", "shape": "dot", "size": 10.089285714285714, "title": "World"}, {"color": "#6FA8DC", "id": "Distinctive Image Features", "label": "Distinctive Image Features", "shape": "dot", "size": 10.089285714285714, "title": "Distinctive Image Features"}, {"color": "#6FA8DC", "id": "Scale-Invariant Keypoints", "label": "Scale-Invariant Keypoints", "shape": "dot", "size": 10.089285714285714, "title": "Scale-Invariant Keypoints"}, {"color": "#6FA8DC", "id": "Deepface", "label": "Deepface", "shape": "dot", "size": 10.089285714285714, "title": "Deepface"}, {"color": "#6FA8DC", "id": "Human-Level Performance", "label": "Human-Level Performance", "shape": "dot", "size": 10.089285714285714, "title": "Human-Level Performance"}, {"color": "#6FA8DC", "id": "Learning a Similarity Metric", "label": "Learning a Similarity Metric", "shape": "dot", "size": 10.089285714285714, "title": "Learning a Similarity Metric"}, {"color": "#6FA8DC", "id": "Face Verification", "label": "Face Verification", "shape": "dot", "size": 10.089285714285714, "title": "Face Verification"}, {"color": "#6FA8DC", "id": "Novel Locations", "label": "Novel Locations", "shape": "dot", "size": 10.089285714285714, "title": "Novel Locations"}, {"color": "#6FA8DC", "id": "Traditional Deep Features", "label": "Traditional Deep Features", "shape": "dot", "size": 10.089285714285714, "title": "Traditional Deep Features"}, {"color": "#6FA8DC", "id": "Chopra et al. (2005)", "label": "Chopra et al. (2005)", "shape": "dot", "size": 10.178571428571429, "title": "Chopra et al. (2005)"}, {"color": "#6FA8DC", "id": "Lin et al. (2013)", "label": "Lin et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Lin et al. (2013)"}, {"color": "#6FA8DC", "id": "Bansal \u0026 Daniilidis (2014)", "label": "Bansal \u0026 Daniilidis (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Bansal \u0026 Daniilidis (2014)"}, {"color": "#6FA8DC", "id": "van der Maaten \u0026 Hinton (2008)", "label": "van der Maaten \u0026 Hinton (2008)", "shape": "dot", "size": 10.089285714285714, "title": "van der Maaten \u0026 Hinton (2008)"}, {"color": "#6FA8DC", "id": "JMLR", "label": "JMLR", "shape": "dot", "size": 10.267857142857142, "title": "JMLR"}, {"color": "#6FA8DC", "id": "Xiao et al. (2010)", "label": "Xiao et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Xiao et al. (2010)"}, {"color": "#6FA8DC", "id": "Felzenszwalb et al. (2010)", "label": "Felzenszwalb et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Felzenszwalb et al. (2010)"}, {"color": "#6FA8DC", "id": "PAMI", "label": "PAMI", "shape": "dot", "size": 10.535714285714286, "title": "PAMI"}, {"color": "#6FA8DC", "id": "Cornell Tech", "label": "Cornell Tech", "shape": "dot", "size": 10.357142857142858, "title": "Cornell Tech"}, {"color": "#6FA8DC", "id": "Brown University", "label": "Brown University", "shape": "dot", "size": 10.089285714285714, "title": "Brown University"}, {"color": "#6FA8DC", "id": "Junho Yim", "label": "Junho Yim", "shape": "dot", "size": 10.089285714285714, "title": "Junho Yim"}, {"color": "#6FA8DC", "id": "Rotating Your Face Using Multi-task Deep Neural Network", "label": "Rotating Your Face Using Multi-task Deep Neural Network", "shape": "dot", "size": 10.446428571428571, "title": "Rotating Your Face Using Multi-task Deep Neural Network"}, {"color": "#6FA8DC", "id": "Heechul Jung", "label": "Heechul Jung", "shape": "dot", "size": 10.178571428571429, "title": "Heechul Jung"}, {"color": "#6FA8DC", "id": "Rotating Your face Using Multi-task Deep Neural Network", "label": "Rotating Your face Using Multi-task Deep Neural Network", "shape": "dot", "size": 10.089285714285714, "title": "Rotating Your face Using Multi-task Deep Neural Network"}, {"color": "#6FA8DC", "id": "ByungIn Yoo", "label": "ByungIn Yoo", "shape": "dot", "size": 10.178571428571429, "title": "ByungIn Yoo"}, {"color": "#6FA8DC", "id": "Changkyu Choi", "label": "Changkyu Choi", "shape": "dot", "size": 10.178571428571429, "title": "Changkyu Choi"}, {"color": "#6FA8DC", "id": "Dusik Park", "label": "Dusik Park", "shape": "dot", "size": 10.178571428571429, "title": "Dusik Park"}, {"color": "#6FA8DC", "id": "Junmo Kim", "label": "Junmo Kim", "shape": "dot", "size": 10.625, "title": "Junmo Kim"}, {"color": "#6FA8DC", "id": "Yim_Rotating_Your_Face_2015_CVPR_paper.pdf", "label": "Yim_Rotating_Your_Face_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Yim_Rotating_Your_Face_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "CVPR paper", "label": "CVPR paper", "shape": "dot", "size": 12.857142857142858, "title": "CVPR paper"}, {"color": "#6FA8DC", "id": "Face recognition", "label": "Face recognition", "shape": "dot", "size": 10.178571428571429, "title": "Face recognition"}, {"color": "#6FA8DC", "id": "viewpoint and illumination changes", "label": "viewpoint and illumination changes", "shape": "dot", "size": 10.089285714285714, "title": "viewpoint and illumination changes"}, {"color": "#6FA8DC", "id": "new deep architecture", "label": "new deep architecture", "shape": "dot", "size": 10.178571428571429, "title": "new deep architecture"}, {"color": "#6FA8DC", "id": "novel type of multitask learning", "label": "novel type of multitask learning", "shape": "dot", "size": 10.089285714285714, "title": "novel type of multitask learning"}, {"color": "#6FA8DC", "id": "target-pose face image", "label": "target-pose face image", "shape": "dot", "size": 10.089285714285714, "title": "target-pose face image"}, {"color": "#6FA8DC", "id": "arbitrary pose and illumination image", "label": "arbitrary pose and illumination image", "shape": "dot", "size": 10.089285714285714, "title": "arbitrary pose and illumination image"}, {"color": "#6FA8DC", "id": "target pose", "label": "target pose", "shape": "dot", "size": 10.089285714285714, "title": "target pose"}, {"color": "#6FA8DC", "id": "user\u2019s intention", "label": "user\u2019s intention", "shape": "dot", "size": 10.089285714285714, "title": "user\u2019s intention"}, {"color": "#6FA8DC", "id": "multi-task model", "label": "multi-task model", "shape": "dot", "size": 10.089285714285714, "title": "multi-task model"}, {"color": "#6FA8DC", "id": "identity preservation", "label": "identity preservation", "shape": "dot", "size": 10.089285714285714, "title": "identity preservation"}, {"color": "#6FA8DC", "id": "Controlled Pose Image (CPI)", "label": "Controlled Pose Image (CPI)", "shape": "dot", "size": 10.089285714285714, "title": "Controlled Pose Image (CPI)"}, {"color": "#6FA8DC", "id": "pose-illumination- invariant feature", "label": "pose-illumination- invariant feature", "shape": "dot", "size": 10.089285714285714, "title": "pose-illumination- invariant feature"}, {"color": "#6FA8DC", "id": "state-of-the-art algorithms", "label": "state-of-the-art algorithms", "shape": "dot", "size": 10.178571428571429, "title": "state-of-the-art algorithms"}, {"color": "#6FA8DC", "id": "MultiPIE dataset", "label": "MultiPIE dataset", "shape": "dot", "size": 10.267857142857142, "title": "MultiPIE dataset"}, {"color": "#6FA8DC", "id": "Proposed method", "label": "Proposed method", "shape": "dot", "size": 10.446428571428571, "title": "Proposed method"}, {"color": "#6FA8DC", "id": "School of Electrical Engineerin, KAIST", "label": "School of Electrical Engineerin, KAIST", "shape": "dot", "size": 10.089285714285714, "title": "School of Electrical Engineerin, KAIST"}, {"color": "#6FA8DC", "id": "Samsung Advanced Institute of Technology", "label": "Samsung Advanced Institute of Technology", "shape": "dot", "size": 10.267857142857142, "title": "Samsung Advanced Institute of Technology"}, {"color": "#6FA8DC", "id": "School of Electrical Engineering, KAIST", "label": "School of Electrical Engineering, KAIST", "shape": "dot", "size": 10.089285714285714, "title": "School of Electrical Engineering, KAIST"}, {"color": "#6FA8DC", "id": "Ramakrishna Vedantam", "label": "Ramakrishna Vedantam", "shape": "dot", "size": 10.089285714285714, "title": "Ramakrishna Vedantam"}, {"color": "#6FA8DC", "id": "CIDEr", "label": "CIDEr", "shape": "dot", "size": 10.714285714285714, "title": "CIDEr"}, {"color": "#6FA8DC", "id": "C. Lawrence Zitnick", "label": "C. Lawrence Zitnick", "shape": "dot", "size": 10.178571428571429, "title": "C. Lawrence Zitnick"}, {"color": "#6FA8DC", "id": "Devi Parikh", "label": "Devi Parikh", "shape": "dot", "size": 10.178571428571429, "title": "Devi Parikh"}, {"color": "#6FA8DC", "id": "School of Electrical Engineering", "label": "School of Electrical Engineering", "shape": "dot", "size": 10.178571428571429, "title": "School of Electrical Engineering"}, {"color": "#6FA8DC", "id": "junmo.kim@kaisten.ac.kr", "label": "junmo.kim@kaisten.ac.kr", "shape": "dot", "size": 10.089285714285714, "title": "junmo.kim@kaisten.ac.kr"}, {"color": "#6FA8DC", "id": "Image Description Evaluation", "label": "Image Description Evaluation", "shape": "dot", "size": 10.089285714285714, "title": "Image Description Evaluation"}, {"color": "#6FA8DC", "id": "KAIST", "label": "KAIST", "shape": "dot", "size": 10.178571428571429, "title": "KAIST"}, {"color": "#6FA8DC", "id": "Image Description", "label": "Image Description", "shape": "dot", "size": 10.535714285714286, "title": "Image Description"}, {"color": "#6FA8DC", "id": "Computer Vision", "label": "Computer Vision", "shape": "dot", "size": 12.5, "title": "Computer Vision"}, {"color": "#6FA8DC", "id": "Natural Language Processing", "label": "Natural Language Processing", "shape": "dot", "size": 10.178571428571429, "title": "Natural Language Processing"}, {"color": "#6FA8DC", "id": "Object Detection", "label": "Object Detection", "shape": "dot", "size": 11.517857142857142, "title": "Object Detection"}, {"color": "#6FA8DC", "id": "Attribute Classification", "label": "Attribute Classification", "shape": "dot", "size": 10.089285714285714, "title": "Attribute Classification"}, {"color": "#6FA8DC", "id": "Paradigm", "label": "Paradigm", "shape": "dot", "size": 10.357142857142858, "title": "Paradigm"}, {"color": "#6FA8DC", "id": "Human Consensus", "label": "Human Consensus", "shape": "dot", "size": 10.089285714285714, "title": "Human Consensus"}, {"color": "#6FA8DC", "id": "Triplet-based Method", "label": "Triplet-based Method", "shape": "dot", "size": 10.089285714285714, "title": "Triplet-based Method"}, {"color": "#6FA8DC", "id": "Automated Metric", "label": "Automated Metric", "shape": "dot", "size": 10.089285714285714, "title": "Automated Metric"}, {"color": "#6FA8DC", "id": "Datasets", "label": "Datasets", "shape": "dot", "size": 10.267857142857142, "title": "Datasets"}, {"color": "#6FA8DC", "id": "PASCAL-50S", "label": "PASCAL-50S", "shape": "dot", "size": 10.178571428571429, "title": "PASCAL-50S"}, {"color": "#6FA8DC", "id": "ABSTRACT-50S", "label": "ABSTRACT-50S", "shape": "dot", "size": 10.089285714285714, "title": "ABSTRACT-50S"}, {"color": "#6FA8DC", "id": "Metric", "label": "Metric", "shape": "dot", "size": 10.089285714285714, "title": "Metric"}, {"color": "#6FA8DC", "id": "Human Judgment", "label": "Human Judgment", "shape": "dot", "size": 10.089285714285714, "title": "Human Judgment"}, {"color": "#6FA8DC", "id": "nsensus", "label": "nsensus", "shape": "dot", "size": 10.089285714285714, "title": "nsensus"}, {"color": "#6FA8DC", "id": "metric", "label": "metric", "shape": "dot", "size": 10.178571428571429, "title": "metric"}, {"color": "#6FA8DC", "id": "human judgment", "label": "human judgment", "shape": "dot", "size": 10.089285714285714, "title": "human judgment"}, {"color": "#6FA8DC", "id": "existing metrics", "label": "existing metrics", "shape": "dot", "size": 10.089285714285714, "title": "existing metrics"}, {"color": "#6FA8DC", "id": "sentences", "label": "sentences", "shape": "dot", "size": 10.089285714285714, "title": "sentences"}, {"color": "#6FA8DC", "id": "various sources", "label": "various sources", "shape": "dot", "size": 10.089285714285714, "title": "various sources"}, {"color": "#6FA8DC", "id": "CIDEr-D", "label": "CIDEr-D", "shape": "dot", "size": 10.178571428571429, "title": "CIDEr-D"}, {"color": "#6FA8DC", "id": "MS COCO evaluation server", "label": "MS COCO evaluation server", "shape": "dot", "size": 10.178571428571429, "title": "MS COCO evaluation server"}, {"color": "#6FA8DC", "id": "systematic evaluation", "label": "systematic evaluation", "shape": "dot", "size": 10.089285714285714, "title": "systematic evaluation"}, {"color": "#6FA8DC", "id": "image description approaches", "label": "image description approaches", "shape": "dot", "size": 10.089285714285714, "title": "image description approaches"}, {"color": "#6FA8DC", "id": "protocol", "label": "protocol", "shape": "dot", "size": 10.089285714285714, "title": "protocol"}, {"color": "#6FA8DC", "id": "Automated Metrics", "label": "Automated Metrics", "shape": "dot", "size": 10.089285714285714, "title": "Automated Metrics"}, {"color": "#6FA8DC", "id": "Microsoft Research", "label": "Microsoft Research", "shape": "dot", "size": 11.964285714285715, "title": "Microsoft Research"}, {"color": "#6FA8DC", "id": "Virginia Tech", "label": "Virginia Tech", "shape": "dot", "size": 10.178571428571429, "title": "Virginia Tech"}, {"color": "#6FA8DC", "id": "Zhenzhong Lan", "label": "Zhenzhong Lan", "shape": "dot", "size": 10.178571428571429, "title": "Zhenzhong Lan"}, {"color": "#6FA8DC", "id": "Beyond Gaussian Pyramid", "label": "Beyond Gaussian Pyramid", "shape": "dot", "size": 10.357142857142858, "title": "Beyond Gaussian Pyramid"}, {"color": "#6FA8DC", "id": "Alexander G. Hauptmann", "label": "Alexander G. Hauptmann", "shape": "dot", "size": 10.178571428571429, "title": "Alexander G. Hauptmann"}, {"color": "#6FA8DC", "id": "Bhiksha Raj", "label": "Bhiksha Raj", "shape": "dot", "size": 10.267857142857142, "title": "Bhiksha Raj"}, {"color": "#6FA8DC", "id": "Lan_Beyond_Gausian_Pyramid_2015_CVPR_supplemental", "label": "Lan_Beyond_Gausian_Pyramid_2015_CVPR_supplemental", "shape": "dot", "size": 10.267857142857142, "title": "Lan_Beyond_Gausian_Pyramid_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "Beyond Gaussian Pyramid: Multi-skip Feature Stacking for Action Recognition", "label": "Beyond Gaussian Pyramid: Multi-skip Feature Stacking for Action Recognition", "shape": "dot", "size": 10.267857142857142, "title": "Beyond Gaussian Pyramid: Multi-skip Feature Stacking for Action Recognition"}, {"color": "#6FA8DC", "id": "Action Recognition", "label": "Action Recognition", "shape": "dot", "size": 10.982142857142858, "title": "Action Recognition"}, {"color": "#6FA8DC", "id": "proof of theorem 1", "label": "proof of theorem 1", "shape": "dot", "size": 10.089285714285714, "title": "proof of theorem 1"}, {"color": "#6FA8DC", "id": "proof of theorem 2", "label": "proof of theorem 2", "shape": "dot", "size": 10.089285714285714, "title": "proof of theorem 2"}, {"color": "#6FA8DC", "id": "School of Computer Science, Carnegie Mellon University", "label": "School of Computer Science, Carnegie Mellon University", "shape": "dot", "size": 10.357142857142858, "title": "School of Computer Science, Carnegie Mellon University"}, {"color": "#6FA8DC", "id": "Ming Lin", "label": "Ming Lin", "shape": "dot", "size": 10.089285714285714, "title": "Ming Lin"}, {"color": "#6FA8DC", "id": "Feature Stacking", "label": "Feature Stacking", "shape": "dot", "size": 10.178571428571429, "title": "Feature Stacking"}, {"color": "#6FA8DC", "id": "Matrix Bernstein\u0027s Inequality", "label": "Matrix Bernstein\u0027s Inequality", "shape": "dot", "size": 10.089285714285714, "title": "Matrix Bernstein\u0027s Inequality"}, {"color": "#6FA8DC", "id": "Condition Number", "label": "Condition Number", "shape": "dot", "size": 10.089285714285714, "title": "Condition Number"}, {"color": "#6FA8DC", "id": "Alexander G. Hauptman", "label": "Alexander G. Hauptman", "shape": "dot", "size": 10.089285714285714, "title": "Alexander G. Hauptman"}, {"color": "#6FA8DC", "id": "cli@cs.cmu.edu", "label": "cli@cs.cmu.edu", "shape": "dot", "size": 10.089285714285714, "title": "cli@cs.cmu.edu"}, {"color": "#6FA8DC", "id": "bhiksha@cs.cmu.edu", "label": "bhiksha@cs.cmu.edu", "shape": "dot", "size": 10.089285714285714, "title": "bhiksha@cs.cmu.edu"}, {"color": "#6FA8DC", "id": "Kwang In Kim", "label": "Kwang In Kim", "shape": "dot", "size": 10.089285714285714, "title": "Kwang In Kim"}, {"color": "#6FA8DC", "id": "Kim_Local_High-Order_Regularization_2015_CVPR_paper.pdf", "label": "Kim_Local_High-Order_Regularization_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.178571428571429, "title": "Kim_Local_High-Order_Regularization_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "James Tompkin", "label": "James Tompkin", "shape": "dot", "size": 10.089285714285714, "title": "James Tompkin"}, {"color": "#6FA8DC", "id": "Hanspeter Pfister", "label": "Hanspeter Pfister", "shape": "dot", "size": 10.089285714285714, "title": "Hanspeter Pfister"}, {"color": "#6FA8DC", "id": "Kim_Local_High-Order_RegularIZATION_2015_CVPR_paper.pdf", "label": "Kim_Local_High-Order_RegularIZATION_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.267857142857142, "title": "Kim_Local_High-Order_RegularIZATION_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Christian Theobalt", "label": "Christian Theobalt", "shape": "dot", "size": 10.267857142857142, "title": "Christian Theobalt"}, {"color": "#6FA8DC", "id": "Local High-order Regularization on Data Manifolds", "label": "Local High-order Regularization on Data Manifolds", "shape": "dot", "size": 10.089285714285714, "title": "Local High-order Regularization on Data Manifolds"}, {"color": "#6FA8DC", "id": "Carnegie Mellon University", "label": "Carnegie Mellon University", "shape": "dot", "size": 10.625, "title": "Carnegie Mellon University"}, {"color": "#6FA8DC", "id": "School of Computer Science", "label": "School of Computer Science", "shape": "dot", "size": 10.892857142857142, "title": "School of Computer Science"}, {"color": "#6FA8DC", "id": "Graph Laplacian Regularizer", "label": "Graph Laplacian Regularizer", "shape": "dot", "size": 10.089285714285714, "title": "Graph Laplacian Regularizer"}, {"color": "#6FA8DC", "id": "degeneracy", "label": "degeneracy", "shape": "dot", "size": 10.178571428571429, "title": "degeneracy"}, {"color": "#6FA8DC", "id": "Iterated Graph Laplacian", "label": "Iterated Graph Laplacian", "shape": "dot", "size": 10.178571428571429, "title": "Iterated Graph Laplacian"}, {"color": "#6FA8DC", "id": "computational complexity", "label": "computational complexity", "shape": "dot", "size": 10.178571428571429, "title": "computational complexity"}, {"color": "#6FA8DC", "id": "Proposed Regularizer", "label": "Proposed Regularizer", "shape": "dot", "size": 10.178571428571429, "title": "Proposed Regularizer"}, {"color": "#6FA8DC", "id": "sparsity", "label": "sparsity", "shape": "dot", "size": 10.178571428571429, "title": "sparsity"}, {"color": "#6FA8DC", "id": "Approach", "label": "Approach", "shape": "dot", "size": 11.875, "title": "Approach"}, {"color": "#6FA8DC", "id": "manifold approximation", "label": "manifold approximation", "shape": "dot", "size": 10.089285714285714, "title": "manifold approximation"}, {"color": "#6FA8DC", "id": "local derivative evaluations", "label": "local derivative evaluations", "shape": "dot", "size": 10.089285714285714, "title": "local derivative evaluations"}, {"color": "#6FA8DC", "id": "Experiments", "label": "Experiments", "shape": "dot", "size": 11.339285714285715, "title": "Experiments"}, {"color": "#6FA8DC", "id": "Manifold Approximation", "label": "Manifold Approximation", "shape": "dot", "size": 10.178571428571429, "title": "Manifold Approximation"}, {"color": "#6FA8DC", "id": "surrogate geometry", "label": "surrogate geometry", "shape": "dot", "size": 10.089285714285714, "title": "surrogate geometry"}, {"color": "#6FA8DC", "id": "Graph Laplacian Regularization", "label": "Graph Laplacian Regularization", "shape": "dot", "size": 10.267857142857142, "title": "Graph Laplacian Regularization"}, {"color": "#6FA8DC", "id": "Semi-Supervised Learning", "label": "Semi-Supervised Learning", "shape": "dot", "size": 10.267857142857142, "title": "Semi-Supervised Learning"}, {"color": "#6FA8DC", "id": "Laplacian eigenmaps", "label": "Laplacian eigenmaps", "shape": "dot", "size": 10.178571428571429, "title": "Laplacian eigenmaps"}, {"color": "#6FA8DC", "id": "dimensionality reduction", "label": "dimensionality reduction", "shape": "dot", "size": 10.357142857142858, "title": "dimensionality reduction"}, {"color": "#6FA8DC", "id": "High-Order Derivatives", "label": "High-Order Derivatives", "shape": "dot", "size": 10.089285714285714, "title": "High-Order Derivatives"}, {"color": "#6FA8DC", "id": "Hessian eigenmaps", "label": "Hessian eigenmaps", "shape": "dot", "size": 10.267857142857142, "title": "Hessian eigenmaps"}, {"color": "#6FA8DC", "id": "Hessian eigenMaps", "label": "Hessian eigenMaps", "shape": "dot", "size": 10.089285714285714, "title": "Hessian eigenMaps"}, {"color": "#6FA8DC", "id": "locally linear embedding", "label": "locally linear embedding", "shape": "dot", "size": 10.089285714285714, "title": "locally linear embedding"}, {"color": "#6FA8DC", "id": "Normalized cuts", "label": "Normalized cuts", "shape": "dot", "size": 10.089285714285714, "title": "Normalized cuts"}, {"color": "#6FA8DC", "id": "image segmentation", "label": "image segmentation", "shape": "dot", "size": 10.535714285714286, "title": "image segmentation"}, {"color": "#6FA8DC", "id": "Reproducing Kernel Hilbert Space (RKHS)", "label": "Reproducing Kernel Hilbert Space (RKHS)", "shape": "dot", "size": 10.178571428571429, "title": "Reproducing Kernel Hilbert Space (RKHS)"}, {"color": "#6FA8DC", "id": "Spectral Clustering", "label": "Spectral Clustering", "shape": "dot", "size": 10.267857142857142, "title": "Spectral Clustering"}, {"color": "#6FA8DC", "id": "Plug-in classifiers", "label": "Plug-in classifiers", "shape": "dot", "size": 10.089285714285714, "title": "Plug-in classifiers"}, {"color": "#6FA8DC", "id": "fast learning rates", "label": "fast learning rates", "shape": "dot", "size": 10.089285714285714, "title": "fast learning rates"}, {"color": "#6FA8DC", "id": "Supervised Learning", "label": "Supervised Learning", "shape": "dot", "size": 10.267857142857142, "title": "Supervised Learning"}, {"color": "#6FA8DC", "id": "MIT Press", "label": "MIT Press", "shape": "dot", "size": 10.089285714285714, "title": "MIT Press"}, {"color": "#6FA8DC", "id": "2006", "label": "2006", "shape": "dot", "size": 10.089285714285714, "title": "2006"}, {"color": "#6FA8DC", "id": "Statistics and Computing", "label": "Statistics and Computing", "shape": "dot", "size": 10.089285714285714, "title": "Statistics and Computing"}, {"color": "#6FA8DC", "id": "Normalized Cuts", "label": "Normalized Cuts", "shape": "dot", "size": 10.267857142857142, "title": "Normalized Cuts"}, {"color": "#6FA8DC", "id": "Image Segmentation", "label": "Image Segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Image Segmentation"}, {"color": "#6FA8DC", "id": "Real Analysis and Probability", "label": "Real Analysis and Probability", "shape": "dot", "size": 10.089285714285714, "title": "Real Analysis and Probability"}, {"color": "#6FA8DC", "id": "Cambridge University Press", "label": "Cambridge University Press", "shape": "dot", "size": 10.267857142857142, "title": "Cambridge University Press"}, {"color": "#6FA8DC", "id": "Graphs", "label": "Graphs", "shape": "dot", "size": 10.089285714285714, "title": "Graphs"}, {"color": "#6FA8DC", "id": "Manifolds", "label": "Manifolds", "shape": "dot", "size": 10.089285714285714, "title": "Manifolds"}, {"color": "#6FA8DC", "id": "Graph Laplacians", "label": "Graph Laplacians", "shape": "dot", "size": 10.089285714285714, "title": "Graph Laplacians"}, {"color": "#6FA8DC", "id": "Pointwise Consistency", "label": "Pointwise Consistency", "shape": "dot", "size": 10.089285714285714, "title": "Pointwise Consistency"}, {"color": "#6FA8DC", "id": "Jianping Shi", "label": "Jianping Shi", "shape": "dot", "size": 10.357142857142858, "title": "Jianping Shi"}, {"color": "#6FA8DC", "id": "Just Noticeable Defocus Blur Detection and Estimation", "label": "Just Noticeable Defocus Blur Detection and Estimation", "shape": "dot", "size": 10.357142857142858, "title": "Just Noticeable Defocus Blur Detection and Estimation"}, {"color": "#6FA8DC", "id": "Li Xu", "label": "Li Xu", "shape": "dot", "size": 10.357142857142858, "title": "Li Xu"}, {"color": "#6FA8DC", "id": "Jiaya Jia", "label": "Jiaya Jia", "shape": "dot", "size": 10.357142857142858, "title": "Jiaya Jia"}, {"color": "#6FA8DC", "id": "Just Noticeable Defocus Blur Detectio and Estimation", "label": "Just Noticeable Defocus Blur Detectio and Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Just Noticeable Defocus Blur Detectio and Estimation"}, {"color": "#6FA8DC", "id": "Shi_Just_Noticeable_Defocus_2015_CVPR_paper.pdf", "label": "Shi_Just_Noticeable_Defocus_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Shi_Just_Noticeable_Defocus_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "MPI for Informatics", "label": "MPI for Informatics", "shape": "dot", "size": 10.089285714285714, "title": "MPI for Informatics"}, {"color": "#6FA8DC", "id": "just noticeable blur", "label": "just noticeable blur", "shape": "dot", "size": 10.178571428571429, "title": "just noticeable blur"}, {"color": "#6FA8DC", "id": "defocus", "label": "defocus", "shape": "dot", "size": 10.089285714285714, "title": "defocus"}, {"color": "#6FA8DC", "id": "small number of pixels", "label": "small number of pixels", "shape": "dot", "size": 10.089285714285714, "title": "small number of pixels"}, {"color": "#6FA8DC", "id": "slight edge blurriness", "label": "slight edge blurriness", "shape": "dot", "size": 10.089285714285714, "title": "slight edge blurriness"}, {"color": "#6FA8DC", "id": "informative clues", "label": "informative clues", "shape": "dot", "size": 10.178571428571429, "title": "informative clues"}, {"color": "#6FA8DC", "id": "depth", "label": "depth", "shape": "dot", "size": 10.178571428571429, "title": "depth"}, {"color": "#6FA8DC", "id": "blur descriptors", "label": "blur descriptors", "shape": "dot", "size": 10.089285714285714, "title": "blur descriptors"}, {"color": "#6FA8DC", "id": "local information", "label": "local information", "shape": "dot", "size": 10.089285714285714, "title": "local information"}, {"color": "#6FA8DC", "id": "blur feature", "label": "blur feature", "shape": "dot", "size": 10.178571428571429, "title": "blur feature"}, {"color": "#6FA8DC", "id": "sparse representation", "label": "sparse representation", "shape": "dot", "size": 10.089285714285714, "title": "sparse representation"}, {"color": "#6FA8DC", "id": "image decomposition", "label": "image decomposition", "shape": "dot", "size": 10.089285714285714, "title": "image decomposition"}, {"color": "#6FA8DC", "id": "sparse edge representation", "label": "sparse edge representation", "shape": "dot", "size": 10.178571428571429, "title": "sparse edge representation"}, {"color": "#6FA8DC", "id": "blur strength estimation", "label": "blur strength estimation", "shape": "dot", "size": 10.089285714285714, "title": "blur strength estimation"}, {"color": "#6FA8DC", "id": "age decomposition", "label": "age decomposition", "shape": "dot", "size": 10.089285714285714, "title": "age decomposition"}, {"color": "#6FA8DC", "id": "feature", "label": "feature", "shape": "dot", "size": 10.178571428571429, "title": "feature"}, {"color": "#6FA8DC", "id": "generality", "label": "generality", "shape": "dot", "size": 10.089285714285714, "title": "generality"}, {"color": "#6FA8DC", "id": "The Chinese University of Hong Kong", "label": "The Chinese University of Hong Kong", "shape": "dot", "size": 10.178571428571429, "title": "The Chinese University of Hong Kong"}, {"color": "#6FA8DC", "id": "Lenovo R\u0026T", "label": "Lenovo R\u0026T", "shape": "dot", "size": 10.089285714285714, "title": "Lenovo R\u0026T"}, {"color": "#6FA8DC", "id": "Bernt Schiele", "label": "Bernt Schiele", "shape": "dot", "size": 10.267857142857142, "title": "Bernt Schiele"}, {"color": "#6FA8DC", "id": "Filtered Channel Features for Pedestrian Detection", "label": "Filtered Channel Features for Pedestrian Detection", "shape": "dot", "size": 10.357142857142858, "title": "Filtered Channel Features for Pedestrian Detection"}, {"color": "#6FA8DC", "id": "Shanshan Zhang", "label": "Shanshan Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Shanshan Zhang"}, {"color": "#6FA8DC", "id": "Rodrigo Benenson", "label": "Rodrigo Benenson", "shape": "dot", "size": 10.357142857142858, "title": "Rodrigo Benenson"}, {"color": "#6FA8DC", "id": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental.pdf", "label": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental", "label": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental", "shape": "dot", "size": 10.178571428571429, "title": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "Checkerboards4x3 model", "label": "Checkerboards4x3 model", "shape": "dot", "size": 10.089285714285714, "title": "Checkerboards4x3 model"}, {"color": "#6FA8DC", "id": "pedestrian detection model", "label": "pedestrian detection model", "shape": "dot", "size": 10.089285714285714, "title": "pedestrian detection model"}, {"color": "#6FA8DC", "id": "Roerei model", "label": "Roerei model", "shape": "dot", "size": 10.089285714285714, "title": "Roerei model"}, {"color": "#6FA8DC", "id": "weaker model", "label": "weaker model", "shape": "dot", "size": 10.089285714285714, "title": "weaker model"}, {"color": "#6FA8DC", "id": "filtered channels", "label": "filtered channels", "shape": "dot", "size": 10.178571428571429, "title": "filtered channels"}, {"color": "#6FA8DC", "id": "areas of pedestrian deemed informative", "label": "areas of pedestrian deemed informative", "shape": "dot", "size": 10.089285714285714, "title": "areas of pedestrian deemed informative"}, {"color": "#6FA8DC", "id": "extraction of discriminative information", "label": "extraction of discriminative information", "shape": "dot", "size": 10.089285714285714, "title": "extraction of discriminative information"}, {"color": "#6FA8DC", "id": "channel U", "label": "channel U", "shape": "dot", "size": 10.089285714285714, "title": "channel U"}, {"color": "#6FA8DC", "id": "face", "label": "face", "shape": "dot", "size": 10.089285714285714, "title": "face"}, {"color": "#6FA8DC", "id": "channel L", "label": "channel L", "shape": "dot", "size": 10.089285714285714, "title": "channel L"}, {"color": "#6FA8DC", "id": "body", "label": "body", "shape": "dot", "size": 10.178571428571429, "title": "body"}, {"color": "#6FA8DC", "id": "gradient magnitude channel", "label": "gradient magnitude channel", "shape": "dot", "size": 10.089285714285714, "title": "gradient magnitude channel"}, {"color": "#6FA8DC", "id": "filter usage distribution", "label": "filter usage distribution", "shape": "dot", "size": 10.178571428571429, "title": "filter usage distribution"}, {"color": "#6FA8DC", "id": "filter bank families", "label": "filter bank families", "shape": "dot", "size": 10.178571428571429, "title": "filter bank families"}, {"color": "#6FA8DC", "id": "filter", "label": "filter", "shape": "dot", "size": 10.178571428571429, "title": "filter"}, {"color": "#6FA8DC", "id": "feature for decision tree split nodes", "label": "feature for decision tree split nodes", "shape": "dot", "size": 10.089285714285714, "title": "feature for decision tree split nodes"}, {"color": "#6FA8DC", "id": "decision tree split node feature", "label": "decision tree split node feature", "shape": "dot", "size": 10.089285714285714, "title": "decision tree split node feature"}, {"color": "#6FA8DC", "id": "text", "label": "text", "shape": "dot", "size": 10.089285714285714, "title": "text"}, {"color": "#6FA8DC", "id": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gools, L. (2013)", "label": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gools, L. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gools, L. (2013)"}, {"color": "#6FA8DC", "id": "Roerei, et al.", "label": "Roerei, et al.", "shape": "dot", "size": 10.089285714285714, "title": "Roerei, et al."}, {"color": "#6FA8DC", "id": "filter usage", "label": "filter usage", "shape": "dot", "size": 10.178571428571429, "title": "filter usage"}, {"color": "#6FA8DC", "id": "ACF", "label": "ACF", "shape": "dot", "size": 10.089285714285714, "title": "ACF"}, {"color": "#6FA8DC", "id": "decision tree split nodes", "label": "decision tree split nodes", "shape": "dot", "size": 10.089285714285714, "title": "decision tree split nodes"}, {"color": "#6FA8DC", "id": "filter features", "label": "filter features", "shape": "dot", "size": 10.178571428571429, "title": "filter features"}, {"color": "#6FA8DC", "id": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gool, L. (2013)", "label": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gool, L. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gool, L. (2013)"}, {"color": "#6FA8DC", "id": "decision tree", "label": "decision tree", "shape": "dot", "size": 10.089285714285714, "title": "decision tree"}, {"color": "#6FA8DC", "id": "spatial feature distribution", "label": "spatial feature distribution", "shape": "dot", "size": 10.089285714285714, "title": "spatial feature distribution"}, {"color": "#6FA8DC", "id": "pedestrian detection", "label": "pedestrian detection", "shape": "dot", "size": 10.714285714285714, "title": "pedestrian detection"}, {"color": "#6FA8DC", "id": "parametrization of the trifocal tensor", "label": "parametrization of the trifocal tensor", "shape": "dot", "size": 10.446428571428571, "title": "parametrization of the trifocal tensor"}, {"color": "#6FA8DC", "id": "quotient Riemannian manifold", "label": "quotient Riemannian manifold", "shape": "dot", "size": 10.089285714285714, "title": "quotient Riemannian manifold"}, {"color": "#6FA8DC", "id": "almost symmetric", "label": "almost symmetric", "shape": "dot", "size": 10.089285714285714, "title": "almost symmetric"}, {"color": "#6FA8DC", "id": "preferred camera", "label": "preferred camera", "shape": "dot", "size": 10.089285714285714, "title": "preferred camera"}, {"color": "#6FA8DC", "id": "optimization techniques on manifolds", "label": "optimization techniques on manifolds", "shape": "dot", "size": 10.089285714285714, "title": "optimization techniques on manifolds"}, {"color": "#6FA8DC", "id": "Riemannian structure", "label": "Riemannian structure", "shape": "dot", "size": 10.089285714285714, "title": "Riemannian structure"}, {"color": "#6FA8DC", "id": "notion of distance", "label": "notion of distance", "shape": "dot", "size": 10.089285714285714, "title": "notion of distance"}, {"color": "#6FA8DC", "id": "distance between trifocal tensors", "label": "distance between trifocal tensors", "shape": "dot", "size": 10.178571428571429, "title": "distance between trifocal tensors"}, {"color": "#6FA8DC", "id": "meaningful results", "label": "meaningful results", "shape": "dot", "size": 10.089285714285714, "title": "meaningful results"}, {"color": "#6FA8DC", "id": "Structure from Motion problem", "label": "Structure from Motion problem", "shape": "dot", "size": 10.089285714285714, "title": "Structure from Motion problem"}, {"color": "#6FA8DC", "id": "work", "label": "work", "shape": "dot", "size": 10.625, "title": "work"}, {"color": "#6FA8DC", "id": "new formulation of the trifocal tensor", "label": "new formulation of the trifocal tensor", "shape": "dot", "size": 10.089285714285714, "title": "new formulation of the trifocal tensor"}, {"color": "#6FA8DC", "id": "trifocal tensor", "label": "trifocal tensor", "shape": "dot", "size": 10.089285714285714, "title": "trifocal tensor"}, {"color": "#6FA8DC", "id": "tensor", "label": "tensor", "shape": "dot", "size": 10.089285714285714, "title": "tensor"}, {"color": "#6FA8DC", "id": "Structure from Motion", "label": "Structure from Motion", "shape": "dot", "size": 10.178571428571429, "title": "Structure from Motion"}, {"color": "#6FA8DC", "id": "Trifocal Tensor", "label": "Trifocal Tensor", "shape": "dot", "size": 10.178571428571429, "title": "Trifocal Tensor"}, {"color": "#6FA8DC", "id": "distances", "label": "distances", "shape": "dot", "size": 10.089285714285714, "title": "distances"}, {"color": "#6FA8DC", "id": "Geometric Computer Vision", "label": "Geometric Computer Vision", "shape": "dot", "size": 10.178571428571429, "title": "Geometric Computer Vision"}, {"color": "#6FA8DC", "id": "Camera Calibration", "label": "Camera Calibration", "shape": "dot", "size": 10.267857142857142, "title": "Camera Calibration"}, {"color": "#6FA8DC", "id": "Optimization Algorithms", "label": "Optimization Algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Optimization Algorithms"}, {"color": "#6FA8DC", "id": "Absil, Mahony, and Sepulchre", "label": "Absil, Mahony, and Sepulchre", "shape": "dot", "size": 10.089285714285714, "title": "Absil, Mahony, and Sepulchre"}, {"color": "#6FA8DC", "id": "Nonlinear Programming", "label": "Nonlinear Programming", "shape": "dot", "size": 10.089285714285714, "title": "Nonlinear Programming"}, {"color": "#6FA8DC", "id": "Bertsekas", "label": "Bertsekas", "shape": "dot", "size": 10.089285714285714, "title": "Bertsekas"}, {"color": "#6FA8DC", "id": "Manopt", "label": "Manopt", "shape": "dot", "size": 10.089285714285714, "title": "Manopt"}, {"color": "#6FA8DC", "id": "Boumal, Mishra, Absil, and Sepulchre", "label": "Boumal, Mishra, Absil, and Sepulchre", "shape": "dot", "size": 10.089285714285714, "title": "Boumal, Mishra, Absil, and Sepulchre"}, {"color": "#6FA8DC", "id": "Lines and points", "label": "Lines and points", "shape": "dot", "size": 10.089285714285714, "title": "Lines and points"}, {"color": "#6FA8DC", "id": "Hartley\u0027s work", "label": "Hartley\u0027s work", "shape": "dot", "size": 10.089285714285714, "title": "Hartley\u0027s work"}, {"color": "#6FA8DC", "id": "Multiple View Geometry", "label": "Multiple View Geometry", "shape": "dot", "size": 10.089285714285714, "title": "Multiple View Geometry"}, {"color": "#6FA8DC", "id": "Hartley and Zisserman", "label": "Hartley and Zisserman", "shape": "dot", "size": 10.089285714285714, "title": "Hartley and Zisserman"}, {"color": "#6FA8DC", "id": "Hartley, R. I.", "label": "Hartley, R. I.", "shape": "dot", "size": 10.267857142857142, "title": "Hartley, R. I."}, {"color": "#6FA8DC", "id": "views and the trifocal tensor", "label": "views and the trifocal tensor", "shape": "dot", "size": 10.178571428571429, "title": "views and the trifocal tensor"}, {"color": "#6FA8DC", "id": "Int. J. Comput. Vision", "label": "Int. J. Comput. Vision", "shape": "dot", "size": 10.178571428571429, "title": "Int. J. Comput. Vision"}, {"color": "#6FA8DC", "id": "Projective reconstruction from line correspondences", "label": "Projective reconstruction from line correspondences", "shape": "dot", "size": 10.178571428571429, "title": "Projective reconstruction from line correspondences"}, {"color": "#6FA8DC", "id": "IEEE Conf. on Computer Vision and Pattern Recognition", "label": "IEEE Conf. on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Conf. on Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "Papapdoulo, T.", "label": "Papapdoulo, T.", "shape": "dot", "size": 10.089285714285714, "title": "Papapdoulo, T."}, {"color": "#6FA8DC", "id": "A new characterization of the trifocal tensor", "label": "A new characterization of the trifocal tensor", "shape": "dot", "size": 10.178571428571429, "title": "A new characterization of the trifocal tensor"}, {"color": "#6FA8DC", "id": "European Conference on Computer Vision", "label": "European Conference on Computer Vision", "shape": "dot", "size": 10.892857142857142, "title": "European Conference on Computer Vision"}, {"color": "#6FA8DC", "id": "Kendall, D. G.", "label": "Kendall, D. G.", "shape": "dot", "size": 10.089285714285714, "title": "Kendall, D. G."}, {"color": "#6FA8DC", "id": "Shape Manifolds, Procustean Metrics, and Complex Projective Spaces", "label": "Shape Manifolds, Procustean Metrics, and Complex Projective Spaces", "shape": "dot", "size": 10.178571428571429, "title": "Shape Manifolds, Procustean Metrics, and Complex Projective Spaces"}, {"color": "#6FA8DC", "id": "Bulletin of the London Mathematical Society", "label": "Bulletin of the London Mathematical Society", "shape": "dot", "size": 10.089285714285714, "title": "Bulletin of the London Mathematical Society"}, {"color": "#6FA8DC", "id": "Torr, P.", "label": "Torr, P.", "shape": "dot", "size": 10.178571428571429, "title": "Torr, P."}, {"color": "#6FA8DC", "id": "Robust parameterization and computation of the trifocal tensor", "label": "Robust parameterization and computation of the trifocal tensor", "shape": "dot", "size": 10.178571428571429, "title": "Robust parameterization and computation of the trifocal tensor"}, {"color": "#6FA8DC", "id": "Image and Vision Computing", "label": "Image and Vision Computing", "shape": "dot", "size": 10.178571428571429, "title": "Image and Vision Computing"}, {"color": "#6FA8DC", "id": "Multiple View Geometry in Computer Vision", "label": "Multiple View Geometry in Computer Vision", "shape": "dot", "size": 10.178571428571429, "title": "Multiple View Geometry in Computer Vision"}, {"color": "#6FA8DC", "id": "Robust parameterization", "label": "Robust parameterization", "shape": "dot", "size": 10.089285714285714, "title": "Robust parameterization"}, {"color": "#6FA8DC", "id": "Weng, J.", "label": "Weng, J.", "shape": "dot", "size": 10.089285714285714, "title": "Weng, J."}, {"color": "#6FA8DC", "id": "Motion and structure", "label": "Motion and structure", "shape": "dot", "size": 10.089285714285714, "title": "Motion and structure"}, {"color": "#6FA8DC", "id": "Grasp Laboratory", "label": "Grasp Laboratory", "shape": "dot", "size": 10.089285714285714, "title": "Grasp Laboratory"}, {"color": "#6FA8DC", "id": "tron@seas.upenn.edu", "label": "tron@seas.upenn.edu", "shape": "dot", "size": 10.089285714285714, "title": "tron@seas.upenn.edu"}, {"color": "#6FA8DC", "id": "Roberto Tron", "label": "Roberto Tron", "shape": "dot", "size": 10.089285714285714, "title": "Roberto Tron"}, {"color": "#6FA8DC", "id": "kostas@cis.upenn.edu", "label": "kostas@cis.upenn.edu", "shape": "dot", "size": 10.089285714285714, "title": "kostas@cis.upenn.edu"}, {"color": "#6FA8DC", "id": "Kostas Daniilidis", "label": "Kostas Daniilidis", "shape": "dot", "size": 10.089285714285714, "title": "Kostas Daniilidis"}, {"color": "#6FA8DC", "id": "Fast 2D Border Ownership Assignment", "label": "Fast 2D Border Ownership Assignment", "shape": "dot", "size": 10.267857142857142, "title": "Fast 2D Border Ownership Assignment"}, {"color": "#6FA8DC", "id": "Cornelia Ferm\u00fcller", "label": "Cornelia Ferm\u00fcller", "shape": "dot", "size": 10.178571428571429, "title": "Cornelia Ferm\u00fcller"}, {"color": "#6FA8DC", "id": "Ching L. Teo", "label": "Ching L. Teo", "shape": "dot", "size": 10.178571428571429, "title": "Ching L. Teo"}, {"color": "#6FA8DC", "id": "Yiannis Aloimonos", "label": "Yiannis Aloimonos", "shape": "dot", "size": 10.089285714285714, "title": "Yiannis Aloimonos"}, {"color": "#6FA8DC", "id": "Teo_Fast_2D_Border_2015_CVPR_paper.pdf", "label": "Teo_Fast_2D_Border_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Teo_Fast_2D_Border_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "PDF document", "label": "PDF document", "shape": "dot", "size": 10.267857142857142, "title": "PDF document"}, {"color": "#6FA8DC", "id": "border ownership assignment", "label": "border ownership assignment", "shape": "dot", "size": 10.089285714285714, "title": "border ownership assignment"}, {"color": "#6FA8DC", "id": "Structured Random Forests (SRF)", "label": "Structured Random Forests (SRF)", "shape": "dot", "size": 10.267857142857142, "title": "Structured Random Forests (SRF)"}, {"color": "#6FA8DC", "id": "boundary detection", "label": "boundary detection", "shape": "dot", "size": 10.089285714285714, "title": "boundary detection"}, {"color": "#6FA8DC", "id": "border ownership structure", "label": "border ownership structure", "shape": "dot", "size": 10.089285714285714, "title": "border ownership structure"}, {"color": "#6FA8DC", "id": "shape descriptors", "label": "shape descriptors", "shape": "dot", "size": 10.267857142857142, "title": "shape descriptors"}, {"color": "#6FA8DC", "id": "HoG-like descriptors", "label": "HoG-like descriptors", "shape": "dot", "size": 10.089285714285714, "title": "HoG-like descriptors"}, {"color": "#6FA8DC", "id": "spectral properties", "label": "spectral properties", "shape": "dot", "size": 10.178571428571429, "title": "spectral properties"}, {"color": "#6FA8DC", "id": "PCA", "label": "PCA", "shape": "dot", "size": 10.178571428571429, "title": "PCA"}, {"color": "#6FA8DC", "id": "semi-global grouping cues", "label": "semi-global grouping cues", "shape": "dot", "size": 10.178571428571429, "title": "semi-global grouping cues"}, {"color": "#6FA8DC", "id": "perceived depth", "label": "perceived depth", "shape": "dot", "size": 10.089285714285714, "title": "perceived depth"}, {"color": "#6FA8DC", "id": "Berkeley Segmentation Dataset (BSDS)", "label": "Berkeley Segmentation Dataset (BSDS)", "shape": "dot", "size": 10.089285714285714, "title": "Berkeley Segmentation Dataset (BSDS)"}, {"color": "#6FA8DC", "id": "NYU Depth V2 dataset", "label": "NYU Depth V2 dataset", "shape": "dot", "size": 10.178571428571429, "title": "NYU Depth V2 dataset"}, {"color": "#6FA8DC", "id": "multi-stage approaches", "label": "multi-stage approaches", "shape": "dot", "size": 10.089285714285714, "title": "multi-stage approaches"}, {"color": "#6FA8DC", "id": "Experimental results", "label": "Experimental results", "shape": "dot", "size": 10.625, "title": "Experimental results"}, {"color": "#6FA8DC", "id": "Berkeley Segmentation Dataset", "label": "Berkeley Segmentation Dataset", "shape": "dot", "size": 10.089285714285714, "title": "Berkeley Segmentation Dataset"}, {"color": "#6FA8DC", "id": "Feature Extraction", "label": "Feature Extraction", "shape": "dot", "size": 10.178571428571429, "title": "Feature Extraction"}, {"color": "#6FA8DC", "id": "HoG", "label": "HoG", "shape": "dot", "size": 10.089285714285714, "title": "HoG"}, {"color": "#6FA8DC", "id": "Hierarchical Image Segmentation", "label": "Hierarchical Image Segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Hierarchical Image Segmentation"}, {"color": "#6FA8DC", "id": "Cheng et al. (2014)", "label": "Cheng et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Cheng et al. (2014)"}, {"color": "#6FA8DC", "id": "Bing", "label": "Bing", "shape": "dot", "size": 10.089285714285714, "title": "Bing"}, {"color": "#6FA8DC", "id": "Dalal \u0026 Triggs (2005)", "label": "Dalal \u0026 Triggs (2005)", "shape": "dot", "size": 10.178571428571429, "title": "Dalal \u0026 Triggs (2005)"}, {"color": "#6FA8DC", "id": "Histograms of oriented gradients", "label": "Histograms of oriented gradients", "shape": "dot", "size": 10.625, "title": "Histograms of oriented gradients"}, {"color": "#6FA8DC", "id": "human detection", "label": "human detection", "shape": "dot", "size": 10.446428571428571, "title": "human detection"}, {"color": "#6FA8DC", "id": "Binarized normed gradients", "label": "Binarized normed gradients", "shape": "dot", "size": 10.178571428571429, "title": "Binarized normed gradients"}, {"color": "#6FA8DC", "id": "objectness estimation", "label": "objectness estimation", "shape": "dot", "size": 10.178571428571429, "title": "objectness estimation"}, {"color": "#6FA8DC", "id": "300fps", "label": "300fps", "shape": "dot", "size": 10.089285714285714, "title": "300fps"}, {"color": "#6FA8DC", "id": "Fast edge detection", "label": "Fast edge detection", "shape": "dot", "size": 10.089285714285714, "title": "Fast edge detection"}, {"color": "#6FA8DC", "id": "structured forests", "label": "structured forests", "shape": "dot", "size": 10.089285714285714, "title": "structured forests"}, {"color": "#6FA8DC", "id": "Fast feature pyramids", "label": "Fast feature pyramids", "shape": "dot", "size": 10.089285714285714, "title": "Fast feature pyramids"}, {"color": "#6FA8DC", "id": "object detection", "label": "object detection", "shape": "dot", "size": 11.339285714285715, "title": "object detection"}, {"color": "#6FA8DC", "id": "Category-independent object proposals", "label": "Category-independent object proposals", "shape": "dot", "size": 10.089285714285714, "title": "Category-independent object proposals"}, {"color": "#6FA8DC", "id": "diverse ranking", "label": "diverse ranking", "shape": "dot", "size": 10.089285714285714, "title": "diverse ranking"}, {"color": "#6FA8DC", "id": "Extremely randomized trees", "label": "Extremely randomized trees", "shape": "dot", "size": 10.089285714285714, "title": "Extremely randomized trees"}, {"color": "#6FA8DC", "id": "machine learning algorithm", "label": "machine learning algorithm", "shape": "dot", "size": 10.267857142857142, "title": "machine learning algorithm"}, {"color": "#6FA8DC", "id": "Perceptual organization", "label": "Perceptual organization", "shape": "dot", "size": 10.089285714285714, "title": "Perceptual organization"}, {"color": "#6FA8DC", "id": "recognition of indoor scenes", "label": "recognition of indoor scenes", "shape": "dot", "size": 10.089285714285714, "title": "recognition of indoor scenes"}, {"color": "#6FA8DC", "id": "Random decision forests", "label": "Random decision forests", "shape": "dot", "size": 10.089285714285714, "title": "Random decision forests"}, {"color": "#6FA8DC", "id": "Computer Vision Lab", "label": "Computer Vision Lab", "shape": "dot", "size": 10.178571428571429, "title": "Computer Vision Lab"}, {"color": "#6FA8DC", "id": "University of Maryland", "label": "University of Maryland", "shape": "dot", "size": 10.535714285714286, "title": "University of Maryland"}, {"color": "#6FA8DC", "id": "College Park, MD", "label": "College Park, MD", "shape": "dot", "size": 10.089285714285714, "title": "College Park, MD"}, {"color": "#6FA8DC", "id": "Computer Vision\u003c0xC2\u003e\u003c0xA0\u003eLab", "label": "Computer Vision\u003c0xC2\u003e\u003c0xA0\u003eLab", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision\u003c0xC2\u003e\u003c0xA0\u003eLab"}, {"color": "#6FA8DC", "id": "Mostafa Abdelrahman", "label": "Mostafa Abdelrahman", "shape": "dot", "size": 10.267857142857142, "title": "Mostafa Abdelrahman"}, {"color": "#6FA8DC", "id": "Heat Diffusion Over Weighted Manifolds", "label": "Heat Diffusion Over Weighted Manifolds", "shape": "dot", "size": 10.535714285714286, "title": "Heat Diffusion Over Weighted Manifolds"}, {"color": "#6FA8DC", "id": "Aly Farag", "label": "Aly Farag", "shape": "dot", "size": 10.267857142857142, "title": "Aly Farag"}, {"color": "#6FA8DC", "id": "David Swanson", "label": "David Swanson", "shape": "dot", "size": 10.267857142857142, "title": "David Swanson"}, {"color": "#6FA8DC", "id": "Moumen T. El-Melegy", "label": "Moumen T. El-Melegy", "shape": "dot", "size": 10.267857142857142, "title": "Moumen T. El-Melegy"}, {"color": "#6FA8DC", "id": "descriptor", "label": "descriptor", "shape": "dot", "size": 10.357142857142858, "title": "descriptor"}, {"color": "#6FA8DC", "id": "Abdelrahman_Heat_Diffusion_Over_2015_CVPR_paper.pdf", "label": "Abdelrahman_Heat_Diffusion_Over_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Abdelrahman_Heat_Diffusion_Over_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "photometric features", "label": "photometric features", "shape": "dot", "size": 10.089285714285714, "title": "photometric features"}, {"color": "#6FA8DC", "id": "existing descriptors", "label": "existing descriptors", "shape": "dot", "size": 10.267857142857142, "title": "existing descriptors"}, {"color": "#6FA8DC", "id": "geometric properties", "label": "geometric properties", "shape": "dot", "size": 10.178571428571429, "title": "geometric properties"}, {"color": "#6FA8DC", "id": "topological properties", "label": "topological properties", "shape": "dot", "size": 10.089285714285714, "title": "topological properties"}, {"color": "#6FA8DC", "id": "Weighted Heat Kernel Signature (W-HKS)", "label": "Weighted Heat Kernel Signature (W-HKS)", "shape": "dot", "size": 10.089285714285714, "title": "Weighted Heat Kernel Signature (W-HKS)"}, {"color": "#6FA8DC", "id": "textured 3D non-rigid models", "label": "textured 3D non-rigid models", "shape": "dot", "size": 10.089285714285714, "title": "textured 3D non-rigid models"}, {"color": "#6FA8DC", "id": "photometric information", "label": "photometric information", "shape": "dot", "size": 10.267857142857142, "title": "photometric information"}, {"color": "#6FA8DC", "id": "shape manifold", "label": "shape manifold", "shape": "dot", "size": 10.089285714285714, "title": "shape manifold"}, {"color": "#6FA8DC", "id": "new discretization method", "label": "new discretization method", "shape": "dot", "size": 10.089285714285714, "title": "new discretization method"}, {"color": "#6FA8DC", "id": "discretization method", "label": "discretization method", "shape": "dot", "size": 10.089285714285714, "title": "discretization method"}, {"color": "#6FA8DC", "id": "finite element approximation", "label": "finite element approximation", "shape": "dot", "size": 10.089285714285714, "title": "finite element approximation"}, {"color": "#6FA8DC", "id": "weighted heat kernel signature", "label": "weighted heat kernel signature", "shape": "dot", "size": 10.267857142857142, "title": "weighted heat kernel signature"}, {"color": "#6FA8DC", "id": "geometric information", "label": "geometric information", "shape": "dot", "size": 10.267857142857142, "title": "geometric information"}, {"color": "#6FA8DC", "id": "method for scale invariance", "label": "method for scale invariance", "shape": "dot", "size": 10.089285714285714, "title": "method for scale invariance"}, {"color": "#6FA8DC", "id": "heat kernel signature", "label": "heat kernel signature", "shape": "dot", "size": 10.178571428571429, "title": "heat kernel signature"}, {"color": "#6FA8DC", "id": "scale invariance", "label": "scale invariance", "shape": "dot", "size": 10.089285714285714, "title": "scale invariance"}, {"color": "#6FA8DC", "id": "high performance", "label": "high performance", "shape": "dot", "size": 10.178571428571429, "title": "high performance"}, {"color": "#6FA8DC", "id": "challenges", "label": "challenges", "shape": "dot", "size": 10.178571428571429, "title": "challenges"}, {"color": "#6FA8DC", "id": "pure geometric methods", "label": "pure geometric methods", "shape": "dot", "size": 10.089285714285714, "title": "pure geometric methods"}, {"color": "#6FA8DC", "id": "pure photometric methods", "label": "pure photometric methods", "shape": "dot", "size": 10.089285714285714, "title": "pure photometric methods"}, {"color": "#6FA8DC", "id": "experimental results", "label": "experimental results", "shape": "dot", "size": 10.982142857142858, "title": "experimental results"}, {"color": "#6FA8DC", "id": "approach\u0027s performance", "label": "approach\u0027s performance", "shape": "dot", "size": 10.089285714285714, "title": "approach\u0027s performance"}, {"color": "#6FA8DC", "id": "textured shape retrieval", "label": "textured shape retrieval", "shape": "dot", "size": 10.089285714285714, "title": "textured shape retrieval"}, {"color": "#6FA8DC", "id": "Textured 3D Shape Retrieval", "label": "Textured 3D Shape Retrieval", "shape": "dot", "size": 10.089285714285714, "title": "Textured 3D Shape Retrieval"}, {"color": "#6FA8DC", "id": "Challenges", "label": "Challenges", "shape": "dot", "size": 10.178571428571429, "title": "Challenges"}, {"color": "#6FA8DC", "id": "Pure Geometric Methods", "label": "Pure Geometric Methods", "shape": "dot", "size": 10.089285714285714, "title": "Pure Geometric Methods"}, {"color": "#6FA8DC", "id": "Photometric Shape Descriptors", "label": "Photometric Shape Descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Photometric Shape Descriptors"}, {"color": "#6FA8DC", "id": "Weighted Heat Kernel Signature", "label": "Weighted Heat Kernel Signature", "shape": "dot", "size": 10.089285714285714, "title": "Weighted Heat Kernel Signature"}, {"color": "#6FA8DC", "id": "Heat Diffusion on Manifold", "label": "Heat Diffusion on Manifold", "shape": "dot", "size": 10.089285714285714, "title": "Heat Diffusion on Manifold"}, {"color": "#6FA8DC", "id": "Electrical Engineering Department", "label": "Electrical Engineering Department", "shape": "dot", "size": 10.267857142857142, "title": "Electrical Engineering Department"}, {"color": "#6FA8DC", "id": "Assiut University", "label": "Assiut University", "shape": "dot", "size": 10.357142857142858, "title": "Assiut University"}, {"color": "#6FA8DC", "id": "CVIP Lab", "label": "CVIP Lab", "shape": "dot", "size": 10.089285714285714, "title": "CVIP Lab"}, {"color": "#6FA8DC", "id": "University of Louisville", "label": "University of Louisville", "shape": "dot", "size": 10.178571428571429, "title": "University of Louisville"}, {"color": "#6FA8DC", "id": "Department of Mathematics", "label": "Department of Mathematics", "shape": "dot", "size": 10.089285714285714, "title": "Department of Mathematics"}, {"color": "#6FA8DC", "id": "Assiut", "label": "Assiut", "shape": "dot", "size": 10.089285714285714, "title": "Assiut"}, {"color": "#6FA8DC", "id": "Si Liu", "label": "Si Liu", "shape": "dot", "size": 10.178571428571429, "title": "Si Liu"}, {"color": "#6FA8DC", "id": "Matching-CNN Meets KNN", "label": "Matching-CNN Meets KNN", "shape": "dot", "size": 10.803571428571429, "title": "Matching-CNN Meets KNN"}, {"color": "#6FA8DC", "id": "Xiaodan Liang", "label": "Xiaodan Liang", "shape": "dot", "size": 10.178571428571429, "title": "Xiaodan Liang"}, {"color": "#6FA8DC", "id": "Luoqi Liu", "label": "Luoqi Liu", "shape": "dot", "size": 10.178571428571429, "title": "Luoqi Liu"}, {"color": "#6FA8DC", "id": "Xiaohui Shen", "label": "Xiaohui Shen", "shape": "dot", "size": 10.357142857142858, "title": "Xiaohui Shen"}, {"color": "#6FA8DC", "id": "Jianchao Yang", "label": "Jianchao Yang", "shape": "dot", "size": 10.178571428571429, "title": "Jianchao Yang"}, {"color": "#6FA8DC", "id": "Changshen Xu", "label": "Changshen Xu", "shape": "dot", "size": 10.178571428571429, "title": "Changshen Xu"}, {"color": "#6FA8DC", "id": "Liang Lin", "label": "Liang Lin", "shape": "dot", "size": 10.178571428571429, "title": "Liang Lin"}, {"color": "#6FA8DC", "id": "Xiaochun Cao", "label": "Xiaochun Cao", "shape": "dot", "size": 10.178571428571429, "title": "Xiaochun Cao"}, {"color": "#6FA8DC", "id": "Shuicheng Yan", "label": "Shuicheng Yan", "shape": "dot", "size": 10.267857142857142, "title": "Shuicheng Yan"}, {"color": "#6FA8DC", "id": "Work", "label": "Work", "shape": "dot", "size": 10.089285714285714, "title": "Work"}, {"color": "#6FA8DC", "id": "Solution", "label": "Solution", "shape": "dot", "size": 10.178571428571429, "title": "Solution"}, {"color": "#6FA8DC", "id": "Human Parsing", "label": "Human Parsing", "shape": "dot", "size": 10.089285714285714, "title": "Human Parsing"}, {"color": "#6FA8DC", "id": "Quasi-parametric Model", "label": "Quasi-parametric Model", "shape": "dot", "size": 10.267857142857142, "title": "Quasi-parametric Model"}, {"color": "#6FA8DC", "id": "KNN Framework", "label": "KNN Framework", "shape": "dot", "size": 10.089285714285714, "title": "KNN Framework"}, {"color": "#6FA8DC", "id": "M-CNN", "label": "M-CNN", "shape": "dot", "size": 10.535714285714286, "title": "M-CNN"}, {"color": "#6FA8DC", "id": "Matching Confidence", "label": "Matching Confidence", "shape": "dot", "size": 10.089285714285714, "title": "Matching Confidence"}, {"color": "#6FA8DC", "id": "Displacements", "label": "Displacements", "shape": "dot", "size": 10.089285714285714, "title": "Displacements"}, {"color": "#6FA8DC", "id": "KNN Images", "label": "KNN Images", "shape": "dot", "size": 10.089285714285714, "title": "KNN Images"}, {"color": "#6FA8DC", "id": "Semantic Regions", "label": "Semantic Regions", "shape": "dot", "size": 10.089285714285714, "title": "Semantic Regions"}, {"color": "#6FA8DC", "id": "Matched Regions", "label": "Matched Regions", "shape": "dot", "size": 10.089285714285714, "title": "Matched Regions"}, {"color": "#6FA8DC", "id": "Result", "label": "Result", "shape": "dot", "size": 10.089285714285714, "title": "Result"}, {"color": "#6FA8DC", "id": "Evaluations", "label": "Evaluations", "shape": "dot", "size": 10.089285714285714, "title": "Evaluations"}, {"color": "#6FA8DC", "id": "Performance Gains", "label": "Performance Gains", "shape": "dot", "size": 10.089285714285714, "title": "Performance Gains"}, {"color": "#6FA8DC", "id": "superpixel smoothing", "label": "superpixel smoothing", "shape": "dot", "size": 10.089285714285714, "title": "superpixel smoothing"}, {"color": "#6FA8DC", "id": "matched regions", "label": "matched regions", "shape": "dot", "size": 10.089285714285714, "title": "matched regions"}, {"color": "#6FA8DC", "id": "performance", "label": "performance", "shape": "dot", "size": 11.875, "title": "performance"}, {"color": "#6FA8DC", "id": "SKLOIs", "label": "SKLOIs", "shape": "dot", "size": 10.267857142857142, "title": "SKLOIs"}, {"color": "#6FA8DC", "id": "IIE", "label": "IIE", "shape": "dot", "size": 10.178571428571429, "title": "IIE"}, {"color": "#6FA8DC", "id": "National University of Singapore", "label": "National University of Singapore", "shape": "dot", "size": 10.982142857142858, "title": "National University of Singapore"}, {"color": "#6FA8DC", "id": "Adobe Research", "label": "Adobe Research", "shape": "dot", "size": 10.714285714285714, "title": "Adobe Research"}, {"color": "#6FA8DC", "id": "IA", "label": "IA", "shape": "dot", "size": 10.089285714285714, "title": "IA"}, {"color": "#6FA8DC", "id": "Sun Yat-sen University", "label": "Sun Yat-sen University", "shape": "dot", "size": 10.089285714285714, "title": "Sun Yat-sen University"}, {"color": "#6FA8DC", "id": "OIS", "label": "OIS", "shape": "dot", "size": 10.089285714285714, "title": "OIS"}, {"color": "#6FA8DC", "id": "Yunsheng Jiang", "label": "Yunsheng Jiang", "shape": "dot", "size": 10.089285714285714, "title": "Yunsheng Jiang"}, {"color": "#6FA8DC", "id": "Combination Features and Models for Human Detection", "label": "Combination Features and Models for Human Detection", "shape": "dot", "size": 10.446428571428571, "title": "Combination Features and Models for Human Detection"}, {"color": "#6FA8DC", "id": "Jinwen Ma", "label": "Jinwen Ma", "shape": "dot", "size": 10.357142857142858, "title": "Jinwen Ma"}, {"color": "#6FA8DC", "id": "Combination Features and Models for Human Description", "label": "Combination Features and Models for Human Description", "shape": "dot", "size": 10.089285714285714, "title": "Combination Features and Models for Human Description"}, {"color": "#6FA8DC", "id": "Human Detection", "label": "Human Detection", "shape": "dot", "size": 10.178571428571429, "title": "Human Detection"}, {"color": "#6FA8DC", "id": "Jiang_Combination_Features_and_2015_CVPR_paper.pdf", "label": "Jiang_Combination_Features_and_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Jiang_Combination_Features_and_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "combination models", "label": "combination models", "shape": "dot", "size": 10.178571428571429, "title": "combination models"}, {"color": "#6FA8DC", "id": "complementary features", "label": "complementary features", "shape": "dot", "size": 10.089285714285714, "title": "complementary features"}, {"color": "#6FA8DC", "id": "existing features", "label": "existing features", "shape": "dot", "size": 10.089285714285714, "title": "existing features"}, {"color": "#6FA8DC", "id": "biases", "label": "biases", "shape": "dot", "size": 10.178571428571429, "title": "biases"}, {"color": "#6FA8DC", "id": "HOG-III features", "label": "HOG-III features", "shape": "dot", "size": 10.178571428571429, "title": "HOG-III features"}, {"color": "#6FA8DC", "id": "color features", "label": "color features", "shape": "dot", "size": 10.089285714285714, "title": "color features"}, {"color": "#6FA8DC", "id": "weighted-NMS fusion algorithm", "label": "weighted-NMS fusion algorithm", "shape": "dot", "size": 10.089285714285714, "title": "weighted-NMS fusion algorithm"}, {"color": "#6FA8DC", "id": "approaches", "label": "approaches", "shape": "dot", "size": 10.267857142857142, "title": "approaches"}, {"color": "#6FA8DC", "id": "detection performance", "label": "detection performance", "shape": "dot", "size": 10.625, "title": "detection performance"}, {"color": "#6FA8DC", "id": "computational efficiency", "label": "computational efficiency", "shape": "dot", "size": 10.089285714285714, "title": "computational efficiency"}, {"color": "#6FA8DC", "id": "experiments", "label": "experiments", "shape": "dot", "size": 11.785714285714285, "title": "experiments"}, {"color": "#6FA8DC", "id": "PASCAL VOC datasets", "label": "PASCAL VOC datasets", "shape": "dot", "size": 10.089285714285714, "title": "PASCAL VOC datasets"}, {"color": "#6FA8DC", "id": "Belongie et al. (2001)", "label": "Belongie et al. (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Belongie et al. (2001)"}, {"color": "#6FA8DC", "id": "IEEE Int\u0027l Conf. on Computer Vision (IC CV)", "label": "IEEE Int\u0027l Conf. on Computer Vision (IC CV)", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Int\u0027l Conf. on Computer Vision (IC CV)"}, {"color": "#6FA8DC", "id": "Hubel (1995)", "label": "Hubel (1995)", "shape": "dot", "size": 10.089285714285714, "title": "Hubel (1995)"}, {"color": "#6FA8DC", "id": "Eye, brain, and vision", "label": "Eye, brain, and vision", "shape": "dot", "size": 10.178571428571429, "title": "Eye, brain, and vision"}, {"color": "#6FA8DC", "id": "Ioffe \u0026 Forsyth (2001)", "label": "Ioffe \u0026 Forsyth (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Ioffe \u0026 Forsyth (2001)"}, {"color": "#6FA8DC", "id": "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)", "label": "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)", "shape": "dot", "size": 10.357142857142858, "title": "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)"}, {"color": "#6FA8DC", "id": "Dalal (2006)", "label": "Dalal (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Dalal (2006)"}, {"color": "#6FA8DC", "id": "Finding people in images and videos", "label": "Finding people in images and videos", "shape": "dot", "size": 10.089285714285714, "title": "Finding people in images and videos"}, {"color": "#6FA8DC", "id": "Felzenszwalb et al. (2008)", "label": "Felzenszwalb et al. (2008)", "shape": "dot", "size": 10.178571428571429, "title": "Felzenszwalb et al. (2008)"}, {"color": "#6FA8DC", "id": "HOG-III Features", "label": "HOG-III Features", "shape": "dot", "size": 10.089285714285714, "title": "HOG-III Features"}, {"color": "#6FA8DC", "id": "Model Fusion", "label": "Model Fusion", "shape": "dot", "size": 10.089285714285714, "title": "Model Fusion"}, {"color": "#6FA8DC", "id": "Weighted-NMS", "label": "Weighted-NMS", "shape": "dot", "size": 10.089285714285714, "title": "Weighted-NMS"}, {"color": "#6FA8DC", "id": "Matching Shapes", "label": "Matching Shapes", "shape": "dot", "size": 10.089285714285714, "title": "Matching Shapes"}, {"color": "#6FA8DC", "id": "elzenszwalb, P. F.", "label": "elzenszwalb, P. F.", "shape": "dot", "size": 10.089285714285714, "title": "elzenszwalb, P. F."}, {"color": "#6FA8DC", "id": "A discriminatively trained, multiscale, deformable part model", "label": "A discriminatively trained, multiscale, deformable part model", "shape": "dot", "size": 10.178571428571429, "title": "A discriminatively trained, multiscale, deformable part model"}, {"color": "#6FA8DC", "id": "Girshick, R. B.", "label": "Girshick, R. B.", "shape": "dot", "size": 10.178571428571429, "title": "Girshick, R. B."}, {"color": "#6FA8DC", "id": "Viola, P.", "label": "Viola, P.", "shape": "dot", "size": 10.089285714285714, "title": "Viola, P."}, {"color": "#6FA8DC", "id": "Robust real-time face detection", "label": "Robust real-time face detection", "shape": "dot", "size": 10.178571428571429, "title": "Robust real-time face detection"}, {"color": "#6FA8DC", "id": "Object detection grammar", "label": "Object detection grammar", "shape": "dot", "size": 10.178571428571429, "title": "Object detection grammar"}, {"color": "#6FA8DC", "id": "Object detection with grammar models", "label": "Object detection with grammar models", "shape": "dot", "size": 10.178571428571429, "title": "Object detection with grammar models"}, {"color": "#6FA8DC", "id": "A discriminatively trained, mult scale, deformable part model", "label": "A discriminatively trained, mult scale, deformable part model", "shape": "dot", "size": 10.089285714285714, "title": "A discriminatively trained, mult scale, deformable part model"}, {"color": "#6FA8DC", "id": "International Journal of Computer Vision", "label": "International Journal of Computer Vision", "shape": "dot", "size": 10.982142857142858, "title": "International Journal of Computer Vision"}, {"color": "#6FA8DC", "id": "IEEE Int\u2019l Conf. on Computer Vision (ICCV) Workshops", "label": "IEEE Int\u2019l Conf. on Computer Vision (ICCV) Workshops", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Int\u2019l Conf. on Computer Vision (ICCV) Workshops"}, {"color": "#6FA8DC", "id": "Advances in Neural Information Processing Systems", "label": "Advances in Neural Information Processing Systems", "shape": "dot", "size": 10.535714285714286, "title": "Advances in Neural Information Processing Systems"}, {"color": "#6FA8DC", "id": "Gkioxari, G.", "label": "Gkioxari, G.", "shape": "dot", "size": 10.267857142857142, "title": "Gkioxari, G."}, {"color": "#6FA8DC", "id": "Using k-poselets for detecting people and localizing their keypoints", "label": "Using k-poselets for detecting people and localizing their keypoints", "shape": "dot", "size": 10.089285714285714, "title": "Using k-poselets for detecting people and localizing their keypoints"}, {"color": "#6FA8DC", "id": "Hariharan, B.", "label": "Hariharan, B.", "shape": "dot", "size": 10.178571428571429, "title": "Hariharan, B."}, {"color": "#6FA8DC", "id": "GkioxARI, G.", "label": "GkioxARI, G.", "shape": "dot", "size": 10.089285714285714, "title": "GkioxARI, G."}, {"color": "#6FA8DC", "id": "Girshick, R.", "label": "Girshick, R.", "shape": "dot", "size": 10.357142857142858, "title": "Girshick, R."}, {"color": "#6FA8DC", "id": "Malik, J.", "label": "Malik, J.", "shape": "dot", "size": 10.089285714285714, "title": "Malik, J."}, {"color": "#6FA8DC", "id": "YunshEng Jiang", "label": "YunshEng Jiang", "shape": "dot", "size": 10.178571428571429, "title": "YunshEng Jiang"}, {"color": "#6FA8DC", "id": "Peking University", "label": "Peking University", "shape": "dot", "size": 10.267857142857142, "title": "Peking University"}, {"color": "#6FA8DC", "id": "Department of Information Science", "label": "Department of Information Science", "shape": "dot", "size": 10.178571428571429, "title": "Department of Information Science"}, {"color": "#6FA8DC", "id": "Cheng", "label": "Cheng", "shape": "dot", "size": 10.535714285714286, "title": "Cheng"}, {"color": "#6FA8DC", "id": "Effective Learning-Based Illuminant Estimation Using Simple Features", "label": "Effective Learning-Based Illuminant Estimation Using Simple Features", "shape": "dot", "size": 10.089285714285714, "title": "Effective Learning-Based Illuminant Estimation Using Simple Features"}, {"color": "#6FA8DC", "id": "Price", "label": "Price", "shape": "dot", "size": 10.089285714285714, "title": "Price"}, {"color": "#6FA8DC", "id": "Cohen", "label": "Cohen", "shape": "dot", "size": 10.089285714285714, "title": "Cohen"}, {"color": "#6FA8DC", "id": "Michael S. Brown", "label": "Michael S. Brown", "shape": "dot", "size": 10.178571428571429, "title": "Michael S. Brown"}, {"color": "#6FA8DC", "id": "Illumination estimation", "label": "Illumination estimation", "shape": "dot", "size": 10.178571428571429, "title": "Illumination estimation"}, {"color": "#6FA8DC", "id": "determining chromaticity", "label": "determining chromaticity", "shape": "dot", "size": 10.089285714285714, "title": "determining chromaticity"}, {"color": "#6FA8DC", "id": "white-balancing", "label": "white-balancing", "shape": "dot", "size": 10.089285714285714, "title": "white-balancing"}, {"color": "#6FA8DC", "id": "computational color constancy", "label": "computational color constancy", "shape": "dot", "size": 10.089285714285714, "title": "computational color constancy"}, {"color": "#6FA8DC", "id": "computer vision", "label": "computer vision", "shape": "dot", "size": 11.875, "title": "computer vision"}, {"color": "#6FA8DC", "id": "problem", "label": "problem", "shape": "dot", "size": 10.982142857142858, "title": "problem"}, {"color": "#6FA8DC", "id": "ill-posed", "label": "ill-posed", "shape": "dot", "size": 10.089285714285714, "title": "ill-posed"}, {"color": "#6FA8DC", "id": "four simple color features", "label": "four simple color features", "shape": "dot", "size": 10.089285714285714, "title": "four simple color features"}, {"color": "#6FA8DC", "id": "regression trees", "label": "regression trees", "shape": "dot", "size": 10.178571428571429, "title": "regression trees"}, {"color": "#6FA8DC", "id": "existing learning-based methods", "label": "existing learning-based methods", "shape": "dot", "size": 10.178571428571429, "title": "existing learning-based methods"}, {"color": "#6FA8DC", "id": "best results", "label": "best results", "shape": "dot", "size": 10.267857142857142, "title": "best results"}, {"color": "#6FA8DC", "id": "results", "label": "results", "shape": "dot", "size": 10.267857142857142, "title": "results"}, {"color": "#6FA8DC", "id": "color constancy data sets", "label": "color constancy data sets", "shape": "dot", "size": 10.089285714285714, "title": "color constancy data sets"}, {"color": "#6FA8DC", "id": "our approach", "label": "our approach", "shape": "dot", "size": 10.178571428571429, "title": "our approach"}, {"color": "#6FA8DC", "id": "modern color constancy data sets", "label": "modern color constancy data sets", "shape": "dot", "size": 10.089285714285714, "title": "modern color constancy data sets"}, {"color": "#6FA8DC", "id": "Forsyth, D. A.", "label": "Forsyth, D. A.", "shape": "dot", "size": 10.178571428571429, "title": "Forsyth, D. A."}, {"color": "#6FA8DC", "id": "novel algorithm", "label": "novel algorithm", "shape": "dot", "size": 10.089285714285714, "title": "novel algorithm"}, {"color": "#6FA8DC", "id": "Bani\u0107, N.", "label": "Bani\u0107, N.", "shape": "dot", "size": 10.089285714285714, "title": "Bani\u0107, N."}, {"color": "#6FA8DC", "id": "Color dog", "label": "Color dog", "shape": "dot", "size": 10.267857142857142, "title": "Color dog"}, {"color": "#6FA8DC", "id": "global illumination estimation", "label": "global illumination estimation", "shape": "dot", "size": 10.089285714285714, "title": "global illumination estimation"}, {"color": "#6FA8DC", "id": "Funt, B.", "label": "Funt, B.", "shape": "dot", "size": 10.089285714285714, "title": "Funt, B."}, {"color": "#6FA8DC", "id": "support vector regression", "label": "support vector regression", "shape": "dot", "size": 10.178571428571429, "title": "support vector regression"}, {"color": "#6FA8DC", "id": "illumination chromaticity", "label": "illumination chromaticity", "shape": "dot", "size": 10.089285714285714, "title": "illumination chromaticity"}, {"color": "#6FA8DC", "id": "Gao, S.", "label": "Gao, S.", "shape": "dot", "size": 10.178571428571429, "title": "Gao, S."}, {"color": "#6FA8DC", "id": "color constancy", "label": "color constancy", "shape": "dot", "size": 10.446428571428571, "title": "color constancy"}, {"color": "#6FA8DC", "id": "local surface reflectance statistics", "label": "local surface reflectance statistics", "shape": "dot", "size": 10.089285714285714, "title": "local surface reflectance statistics"}, {"color": "#6FA8DC", "id": "Learning-Based Methods", "label": "Learning-Based Methods", "shape": "dot", "size": 10.089285714285714, "title": "Learning-Based Methods"}, {"color": "#6FA8DC", "id": "slower than", "label": "slower than", "shape": "dot", "size": 10.089285714285714, "title": "slower than"}, {"color": "#6FA8DC", "id": "Color and Imaging Conference", "label": "Color and Imaging Conference", "shape": "dot", "size": 10.089285714285714, "title": "Color and Imaging Conference"}, {"color": "#6FA8DC", "id": "via support vector regression", "label": "via support vector regression", "shape": "dot", "size": 10.089285714285714, "title": "via support vector regression"}, {"color": "#6FA8DC", "id": "Ef\ufb01cient color constancy with local surface re\ufb02ectance statistics", "label": "Ef\ufb01cient color constancy with local surface re\ufb02ectance statistics", "shape": "dot", "size": 10.089285714285714, "title": "Ef\ufb01cient color constancy with local surface re\ufb02ectance statistics"}, {"color": "#6FA8DC", "id": "Barnard, K.", "label": "Barnard, K.", "shape": "dot", "size": 10.178571428571429, "title": "Barnard, K."}, {"color": "#6FA8DC", "id": "A comparison of computational color constancy algorithms", "label": "A comparison of computational color constancy algorithms", "shape": "dot", "size": 10.178571428571429, "title": "A comparison of computational color constancy algorithms"}, {"color": "#6FA8DC", "id": "TIP", "label": "TIP", "shape": "dot", "size": 10.267857142857142, "title": "TIP"}, {"color": "#6FA8DC", "id": "A data set for color research", "label": "A data set for color research", "shape": "dot", "size": 10.178571428571429, "title": "A data set for color research"}, {"color": "#6FA8DC", "id": "Color Research \u0026 Application", "label": "Color Research \u0026 Application", "shape": "dot", "size": 10.089285714285714, "title": "Color Research \u0026 Application"}, {"color": "#6FA8DC", "id": "Gehler, P. V.", "label": "Gehler, P. V.", "shape": "dot", "size": 10.089285714285714, "title": "Gehler, P. V."}, {"color": "#6FA8DC", "id": "Bayesian color constancy revisited", "label": "Bayesian color constancy revisited", "shape": "dot", "size": 10.178571428571429, "title": "Bayesian color constancy revisited"}, {"color": "#6FA8DC", "id": "Bianco, S.", "label": "Bianco, S.", "shape": "dot", "size": 10.178571428571429, "title": "Bianco, S."}, {"color": "#6FA8DC", "id": "Improving color constancy using indoor - outdoor image classification", "label": "Improving color constancy using indoor - outdoor image classification", "shape": "dot", "size": 10.178571428571429, "title": "Improving color constancy using indoor - outdoor image classification"}, {"color": "#6FA8DC", "id": "Automatic color constancy algorithm selection and combination", "label": "Automatic color constancy algorithm selection and combination", "shape": "dot", "size": 10.178571428571429, "title": "Automatic color constancy algorithm selection and combination"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Image Processing", "label": "IEEE Transactions on Image Processing", "shape": "dot", "size": 10.892857142857142, "title": "IEEE Transactions on Image Processing"}, {"color": "#6FA8DC", "id": "Botev, Z.", "label": "Botev, Z.", "shape": "dot", "size": 10.089285714285714, "title": "Botev, Z."}, {"color": "#6FA8DC", "id": "Kernel density estimation via diffusion", "label": "Kernel density estimation via diffusion", "shape": "dot", "size": 10.089285714285714, "title": "Kernel density estimation via diffusion"}, {"color": "#6FA8DC", "id": "The Annals of Statistics", "label": "The Annals of Statistics", "shape": "dot", "size": 10.178571428571429, "title": "The Annals of Statistics"}, {"color": "#6FA8DC", "id": "Dongliang Cheng", "label": "Dongliang Cheng", "shape": "dot", "size": 10.089285714285714, "title": "Dongliang Cheng"}, {"color": "#6FA8DC", "id": "Brian Price", "label": "Brian Price", "shape": "dot", "size": 10.178571428571429, "title": "Brian Price"}, {"color": "#6FA8DC", "id": "Scott Cohen", "label": "Scott Cohen", "shape": "dot", "size": 10.089285714285714, "title": "Scott Cohen"}, {"color": "#6FA8DC", "id": "Hui Wu", "label": "Hui Wu", "shape": "dot", "size": 10.446428571428571, "title": "Hui Wu"}, {"color": "#6FA8DC", "id": "Robust Regression on Image Manifolds for Ordered Label Denoising", "label": "Robust Regression on Image Manifolds for Ordered Label Denoising", "shape": "dot", "size": 10.089285714285714, "title": "Robust Regression on Image Manifolds for Ordered Label Denoising"}, {"color": "#6FA8DC", "id": "Richard Souvenir", "label": "Richard Souvenir", "shape": "dot", "size": 10.446428571428571, "title": "Richard Souvenir"}, {"color": "#6FA8DC", "id": "Robust Regression on Image Manifold for Ordered Label Denoising", "label": "Robust Regression on Image Manifold for Ordered Label Denoising", "shape": "dot", "size": 10.089285714285714, "title": "Robust Regression on Image Manifold for Ordered Label Denoising"}, {"color": "#6FA8DC", "id": "Wu_Robust_Regression_on_2015_CVPR_supplemental.pdf", "label": "Wu_Robust_Regression_on_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Wu_Robust_Regression_on_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "supplemental material", "label": "supplemental material", "shape": "dot", "size": 10.089285714285714, "title": "supplemental material"}, {"color": "#6FA8DC", "id": "Wu_Robust_Regression_on_2015_CVPR_supplemental", "label": "Wu_Robust_Regression_on_2015_CVPR_supplemental", "shape": "dot", "size": 10.089285714285714, "title": "Wu_Robust_Regression_on_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "Robust Regression", "label": "Robust Regression", "shape": "dot", "size": 10.714285714285714, "title": "Robust Regression"}, {"color": "#6FA8DC", "id": "Wu_Robust_Reservation_on_2015_CVPR_supplemental", "label": "Wu_Robust_Reservation_on_2015_CVPR_supplemental", "shape": "dot", "size": 10.089285714285714, "title": "Wu_Robust_Reservation_on_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "Ordered Label Denoising", "label": "Ordered Label Denoising", "shape": "dot", "size": 10.089285714285714, "title": "Ordered Label Denoising"}, {"color": "#6FA8DC", "id": "Figures 1-4", "label": "Figures 1-4", "shape": "dot", "size": 10.089285714285714, "title": "Figures 1-4"}, {"color": "#6FA8DC", "id": "RANSC", "label": "RANSC", "shape": "dot", "size": 10.089285714285714, "title": "RANSC"}, {"color": "#6FA8DC", "id": "K-NN", "label": "K-NN", "shape": "dot", "size": 10.089285714285714, "title": "K-NN"}, {"color": "#6FA8DC", "id": "RBFN", "label": "RBFN", "shape": "dot", "size": 10.089285714285714, "title": "RBFN"}, {"color": "#6FA8DC", "id": "SVR", "label": "SVR", "shape": "dot", "size": 10.089285714285714, "title": "SVR"}, {"color": "#6FA8DC", "id": "KSPCA", "label": "KSPCA", "shape": "dot", "size": 10.089285714285714, "title": "KSPCA"}, {"color": "#6FA8DC", "id": "H3R", "label": "H3R", "shape": "dot", "size": 10.089285714285714, "title": "H3R"}, {"color": "#6FA8DC", "id": "Statue Data Set", "label": "Statue Data Set", "shape": "dot", "size": 10.089285714285714, "title": "Statue Data Set"}, {"color": "#6FA8DC", "id": "Image Manifolds", "label": "Image Manifolds", "shape": "dot", "size": 10.178571428571429, "title": "Image Manifolds"}, {"color": "#6FA8DC", "id": "Face Pose Estimation", "label": "Face Pose Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Face Pose Estimation"}, {"color": "#6FA8DC", "id": "University of North Carolina at Charlotte", "label": "University of North Carolina at Charlotte", "shape": "dot", "size": 10.178571428571429, "title": "University of North Carolina at Charlotte"}, {"color": "#6FA8DC", "id": "Y. Cheng", "label": "Y. Cheng", "shape": "dot", "size": 10.267857142857142, "title": "Y. Cheng"}, {"color": "#6FA8DC", "id": "University of North Carolin", "label": "University of North Carolin", "shape": "dot", "size": 10.535714285714286, "title": "University of North Carolin"}, {"color": "#6FA8DC", "id": "J. A. Lopez", "label": "J. A. Lopez", "shape": "dot", "size": 10.178571428571429, "title": "J. A. Lopez"}, {"color": "#6FA8DC", "id": "O. Camps", "label": "O. Camps", "shape": "dot", "size": 10.178571428571429, "title": "O. Camps"}, {"color": "#6FA8DC", "id": "M. Sznaier", "label": "M. Sznaier", "shape": "dot", "size": 10.178571428571429, "title": "M. Sznaier"}, {"color": "#6FA8DC", "id": "A Convex Optimization Approach", "label": "A Convex Optimization Approach", "shape": "dot", "size": 10.089285714285714, "title": "A Convex Optimization Approach"}, {"color": "#6FA8DC", "id": "Cheng_A_Convex_Optimization_2015_CVPR_paper", "label": "Cheng_A_Convex_Optimization_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Cheng_A_Convex_Optimization_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "hwu13@uncc.edu", "label": "hwu13@uncc.edu", "shape": "dot", "size": 10.089285714285714, "title": "hwu13@uncc.edu"}, {"color": "#6FA8DC", "id": "souvenir@uncc.edu", "label": "souvenir@uncc.edu", "shape": "dot", "size": 10.089285714285714, "title": "souvenir@uncc.edu"}, {"color": "#6FA8DC", "id": "fundamental matrix estimation problem", "label": "fundamental matrix estimation problem", "shape": "dot", "size": 10.089285714285714, "title": "fundamental matrix estimation problem"}, {"color": "#6FA8DC", "id": "framework", "label": "framework", "shape": "dot", "size": 13.125, "title": "framework"}, {"color": "#6FA8DC", "id": "general nonconvex", "label": "general nonconvex", "shape": "dot", "size": 10.089285714285714, "title": "general nonconvex"}, {"color": "#6FA8DC", "id": "rank-2 constraint", "label": "rank-2 constraint", "shape": "dot", "size": 10.089285714285714, "title": "rank-2 constraint"}, {"color": "#6FA8DC", "id": "noise", "label": "noise", "shape": "dot", "size": 10.178571428571429, "title": "noise"}, {"color": "#6FA8DC", "id": "nonconvex", "label": "nonconvex", "shape": "dot", "size": 10.089285714285714, "title": "nonconvex"}, {"color": "#6FA8DC", "id": "sequence of convex semi-de\ufb01nite programs", "label": "sequence of convex semi-de\ufb01nite programs", "shape": "dot", "size": 10.089285714285714, "title": "sequence of convex semi-de\ufb01nite programs"}, {"color": "#6FA8DC", "id": "algorithm", "label": "algorithm", "shape": "dot", "size": 14.285714285714285, "title": "algorithm"}, {"color": "#6FA8DC", "id": "extensible", "label": "extensible", "shape": "dot", "size": 10.089285714285714, "title": "extensible"}, {"color": "#6FA8DC", "id": "partially labeled correspondences", "label": "partially labeled correspondences", "shape": "dot", "size": 10.089285714285714, "title": "partially labeled correspondences"}, {"color": "#6FA8DC", "id": "co-occurrence information", "label": "co-occurrence information", "shape": "dot", "size": 10.089285714285714, "title": "co-occurrence information"}, {"color": "#6FA8DC", "id": "high percentage of outliers", "label": "high percentage of outliers", "shape": "dot", "size": 10.089285714285714, "title": "high percentage of outliers"}, {"color": "#6FA8DC", "id": "optimization", "label": "optimization", "shape": "dot", "size": 10.267857142857142, "title": "optimization"}, {"color": "#6FA8DC", "id": "robust", "label": "robust", "shape": "dot", "size": 10.178571428571429, "title": "robust"}, {"color": "#6FA8DC", "id": "Multiple view geometry", "label": "Multiple view geometry", "shape": "dot", "size": 10.446428571428571, "title": "Multiple view geometry"}, {"color": "#6FA8DC", "id": "topic", "label": "topic", "shape": "dot", "size": 10.446428571428571, "title": "topic"}, {"color": "#6FA8DC", "id": "Hartley, R. \u0026 Zisserman, A.", "label": "Hartley, R. \u0026 Zisserman, A.", "shape": "dot", "size": 10.089285714285714, "title": "Hartley, R. \u0026 Zisserman, A."}, {"color": "#6FA8DC", "id": "Mohan, K. \u0026 Fazel, M.", "label": "Mohan, K. \u0026 Fazel, M.", "shape": "dot", "size": 10.089285714285714, "title": "Mohan, K. \u0026 Fazel, M."}, {"color": "#6FA8DC", "id": "Iterative reweighted algorithms", "label": "Iterative reweighted algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Iterative reweighted algorithms"}, {"color": "#6FA8DC", "id": "Lasserre, J. B.", "label": "Lasserre, J. B.", "shape": "dot", "size": 10.089285714285714, "title": "Lasserre, J. B."}, {"color": "#6FA8DC", "id": "Global optimization with polynomials", "label": "Global optimization with polynomials", "shape": "dot", "size": 10.178571428571429, "title": "Global optimization with polynomials"}, {"color": "#6FA8DC", "id": "polynomial optimization methods", "label": "polynomial optimization methods", "shape": "dot", "size": 10.089285714285714, "title": "polynomial optimization methods"}, {"color": "#6FA8DC", "id": "outliers", "label": "outliers", "shape": "dot", "size": 10.625, "title": "outliers"}, {"color": "#6FA8DC", "id": "Method\u0027s effectiveness", "label": "Method\u0027s effectiveness", "shape": "dot", "size": 10.089285714285714, "title": "Method\u0027s effectiveness"}, {"color": "#6FA8DC", "id": "Fundamental Matrix Estimation", "label": "Fundamental Matrix Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Fundamental Matrix Estimation"}, {"color": "#6FA8DC", "id": "Robust Optimization", "label": "Robust Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Robust Optimization"}, {"color": "#6FA8DC", "id": "Rank-Constrained Optimization", "label": "Rank-Constrained Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Rank-Constrained Optimization"}, {"color": "#6FA8DC", "id": "Global optimization", "label": "Global optimization", "shape": "dot", "size": 10.178571428571429, "title": "Global optimization"}, {"color": "#6FA8DC", "id": "polynomial methods", "label": "polynomial methods", "shape": "dot", "size": 10.178571428571429, "title": "polynomial methods"}, {"color": "#6FA8DC", "id": "optimization methods", "label": "optimization methods", "shape": "dot", "size": 10.089285714285714, "title": "optimization methods"}, {"color": "#6FA8DC", "id": "Lasserre", "label": "Lasserre", "shape": "dot", "size": 10.089285714285714, "title": "Lasserre"}, {"color": "#6FA8DC", "id": "Global optimization with polynomials and the problem of moments", "label": "Global optimization with polynomials and the problem of moments", "shape": "dot", "size": 10.089285714285714, "title": "Global optimization with polynomials and the problem of moments"}, {"color": "#6FA8DC", "id": "Bugarin et al.", "label": "Bugarin et al.", "shape": "dot", "size": 10.089285714285714, "title": "Bugarin et al."}, {"color": "#6FA8DC", "id": "polynomial global optimization", "label": "polynomial global optimization", "shape": "dot", "size": 10.267857142857142, "title": "polynomial global optimization"}, {"color": "#6FA8DC", "id": "fundamental matrix estimation", "label": "fundamental matrix estimation", "shape": "dot", "size": 10.714285714285714, "title": "fundamental matrix estimation"}, {"color": "#6FA8DC", "id": "eight-point algorithm", "label": "eight-point algorithm", "shape": "dot", "size": 10.357142857142858, "title": "eight-point algorithm"}, {"color": "#6FA8DC", "id": "Torr \u0026 Murray", "label": "Torr \u0026 Murray", "shape": "dot", "size": 10.089285714285714, "title": "Torr \u0026 Murray"}, {"color": "#6FA8DC", "id": "fundamental matrix estimation methods", "label": "fundamental matrix estimation methods", "shape": "dot", "size": 10.089285714285714, "title": "fundamental matrix estimation methods"}, {"color": "#6FA8DC", "id": "computer vision technique", "label": "computer vision technique", "shape": "dot", "size": 10.267857142857142, "title": "computer vision technique"}, {"color": "#6FA8DC", "id": "International journal of computer vision", "label": "International journal of computer vision", "shape": "dot", "size": 10.267857142857142, "title": "International journal of computer vision"}, {"color": "#6FA8DC", "id": "Computer Vision and Pattern Recognition (CVPR)", "label": "Computer Vision and Pattern Recognition (CVPR)", "shape": "dot", "size": 10.267857142857142, "title": "Computer Vision and Pattern Recognition (CVPR)"}, {"color": "#6FA8DC", "id": "Mlesac", "label": "Mlesac", "shape": "dot", "size": 10.178571428571429, "title": "Mlesac"}, {"color": "#6FA8DC", "id": "robust estimator", "label": "robust estimator", "shape": "dot", "size": 10.089285714285714, "title": "robust estimator"}, {"color": "#6FA8DC", "id": "Computer Vision and Image Understanding", "label": "Computer Vision and Image Understanding", "shape": "dot", "size": 10.267857142857142, "title": "Computer Vision and Image Understanding"}, {"color": "#6FA8DC", "id": "SDP relaxations", "label": "SDP relaxations", "shape": "dot", "size": 10.267857142857142, "title": "SDP relaxations"}, {"color": "#6FA8DC", "id": "SIAM Journal on Optimization", "label": "SIAM Journal on Optimization", "shape": "dot", "size": 10.089285714285714, "title": "SIAM Journal on Optimization"}, {"color": "#6FA8DC", "id": "Zheng, Y., Sugimoto, S., \u0026 Okutomi, M.", "label": "Zheng, Y., Sugimoto, S., \u0026 Okutomi, M.", "shape": "dot", "size": 10.089285714285714, "title": "Zheng, Y., Sugimoto, S., \u0026 Okutomi, M."}, {"color": "#6FA8DC", "id": "fundamental matrix estimation method", "label": "fundamental matrix estimation method", "shape": "dot", "size": 10.089285714285714, "title": "fundamental matrix estimation method"}, {"color": "#6FA8DC", "id": "Lasserre (2006)", "label": "Lasserre (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Lasserre (2006)"}, {"color": "#6FA8DC", "id": "Sugaya \u0026 Kanatani (2007)", "label": "Sugaya \u0026 Kanatani (2007)", "shape": "dot", "size": 10.089285714285714, "title": "Sugaya \u0026 Kanatani (2007)"}, {"color": "#6FA8DC", "id": "high-accuracy computation", "label": "high-accuracy computation", "shape": "dot", "size": 10.089285714285714, "title": "high-accuracy computation"}, {"color": "#6FA8DC", "id": "Northeastern University", "label": "Northeastern University", "shape": "dot", "size": 10.803571428571429, "title": "Northeastern University"}, {"color": "#6FA8DC", "id": "polynomial optimization", "label": "polynomial optimization", "shape": "dot", "size": 10.089285714285714, "title": "polynomial optimization"}, {"color": "#6FA8DC", "id": "RANSA", "label": "RANSA", "shape": "dot", "size": 10.446428571428571, "title": "RANSA"}, {"color": "#6FA8DC", "id": "image analysis", "label": "image analysis", "shape": "dot", "size": 10.267857142857142, "title": "image analysis"}, {"color": "#6FA8DC", "id": "University", "label": "University", "shape": "dot", "size": 10.089285714285714, "title": "University"}, {"color": "#6FA8DC", "id": "Boston", "label": "Boston", "shape": "dot", "size": 10.267857142857142, "title": "Boston"}, {"color": "#6FA8DC", "id": "Massachusetts", "label": "Massachusetts", "shape": "dot", "size": 10.089285714285714, "title": "Massachusetts"}, {"color": "#6FA8DC", "id": "Jian Sun", "label": "Jian Sun", "shape": "dot", "size": 10.535714285714286, "title": "Jian Sun"}, {"color": "#6FA8DC", "id": "Learning a Convolutional Neural Network", "label": "Learning a Convolutional Neural Network", "shape": "dot", "size": 10.446428571428571, "title": "Learning a Convolutional Neural Network"}, {"color": "#6FA8DC", "id": "Wenfei Cao", "label": "Wenfei Cao", "shape": "dot", "size": 10.089285714285714, "title": "Wenfei Cao"}, {"color": "#6FA8DC", "id": "Jean Ponce", "label": "Jean Ponce", "shape": "dot", "size": 10.446428571428571, "title": "Jean Ponce"}, {"color": "#6FA8DC", "id": "Non-uniform Motion Blur Removal", "label": "Non-uniform Motion Blur Removal", "shape": "dot", "size": 10.089285714285714, "title": "Non-uniform Motion Blur Removal"}, {"color": "#6FA8DC", "id": "lopez.jo@husky.neu.edu", "label": "lopez.jo@husky.neu.edu", "shape": "dot", "size": 10.089285714285714, "title": "lopez.jo@husky.neu.edu"}, {"color": "#6FA8DC", "id": "camps@coe.neu.edu", "label": "camps@coe.neu.edu", "shape": "dot", "size": 10.089285714285714, "title": "camps@coe.neu.edu"}, {"color": "#6FA8DC", "id": "msznaier@coe.neu.edu", "label": "msznaier@coe.neu.edu", "shape": "dot", "size": 10.089285714285714, "title": "msznaier@coe.neu.edu"}, {"color": "#6FA8DC", "id": "problem of estimating and removing non-uniform motion blur", "label": "problem of estimating and removing non-uniform motion blur", "shape": "dot", "size": 10.089285714285714, "title": "problem of estimating and removing non-uniform motion blur"}, {"color": "#6FA8DC", "id": "authors", "label": "authors", "shape": "dot", "size": 10.625, "title": "authors"}, {"color": "#6FA8DC", "id": "CNN", "label": "CNN", "shape": "dot", "size": 10.267857142857142, "title": "CNN"}, {"color": "#6FA8DC", "id": "convolutional neural network", "label": "convolutional neural network", "shape": "dot", "size": 10.178571428571429, "title": "convolutional neural network"}, {"color": "#6FA8DC", "id": "motion kernels", "label": "motion kernels", "shape": "dot", "size": 10.089285714285714, "title": "motion kernels"}, {"color": "#6FA8DC", "id": "image rotations", "label": "image rotations", "shape": "dot", "size": 10.089285714285714, "title": "image rotations"}, {"color": "#6FA8DC", "id": "Markov random field model", "label": "Markov random field model", "shape": "dot", "size": 10.446428571428571, "title": "Markov random field model"}, {"color": "#6FA8DC", "id": "inferring dense non-uniform motion blur field", "label": "inferring dense non-uniform motion blur field", "shape": "dot", "size": 10.089285714285714, "title": "inferring dense non-uniform motion blur field"}, {"color": "#6FA8DC", "id": "motion smoothness", "label": "motion smoothness", "shape": "dot", "size": 10.089285714285714, "title": "motion smoothness"}, {"color": "#6FA8DC", "id": "deblurring model", "label": "deblurring model", "shape": "dot", "size": 10.535714285714286, "title": "deblurring model"}, {"color": "#6FA8DC", "id": "motion blur", "label": "motion blur", "shape": "dot", "size": 10.178571428571429, "title": "motion blur"}, {"color": "#6FA8DC", "id": "patch-level image prior", "label": "patch-level image prior", "shape": "dot", "size": 10.178571428571429, "title": "patch-level image prior"}, {"color": "#6FA8DC", "id": "complex non-uniform motion blur", "label": "complex non-uniform motion blur", "shape": "dot", "size": 10.089285714285714, "title": "complex non-uniform motion blur"}, {"color": "#6FA8DC", "id": "ion blur", "label": "ion blur", "shape": "dot", "size": 10.089285714285714, "title": "ion blur"}, {"color": "#6FA8DC", "id": "non-uniform model", "label": "non-uniform model", "shape": "dot", "size": 10.089285714285714, "title": "non-uniform model"}, {"color": "#6FA8DC", "id": "non-uniform motion blur", "label": "non-uniform motion blur", "shape": "dot", "size": 10.089285714285714, "title": "non-uniform motion blur"}, {"color": "#6FA8DC", "id": "patch-based image processing", "label": "patch-based image processing", "shape": "dot", "size": 10.089285714285714, "title": "patch-based image processing"}, {"color": "#6FA8DC", "id": "image artifact", "label": "image artifact", "shape": "dot", "size": 10.089285714285714, "title": "image artifact"}, {"color": "#6FA8DC", "id": "image quality", "label": "image quality", "shape": "dot", "size": 10.267857142857142, "title": "image quality"}, {"color": "#6FA8DC", "id": "Object detection systems", "label": "Object detection systems", "shape": "dot", "size": 10.178571428571429, "title": "Object detection systems"}, {"color": "#6FA8DC", "id": "large number of classes", "label": "large number of classes", "shape": "dot", "size": 10.089285714285714, "title": "large number of classes"}, {"color": "#6FA8DC", "id": "extensive convolution operations", "label": "extensive convolution operations", "shape": "dot", "size": 10.089285714285714, "title": "extensive convolution operations"}, {"color": "#6FA8DC", "id": "long detection times", "label": "long detection times", "shape": "dot", "size": 10.089285714285714, "title": "long detection times"}, {"color": "#6FA8DC", "id": "sparse coding methods", "label": "sparse coding methods", "shape": "dot", "size": 10.178571428571429, "title": "sparse coding methods"}, {"color": "#6FA8DC", "id": "Regularized Sparse Coding", "label": "Regularized Sparse Coding", "shape": "dot", "size": 10.625, "title": "Regularized Sparse Coding"}, {"color": "#6FA8DC", "id": "filter functionality reconstruction", "label": "filter functionality reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "filter functionality reconstruction"}, {"color": "#6FA8DC", "id": "score map error", "label": "score map error", "shape": "dot", "size": 10.089285714285714, "title": "score map error"}, {"color": "#6FA8DC", "id": "16x speedup", "label": "16x speedup", "shape": "dot", "size": 10.178571428571429, "title": "16x speedup"}, {"color": "#6FA8DC", "id": "ILSVIRC 2013", "label": "ILSVIRC 2013", "shape": "dot", "size": 10.089285714285714, "title": "ILSVIRC 2013"}, {"color": "#6FA8DC", "id": "0.04 mAP drop", "label": "0.04 mAP drop", "shape": "dot", "size": 10.089285714285714, "title": "0.04 mAP drop"}, {"color": "#6FA8DC", "id": "Deformable Part Model", "label": "Deformable Part Model", "shape": "dot", "size": 10.178571428571429, "title": "Deformable Part Model"}, {"color": "#6FA8DC", "id": "parallel computing", "label": "parallel computing", "shape": "dot", "size": 10.267857142857142, "title": "parallel computing"}, {"color": "#6FA8DC", "id": "GPUs", "label": "GPUs", "shape": "dot", "size": 10.089285714285714, "title": "GPUs"}, {"color": "#6FA8DC", "id": "Ting-Hsuan Chao", "label": "Ting-Hsuan Chao", "shape": "dot", "size": 10.089285714285714, "title": "Ting-Hsuan Chao"}, {"color": "#6FA8DC", "id": "National Taiwan University", "label": "National Taiwan University", "shape": "dot", "size": 10.357142857142858, "title": "National Taiwan University"}, {"color": "#6FA8DC", "id": "Yen-Liang Lin", "label": "Yen-Liang Lin", "shape": "dot", "size": 10.089285714285714, "title": "Yen-Liang Lin"}, {"color": "#6FA8DC", "id": "Yin-Hsi Kuo", "label": "Yin-Hsi Kuo", "shape": "dot", "size": 10.089285714285714, "title": "Yin-Hsi Kuo"}, {"color": "#6FA8DC", "id": "Winston H. Hsu", "label": "Winston H. Hsu", "shape": "dot", "size": 10.089285714285714, "title": "Winston H. Hsu"}, {"color": "#6FA8DC", "id": "Xiao-Ming Wu", "label": "Xiao-Ming Wu", "shape": "dot", "size": 10.357142857142858, "title": "Xiao-Ming Wu"}, {"color": "#6FA8DC", "id": "author", "label": "author", "shape": "dot", "size": 10.625, "title": "author"}, {"color": "#6FA8DC", "id": "Zhenguo Li", "label": "Zhenguo Li", "shape": "dot", "size": 10.446428571428571, "title": "Zhenguo Li"}, {"color": "#6FA8DC", "id": "Shih-Fu Chang", "label": "Shih-Fu Chang", "shape": "dot", "size": 10.535714285714286, "title": "Shih-Fu Chang"}, {"color": "#6FA8DC", "id": "X.-M. Wu", "label": "X.-M. Wu", "shape": "dot", "size": 10.535714285714286, "title": "X.-M. Wu"}, {"color": "#6FA8DC", "id": "Department of Electrical Engineering, Columbia University", "label": "Department of Electrical Engineering, Columbia University", "shape": "dot", "size": 10.178571428571429, "title": "Department of Electrical Engineering, Columbia University"}, {"color": "#6FA8DC", "id": "Huawei Noah\u2019s Ark Lab, Hong Kong", "label": "Huawei Noah\u2019s Ark Lab, Hong Kong", "shape": "dot", "size": 10.089285714285714, "title": "Huawei Noah\u2019s Ark Lab, Hong Kong"}, {"color": "#6FA8DC", "id": "xmwu@ee.columbia.edu", "label": "xmwu@ee.columbia.edu", "shape": "dot", "size": 10.178571428571429, "title": "xmwu@ee.columbia.edu"}, {"color": "#6FA8DC", "id": "li.zhenguo@huawei.com", "label": "li.zhenguo@huawei.com", "shape": "dot", "size": 10.089285714285714, "title": "li.zhenguo@huawei.com"}, {"color": "#6FA8DC", "id": "sfchang@ee.columbia.edu", "label": "sfchang@ee.columbia.edu", "shape": "dot", "size": 10.178571428571429, "title": "sfchang@ee.columbia.edu"}, {"color": "#6FA8DC", "id": "Analyzing the harmonic structure in graph-based learning", "label": "Analyzing the harmonic structure in graph-based learning", "shape": "dot", "size": 10.535714285714286, "title": "Analyzing the harmonic structure in graph-based learning"}, {"color": "#6FA8DC", "id": "New insights into laplacian similarity search", "label": "New insights into laplacian similarity search", "shape": "dot", "size": 10.089285714285714, "title": "New insights into laplacian similarity search"}, {"color": "#6FA8DC", "id": "Xuan Dong", "label": "Xuan Dong", "shape": "dot", "size": 10.178571428571429, "title": "Xuan Dong"}, {"color": "#6FA8DC", "id": "Region-based Temporally Consistent Video Post-processing", "label": "Region-based Temporally Consistent Video Post-processing", "shape": "dot", "size": 10.714285714285714, "title": "Region-based Temporally Consistent Video Post-processing"}, {"color": "#6FA8DC", "id": "Boyan Bonev", "label": "Boyan Bonev", "shape": "dot", "size": 10.267857142857142, "title": "Boyan Bonev"}, {"color": "#6FA8DC", "id": "Region-based Temporately Consistent Video Post-processing", "label": "Region-based Temporately Consistent Video Post-processing", "shape": "dot", "size": 10.089285714285714, "title": "Region-based Temporately Consistent Video Post-processing"}, {"color": "#6FA8DC", "id": "Yu Zhu", "label": "Yu Zhu", "shape": "dot", "size": 10.267857142857142, "title": "Yu Zhu"}, {"color": "#6FA8DC", "id": "Alan L. Yuille", "label": "Alan L. Yuille", "shape": "dot", "size": 10.267857142857142, "title": "Alan L. Yuille"}, {"color": "#6FA8DC", "id": "Region-based Temporically Consistent Video Post-processing", "label": "Region-based Temporically Consistent Video Post-processing", "shape": "dot", "size": 10.089285714285714, "title": "Region-based Temporically Consistent Video Post-processing"}, {"color": "#6FA8DC", "id": "Columbia University", "label": "Columbia University", "shape": "dot", "size": 10.357142857142858, "title": "Columbia University"}, {"color": "#6FA8DC", "id": "Department of Electrical Engineering", "label": "Department of Electrical Engineering", "shape": "dot", "size": 10.267857142857142, "title": "Department of Electrical Engineering"}, {"color": "#6FA8DC", "id": "Dong_Region-Based_Temporally_Consistent_2015_CVPR_paper.pdf", "label": "Dong_Region-Based_Temporally_Consistent_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Dong_Region-Based_Temporally_Consistent_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "temporally consistent video post-processing", "label": "temporally consistent video post-processing", "shape": "dot", "size": 10.089285714285714, "title": "temporally consistent video post-processing"}, {"color": "#6FA8DC", "id": "goal", "label": "goal", "shape": "dot", "size": 10.446428571428571, "title": "goal"}, {"color": "#6FA8DC", "id": "fidelity", "label": "fidelity", "shape": "dot", "size": 10.267857142857142, "title": "fidelity"}, {"color": "#6FA8DC", "id": "enhancement algorithms", "label": "enhancement algorithms", "shape": "dot", "size": 10.178571428571429, "title": "enhancement algorithms"}, {"color": "#6FA8DC", "id": "spatially consistent prior", "label": "spatially consistent prior", "shape": "dot", "size": 10.178571428571429, "title": "spatially consistent prior"}, {"color": "#6FA8DC", "id": "pixels with same RGB values", "label": "pixels with same RGB values", "shape": "dot", "size": 10.089285714285714, "title": "pixels with same RGB values"}, {"color": "#6FA8DC", "id": "frame", "label": "frame", "shape": "dot", "size": 10.089285714285714, "title": "frame"}, {"color": "#6FA8DC", "id": "enhancement of regions", "label": "enhancement of regions", "shape": "dot", "size": 10.357142857142858, "title": "enhancement of regions"}, {"color": "#6FA8DC", "id": "temporal consistency", "label": "temporal consistency", "shape": "dot", "size": 10.357142857142858, "title": "temporal consistency"}, {"color": "#6FA8DC", "id": "spatial consistency", "label": "spatial consistency", "shape": "dot", "size": 10.357142857142858, "title": "spatial consistency"}, {"color": "#6FA8DC", "id": "high fidelity", "label": "high fidelity", "shape": "dot", "size": 10.178571428571429, "title": "high fidelity"}, {"color": "#6FA8DC", "id": "original enhancement algorithms are unknown", "label": "original enhancement algorithms are unknown", "shape": "dot", "size": 10.089285714285714, "title": "original enhancement algorithms are unknown"}, {"color": "#6FA8DC", "id": "original enhancement algorithms are inaccessible", "label": "original enhancement algorithms are inaccessible", "shape": "dot", "size": 10.089285714285714, "title": "original enhancement algorithms are inaccessible"}, {"color": "#6FA8DC", "id": "frames", "label": "frames", "shape": "dot", "size": 10.178571428571429, "title": "frames"}, {"color": "#6FA8DC", "id": "Slic superpixels", "label": "Slic superpixels", "shape": "dot", "size": 10.535714285714286, "title": "Slic superpixels"}, {"color": "#6FA8DC", "id": "superpixel methods", "label": "superpixel methods", "shape": "dot", "size": 10.089285714285714, "title": "superpixel methods"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "shape": "dot", "size": 12.410714285714286, "title": "IEEE Transactions on Pattern Analysis and Machine Intelligence"}, {"color": "#6FA8DC", "id": "tone management", "label": "tone management", "shape": "dot", "size": 10.089285714285714, "title": "tone management"}, {"color": "#6FA8DC", "id": "ACM Trans. on Graph.", "label": "ACM Trans. on Graph.", "shape": "dot", "size": 10.446428571428571, "title": "ACM Trans. on Graph."}, {"color": "#6FA8DC", "id": "video color grading", "label": "video color grading", "shape": "dot", "size": 10.089285714285714, "title": "video color grading"}, {"color": "#6FA8DC", "id": "color transformation", "label": "color transformation", "shape": "dot", "size": 10.267857142857142, "title": "color transformation"}, {"color": "#6FA8DC", "id": "Image Enhancement Algorithms", "label": "Image Enhancement Algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Image Enhancement Algorithms"}, {"color": "#6FA8DC", "id": "Y. Chang", "label": "Y. Chang", "shape": "dot", "size": 10.178571428571429, "title": "Y. Chang"}, {"color": "#6FA8DC", "id": "Example-based color transformation of image and video using basic color categories", "label": "Example-based color transformation of image and video using basic color categories", "shape": "dot", "size": 10.446428571428571, "title": "Example-based color transformation of image and video using basic color categories"}, {"color": "#6FA8DC", "id": "S. Saito", "label": "S. Saito", "shape": "dot", "size": 10.178571428571429, "title": "S. Saito"}, {"color": "#6FA8DC", "id": "M. Nakajima", "label": "M. Nakajima", "shape": "dot", "size": 10.178571428571429, "title": "M. Nakajima"}, {"color": "#6FA8DC", "id": "16", "label": "16", "shape": "dot", "size": 10.089285714285714, "title": "16"}, {"color": "#6FA8DC", "id": "article", "label": "article", "shape": "dot", "size": 10.178571428571429, "title": "article"}, {"color": "#6FA8DC", "id": "1\u201311", "label": "1\u201311", "shape": "dot", "size": 10.089285714285714, "title": "1\u201311"}, {"color": "#6FA8DC", "id": "2013", "label": "2013", "shape": "dot", "size": 10.089285714285714, "title": "2013"}, {"color": "#6FA8DC", "id": "Example-based color transformation", "label": "Example-based color transformation", "shape": "dot", "size": 10.178571428571429, "title": "Example-based color transformation"}, {"color": "#6FA8DC", "id": "Example-based color transform", "label": "Example-based color transform", "shape": "dot", "size": 10.089285714285714, "title": "Example-based color transform"}, {"color": "#6FA8DC", "id": "Z. Farbman", "label": "Z. Farbman", "shape": "dot", "size": 10.089285714285714, "title": "Z. Farbman"}, {"color": "#6FA8DC", "id": "Tonal stabilization of video", "label": "Tonal stabilization of video", "shape": "dot", "size": 10.267857142857142, "title": "Tonal stabilization of video"}, {"color": "#6FA8DC", "id": "D. Lischinski", "label": "D. Lischinski", "shape": "dot", "size": 10.089285714285714, "title": "D. Lischinski"}, {"color": "#6FA8DC", "id": "P. F. Felzenszwalb", "label": "P. F. Felzenszwalb", "shape": "dot", "size": 10.089285714285714, "title": "P. F. Felzenszwalb"}, {"color": "#6FA8DC", "id": "Efficient belief propagation", "label": "Efficient belief propagation", "shape": "dot", "size": 10.267857142857142, "title": "Efficient belief propagation"}, {"color": "#6FA8DC", "id": "D. P. Huttenlocher", "label": "D. P. Huttenlocher", "shape": "dot", "size": 10.089285714285714, "title": "D. P. Huttenlocher"}, {"color": "#6FA8DC", "id": "M. Grundmann", "label": "M. Grundmann", "shape": "dot", "size": 10.089285714285714, "title": "M. Grundmann"}, {"color": "#6FA8DC", "id": "Post-processing approach", "label": "Post-processing approach", "shape": "dot", "size": 10.089285714285714, "title": "Post-processing approach"}, {"color": "#6FA8DC", "id": "Y. Hacohen", "label": "Y. Hacohen", "shape": "dot", "size": 10.089285714285714, "title": "Y. Hacohen"}, {"color": "#6FA8DC", "id": "Non-rigid dense correspondence", "label": "Non-rigid dense correspondence", "shape": "dot", "size": 10.089285714285714, "title": "Non-rigid dense correspondence"}, {"color": "#6FA8DC", "id": "N. K. Kalantari", "label": "N. K. Kalantari", "shape": "dot", "size": 10.089285714285714, "title": "N. K. Kalantari"}, {"color": "#6FA8DC", "id": "Patch-based high dynamic range video", "label": "Patch-based high dynamic range video", "shape": "dot", "size": 10.267857142857142, "title": "Patch-based high dynamic range video"}, {"color": "#6FA8DC", "id": "age enhancement", "label": "age enhancement", "shape": "dot", "size": 10.089285714285714, "title": "age enhancement"}, {"color": "#6FA8DC", "id": "ACM Trans. Graph.", "label": "ACM Trans. Graph.", "shape": "dot", "size": 10.089285714285714, "title": "ACM Trans. Graph."}, {"color": "#6FA8DC", "id": "N. K. Kalantria", "label": "N. K. Kalantria", "shape": "dot", "size": 10.089285714285714, "title": "N. K. Kalantria"}, {"color": "#6FA8DC", "id": "S. B. Kang", "label": "S. B. Kang", "shape": "dot", "size": 10.089285714285714, "title": "S. B. Kang"}, {"color": "#6FA8DC", "id": "High dynamic range video", "label": "High dynamic range video", "shape": "dot", "size": 10.178571428571429, "title": "High dynamic range video"}, {"color": "#6FA8DC", "id": "Tsinghua University", "label": "Tsinghua University", "shape": "dot", "size": 10.267857142857142, "title": "Tsinghua University"}, {"color": "#6FA8DC", "id": "UC Los Angeles", "label": "UC Los Angeles", "shape": "dot", "size": 10.178571428571429, "title": "UC Los Angeles"}, {"color": "#6FA8DC", "id": "Northwestern Polytechnical University", "label": "Northwestern Polytechnical University", "shape": "dot", "size": 10.357142857142858, "title": "Northwestern Polytechnical University"}, {"color": "#6FA8DC", "id": "Lionel Gueguen", "label": "Lionel Gueguen", "shape": "dot", "size": 10.089285714285714, "title": "Lionel Gueguen"}, {"color": "#6FA8DC", "id": "Large-Scale Damage Detection Using Satellite Imagery", "label": "Large-Scale Damage Detection Using Satellite Imagery", "shape": "dot", "size": 10.267857142857142, "title": "Large-Scale Damage Detection Using Satellite Imagery"}, {"color": "#6FA8DC", "id": "Raffay Hamid", "label": "Raffay Hamid", "shape": "dot", "size": 10.267857142857142, "title": "Raffay Hamid"}, {"color": "#6FA8DC", "id": "Satellite imagery", "label": "Satellite imagery", "shape": "dot", "size": 10.089285714285714, "title": "Satellite imagery"}, {"color": "#6FA8DC", "id": "assessing damages", "label": "assessing damages", "shape": "dot", "size": 10.089285714285714, "title": "assessing damages"}, {"color": "#6FA8DC", "id": "Manual inspection", "label": "Manual inspection", "shape": "dot", "size": 10.089285714285714, "title": "Manual inspection"}, {"color": "#6FA8DC", "id": "vast amount of data", "label": "vast amount of data", "shape": "dot", "size": 10.089285714285714, "title": "vast amount of data"}, {"color": "#6FA8DC", "id": "damage detection", "label": "damage detection", "shape": "dot", "size": 10.089285714285714, "title": "damage detection"}, {"color": "#6FA8DC", "id": "semi-supervised learning", "label": "semi-supervised learning", "shape": "dot", "size": 10.178571428571429, "title": "semi-supervised learning"}, {"color": "#6FA8DC", "id": "study", "label": "study", "shape": "dot", "size": 10.535714285714286, "title": "study"}, {"color": "#6FA8DC", "id": "88 million images", "label": "88 million images", "shape": "dot", "size": 10.089285714285714, "title": "88 million images"}, {"color": "#6FA8DC", "id": "4,665 KM2", "label": "4,665 KM2", "shape": "dot", "size": 10.178571428571429, "title": "4,665 KM2"}, {"color": "#6FA8DC", "id": "12 locations", "label": "12 locations", "shape": "dot", "size": 10.089285714285714, "title": "12 locations"}, {"color": "#6FA8DC", "id": "sun angle", "label": "sun angle", "shape": "dot", "size": 10.089285714285714, "title": "sun angle"}, {"color": "#6FA8DC", "id": "sensor resolution", "label": "sensor resolution", "shape": "dot", "size": 10.089285714285714, "title": "sensor resolution"}, {"color": "#6FA8DC", "id": "registration differences", "label": "registration differences", "shape": "dot", "size": 10.089285714285714, "title": "registration differences"}, {"color": "#6FA8DC", "id": "user study", "label": "user study", "shape": "dot", "size": 10.178571428571429, "title": "user study"}, {"color": "#6FA8DC", "id": "ten-fold reduction", "label": "ten-fold reduction", "shape": "dot", "size": 10.267857142857142, "title": "ten-fold reduction"}, {"color": "#6FA8DC", "id": "human annotation time", "label": "human annotation time", "shape": "dot", "size": 10.089285714285714, "title": "human annotation time"}, {"color": "#6FA8DC", "id": "hierarchical shape features", "label": "hierarchical shape features", "shape": "dot", "size": 10.178571428571429, "title": "hierarchical shape features"}, {"color": "#6FA8DC", "id": "bag-of-visual words setting", "label": "bag-of-visual words setting", "shape": "dot", "size": 10.089285714285714, "title": "bag-of-visual words setting"}, {"color": "#6FA8DC", "id": "representation", "label": "representation", "shape": "dot", "size": 10.625, "title": "representation"}, {"color": "#6FA8DC", "id": "five alternatives", "label": "five alternatives", "shape": "dot", "size": 10.089285714285714, "title": "five alternatives"}, {"color": "#6FA8DC", "id": "detection accuracy", "label": "detection accuracy", "shape": "dot", "size": 10.178571428571429, "title": "detection accuracy"}, {"color": "#6FA8DC", "id": "manual inspection", "label": "manual inspection", "shape": "dot", "size": 10.089285714285714, "title": "manual inspection"}, {"color": "#6FA8DC", "id": "minimal loss", "label": "minimal loss", "shape": "dot", "size": 10.089285714285714, "title": "minimal loss"}, {"color": "#6FA8DC", "id": "time efficiency", "label": "time efficiency", "shape": "dot", "size": 10.089285714285714, "title": "time efficiency"}, {"color": "#6FA8DC", "id": "annotation process", "label": "annotation process", "shape": "dot", "size": 10.089285714285714, "title": "annotation process"}, {"color": "#6FA8DC", "id": "User study", "label": "User study", "shape": "dot", "size": 10.178571428571429, "title": "User study"}, {"color": "#6FA8DC", "id": "ten-fold reduction in annotation time", "label": "ten-fold reduction in annotation time", "shape": "dot", "size": 10.089285714285714, "title": "ten-fold reduction in annotation time"}, {"color": "#6FA8DC", "id": "minimal loss in detection accuracy", "label": "minimal loss in detection accuracy", "shape": "dot", "size": 10.089285714285714, "title": "minimal loss in detection accuracy"}, {"color": "#6FA8DC", "id": "Damage detection", "label": "Damage detection", "shape": "dot", "size": 10.178571428571429, "title": "Damage detection"}, {"color": "#6FA8DC", "id": "Hierarchical shape features", "label": "Hierarchical shape features", "shape": "dot", "size": 10.089285714285714, "title": "Hierarchical shape features"}, {"color": "#6FA8DC", "id": "Semi-supervised learning", "label": "Semi-supervised learning", "shape": "dot", "size": 10.178571428571429, "title": "Semi-supervised learning"}, {"color": "#6FA8DC", "id": "Novelty detection", "label": "Novelty detection", "shape": "dot", "size": 10.178571428571429, "title": "Novelty detection"}, {"color": "#6FA8DC", "id": "Xia et al. (2010)", "label": "Xia et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Xia et al. (2010)"}, {"color": "#6FA8DC", "id": "Shape-based invariant texture indexing", "label": "Shape-based invariant texture indexing", "shape": "dot", "size": 10.089285714285714, "title": "Shape-based invariant texture indexing"}, {"color": "#6FA8DC", "id": "Markou \u0026 Singh (2003)", "label": "Markou \u0026 Singh (2003)", "shape": "dot", "size": 10.089285714285714, "title": "Markou \u0026 Singh (2003)"}, {"color": "#6FA8DC", "id": "Blanchard et al. (2010)", "label": "Blanchard et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Blanchard et al. (2010)"}, {"color": "#6FA8DC", "id": "Semi-supervised novelty detection", "label": "Semi-supervised novelty detection", "shape": "dot", "size": 10.089285714285714, "title": "Semi-supervised novelty detection"}, {"color": "#6FA8DC", "id": "Bruzone \u0026 Prieto (2000)", "label": "Bruzone \u0026 Prieto (2000)", "shape": "dot", "size": 10.089285714285714, "title": "Bruzone \u0026 Prieto (2000)"}, {"color": "#6FA8DC", "id": "Difference image", "label": "Difference image", "shape": "dot", "size": 10.178571428571429, "title": "Difference image"}, {"color": "#6FA8DC", "id": "Unsupervised change detection", "label": "Unsupervised change detection", "shape": "dot", "size": 10.089285714285714, "title": "Unsupervised change detection"}, {"color": "#6FA8DC", "id": "Satellite imagery analysis", "label": "Satellite imagery analysis", "shape": "dot", "size": 10.089285714285714, "title": "Satellite imagery analysis"}, {"color": "#6FA8DC", "id": "Bruzzone", "label": "Bruzzone", "shape": "dot", "size": 10.089285714285714, "title": "Bruzzone"}, {"color": "#6FA8DC", "id": "Automatic analysis of the difference image", "label": "Automatic analysis of the difference image", "shape": "dot", "size": 10.267857142857142, "title": "Automatic analysis of the difference image"}, {"color": "#6FA8DC", "id": "Prieto", "label": "Prieto", "shape": "dot", "size": 10.089285714285714, "title": "Prieto"}, {"color": "#6FA8DC", "id": "Gerard", "label": "Gerard", "shape": "dot", "size": 10.089285714285714, "title": "Gerard"}, {"color": "#6FA8DC", "id": "A quasi-linear algorithm", "label": "A quasi-linear algorithm", "shape": "dot", "size": 10.178571428571429, "title": "A quasi-linear algorithm"}, {"color": "#6FA8DC", "id": "International Symposium on Mathematical Morphology", "label": "International Symposium on Mathematical Morphology", "shape": "dot", "size": 10.089285714285714, "title": "International Symposium on Mathematical Morphology"}, {"color": "#6FA8DC", "id": "Monasse", "label": "Monasse", "shape": "dot", "size": 10.089285714285714, "title": "Monasse"}, {"color": "#6FA8DC", "id": "Fast computation of a contrast-invariant image representation", "label": "Fast computation of a contrast-invariant image representation", "shape": "dot", "size": 10.178571428571429, "title": "Fast computation of a contrast-invariant image representation"}, {"color": "#6FA8DC", "id": "Guichard", "label": "Guichard", "shape": "dot", "size": 10.089285714285714, "title": "Guichard"}, {"color": "#6FA8DC", "id": "Nielsen", "label": "Nielsen", "shape": "dot", "size": 10.089285714285714, "title": "Nielsen"}, {"color": "#6FA8DC", "id": "The regularized iteratively reweighted mad method", "label": "The regularized iteratively reweighted mad method", "shape": "dot", "size": 10.178571428571429, "title": "The regularized iteratively reweighted mad method"}, {"color": "#6FA8DC", "id": "Vaduva", "label": "Vaduva", "shape": "dot", "size": 10.089285714285714, "title": "Vaduva"}, {"color": "#6FA8DC", "id": "A latent analysis of earth surface dynamic evolution", "label": "A latent analysis of earth surface dynamic evolution", "shape": "dot", "size": 10.178571428571429, "title": "A latent analysis of earth surface dynamic evolution"}, {"color": "#6FA8DC", "id": "at", "label": "at", "shape": "dot", "size": 10.089285714285714, "title": "at"}, {"color": "#6FA8DC", "id": "A latent analysis of earth surface dynamic evolution using change map time series", "label": "A latent analysis of earth surface dynamic evolution using change map time series", "shape": "dot", "size": 10.178571428571429, "title": "A latent analysis of earth surface dynamic evolution using change map time series"}, {"color": "#6FA8DC", "id": "Lazarescu", "label": "Lazarescu", "shape": "dot", "size": 10.089285714285714, "title": "Lazarescu"}, {"color": "#6FA8DC", "id": "Datcu", "label": "Datcu", "shape": "dot", "size": 10.089285714285714, "title": "Datcu"}, {"color": "#6FA8DC", "id": "A latent anisotropy of earth surface dynamic evolution using change map time series", "label": "A latent anisotropy of earth surface dynamic evolution using change map time series", "shape": "dot", "size": 10.089285714285714, "title": "A latent anisotropy of earth surface dynamic evolution using change map time series"}, {"color": "#6FA8DC", "id": "Gomez-Chova", "label": "Gomez-Chova", "shape": "dot", "size": 10.089285714285714, "title": "Gomez-Chova"}, {"color": "#6FA8DC", "id": "Kernel-based framework for multitemporal and multisource remote sensing data classification and change detection", "label": "Kernel-based framework for multitemporal and multisource remote sensing data classification and change detection", "shape": "dot", "size": 10.089285714285714, "title": "Kernel-based framework for multitemporal and multisource remote sensing data classification and change detection"}, {"color": "#6FA8DC", "id": "Wang", "label": "Wang", "shape": "dot", "size": 10.357142857142858, "title": "Wang"}, {"color": "#6FA8DC", "id": "Locality-constrained linear coding for image classification", "label": "Locality-constrained linear coding for image classification", "shape": "dot", "size": 10.178571428571429, "title": "Locality-constrained linear coding for image classification"}, {"color": "#6FA8DC", "id": "Yang", "label": "Yang", "shape": "dot", "size": 10.178571428571429, "title": "Yang"}, {"color": "#6FA8DC", "id": "Song", "label": "Song", "shape": "dot", "size": 10.089285714285714, "title": "Song"}, {"color": "#6FA8DC", "id": "Fusing Subcategory Probabilities for Texture Classi\ufb01cation", "label": "Fusing Subcategory Probabilities for Texture Classi\ufb01cation", "shape": "dot", "size": 10.178571428571429, "title": "Fusing Subcategory Probabilities for Texture Classi\ufb01cation"}, {"color": "#6FA8DC", "id": "Cai", "label": "Cai", "shape": "dot", "size": 10.089285714285714, "title": "Cai"}, {"color": "#6FA8DC", "id": "Gueguen", "label": "Gueguen", "shape": "dot", "size": 10.089285714285714, "title": "Gueguen"}, {"color": "#6FA8DC", "id": "DigitalGlobe Inc.", "label": "DigitalGlobe Inc.", "shape": "dot", "size": 10.267857142857142, "title": "DigitalGlobe Inc."}, {"color": "#6FA8DC", "id": "Hamid", "label": "Hamid", "shape": "dot", "size": 10.089285714285714, "title": "Hamid"}, {"color": "#6FA8DC", "id": "mhamid@digitalGlobe.com", "label": "mhamid@digitalGlobe.com", "shape": "dot", "size": 10.089285714285714, "title": "mhamid@digitalGlobe.com"}, {"color": "#6FA8DC", "id": "Yang Song", "label": "Yang Song", "shape": "dot", "size": 10.178571428571429, "title": "Yang Song"}, {"color": "#6FA8DC", "id": "Fusing Subcategory Probabilities for Texture Classification", "label": "Fusing Subcategory Probabilities for Texture Classification", "shape": "dot", "size": 10.625, "title": "Fusing Subcategory Probabilities for Texture Classification"}, {"color": "#6FA8DC", "id": "Qing Li", "label": "Qing Li", "shape": "dot", "size": 10.089285714285714, "title": "Qing Li"}, {"color": "#6FA8DC", "id": "Fusing SubCategory Probabilities for Texture Classification", "label": "Fusing SubCategory Probabilities for Texture Classification", "shape": "dot", "size": 10.089285714285714, "title": "Fusing SubCategory Probabilities for Texture Classification"}, {"color": "#6FA8DC", "id": "Fan Zhang", "label": "Fan Zhang", "shape": "dot", "size": 10.089285714285714, "title": "Fan Zhang"}, {"color": "#6FA8DC", "id": "David Dagan Feng", "label": "David Dagan Feng", "shape": "dot", "size": 10.178571428571429, "title": "David Dagan Feng"}, {"color": "#6FA8DC", "id": "Heng Huang", "label": "Heng Huang", "shape": "dot", "size": 10.178571428571429, "title": "Heng Huang"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "shape": "dot", "size": 10.803571428571429, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers"}, {"color": "#6FA8DC", "id": "Song_Fusing_Subcategory_Probabilities_2015_CVPR_paper.pdf", "label": "Song_Fusing_Subcategory_Probabilities_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Song_Fusing_Subcategory_Probabilities_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Texture classification", "label": "Texture classification", "shape": "dot", "size": 10.178571428571429, "title": "Texture classification"}, {"color": "#6FA8DC", "id": "high intra-class variation", "label": "high intra-class variation", "shape": "dot", "size": 10.089285714285714, "title": "high intra-class variation"}, {"color": "#6FA8DC", "id": "sub-categorization model", "label": "sub-categorization model", "shape": "dot", "size": 10.178571428571429, "title": "sub-categorization model"}, {"color": "#6FA8DC", "id": "texture classification", "label": "texture classification", "shape": "dot", "size": 10.267857142857142, "title": "texture classification"}, {"color": "#6FA8DC", "id": "class", "label": "class", "shape": "dot", "size": 10.089285714285714, "title": "class"}, {"color": "#6FA8DC", "id": "subcategories", "label": "subcategories", "shape": "dot", "size": 10.267857142857142, "title": "subcategories"}, {"color": "#6FA8DC", "id": "distinctiveness", "label": "distinctiveness", "shape": "dot", "size": 10.089285714285714, "title": "distinctiveness"}, {"color": "#6FA8DC", "id": "representativeness", "label": "representativeness", "shape": "dot", "size": 10.089285714285714, "title": "representativeness"}, {"color": "#6FA8DC", "id": "subcategory probabilities", "label": "subcategory probabilities", "shape": "dot", "size": 10.178571428571429, "title": "subcategory probabilities"}, {"color": "#6FA8DC", "id": "contribution levels", "label": "contribution levels", "shape": "dot", "size": 10.089285714285714, "title": "contribution levels"}, {"color": "#6FA8DC", "id": "cluster qualities", "label": "cluster qualities", "shape": "dot", "size": 10.089285714285714, "title": "cluster qualities"}, {"color": "#6FA8DC", "id": "fused probability", "label": "fused probability", "shape": "dot", "size": 10.089285714285714, "title": "fused probability"}, {"color": "#6FA8DC", "id": "multiclass classification probability", "label": "multiclass classification probability", "shape": "dot", "size": 10.089285714285714, "title": "multiclass classification probability"}, {"color": "#6FA8DC", "id": "KTH-TIPS2 dataset", "label": "KTH-TIPS2 dataset", "shape": "dot", "size": 10.089285714285714, "title": "KTH-TIPS2 dataset"}, {"color": "#6FA8DC", "id": "FMD dataset", "label": "FMD dataset", "shape": "dot", "size": 10.089285714285714, "title": "FMD dataset"}, {"color": "#6FA8DC", "id": "DTD dataset", "label": "DTD dataset", "shape": "dot", "size": 10.089285714285714, "title": "DTD dataset"}, {"color": "#6FA8DC", "id": "Texture Classification", "label": "Texture Classification", "shape": "dot", "size": 10.178571428571429, "title": "Texture Classification"}, {"color": "#6FA8DC", "id": "KTH-TIPS2", "label": "KTH-TIPS2", "shape": "dot", "size": 10.089285714285714, "title": "KTH-TIPS2"}, {"color": "#6FA8DC", "id": "FMD", "label": "FMD", "shape": "dot", "size": 10.089285714285714, "title": "FMD"}, {"color": "#6FA8DC", "id": "DTD", "label": "DTD", "shape": "dot", "size": 10.089285714285714, "title": "DTD"}, {"color": "#6FA8DC", "id": "State-of-the-art approaches", "label": "State-of-the-art approaches", "shape": "dot", "size": 10.089285714285714, "title": "State-of-the-art approaches"}, {"color": "#6FA8DC", "id": "BMIT Research Group", "label": "BMIT Research Group", "shape": "dot", "size": 10.357142857142858, "title": "BMIT Research Group"}, {"color": "#6FA8DC", "id": "University of Sydney", "label": "University of Sydney", "shape": "dot", "size": 10.267857142857142, "title": "University of Sydney"}, {"color": "#6FA8DC", "id": "School of IT", "label": "School of IT", "shape": "dot", "size": 10.178571428571429, "title": "School of IT"}, {"color": "#6FA8DC", "id": "Australia", "label": "Australia", "shape": "dot", "size": 10.357142857142858, "title": "Australia"}, {"color": "#6FA8DC", "id": "Department of Computer Science and Engineering", "label": "Department of Computer Science and Engineering", "shape": "dot", "size": 10.178571428571429, "title": "Department of Computer Science and Engineering"}, {"color": "#6FA8DC", "id": "University of Texas, Arlington", "label": "University of Texas, Arlington", "shape": "dot", "size": 10.089285714285714, "title": "University of Texas, Arlington"}, {"color": "#6FA8DC", "id": "Manohar Paluri", "label": "Manohar Paluri", "shape": "dot", "size": 10.267857142857142, "title": "Manohar Paluri"}, {"color": "#6FA8DC", "id": "Beyond Frontal Faces", "label": "Beyond Frontal Faces", "shape": "dot", "size": 10.446428571428571, "title": "Beyond Frontal Faces"}, {"color": "#6FA8DC", "id": "Yaniv Taigman", "label": "Yaniv Taigman", "shape": "dot", "size": 10.267857142857142, "title": "Yaniv Taigman"}, {"color": "#6FA8DC", "id": "Rob Fergus", "label": "Rob Fergus", "shape": "dot", "size": 10.267857142857142, "title": "Rob Fergus"}, {"color": "#6FA8DC", "id": "Lubomir Bourdev", "label": "Lubomir Bourdev", "shape": "dot", "size": 10.267857142857142, "title": "Lubomir Bourdev"}, {"color": "#6FA8DC", "id": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper", "label": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper", "shape": "dot", "size": 10.446428571428571, "title": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "recognizing peoples\u2019 identities", "label": "recognizing peoples\u2019 identities", "shape": "dot", "size": 10.178571428571429, "title": "recognizing peoples\u2019 identities"}, {"color": "#6FA8DC", "id": "PIPA dataset", "label": "PIPA dataset", "shape": "dot", "size": 10.267857142857142, "title": "PIPA dataset"}, {"color": "#6FA8DC", "id": "60000 instances", "label": "60000 instances", "shape": "dot", "size": 10.089285714285714, "title": "60000 instances"}, {"color": "#6FA8DC", "id": "2000 individuals", "label": "2000 individuals", "shape": "dot", "size": 10.089285714285714, "title": "2000 individuals"}, {"color": "#6FA8DC", "id": "PIPER method", "label": "PIPER method", "shape": "dot", "size": 10.178571428571429, "title": "PIPER method"}, {"color": "#6FA8DC", "id": "face recognizer", "label": "face recognizer", "shape": "dot", "size": 10.267857142857142, "title": "face recognizer"}, {"color": "#6FA8DC", "id": "global recognizer", "label": "global recognizer", "shape": "dot", "size": 10.178571428571429, "title": "global recognizer"}, {"color": "#6FA8DC", "id": "person images", "label": "person images", "shape": "dot", "size": 10.089285714285714, "title": "person images"}, {"color": "#6FA8DC", "id": "frontal face", "label": "frontal face", "shape": "dot", "size": 10.089285714285714, "title": "frontal face"}, {"color": "#6FA8DC", "id": "person recognizers", "label": "person recognizers", "shape": "dot", "size": 10.089285714285714, "title": "person recognizers"}, {"color": "#6FA8DC", "id": "deep convolutional networks", "label": "deep convolutional networks", "shape": "dot", "size": 10.267857142857142, "title": "deep convolutional networks"}, {"color": "#6FA8DC", "id": "discount pose variations", "label": "discount pose variations", "shape": "dot", "size": 10.089285714285714, "title": "discount pose variations"}, {"color": "#6FA8DC", "id": "PIPER", "label": "PIPER", "shape": "dot", "size": 10.267857142857142, "title": "PIPER"}, {"color": "#6FA8DC", "id": "DeepFace", "label": "DeepFace", "shape": "dot", "size": 10.357142857142858, "title": "DeepFace"}, {"color": "#6FA8DC", "id": "best face recognizers", "label": "best face recognizers", "shape": "dot", "size": 10.089285714285714, "title": "best face recognizers"}, {"color": "#6FA8DC", "id": "LFW dataset", "label": "LFW dataset", "shape": "dot", "size": 10.267857142857142, "title": "LFW dataset"}, {"color": "#6FA8DC", "id": "unconstrained setup", "label": "unconstrained setup", "shape": "dot", "size": 10.089285714285714, "title": "unconstrained setup"}, {"color": "#6FA8DC", "id": "Pose Invariant Recognition", "label": "Pose Invariant Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Pose Invariant Recognition"}, {"color": "#6FA8DC", "id": "Paul Wohlhart", "label": "Paul Wohlhart", "shape": "dot", "size": 10.625, "title": "Paul Wohlhart"}, {"color": "#6FA8DC", "id": "Institute for Computer Vision and Graphics, Graz University of Technology, Austria", "label": "Institute for Computer Vision and Graphics, Graz University of Technology, Austria", "shape": "dot", "size": 10.089285714285714, "title": "Institute for Computer Vision and Graphics, Graz University of Technology, Austria"}, {"color": "#6FA8DC", "id": "Learning Descriptors for Object Recognition and 3D Pose Estimation", "label": "Learning Descriptors for Object Recognition and 3D Pose Estimation", "shape": "dot", "size": 10.178571428571429, "title": "Learning Descriptors for Object Recognition and 3D Pose Estimation"}, {"color": "#6FA8DC", "id": "cvpr_papers", "label": "cvpr_papers", "shape": "dot", "size": 11.071428571428571, "title": "cvpr_papers"}, {"color": "#6FA8DC", "id": "Institute for Computer Vision and Graphics", "label": "Institute for Computer Vision and Graphics", "shape": "dot", "size": 10.446428571428571, "title": "Institute for Computer Vision and Graphics"}, {"color": "#6FA8DC", "id": "Graz University of Technology", "label": "Graz University of Technology", "shape": "dot", "size": 10.446428571428571, "title": "Graz University of Technology"}, {"color": "#6FA8DC", "id": "Austria", "label": "Austria", "shape": "dot", "size": 10.267857142857142, "title": "Austria"}, {"color": "#6FA8DC", "id": "{wohlhart}@icg.tugraz.at", "label": "{wohlhart}@icg.tugraz.at", "shape": "dot", "size": 10.089285714285714, "title": "{wohlhart}@icg.tugraz.at"}, {"color": "#6FA8DC", "id": "2015 CVPR paper", "label": "2015 CVPR paper", "shape": "dot", "size": 10.267857142857142, "title": "2015 CVPR paper"}, {"color": "#6FA8DC", "id": "Learning Descriptors", "label": "Learning Descriptors", "shape": "dot", "size": 10.178571428571429, "title": "Learning Descriptors"}, {"color": "#6FA8DC", "id": "Computer Graphics", "label": "Computer Graphics", "shape": "dot", "size": 10.089285714285714, "title": "Computer Graphics"}, {"color": "#6FA8DC", "id": "IEEE", "label": "IEEE", "shape": "dot", "size": 10.357142857142858, "title": "IEEE"}, {"color": "#6FA8DC", "id": "Vincent LePetit", "label": "Vincent LePetit", "shape": "dot", "size": 10.178571428571429, "title": "Vincent LePetit"}, {"color": "#6FA8DC", "id": "Joe Yue-Hei Ng", "label": "Joe Yue-Hei Ng", "shape": "dot", "size": 10.178571428571429, "title": "Joe Yue-Hei Ng"}, {"color": "#6FA8DC", "id": "Beyond Short Snippets", "label": "Beyond Short Snippets", "shape": "dot", "size": 10.535714285714286, "title": "Beyond Short Snippets"}, {"color": "#6FA8DC", "id": "Matthew Hausknecht", "label": "Matthew Hausknecht", "shape": "dot", "size": 10.178571428571429, "title": "Matthew Hausknecht"}, {"color": "#6FA8DC", "id": "Sudheendra Vijayanarasimhan", "label": "Sudheendra Vijayanarasimhan", "shape": "dot", "size": 10.178571428571429, "title": "Sudheendra Vijayanarasimhan"}, {"color": "#6FA8DC", "id": "Oriol Vinyals", "label": "Oriol Vinyals", "shape": "dot", "size": 10.178571428571429, "title": "Oriol Vinyals"}, {"color": "#6FA8DC", "id": "Rajat Monga", "label": "Rajat Monga", "shape": "dot", "size": 10.178571428571429, "title": "Rajat Monga"}, {"color": "#6FA8DC", "id": "Beyond Short Snppets", "label": "Beyond Short Snppets", "shape": "dot", "size": 10.089285714285714, "title": "Beyond Short Snppets"}, {"color": "#6FA8DC", "id": "George Toderici", "label": "George Toderici", "shape": "dot", "size": 10.178571428571429, "title": "George Toderici"}, {"color": "#6FA8DC", "id": "Convolutional neural networks (CNNs)", "label": "Convolutional neural networks (CNNs)", "shape": "dot", "size": 10.178571428571429, "title": "Convolutional neural networks (CNNs)"}, {"color": "#6FA8DC", "id": "image recognition problems", "label": "image recognition problems", "shape": "dot", "size": 10.089285714285714, "title": "image recognition problems"}, {"color": "#6FA8DC", "id": "recognition", "label": "recognition", "shape": "dot", "size": 10.178571428571429, "title": "recognition"}, {"color": "#6FA8DC", "id": "detection", "label": "detection", "shape": "dot", "size": 10.178571428571429, "title": "detection"}, {"color": "#6FA8DC", "id": "retrieval", "label": "retrieval", "shape": "dot", "size": 10.089285714285714, "title": "retrieval"}, {"color": "#6FA8DC", "id": "deep neural network architectures", "label": "deep neural network architectures", "shape": "dot", "size": 10.089285714285714, "title": "deep neural network architectures"}, {"color": "#6FA8DC", "id": "image information", "label": "image information", "shape": "dot", "size": 10.178571428571429, "title": "image information"}, {"color": "#6FA8DC", "id": "longer time periods", "label": "longer time periods", "shape": "dot", "size": 10.089285714285714, "title": "longer time periods"}, {"color": "#6FA8DC", "id": "convolutional temporal feature pooling architectures", "label": "convolutional temporal feature pooling architectures", "shape": "dot", "size": 10.089285714285714, "title": "convolutional temporal feature pooling architectures"}, {"color": "#6FA8DC", "id": "video", "label": "video", "shape": "dot", "size": 10.446428571428571, "title": "video"}, {"color": "#6FA8DC", "id": "ordered sequence of frames", "label": "ordered sequence of frames", "shape": "dot", "size": 10.089285714285714, "title": "ordered sequence of frames"}, {"color": "#6FA8DC", "id": "recurrent neural network", "label": "recurrent neural network", "shape": "dot", "size": 10.089285714285714, "title": "recurrent neural network"}, {"color": "#6FA8DC", "id": "Long Short-Term Memory (LSTM) cells", "label": "Long Short-Term Memory (LSTM) cells", "shape": "dot", "size": 10.089285714285714, "title": "Long Short-Term Memory (LSTM) cells"}, {"color": "#6FA8DC", "id": "LSTM cells", "label": "LSTM cells", "shape": "dot", "size": 10.089285714285714, "title": "LSTM cells"}, {"color": "#6FA8DC", "id": "output of CNN", "label": "output of CNN", "shape": "dot", "size": 10.089285714285714, "title": "output of CNN"}, {"color": "#6FA8DC", "id": "networks", "label": "networks", "shape": "dot", "size": 10.446428571428571, "title": "networks"}, {"color": "#6FA8DC", "id": "performance improvements", "label": "performance improvements", "shape": "dot", "size": 10.267857142857142, "title": "performance improvements"}, {"color": "#6FA8DC", "id": "UCF-101 datasets", "label": "UCF-101 datasets", "shape": "dot", "size": 10.535714285714286, "title": "UCF-101 datasets"}, {"color": "#6FA8DC", "id": "Sports 1 million dataset", "label": "Sports 1 million dataset", "shape": "dot", "size": 10.178571428571429, "title": "Sports 1 million dataset"}, {"color": "#6FA8DC", "id": "73.1%", "label": "73.1%", "shape": "dot", "size": 10.089285714285714, "title": "73.1%"}, {"color": "#6FA8DC", "id": "60.9%", "label": "60.9%", "shape": "dot", "size": 10.089285714285714, "title": "60.9%"}, {"color": "#6FA8DC", "id": "88.6%", "label": "88.6%", "shape": "dot", "size": 10.089285714285714, "title": "88.6%"}, {"color": "#6FA8DC", "id": "88.0%", "label": "88.0%", "shape": "dot", "size": 10.089285714285714, "title": "88.0%"}, {"color": "#6FA8DC", "id": "optical flow information", "label": "optical flow information", "shape": "dot", "size": 10.089285714285714, "title": "optical flow information"}, {"color": "#6FA8DC", "id": "73.0%", "label": "73.0%", "shape": "dot", "size": 10.089285714285714, "title": "73.0%"}, {"color": "#6FA8DC", "id": "82.6%", "label": "82.6%", "shape": "dot", "size": 10.089285714285714, "title": "82.6%"}, {"color": "#6FA8DC", "id": "University of Maryland, College Park", "label": "University of Maryland, College Park", "shape": "dot", "size": 10.089285714285714, "title": "University of Maryland, College Park"}, {"color": "#6FA8DC", "id": "University of Texas at Austin", "label": "University of Texas at Austin", "shape": "dot", "size": 10.089285714285714, "title": "University of Texas at Austin"}, {"color": "#6FA8DC", "id": "Google, Inc.", "label": "Google, Inc.", "shape": "dot", "size": 10.357142857142858, "title": "Google, Inc."}, {"color": "#6FA8DC", "id": "Ioannis Gkiouslekas", "label": "Ioannis Gkiouslekas", "shape": "dot", "size": 10.178571428571429, "title": "Ioannis Gkiouslekas"}, {"color": "#6FA8DC", "id": "On the Appearance of Translucnt Edges", "label": "On the Appearance of Translucnt Edges", "shape": "dot", "size": 10.089285714285714, "title": "On the Appearance of Translucnt Edges"}, {"color": "#6FA8DC", "id": "Gkiouslekas", "label": "Gkiouslekas", "shape": "dot", "size": 10.089285714285714, "title": "Gkiouslekas"}, {"color": "#6FA8DC", "id": "Harvard SEAS", "label": "Harvard SEAS", "shape": "dot", "size": 10.535714285714286, "title": "Harvard SEAS"}, {"color": "#6FA8DC", "id": "Bruce Walter", "label": "Bruce Walter", "shape": "dot", "size": 10.267857142857142, "title": "Bruce Walter"}, {"color": "#6FA8DC", "id": "Cornell University", "label": "Cornell University", "shape": "dot", "size": 10.357142857142858, "title": "Cornell University"}, {"color": "#6FA8DC", "id": "Edward H. Adelson", "label": "Edward H. Adelson", "shape": "dot", "size": 10.267857142857142, "title": "Edward H. Adelson"}, {"color": "#6FA8DC", "id": "Massachusetts Institute of Technology", "label": "Massachusetts Institute of Technology", "shape": "dot", "size": 10.446428571428571, "title": "Massachusetts Institute of Technology"}, {"color": "#6FA8DC", "id": "Edge Radiance Profiles", "label": "Edge Radiance Profiles", "shape": "dot", "size": 10.089285714285714, "title": "Edge Radiance Profiles"}, {"color": "#6FA8DC", "id": "Walter", "label": "Walter", "shape": "dot", "size": 10.089285714285714, "title": "Walter"}, {"color": "#6FA8DC", "id": "Microfacet models", "label": "Microfacet models", "shape": "dot", "size": 10.267857142857142, "title": "Microfacet models"}, {"color": "#6FA8DC", "id": "refraction through rough surfaces", "label": "refraction through rough surfaces", "shape": "dot", "size": 10.089285714285714, "title": "refraction through rough surfaces"}, {"color": "#6FA8DC", "id": "EGSR", "label": "EGSR", "shape": "dot", "size": 10.089285714285714, "title": "EGSR"}, {"color": "#6FA8DC", "id": "Ioannis Gkioleakas", "label": "Ioannis Gkioleakas", "shape": "dot", "size": 10.178571428571429, "title": "Ioannis Gkioleakas"}, {"color": "#6FA8DC", "id": "Higher Education", "label": "Higher Education", "shape": "dot", "size": 10.357142857142858, "title": "Higher Education"}, {"color": "#6FA8DC", "id": "igkio@seas.harvard.edu", "label": "igkio@seas.harvard.edu", "shape": "dot", "size": 10.089285714285714, "title": "igkio@seas.harvard.edu"}, {"color": "#6FA8DC", "id": "bruce.walter@cornell.edu", "label": "bruce.walter@cornell.edu", "shape": "dot", "size": 10.089285714285714, "title": "bruce.walter@cornell.edu"}, {"color": "#6FA8DC", "id": "adelson@cail.mit.edu", "label": "adelson@cail.mit.edu", "shape": "dot", "size": 10.089285714285714, "title": "adelson@cail.mit.edu"}, {"color": "#6FA8DC", "id": "Academic Degrees", "label": "Academic Degrees", "shape": "dot", "size": 10.089285714285714, "title": "Academic Degrees"}, {"color": "#6FA8DC", "id": "Ioannis Gkiousleas", "label": "Ioannis Gkiousleas", "shape": "dot", "size": 10.089285714285714, "title": "Ioannis Gkiousleas"}, {"color": "#6FA8DC", "id": "Todd Zickler", "label": "Todd Zickler", "shape": "dot", "size": 10.178571428571429, "title": "Todd Zickler"}, {"color": "#6FA8DC", "id": "Kavita Bala", "label": "Kavita Bala", "shape": "dot", "size": 10.535714285714286, "title": "Kavita Bala"}, {"color": "#6FA8DC", "id": "Naeemullah Khan", "label": "Naeemullah Khan", "shape": "dot", "size": 10.089285714285714, "title": "Naeemullah Khan"}, {"color": "#6FA8DC", "id": "Shape-Tailored Local Descriptors", "label": "Shape-Tailored Local Descriptors", "shape": "dot", "size": 10.535714285714286, "title": "Shape-Tailored Local Descriptors"}, {"color": "#6FA8DC", "id": "Marei Algarni", "label": "Marei Algarni", "shape": "dot", "size": 10.178571428571429, "title": "Marei Algarni"}, {"color": "#6FA8DC", "id": "Anthony Yezzi", "label": "Anthony Yezzi", "shape": "dot", "size": 10.178571428571429, "title": "Anthony Yezzi"}, {"color": "#6FA8DC", "id": "Shape-Tailed Local Descriptors", "label": "Shape-Tailed Local Descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Shape-Tailed Local Descriptors"}, {"color": "#6FA8DC", "id": "Ganesh Sundaramoorthi", "label": "Ganesh Sundaramoorthi", "shape": "dot", "size": 10.178571428571429, "title": "Ganesh Sundaramoorthi"}, {"color": "#6FA8DC", "id": "Segmentation", "label": "Segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Segmentation"}, {"color": "#6FA8DC", "id": "Tracking", "label": "Tracking", "shape": "dot", "size": 10.089285714285714, "title": "Tracking"}, {"color": "#6FA8DC", "id": "descriptors", "label": "descriptors", "shape": "dot", "size": 10.714285714285714, "title": "descriptors"}, {"color": "#6FA8DC", "id": "dense descriptors", "label": "dense descriptors", "shape": "dot", "size": 10.089285714285714, "title": "dense descriptors"}, {"color": "#6FA8DC", "id": "texture segmentation", "label": "texture segmentation", "shape": "dot", "size": 10.535714285714286, "title": "texture segmentation"}, {"color": "#6FA8DC", "id": "shape-dependent scale spaces", "label": "shape-dependent scale spaces", "shape": "dot", "size": 10.089285714285714, "title": "shape-dependent scale spaces"}, {"color": "#6FA8DC", "id": "aggregate image data across boundary", "label": "aggregate image data across boundary", "shape": "dot", "size": 10.089285714285714, "title": "aggregate image data across boundary"}, {"color": "#6FA8DC", "id": "Mumford-Shah energy", "label": "Mumford-Shah energy", "shape": "dot", "size": 10.089285714285714, "title": "Mumford-Shah energy"}, {"color": "#6FA8DC", "id": "datasets", "label": "datasets", "shape": "dot", "size": 10.625, "title": "datasets"}, {"color": "#6FA8DC", "id": "accurate segmentation", "label": "accurate segmentation", "shape": "dot", "size": 10.178571428571429, "title": "accurate segmentation"}, {"color": "#6FA8DC", "id": "shape-dependent", "label": "shape-dependent", "shape": "dot", "size": 10.089285714285714, "title": "shape-dependent"}, {"color": "#6FA8DC", "id": "oriented gradients", "label": "oriented gradients", "shape": "dot", "size": 10.089285714285714, "title": "oriented gradients"}, {"color": "#6FA8DC", "id": "state-of-the-art", "label": "state-of-the-art", "shape": "dot", "size": 10.357142857142858, "title": "state-of-the-art"}, {"color": "#6FA8DC", "id": "non-shape dependent", "label": "non-shape dependent", "shape": "dot", "size": 10.089285714285714, "title": "non-shape dependent"}, {"color": "#6FA8DC", "id": "more accurate segmentation", "label": "more accurate segmentation", "shape": "dot", "size": 10.089285714285714, "title": "more accurate segmentation"}, {"color": "#6FA8DC", "id": "textured object tracking", "label": "textured object tracking", "shape": "dot", "size": 10.089285714285714, "title": "textured object tracking"}, {"color": "#6FA8DC", "id": "Shape-Tailored Descriptors (STLD)", "label": "Shape-Tailored Descriptors (STLD)", "shape": "dot", "size": 10.089285714285714, "title": "Shape-Tailored Descriptors (STLD)"}, {"color": "#6FA8DC", "id": "Shape-Tailori Descriptors (STLD)", "label": "Shape-Tailori Descriptors (STLD)", "shape": "dot", "size": 10.089285714285714, "title": "Shape-Tailori Descriptors (STLD)"}, {"color": "#6FA8DC", "id": "non-shape dependent descriptors", "label": "non-shape dependent descriptors", "shape": "dot", "size": 10.089285714285714, "title": "non-shape dependent descriptors"}, {"color": "#6FA8DC", "id": "Local Descriptors", "label": "Local Descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Local Descriptors"}, {"color": "#6FA8DC", "id": "King Abdullah University of Science \u0026 Technology (KAUST)", "label": "King Abdullah University of Science \u0026 Technology (KAUST)", "shape": "dot", "size": 10.178571428571429, "title": "King Abdullah University of Science \u0026 Technology (KAUST)"}, {"color": "#6FA8DC", "id": "Georgia Institute of Technology", "label": "Georgia Institute of Technology", "shape": "dot", "size": 10.267857142857142, "title": "Georgia Institute of Technology"}, {"color": "#6FA8DC", "id": "De-An Huang", "label": "De-An Huang", "shape": "dot", "size": 10.267857142857142, "title": "De-An Huang"}, {"color": "#6FA8DC", "id": "How Do We Use Our Hands?", "label": "How Do We Use Our Hands?", "shape": "dot", "size": 10.446428571428571, "title": "How Do We Use Our Hands?"}, {"color": "#6FA8DC", "id": "common grasps", "label": "common grasps", "shape": "dot", "size": 10.089285714285714, "title": "common grasps"}, {"color": "#6FA8DC", "id": "Partial Differential Equations (PDE)", "label": "Partial Differential Equations (PDE)", "shape": "dot", "size": 10.089285714285714, "title": "Partial Differential Equations (PDE)"}, {"color": "#6FA8DC", "id": "Minghuang Ma", "label": "Minghuang Ma", "shape": "dot", "size": 10.535714285714286, "title": "Minghuang Ma"}, {"color": "#6FA8DC", "id": "How DoWe Use Our Hands?", "label": "How DoWe Use Our Hands?", "shape": "dot", "size": 10.089285714285714, "title": "How DoWe Use Our Hands?"}, {"color": "#6FA8DC", "id": "Wei-Chiu Ma", "label": "Wei-Chiu Ma", "shape": "dot", "size": 10.535714285714286, "title": "Wei-Chiu Ma"}, {"color": "#6FA8DC", "id": "Kris M. Kitani", "label": "Kris M. Kitani", "shape": "dot", "size": 10.357142857142858, "title": "Kris M. Kitani"}, {"color": "#6FA8DC", "id": "KAUST", "label": "KAUST", "shape": "dot", "size": 10.178571428571429, "title": "KAUST"}, {"color": "#6FA8DC", "id": "Saudi Arabia", "label": "Saudi Arabia", "shape": "dot", "size": 10.089285714285714, "title": "Saudi Arabia"}, {"color": "#6FA8DC", "id": "ganesh.sundaramoorthi@kust.edu.sa", "label": "ganesh.sundaramoorthi@kust.edu.sa", "shape": "dot", "size": 10.089285714285714, "title": "ganesh.sundaramoorthi@kust.edu.sa"}, {"color": "#6FA8DC", "id": "Huang_How_Do_We2015_CVPR_paper.pdf", "label": "Huang_How_Do_We2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Huang_How_Do_We2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Common Grasps", "label": "Common Grasps", "shape": "dot", "size": 10.267857142857142, "title": "Common Grasps"}, {"color": "#6FA8DC", "id": "Common Graspt", "label": "Common Graspt", "shape": "dot", "size": 10.089285714285714, "title": "Common Graspt"}, {"color": "#6FA8DC", "id": "computer vision techniques", "label": "computer vision techniques", "shape": "dot", "size": 10.089285714285714, "title": "computer vision techniques"}, {"color": "#6FA8DC", "id": "advance prehensile analysis", "label": "advance prehensile analysis", "shape": "dot", "size": 10.089285714285714, "title": "advance prehensile analysis"}, {"color": "#6FA8DC", "id": "prehensile analysis", "label": "prehensile analysis", "shape": "dot", "size": 10.089285714285714, "title": "prehensile analysis"}, {"color": "#6FA8DC", "id": "multi-disciplinary field", "label": "multi-disciplinary field", "shape": "dot", "size": 10.089285714285714, "title": "multi-disciplinary field"}, {"color": "#6FA8DC", "id": "researchers", "label": "researchers", "shape": "dot", "size": 10.089285714285714, "title": "researchers"}, {"color": "#6FA8DC", "id": "hand-object interaction videos", "label": "hand-object interaction videos", "shape": "dot", "size": 10.089285714285714, "title": "hand-object interaction videos"}, {"color": "#6FA8DC", "id": "wearable cameras", "label": "wearable cameras", "shape": "dot", "size": 10.267857142857142, "title": "wearable cameras"}, {"color": "#6FA8DC", "id": "automatically discover common modes of human hand use", "label": "automatically discover common modes of human hand use", "shape": "dot", "size": 10.178571428571429, "title": "automatically discover common modes of human hand use"}, {"color": "#6FA8DC", "id": "unsupervised clustering techniques", "label": "unsupervised clustering techniques", "shape": "dot", "size": 10.089285714285714, "title": "unsupervised clustering techniques"}, {"color": "#6FA8DC", "id": "first-person point-of-view camera", "label": "first-person point-of-view camera", "shape": "dot", "size": 10.089285714285714, "title": "first-person point-of-view camera"}, {"color": "#6FA8DC", "id": "observing human hand use", "label": "observing human hand use", "shape": "dot", "size": 10.089285714285714, "title": "observing human hand use"}, {"color": "#6FA8DC", "id": "common modes of human hand use", "label": "common modes of human hand use", "shape": "dot", "size": 10.089285714285714, "title": "common modes of human hand use"}, {"color": "#6FA8DC", "id": "first-person point-of-view videos", "label": "first-person point-of-view videos", "shape": "dot", "size": 10.178571428571429, "title": "first-person point-of-view videos"}, {"color": "#6FA8DC", "id": "choreographed scenarios", "label": "choreographed scenarios", "shape": "dot", "size": 10.089285714285714, "title": "choreographed scenarios"}, {"color": "#6FA8DC", "id": "Cutkosky grasp taxonomy", "label": "Cutkosky grasp taxonomy", "shape": "dot", "size": 10.089285714285714, "title": "Cutkosky grasp taxonomy"}, {"color": "#6FA8DC", "id": "Grasp Taxonomy", "label": "Grasp Taxonomy", "shape": "dot", "size": 10.089285714285714, "title": "Grasp Taxonomy"}, {"color": "#6FA8DC", "id": "hand-object interaction", "label": "hand-object interaction", "shape": "dot", "size": 10.089285714285714, "title": "hand-object interaction"}, {"color": "#6FA8DC", "id": "Hand-Object Interaction", "label": "Hand-Object Interaction", "shape": "dot", "size": 10.089285714285714, "title": "Hand-Object Interaction"}, {"color": "#6FA8DC", "id": "Determinantal Point Process (DPP)", "label": "Determinantal Point Process (DPP)", "shape": "dot", "size": 10.089285714285714, "title": "Determinantal Point Process (DPP)"}, {"color": "#6FA8DC", "id": "N. Ailon", "label": "N. Ailon", "shape": "dot", "size": 10.089285714285714, "title": "N. Ailon"}, {"color": "#6FA8DC", "id": "Streaming k-means approximation", "label": "Streaming k-means approximation", "shape": "dot", "size": 10.089285714285714, "title": "Streaming k-means approximation"}, {"color": "#6FA8DC", "id": "W. Barbakh", "label": "W. Barbakh", "shape": "dot", "size": 10.089285714285714, "title": "W. Barbakh"}, {"color": "#6FA8DC", "id": "Online clustering algorithms", "label": "Online clustering algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Online clustering algorithms"}, {"color": "#6FA8DC", "id": "A. Fathi", "label": "A. Fathi", "shape": "dot", "size": 10.089285714285714, "title": "A. Fathi"}, {"color": "#6FA8DC", "id": "Social interactions: A first-person perspective", "label": "Social interactions: A first-person perspective", "shape": "dot", "size": 10.089285714285714, "title": "Social interactions: A first-person perspective"}, {"color": "#6FA8DC", "id": "R. Filipovych", "label": "R. Filipovych", "shape": "dot", "size": 10.089285714285714, "title": "R. Filipovych"}, {"color": "#6FA8DC", "id": "Recognizing primitive interactions", "label": "Recognizing primitive interactions", "shape": "dot", "size": 10.089285714285714, "title": "Recognizing primitive interactions"}, {"color": "#6FA8DC", "id": "J. Case-Smith", "label": "J. Case-Smith", "shape": "dot", "size": 10.089285714285714, "title": "J. Case-Smith"}, {"color": "#6FA8DC", "id": "Development of hand skills in children", "label": "Development of hand skills in children", "shape": "dot", "size": 10.267857142857142, "title": "Development of hand skills in children"}, {"color": "#6FA8DC", "id": "L. Cheng", "label": "L. Cheng", "shape": "dot", "size": 10.089285714285714, "title": "L. Cheng"}, {"color": "#6FA8DC", "id": "Pixel-level hand detection in ego-centric videos", "label": "Pixel-level hand detection in ego-centric videos", "shape": "dot", "size": 10.089285714285714, "title": "Pixel-level hand detection in ego-centric videos"}, {"color": "#6FA8DC", "id": "American Occupational Therapy Association", "label": "American Occupational Therapy Association", "shape": "dot", "size": 10.089285714285714, "title": "American Occupational Therapy Association"}, {"color": "#6FA8DC", "id": "M. Cutkosky", "label": "M. Cutkosky", "shape": "dot", "size": 10.089285714285714, "title": "M. Cutkosky"}, {"color": "#6FA8DC", "id": "On grasp choice, grasp models", "label": "On grasp choice, grasp models", "shape": "dot", "size": 10.089285714285714, "title": "On grasp choice, grasp models"}, {"color": "#6FA8DC", "id": "H. N. Djidjev", "label": "H. N. Djidjev", "shape": "dot", "size": 10.089285714285714, "title": "H. N. Djidjev"}, {"color": "#6FA8DC", "id": "Computing shortest paths", "label": "Computing shortest paths", "shape": "dot", "size": 10.089285714285714, "title": "Computing shortest paths"}, {"color": "#6FA8DC", "id": "C. Desai", "label": "C. Desai", "shape": "dot", "size": 10.089285714285714, "title": "C. Desai"}, {"color": "#6FA8DC", "id": "Discriminaitive models for static human-object interactions", "label": "Discriminaitive models for static human-object interactions", "shape": "dot", "size": 10.089285714285714, "title": "Discriminaitive models for static human-object interactions"}, {"color": "#6FA8DC", "id": "Cnegie Mellon University", "label": "Cnegie Mellon University", "shape": "dot", "size": 10.357142857142858, "title": "Cnegie Mellon University"}, {"color": "#6FA8DC", "id": "Kris M. Kitan", "label": "Kris M. Kitan", "shape": "dot", "size": 10.089285714285714, "title": "Kris M. Kitan"}, {"color": "#6FA8DC", "id": "hand skills", "label": "hand skills", "shape": "dot", "size": 10.089285714285714, "title": "hand skills"}, {"color": "#6FA8DC", "id": "Canezie Mellon University", "label": "Canezie Mellon University", "shape": "dot", "size": 10.803571428571429, "title": "Canezie Mellon University"}, {"color": "#6FA8DC", "id": "deanh@andrew.cmu.edu", "label": "deanh@andrew.cmu.edu", "shape": "dot", "size": 10.178571428571429, "title": "deanh@andrew.cmu.edu"}, {"color": "#6FA8DC", "id": "minghuam@andrew.cmu.edu", "label": "minghuam@andrew.cmu.edu", "shape": "dot", "size": 10.089285714285714, "title": "minghuam@andrew.cmu.edu"}, {"color": "#6FA8DC", "id": "weichium@andrew.cmu.edu", "label": "weichium@andrew.cmu.edu", "shape": "dot", "size": 10.089285714285714, "title": "weichium@andrew.cmu.edu"}, {"color": "#6FA8DC", "id": "Edward Johns", "label": "Edward Johns", "shape": "dot", "size": 10.089285714285714, "title": "Edward Johns"}, {"color": "#6FA8DC", "id": "Becoming the Expert", "label": "Becoming the Expert", "shape": "dot", "size": 10.446428571428571, "title": "Becoming the Expert"}, {"color": "#6FA8DC", "id": "Oisin Mac Aodha", "label": "Oisin Mac Aodha", "shape": "dot", "size": 10.089285714285714, "title": "Oisin Mac Aodha"}, {"color": "#6FA8DC", "id": "Becoming the Efficient", "label": "Becoming the Efficient", "shape": "dot", "size": 10.089285714285714, "title": "Becoming the Efficient"}, {"color": "#6FA8DC", "id": "Gabriel J. Brostow", "label": "Gabriel J. Brostow", "shape": "dot", "size": 10.089285714285714, "title": "Gabriel J. Brostow"}, {"color": "#6FA8DC", "id": "Machine Teaching", "label": "Machine Teaching", "shape": "dot", "size": 10.089285714285714, "title": "Machine Teaching"}, {"color": "#6FA8DC", "id": "Johns_Becoming_the_Expert_2015_CVPR_paper.pdf", "label": "Johns_Becoming_the_Expert_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Johns_Becoming_the_Expert_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Interactive Machine Teaching algorithm", "label": "Interactive Machine Teaching algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Interactive Machine Teaching algorithm"}, {"color": "#6FA8DC", "id": "computer", "label": "computer", "shape": "dot", "size": 10.178571428571429, "title": "computer"}, {"color": "#6FA8DC", "id": "challenging visual concepts", "label": "challenging visual concepts", "shape": "dot", "size": 10.089285714285714, "title": "challenging visual concepts"}, {"color": "#6FA8DC", "id": "labeled images", "label": "labeled images", "shape": "dot", "size": 10.089285714285714, "title": "labeled images"}, {"color": "#6FA8DC", "id": "teaching strategy", "label": "teaching strategy", "shape": "dot", "size": 10.089285714285714, "title": "teaching strategy"}, {"color": "#6FA8DC", "id": "experts", "label": "experts", "shape": "dot", "size": 10.089285714285714, "title": "experts"}, {"color": "#6FA8DC", "id": "challenge", "label": "challenge", "shape": "dot", "size": 10.714285714285714, "title": "challenge"}, {"color": "#6FA8DC", "id": "annotators", "label": "annotators", "shape": "dot", "size": 10.178571428571429, "title": "annotators"}, {"color": "#6FA8DC", "id": "expertise", "label": "expertise", "shape": "dot", "size": 10.089285714285714, "title": "expertise"}, {"color": "#6FA8DC", "id": "Adaptive Algorithms", "label": "Adaptive Algorithms", "shape": "dot", "size": 10.178571428571429, "title": "Adaptive Algorithms"}, {"color": "#6FA8DC", "id": "Interactive Machine Teaching", "label": "Interactive Machine Teaching", "shape": "dot", "size": 10.267857142857142, "title": "Interactive Machine Teaching"}, {"color": "#6FA8DC", "id": "Human Learning", "label": "Human Learning", "shape": "dot", "size": 10.089285714285714, "title": "Human Learning"}, {"color": "#6FA8DC", "id": "Visual Classification", "label": "Visual Classification", "shape": "dot", "size": 10.089285714285714, "title": "Visual Classification"}, {"color": "#6FA8DC", "id": "Bruner", "label": "Bruner", "shape": "dot", "size": 10.089285714285714, "title": "Bruner"}, {"color": "#6FA8DC", "id": "The Process of Education", "label": "The Process of Education", "shape": "dot", "size": 10.178571428571429, "title": "The Process of Education"}, {"color": "#6FA8DC", "id": "foundational concepts", "label": "foundational concepts", "shape": "dot", "size": 10.178571428571429, "title": "foundational concepts"}, {"color": "#6FA8DC", "id": "teaching and learning", "label": "teaching and learning", "shape": "dot", "size": 10.089285714285714, "title": "teaching and learning"}, {"color": "#6FA8DC", "id": "Curriculum learning", "label": "Curriculum learning", "shape": "dot", "size": 10.089285714285714, "title": "Curriculum learning"}, {"color": "#6FA8DC", "id": "teaching strategies", "label": "teaching strategies", "shape": "dot", "size": 10.178571428571429, "title": "teaching strategies"}, {"color": "#6FA8DC", "id": "Love", "label": "Love", "shape": "dot", "size": 10.089285714285714, "title": "Love"}, {"color": "#6FA8DC", "id": "Categorization", "label": "Categorization", "shape": "dot", "size": 10.357142857142858, "title": "Categorization"}, {"color": "#6FA8DC", "id": "cognitive neuroscience", "label": "cognitive neuroscience", "shape": "dot", "size": 10.178571428571429, "title": "cognitive neuroscience"}, {"color": "#6FA8DC", "id": "core tasks", "label": "core tasks", "shape": "dot", "size": 10.089285714285714, "title": "core tasks"}, {"color": "#6FA8DC", "id": "active learning", "label": "active learning", "shape": "dot", "size": 10.267857142857142, "title": "active learning"}, {"color": "#6FA8DC", "id": "Machine teaching", "label": "Machine teaching", "shape": "dot", "size": 10.178571428571429, "title": "Machine teaching"}, {"color": "#6FA8DC", "id": "education", "label": "education", "shape": "dot", "size": 10.089285714285714, "title": "education"}, {"color": "#6FA8DC", "id": "overview", "label": "overview", "shape": "dot", "size": 10.357142857142858, "title": "overview"}, {"color": "#6FA8DC", "id": "technique", "label": "technique", "shape": "dot", "size": 11.160714285714286, "title": "technique"}, {"color": "#6FA8DC", "id": "sampling estimation", "label": "sampling estimation", "shape": "dot", "size": 10.089285714285714, "title": "sampling estimation"}, {"color": "#6FA8DC", "id": "error", "label": "error", "shape": "dot", "size": 10.089285714285714, "title": "error"}, {"color": "#6FA8DC", "id": "machine teaching", "label": "machine teaching", "shape": "dot", "size": 10.178571428571429, "title": "machine teaching"}, {"color": "#6FA8DC", "id": "approach toward optimal education", "label": "approach toward optimal education", "shape": "dot", "size": 10.178571428571429, "title": "approach toward optimal education"}, {"color": "#6FA8DC", "id": "paper\u0027s design", "label": "paper\u0027s design", "shape": "dot", "size": 10.089285714285714, "title": "paper\u0027s design"}, {"color": "#6FA8DC", "id": "learners with limited cognitive capacity", "label": "learners with limited cognitive capacity", "shape": "dot", "size": 10.089285714285714, "title": "learners with limited cognitive capacity"}, {"color": "#6FA8DC", "id": "algorithmic teaching", "label": "algorithmic teaching", "shape": "dot", "size": 10.089285714285714, "title": "algorithmic teaching"}, {"color": "#6FA8DC", "id": "background", "label": "background", "shape": "dot", "size": 10.089285714285714, "title": "background"}, {"color": "#6FA8DC", "id": "Love \u0026 Patil", "label": "Love \u0026 Patil", "shape": "dot", "size": 10.089285714285714, "title": "Love \u0026 Patil"}, {"color": "#6FA8DC", "id": "teaching learners", "label": "teaching learners", "shape": "dot", "size": 10.089285714285714, "title": "teaching learners"}, {"color": "#6FA8DC", "id": "Balbach \u0026 Zeugmann", "label": "Balbach \u0026 Zeugmann", "shape": "dot", "size": 10.089285714285714, "title": "Balbach \u0026 Zeugmann"}, {"color": "#6FA8DC", "id": "algorithmic teaching methods", "label": "algorithmic teaching methods", "shape": "dot", "size": 10.178571428571429, "title": "algorithmic teaching methods"}, {"color": "#6FA8DC", "id": "Basu \u0026 Christensen", "label": "Basu \u0026 Christensen", "shape": "dot", "size": 10.178571428571429, "title": "Basu \u0026 Christensen"}, {"color": "#6FA8DC", "id": "teaching classification boundaries", "label": "teaching classification boundaries", "shape": "dot", "size": 10.089285714285714, "title": "teaching classification boundaries"}, {"color": "#6FA8DC", "id": "Optimal teaching for limited-capacity human learners", "label": "Optimal teaching for limited-capacity human learners", "shape": "dot", "size": 10.089285714285714, "title": "Optimal teaching for limited-capacity human learners"}, {"color": "#6FA8DC", "id": "Language and Automata Theory and Applications", "label": "Language and Automata Theory and Applications", "shape": "dot", "size": 10.089285714285714, "title": "Language and Automata Theory and Applications"}, {"color": "#6FA8DC", "id": "Recent developments in algorithmic teaching", "label": "Recent developments in algorithmic teaching", "shape": "dot", "size": 10.089285714285714, "title": "Recent developments in algorithmic teaching"}, {"color": "#6FA8DC", "id": "teaching classification tasks", "label": "teaching classification tasks", "shape": "dot", "size": 10.178571428571429, "title": "teaching classification tasks"}, {"color": "#6FA8DC", "id": "Gigu`ere \u0026 Love", "label": "Gigu`ere \u0026 Love", "shape": "dot", "size": 10.089285714285714, "title": "Gigu`ere \u0026 Love"}, {"color": "#6FA8DC", "id": "cognitive limitations", "label": "cognitive limitations", "shape": "dot", "size": 10.178571428571429, "title": "cognitive limitations"}, {"color": "#6FA8DC", "id": "Chin", "label": "Chin", "shape": "dot", "size": 10.089285714285714, "title": "Chin"}, {"color": "#6FA8DC", "id": "University College London", "label": "University College London", "shape": "dot", "size": 10.267857142857142, "title": "University College London"}, {"color": "#6FA8DC", "id": "Eriksson", "label": "Eriksson", "shape": "dot", "size": 10.089285714285714, "title": "Eriksson"}, {"color": "#6FA8DC", "id": "Suter", "label": "Suter", "shape": "dot", "size": 10.089285714285714, "title": "Suter"}, {"color": "#6FA8DC", "id": "Chin_Efficient_Globally_Optimal_2015_CVPR_paper.pdf", "label": "Chin_Efficient_Globally_Optimal_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.178571428571429, "title": "Chin_Efficient_Globally_Optimal_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Efficient Globally Optimal Consensus Maximisation", "label": "Efficient Globally Optimal Consensus Maximisation", "shape": "dot", "size": 10.089285714285714, "title": "Efficient Globally Optimal Consensus Maximisation"}, {"color": "#6FA8DC", "id": "Maximum Consensus", "label": "Maximum Consensus", "shape": "dot", "size": 10.178571428571429, "title": "Maximum Consensus"}, {"color": "#6FA8DC", "id": "Robust Estimation", "label": "Robust Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Robust Estimation"}, {"color": "#6FA8DC", "id": "randomized sample-and-test techniques", "label": "randomized sample-and-test techniques", "shape": "dot", "size": 10.089285714285714, "title": "randomized sample-and-test techniques"}, {"color": "#6FA8DC", "id": "optimality", "label": "optimality", "shape": "dot", "size": 10.089285714285714, "title": "optimality"}, {"color": "#6FA8DC", "id": "globally optimal algorithms", "label": "globally optimal algorithms", "shape": "dot", "size": 10.089285714285714, "title": "globally optimal algorithms"}, {"color": "#6FA8DC", "id": "randomized methods", "label": "randomized methods", "shape": "dot", "size": 10.089285714285714, "title": "randomized methods"}, {"color": "#6FA8DC", "id": "global maximization of consensus", "label": "global maximization of consensus", "shape": "dot", "size": 10.089285714285714, "title": "global maximization of consensus"}, {"color": "#6FA8DC", "id": "tree search problem", "label": "tree search problem", "shape": "dot", "size": 10.178571428571429, "title": "tree search problem"}, {"color": "#6FA8DC", "id": "LP-type methods", "label": "LP-type methods", "shape": "dot", "size": 10.089285714285714, "title": "LP-type methods"}, {"color": "#6FA8DC", "id": "A* search", "label": "A* search", "shape": "dot", "size": 10.089285714285714, "title": "A* search"}, {"color": "#6FA8DC", "id": "orders of magnitude faster performance", "label": "orders of magnitude faster performance", "shape": "dot", "size": 10.089285714285714, "title": "orders of magnitude faster performance"}, {"color": "#6FA8DC", "id": "previous exact methods", "label": "previous exact methods", "shape": "dot", "size": 10.089285714285714, "title": "previous exact methods"}, {"color": "#6FA8DC", "id": "Optimization Problems", "label": "Optimization Problems", "shape": "dot", "size": 10.178571428571429, "title": "Optimization Problems"}, {"color": "#6FA8DC", "id": "A* Search", "label": "A* Search", "shape": "dot", "size": 10.178571428571429, "title": "A* Search"}, {"color": "#6FA8DC", "id": "Search Algorithm", "label": "Search Algorithm", "shape": "dot", "size": 10.178571428571429, "title": "Search Algorithm"}, {"color": "#6FA8DC", "id": "Tree Search", "label": "Tree Search", "shape": "dot", "size": 10.089285714285714, "title": "Tree Search"}, {"color": "#6FA8DC", "id": "LP-type Methods", "label": "LP-type Methods", "shape": "dot", "size": 10.089285714285714, "title": "LP-type Methods"}, {"color": "#6FA8DC", "id": "N. Amenta", "label": "N. Amenta", "shape": "dot", "size": 10.089285714285714, "title": "N. Amenta"}, {"color": "#6FA8DC", "id": "Optimal Point Placement for Mesh Smoothing", "label": "Optimal Point Placement for Mesh Smoothing", "shape": "dot", "size": 10.267857142857142, "title": "Optimal Point Placement for Mesh Smoothing"}, {"color": "#6FA8DC", "id": "M. Bern", "label": "M. Bern", "shape": "dot", "size": 10.089285714285714, "title": "M. Bern"}, {"color": "#6FA8DC", "id": "D. Eppstein", "label": "D. Eppstein", "shape": "dot", "size": 10.089285714285714, "title": "D. Eppstein"}, {"color": "#6FA8DC", "id": "B. Chazelle", "label": "B. Chazelle", "shape": "dot", "size": 10.089285714285714, "title": "B. Chazelle"}, {"color": "#6FA8DC", "id": "On Linear-Time Deterministic Algorithms", "label": "On Linear-Time Deterministic Algorithms", "shape": "dot", "size": 10.178571428571429, "title": "On Linear-Time Deterministic Algorithms"}, {"color": "#6FA8DC", "id": "J. Matou\u02c7sek", "label": "J. Matou\u02c7sek", "shape": "dot", "size": 10.089285714285714, "title": "J. Matou\u02c7sek"}, {"color": "#6FA8DC", "id": "Quasiconvex Programming", "label": "Quasiconvex Programming", "shape": "dot", "size": 10.089285714285714, "title": "Quasiconvex Programming"}, {"color": "#6FA8DC", "id": "Optimization Technique", "label": "Optimization Technique", "shape": "dot", "size": 10.089285714285714, "title": "Optimization Technique"}, {"color": "#6FA8DC", "id": "globally optimal results", "label": "globally optimal results", "shape": "dot", "size": 10.089285714285714, "title": "globally optimal results"}, {"color": "#6FA8DC", "id": "optimization algorithms", "label": "optimization algorithms", "shape": "dot", "size": 10.178571428571429, "title": "optimization algorithms"}, {"color": "#6FA8DC", "id": "core theme", "label": "core theme", "shape": "dot", "size": 10.089285714285714, "title": "core theme"}, {"color": "#6FA8DC", "id": "RANSA algorithm", "label": "RANSA algorithm", "shape": "dot", "size": 10.267857142857142, "title": "RANSA algorithm"}, {"color": "#6FA8DC", "id": "outlier rejection", "label": "outlier rejection", "shape": "dot", "size": 10.089285714285714, "title": "outlier rejection"}, {"color": "#6FA8DC", "id": "multiple view geometry", "label": "multiple view geometry", "shape": "dot", "size": 10.178571428571429, "title": "multiple view geometry"}, {"color": "#6FA8DC", "id": "central topic", "label": "central topic", "shape": "dot", "size": 10.089285714285714, "title": "central topic"}, {"color": "#6FA8DC", "id": "l\u221e triangulation", "label": "l\u221e triangulation", "shape": "dot", "size": 10.089285714285714, "title": "l\u221e triangulation"}, {"color": "#6FA8DC", "id": "outlier handling", "label": "outlier handling", "shape": "dot", "size": 10.089285714285714, "title": "outlier handling"}, {"color": "#6FA8DC", "id": "automated cartography", "label": "automated cartography", "shape": "dot", "size": 10.178571428571429, "title": "automated cartography"}, {"color": "#6FA8DC", "id": "H. Li", "label": "H. Li", "shape": "dot", "size": 10.089285714285714, "title": "H. Li"}, {"color": "#6FA8DC", "id": "algorithm for l\u221e triangulation", "label": "algorithm for l\u221e triangulation", "shape": "dot", "size": 10.178571428571429, "title": "algorithm for l\u221e triangulation"}, {"color": "#6FA8DC", "id": "geometric optimization", "label": "geometric optimization", "shape": "dot", "size": 10.089285714285714, "title": "geometric optimization"}, {"color": "#6FA8DC", "id": "constraints", "label": "constraints", "shape": "dot", "size": 10.178571428571429, "title": "constraints"}, {"color": "#6FA8DC", "id": "C. Olsson, O. Enqvist, and F. Kahl", "label": "C. Olsson, O. Enqvist, and F. Kahl", "shape": "dot", "size": 10.089285714285714, "title": "C. Olsson, O. Enqvist, and F. Kahl"}, {"color": "#6FA8DC", "id": "outlier handling in matching", "label": "outlier handling in matching", "shape": "dot", "size": 10.089285714285714, "title": "outlier handling in matching"}, {"color": "#6FA8DC", "id": "matching", "label": "matching", "shape": "dot", "size": 10.089285714285714, "title": "matching"}, {"color": "#6FA8DC", "id": "registration", "label": "registration", "shape": "dot", "size": 10.089285714285714, "title": "registration"}, {"color": "#6FA8DC", "id": "C. Olsson, A. Eriksson, and F. Kahl", "label": "C. Olsson, A. Eriksson, and F. Kahl", "shape": "dot", "size": 10.089285714285714, "title": "C. Olsson, A. Eriksson, and F. Kahl"}, {"color": "#6FA8DC", "id": "optimization techniques", "label": "optimization techniques", "shape": "dot", "size": 10.535714285714286, "title": "optimization techniques"}, {"color": "#6FA8DC", "id": "l\u221e-norm problems", "label": "l\u221e-norm problems", "shape": "dot", "size": 10.089285714285714, "title": "l\u221e-norm problems"}, {"color": "#6FA8DC", "id": "Tat-Jun Chin", "label": "Tat-Jun Chin", "shape": "dot", "size": 10.178571428571429, "title": "Tat-Jun Chin"}, {"color": "#6FA8DC", "id": "University of Adelaide", "label": "University of Adelaide", "shape": "dot", "size": 10.982142857142858, "title": "University of Adelaide"}, {"color": "#6FA8DC", "id": "Anders Eriksson", "label": "Anders Eriksson", "shape": "dot", "size": 10.178571428571429, "title": "Anders Eriksson"}, {"color": "#6FA8DC", "id": "School of Computer Science, The University of Adelaide", "label": "School of Computer Science, The University of Adelaide", "shape": "dot", "size": 10.178571428571429, "title": "School of Computer Science, The University of Adelaide"}, {"color": "#6FA8DC", "id": "Pulak Purkait", "label": "Pulak Purkait", "shape": "dot", "size": 10.089285714285714, "title": "Pulak Purkait"}, {"color": "#6FA8DC", "id": "School of Electrical Engineering and Computer Science, Queensland University of Technology", "label": "School of Electrical Engineering and Computer Science, Queensland University of Technology", "shape": "dot", "size": 10.089285714285714, "title": "School of Electrical Engineering and Computer Science, Queensland University of Technology"}, {"color": "#6FA8DC", "id": "Julian Straub", "label": "Julian Straub", "shape": "dot", "size": 10.267857142857142, "title": "Julian Straub"}, {"color": "#6FA8DC", "id": "Small-Variance Nonparametric Clustering on the Hypsphere", "label": "Small-Variance Nonparametric Clustering on the Hypsphere", "shape": "dot", "size": 10.446428571428571, "title": "Small-Variance Nonparametric Clustering on the Hypsphere"}, {"color": "#6FA8DC", "id": "Trevor Campbell", "label": "Trevor Campbell", "shape": "dot", "size": 10.267857142857142, "title": "Trevor Campbell"}, {"color": "#6FA8DC", "id": "Jonathan P. How", "label": "Jonathan P. How", "shape": "dot", "size": 10.267857142857142, "title": "Jonathan P. How"}, {"color": "#6FA8DC", "id": "John W. Fisher III", "label": "John W. Fisher III", "shape": "dot", "size": 10.357142857142858, "title": "John W. Fisher III"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf", "label": "Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Small-Variance Nonparametric Clustering on the Hypshere", "label": "Small-Variance Nonparametric Clustering on the Hypshere", "shape": "dot", "size": 10.089285714285714, "title": "Small-Variance Nonparametric Clustering on the Hypshere"}, {"color": "#6FA8DC", "id": "surface normals", "label": "surface normals", "shape": "dot", "size": 10.089285714285714, "title": "surface normals"}, {"color": "#6FA8DC", "id": "distribution of structural regularities", "label": "distribution of structural regularities", "shape": "dot", "size": 10.089285714285714, "title": "distribution of structural regularities"}, {"color": "#6FA8DC", "id": "algorithms", "label": "algorithms", "shape": "dot", "size": 10.625, "title": "algorithms"}, {"color": "#6FA8DC", "id": "Bayesian nonparametric von-Mises-Fisher (vMF) mixture distributions", "label": "Bayesian nonparametric von-Mises-Fisher (vMF) mixture distributions", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian nonparametric von-Mises-Fisher (vMF) mixture distributions"}, {"color": "#6FA8DC", "id": "DDP-vMF-means", "label": "DDP-vMF-means", "shape": "dot", "size": 10.178571428571429, "title": "DDP-vMF-means"}, {"color": "#6FA8DC", "id": "temporally evolving cluster structure", "label": "temporally evolving cluster structure", "shape": "dot", "size": 10.089285714285714, "title": "temporally evolving cluster structure"}, {"color": "#6FA8DC", "id": "geometry of directional data", "label": "geometry of directional data", "shape": "dot", "size": 10.089285714285714, "title": "geometry of directional data"}, {"color": "#6FA8DC", "id": "directional data", "label": "directional data", "shape": "dot", "size": 10.089285714285714, "title": "directional data"}, {"color": "#6FA8DC", "id": "unit sphere", "label": "unit sphere", "shape": "dot", "size": 10.089285714285714, "title": "unit sphere"}, {"color": "#6FA8DC", "id": "DP-vMF-means", "label": "DP-vMF-means", "shape": "dot", "size": 10.089285714285714, "title": "DP-vMF-means"}, {"color": "#6FA8DC", "id": "Dirichlet process (DP) vMF mixture", "label": "Dirichlet process (DP) vMF mixture", "shape": "dot", "size": 10.089285714285714, "title": "Dirichlet process (DP) vMF mixture"}, {"color": "#6FA8DC", "id": "streaming data", "label": "streaming data", "shape": "dot", "size": 10.089285714285714, "title": "streaming data"}, {"color": "#6FA8DC", "id": "synthetic directional data", "label": "synthetic directional data", "shape": "dot", "size": 10.089285714285714, "title": "synthetic directional data"}, {"color": "#6FA8DC", "id": "real 3D surface normals", "label": "real 3D surface normals", "shape": "dot", "size": 10.089285714285714, "title": "real 3D surface normals"}, {"color": "#6FA8DC", "id": "3D surface normals", "label": "3D surface normals", "shape": "dot", "size": 10.089285714285714, "title": "3D surface normals"}, {"color": "#6FA8DC", "id": "high dimensional directional data", "label": "high dimensional directional data", "shape": "dot", "size": 10.267857142857142, "title": "high dimensional directional data"}, {"color": "#6FA8DC", "id": "protein backbone configurations", "label": "protein backbone configurations", "shape": "dot", "size": 10.178571428571429, "title": "protein backbone configurations"}, {"color": "#6FA8DC", "id": "semantic word vectors", "label": "semantic word vectors", "shape": "dot", "size": 10.178571428571429, "title": "semantic word vectors"}, {"color": "#6FA8DC", "id": "Algorithms", "label": "Algorithms", "shape": "dot", "size": 10.535714285714286, "title": "Algorithms"}, {"color": "#6FA8DC", "id": "RGB-D sensors", "label": "RGB-D sensors", "shape": "dot", "size": 10.178571428571429, "title": "RGB-D sensors"}, {"color": "#6FA8DC", "id": "Surface Normals", "label": "Surface Normals", "shape": "dot", "size": 10.089285714285714, "title": "Surface Normals"}, {"color": "#6FA8DC", "id": "Bayesian Nonparametric Clustering", "label": "Bayesian Nonparametric Clustering", "shape": "dot", "size": 10.267857142857142, "title": "Bayesian Nonparametric Clustering"}, {"color": "#6FA8DC", "id": "von-Mises-Fisher Distributions", "label": "von-Mises-Fisher Distributions", "shape": "dot", "size": 10.178571428571429, "title": "von-Mises-Fisher Distributions"}, {"color": "#6FA8DC", "id": "Streaming Data Analysis", "label": "Streaming Data Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Streaming Data Analysis"}, {"color": "#6FA8DC", "id": "Abramowitz \u0026 Stegun", "label": "Abramowitz \u0026 Stegun", "shape": "dot", "size": 10.089285714285714, "title": "Abramowitz \u0026 Stegun"}, {"color": "#6FA8DC", "id": "mathematical background", "label": "mathematical background", "shape": "dot", "size": 10.089285714285714, "title": "mathematical background"}, {"color": "#6FA8DC", "id": "Neal", "label": "Neal", "shape": "dot", "size": 10.089285714285714, "title": "Neal"}, {"color": "#6FA8DC", "id": "Markov chain sampling", "label": "Markov chain sampling", "shape": "dot", "size": 10.178571428571429, "title": "Markov chain sampling"}, {"color": "#6FA8DC", "id": "Jiang, Kulis, \u0026 Jordan", "label": "Jiang, Kulis, \u0026 Jordan", "shape": "dot", "size": 10.178571428571429, "title": "Jiang, Kulis, \u0026 Jordan"}, {"color": "#6FA8DC", "id": "theoretical analysis", "label": "theoretical analysis", "shape": "dot", "size": 10.089285714285714, "title": "theoretical analysis"}, {"color": "#6FA8DC", "id": "DPMMs", "label": "DPMMs", "shape": "dot", "size": 10.535714285714286, "title": "DPMMs"}, {"color": "#6FA8DC", "id": "Jiang, K., Kulis, B., and Jordan, M.", "label": "Jiang, K., Kulis, B., and Jordan, M.", "shape": "dot", "size": 10.089285714285714, "title": "Jiang, K., Kulis, B., and Jordan, M."}, {"color": "#6FA8DC", "id": "Latent Dirichlet Allocation", "label": "Latent Dirichlet Allocation", "shape": "dot", "size": 10.178571428571429, "title": "Latent Dirichlet Allocation"}, {"color": "#6FA8DC", "id": "spherical topic models", "label": "spherical topic models", "shape": "dot", "size": 10.089285714285714, "title": "spherical topic models"}, {"color": "#6FA8DC", "id": "k-means", "label": "k-means", "shape": "dot", "size": 10.089285714285714, "title": "k-means"}, {"color": "#6FA8DC", "id": "Bayesian nonparametrics", "label": "Bayesian nonparametrics", "shape": "dot", "size": 10.178571428571429, "title": "Bayesian nonparametrics"}, {"color": "#6FA8DC", "id": "Directional statistics", "label": "Directional statistics", "shape": "dot", "size": 10.178571428571429, "title": "Directional statistics"}, {"color": "#6FA8DC", "id": "Mardia, K. V. and Jupp, P. E.", "label": "Mardia, K. V. and Jupp, P. E.", "shape": "dot", "size": 10.089285714285714, "title": "Mardia, K. V. and Jupp, P. E."}, {"color": "#6FA8DC", "id": "Bayesian nonparametric methods", "label": "Bayesian nonparametric methods", "shape": "dot", "size": 10.178571428571429, "title": "Bayesian nonparametric methods"}, {"color": "#6FA8DC", "id": "Ferguson, T.", "label": "Ferguson, T.", "shape": "dot", "size": 10.089285714285714, "title": "Ferguson, T."}, {"color": "#6FA8DC", "id": "John Wiley \u0026 Sons", "label": "John Wiley \u0026 Sons", "shape": "dot", "size": 10.089285714285714, "title": "John Wiley \u0026 Sons"}, {"color": "#6FA8DC", "id": "Ferguson distributions", "label": "Ferguson distributions", "shape": "dot", "size": 10.089285714285714, "title": "Ferguson distributions"}, {"color": "#6FA8DC", "id": "p\u00b4olya urn schemes", "label": "p\u00b4olya urn schemes", "shape": "dot", "size": 10.089285714285714, "title": "p\u00b4olya urn schemes"}, {"color": "#6FA8DC", "id": "spherical data", "label": "spherical data", "shape": "dot", "size": 10.089285714285714, "title": "spherical data"}, {"color": "#6FA8DC", "id": "Dirichlet processes", "label": "Dirichlet processes", "shape": "dot", "size": 10.089285714285714, "title": "Dirichlet processes"}, {"color": "#6FA8DC", "id": "Encyclopedia of Machine Learning", "label": "Encyclopedia of Machine Learning", "shape": "dot", "size": 10.089285714285714, "title": "Encyclopedia of Machine Learning"}, {"color": "#6FA8DC", "id": "CSAIL", "label": "CSAIL", "shape": "dot", "size": 10.446428571428571, "title": "CSAIL"}, {"color": "#6FA8DC", "id": "LIDS", "label": "LIDS", "shape": "dot", "size": 10.446428571428571, "title": "LIDS"}, {"color": "#6FA8DC", "id": "Bayesian analysis", "label": "Bayesian analysis", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian analysis"}, {"color": "#6FA8DC", "id": "nonparametric problems", "label": "nonparametric problems", "shape": "dot", "size": 10.089285714285714, "title": "nonparametric problems"}, {"color": "#6FA8DC", "id": "fisher@csaill.mit.edu", "label": "fisher@csaill.mit.edu", "shape": "dot", "size": 10.089285714285714, "title": "fisher@csaill.mit.edu"}, {"color": "#6FA8DC", "id": "Dingwen Zhang", "label": "Dingwen Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Dingwen Zhang"}, {"color": "#6FA8DC", "id": "Co-Saliency Detection via Looking Deep and Wide", "label": "Co-Saliency Detection via Looking Deep and Wide", "shape": "dot", "size": 10.446428571428571, "title": "Co-Saliency Detection via Looking Deep and Wide"}, {"color": "#6FA8DC", "id": "Junwei Han", "label": "Junwei Han", "shape": "dot", "size": 10.178571428571429, "title": "Junwei Han"}, {"color": "#6FA8DC", "id": "Chao Li", "label": "Chao Li", "shape": "dot", "size": 10.178571428571429, "title": "Chao Li"}, {"color": "#6FA8DC", "id": "Jingdong Wang", "label": "Jingdong Wang", "shape": "dot", "size": 10.267857142857142, "title": "Jingdong Wang"}, {"color": "#6FA8DC", "id": "cvpr_papers/Zhang_Co-Saliency_Detection_via_2015_CVPR_paper.pdf", "label": "cvpr_papers/Zhang_Co-Saliency_Detection_via_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "cvpr_papers/Zhang_Co-Saliency_Detection_via_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "co-saliency detection", "label": "co-saliency detection", "shape": "dot", "size": 10.357142857142858, "title": "co-saliency detection"}, {"color": "#6FA8DC", "id": "video foreground extraction", "label": "video foreground extraction", "shape": "dot", "size": 10.089285714285714, "title": "video foreground extraction"}, {"color": "#6FA8DC", "id": "surveillance", "label": "surveillance", "shape": "dot", "size": 10.089285714285714, "title": "surveillance"}, {"color": "#6FA8DC", "id": "image retrieval", "label": "image retrieval", "shape": "dot", "size": 10.089285714285714, "title": "image retrieval"}, {"color": "#6FA8DC", "id": "image annotation", "label": "image annotation", "shape": "dot", "size": 10.267857142857142, "title": "image annotation"}, {"color": "#6FA8DC", "id": "unified co-saliency detection framework", "label": "unified co-saliency detection framework", "shape": "dot", "size": 10.089285714285714, "title": "unified co-saliency detection framework"}, {"color": "#6FA8DC", "id": "novel insights", "label": "novel insights", "shape": "dot", "size": 10.089285714285714, "title": "novel insights"}, {"color": "#6FA8DC", "id": "network", "label": "network", "shape": "dot", "size": 10.446428571428571, "title": "network"}, {"color": "#6FA8DC", "id": "representation of co-salient objects", "label": "representation of co-salient objects", "shape": "dot", "size": 10.089285714285714, "title": "representation of co-salient objects"}, {"color": "#6FA8DC", "id": "visually similar neighbors", "label": "visually similar neighbors", "shape": "dot", "size": 10.089285714285714, "title": "visually similar neighbors"}, {"color": "#6FA8DC", "id": "neighbors", "label": "neighbors", "shape": "dot", "size": 10.089285714285714, "title": "neighbors"}, {"color": "#6FA8DC", "id": "common background regions", "label": "common background regions", "shape": "dot", "size": 10.089285714285714, "title": "common background regions"}, {"color": "#6FA8DC", "id": "deep information", "label": "deep information", "shape": "dot", "size": 10.089285714285714, "title": "deep information"}, {"color": "#6FA8DC", "id": "wide information", "label": "wide information", "shape": "dot", "size": 10.089285714285714, "title": "wide information"}, {"color": "#6FA8DC", "id": "co-salience scores", "label": "co-salience scores", "shape": "dot", "size": 10.178571428571429, "title": "co-salience scores"}, {"color": "#6FA8DC", "id": "intra-image contrast", "label": "intra-image contrast", "shape": "dot", "size": 10.178571428571429, "title": "intra-image contrast"}, {"color": "#6FA8DC", "id": "intra-group consistency", "label": "intra-group consistency", "shape": "dot", "size": 10.178571428571429, "title": "intra-group consistency"}, {"color": "#6FA8DC", "id": "window-level co-salience scores", "label": "window-level co-salience scores", "shape": "dot", "size": 10.089285714285714, "title": "window-level co-salience scores"}, {"color": "#6FA8DC", "id": "superpixel-level co-salience maps", "label": "superpixel-level co-salience maps", "shape": "dot", "size": 10.178571428571429, "title": "superpixel-level co-salience maps"}, {"color": "#6FA8DC", "id": "foreground region agreement strategy", "label": "foreground region agreement strategy", "shape": "dot", "size": 10.089285714285714, "title": "foreground region agreement strategy"}, {"color": "#6FA8DC", "id": "consistent performance gain", "label": "consistent performance gain", "shape": "dot", "size": 10.178571428571429, "title": "consistent performance gain"}, {"color": "#6FA8DC", "id": "object proposal windows", "label": "object proposal windows", "shape": "dot", "size": 10.089285714285714, "title": "object proposal windows"}, {"color": "#6FA8DC", "id": "Bayesian formulation", "label": "Bayesian formulation", "shape": "dot", "size": 10.178571428571429, "title": "Bayesian formulation"}, {"color": "#6FA8DC", "id": "l-level co-saliency maps", "label": "l-level co-saliency maps", "shape": "dot", "size": 10.089285714285714, "title": "l-level co-saliency maps"}, {"color": "#6FA8DC", "id": "foreground region agreement", "label": "foreground region agreement", "shape": "dot", "size": 10.089285714285714, "title": "foreground region agreement"}, {"color": "#6FA8DC", "id": "proposed approach", "label": "proposed approach", "shape": "dot", "size": 11.428571428571429, "title": "proposed approach"}, {"color": "#6FA8DC", "id": "Co-salient object detection", "label": "Co-salient object detection", "shape": "dot", "size": 10.089285714285714, "title": "Co-salient object detection"}, {"color": "#6FA8DC", "id": "multiple images", "label": "multiple images", "shape": "dot", "size": 10.178571428571429, "title": "multiple images"}, {"color": "#6FA8DC", "id": "Unified approach", "label": "Unified approach", "shape": "dot", "size": 10.089285714285714, "title": "Unified approach"}, {"color": "#6FA8DC", "id": "low rank matrix recovery", "label": "low rank matrix recovery", "shape": "dot", "size": 10.089285714285714, "title": "low rank matrix recovery"}, {"color": "#6FA8DC", "id": "iCoseg", "label": "iCoseg", "shape": "dot", "size": 10.089285714285714, "title": "iCoseg"}, {"color": "#6FA8DC", "id": "intelligent scribble guidance", "label": "intelligent scribble guidance", "shape": "dot", "size": 10.089285714285714, "title": "intelligent scribble guidance"}, {"color": "#6FA8DC", "id": "Co-salience detection", "label": "Co-salience detection", "shape": "dot", "size": 10.178571428571429, "title": "Co-salience detection"}, {"color": "#6FA8DC", "id": "Convolutional Neural Networks (CNNs)", "label": "Convolutional Neural Networks (CNNs)", "shape": "dot", "size": 11.339285714285715, "title": "Convolutional Neural Networks (CNNs)"}, {"color": "#6FA8DC", "id": "Image Group Consistency", "label": "Image Group Consistency", "shape": "dot", "size": 10.089285714285714, "title": "Image Group Consistency"}, {"color": "#6FA8DC", "id": "Bayesian Formulation", "label": "Bayesian Formulation", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian Formulation"}, {"color": "#6FA8DC", "id": "salient object detection", "label": "salient object detection", "shape": "dot", "size": 10.982142857142858, "title": "salient object detection"}, {"color": "#6FA8DC", "id": "Visual Attention", "label": "Visual Attention", "shape": "dot", "size": 10.357142857142858, "title": "Visual Attention"}, {"color": "#6FA8DC", "id": "co-salience detection", "label": "co-salience detection", "shape": "dot", "size": 10.089285714285714, "title": "co-salience detection"}, {"color": "#6FA8DC", "id": "alient object detection", "label": "alient object detection", "shape": "dot", "size": 10.089285714285714, "title": "alient object detection"}, {"color": "#6FA8DC", "id": "CVPR (Conference)", "label": "CVPR (Conference)", "shape": "dot", "size": 10.089285714285714, "title": "CVPR (Conference)"}, {"color": "#6FA8DC", "id": "Xie, Y.", "label": "Xie, Y.", "shape": "dot", "size": 10.089285714285714, "title": "Xie, Y."}, {"color": "#6FA8DC", "id": "Bayesian salience", "label": "Bayesian salience", "shape": "dot", "size": 10.178571428571429, "title": "Bayesian salience"}, {"color": "#6FA8DC", "id": "low and mid level cues", "label": "low and mid level cues", "shape": "dot", "size": 10.089285714285714, "title": "low and mid level cues"}, {"color": "#6FA8DC", "id": "discriminative regional feature integration", "label": "discriminative regional feature integration", "shape": "dot", "size": 10.178571428571429, "title": "discriminative regional feature integration"}, {"color": "#6FA8DC", "id": "Han, J.", "label": "Han, J.", "shape": "dot", "size": 10.089285714285714, "title": "Han, J."}, {"color": "#6FA8DC", "id": "object-oriented visual salieny detection framework", "label": "object-oriented visual salieny detection framework", "shape": "dot", "size": 10.178571428571429, "title": "object-oriented visual salieny detection framework"}, {"color": "#6FA8DC", "id": "sparse coding representations", "label": "sparse coding representations", "shape": "dot", "size": 10.089285714285714, "title": "sparse coding representations"}, {"color": "#6FA8DC", "id": "Rubinstein, M.", "label": "Rubinstein, M.", "shape": "dot", "size": 10.089285714285714, "title": "Rubinstein, M."}, {"color": "#6FA8DC", "id": "joint object discovery", "label": "joint object discovery", "shape": "dot", "size": 10.178571428571429, "title": "joint object discovery"}, {"color": "#6FA8DC", "id": "internet images", "label": "internet images", "shape": "dot", "size": 10.089285714285714, "title": "internet images"}, {"color": "#6FA8DC", "id": "Jiang, H.", "label": "Jiang, H.", "shape": "dot", "size": 10.089285714285714, "title": "Jiang, H."}, {"color": "#6FA8DC", "id": "salient object segmentation", "label": "salient object segmentation", "shape": "dot", "size": 10.178571428571429, "title": "salient object segmentation"}, {"color": "#6FA8DC", "id": "context prior", "label": "context prior", "shape": "dot", "size": 10.089285714285714, "title": "context prior"}, {"color": "#6FA8DC", "id": "IEEE Trans. Image Process.", "label": "IEEE Trans. Image Process.", "shape": "dot", "size": 10.178571428571429, "title": "IEEE Trans. Image Process."}, {"color": "#6FA8DC", "id": "Image Processing", "label": "Image Processing", "shape": "dot", "size": 10.446428571428571, "title": "Image Processing"}, {"color": "#6FA8DC", "id": "is_author_of", "label": "is_author_of", "shape": "dot", "size": 10.357142857142858, "title": "is_author_of"}, {"color": "#6FA8DC", "id": "Cong Zhang", "label": "Cong Zhang", "shape": "dot", "size": 10.267857142857142, "title": "Cong Zhang"}, {"color": "#6FA8DC", "id": "Hongsheng Li", "label": "Hongsheng Li", "shape": "dot", "size": 10.446428571428571, "title": "Hongsheng Li"}, {"color": "#6FA8DC", "id": "Xiaogang Wang", "label": "Xiaogang Wang", "shape": "dot", "size": 10.535714285714286, "title": "Xiaogang Wang"}, {"color": "#6FA8DC", "id": "Xiaokang Yang", "label": "Xiaokang Yang", "shape": "dot", "size": 10.625, "title": "Xiaokang Yang"}, {"color": "#6FA8DC", "id": "Automatic salient object segmentation", "label": "Automatic salient object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Automatic salient object segmentation"}, {"color": "#6FA8DC", "id": "Self-Adaptively Weighted Co-Saliency Detection", "label": "Self-Adaptively Weighted Co-Saliency Detection", "shape": "dot", "size": 10.089285714285714, "title": "Self-Adaptively Weighted Co-Saliency Detection"}, {"color": "#6FA8DC", "id": "jingdw@microsoft.com", "label": "jingdw@microsoft.com", "shape": "dot", "size": 10.089285714285714, "title": "jingdw@microsoft.com"}, {"color": "#6FA8DC", "id": "Cross-Scene Crowd Counting", "label": "Cross-Scene Crowd Counting", "shape": "dot", "size": 10.625, "title": "Cross-Scene Crowd Counting"}, {"color": "#6FA8DC", "id": "Zhang_Cross-Scene_Crowd_Counting_2015_CVPR_paper.pdf", "label": "Zhang_Cross-Scene_Crowd_Counting_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Zhang_Cross-Scene_Crowd_Counting_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Cross-scene crowd counting", "label": "Cross-scene crowd counting", "shape": "dot", "size": 10.178571428571429, "title": "Cross-scene crowd counting"}, {"color": "#6FA8DC", "id": "crowd counting", "label": "crowd counting", "shape": "dot", "size": 10.446428571428571, "title": "crowd counting"}, {"color": "#6FA8DC", "id": "no laborious data annotation", "label": "no laborious data annotation", "shape": "dot", "size": 10.089285714285714, "title": "no laborious data annotation"}, {"color": "#6FA8DC", "id": "existing crowd counting methods", "label": "existing crowd counting methods", "shape": "dot", "size": 10.089285714285714, "title": "existing crowd counting methods"}, {"color": "#6FA8DC", "id": "significant performance drop", "label": "significant performance drop", "shape": "dot", "size": 10.089285714285714, "title": "significant performance drop"}, {"color": "#6FA8DC", "id": "deep convolutional neural network (CNN)", "label": "deep convolutional neural network (CNN)", "shape": "dot", "size": 10.357142857142858, "title": "deep convolutional neural network (CNN)"}, {"color": "#6FA8DC", "id": "crowd density", "label": "crowd density", "shape": "dot", "size": 10.089285714285714, "title": "crowd density"}, {"color": "#6FA8DC", "id": "switchable learning approach", "label": "switchable learning approach", "shape": "dot", "size": 10.089285714285714, "title": "switchable learning approach"}, {"color": "#6FA8DC", "id": "better local optimum", "label": "better local optimum", "shape": "dot", "size": 10.089285714285714, "title": "better local optimum"}, {"color": "#6FA8DC", "id": "data-driven method", "label": "data-driven method", "shape": "dot", "size": 10.089285714285714, "title": "data-driven method"}, {"color": "#6FA8DC", "id": "fine-tune CNN model", "label": "fine-tune CNN model", "shape": "dot", "size": 10.089285714285714, "title": "fine-tune CNN model"}, {"color": "#6FA8DC", "id": "108 crowd scenes", "label": "108 crowd scenes", "shape": "dot", "size": 10.089285714285714, "title": "108 crowd scenes"}, {"color": "#6FA8DC", "id": "nearly 200,000 head", "label": "nearly 200,000 head", "shape": "dot", "size": 10.089285714285714, "title": "nearly 200,000 head"}, {"color": "#6FA8DC", "id": "unseen target crowd scene", "label": "unseen target crowd scene", "shape": "dot", "size": 10.089285714285714, "title": "unseen target crowd scene"}, {"color": "#6FA8DC", "id": "trained CNN model", "label": "trained CNN model", "shape": "dot", "size": 10.089285714285714, "title": "trained CNN model"}, {"color": "#6FA8DC", "id": "200,000 head annotations", "label": "200,000 head annotations", "shape": "dot", "size": 10.089285714285714, "title": "200,000 head annotations"}, {"color": "#6FA8DC", "id": "cross-scene crowd counting methods", "label": "cross-scene crowd counting methods", "shape": "dot", "size": 10.178571428571429, "title": "cross-scene crowd counting methods"}, {"color": "#6FA8DC", "id": "reliability", "label": "reliability", "shape": "dot", "size": 10.089285714285714, "title": "reliability"}, {"color": "#6FA8DC", "id": "CNN model", "label": "CNN model", "shape": "dot", "size": 10.089285714285714, "title": "CNN model"}, {"color": "#6FA8DC", "id": "trained", "label": "trained", "shape": "dot", "size": 10.089285714285714, "title": "trained"}, {"color": "#6FA8DC", "id": "new", "label": "new", "shape": "dot", "size": 10.089285714285714, "title": "new"}, {"color": "#6FA8DC", "id": "Crowd Counting", "label": "Crowd Counting", "shape": "dot", "size": 10.357142857142858, "title": "Crowd Counting"}, {"color": "#6FA8DC", "id": "Deep Convolutional Neural Networks (CNNs)", "label": "Deep Convolutional Neural Networks (CNNs)", "shape": "dot", "size": 10.357142857142858, "title": "Deep Convolutional Neural Networks (CNNs)"}, {"color": "#6FA8DC", "id": "object counting", "label": "object counting", "shape": "dot", "size": 10.267857142857142, "title": "object counting"}, {"color": "#6FA8DC", "id": "Chen et al. (2013)", "label": "Chen et al. (2013)", "shape": "dot", "size": 10.267857142857142, "title": "Chen et al. (2013)"}, {"color": "#6FA8DC", "id": "cumulative attribute space", "label": "cumulative attribute space", "shape": "dot", "size": 10.178571428571429, "title": "cumulative attribute space"}, {"color": "#6FA8DC", "id": "crowd density estimation", "label": "crowd density estimation", "shape": "dot", "size": 10.089285714285714, "title": "crowd density estimation"}, {"color": "#6FA8DC", "id": "Lempitsky \u0026 Zisserman (2010)", "label": "Lempitsky \u0026 Zisserman (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Lempitsky \u0026 Zisserman (2010)"}, {"color": "#6FA8DC", "id": "Chen et al. (2012)", "label": "Chen et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Chen et al. (2012)"}, {"color": "#6FA8DC", "id": "feature mining", "label": "feature mining", "shape": "dot", "size": 10.178571428571429, "title": "feature mining"}, {"color": "#6FA8DC", "id": "localized crowd counting", "label": "localized crowd counting", "shape": "dot", "size": 10.267857142857142, "title": "localized crowd counting"}, {"color": "#6FA8DC", "id": "Loy et al. (2012) research", "label": "Loy et al. (2012) research", "shape": "dot", "size": 10.089285714285714, "title": "Loy et al. (2012) research"}, {"color": "#6FA8DC", "id": "An et al. (2007) research", "label": "An et al. (2007) research", "shape": "dot", "size": 10.089285714285714, "title": "An et al. (2007) research"}, {"color": "#6FA8DC", "id": "kernel ridge regression", "label": "kernel ridge regression", "shape": "dot", "size": 10.178571428571429, "title": "kernel ridge regression"}, {"color": "#6FA8DC", "id": "vision tasks", "label": "vision tasks", "shape": "dot", "size": 10.089285714285714, "title": "vision tasks"}, {"color": "#6FA8DC", "id": "Kai et al. (2014) research", "label": "Kai et al. (2014) research", "shape": "dot", "size": 10.089285714285714, "title": "Kai et al. (2014) research"}, {"color": "#6FA8DC", "id": "fully convolutional network", "label": "fully convolutional network", "shape": "dot", "size": 10.267857142857142, "title": "fully convolutional network"}, {"color": "#6FA8DC", "id": "crowd segmentation", "label": "crowd segmentation", "shape": "dot", "size": 10.178571428571429, "title": "crowd segmentation"}, {"color": "#6FA8DC", "id": "Kong et al. (2006) research", "label": "Kong et al. (2006) research", "shape": "dot", "size": 10.089285714285714, "title": "Kong et al. (2006) research"}, {"color": "#6FA8DC", "id": "viewpoint invariance", "label": "viewpoint invariance", "shape": "dot", "size": 10.089285714285714, "title": "viewpoint invariance"}, {"color": "#6FA8DC", "id": "neural network", "label": "neural network", "shape": "dot", "size": 10.357142857142858, "title": "neural network"}, {"color": "#6FA8DC", "id": "Kong et al. (2006)", "label": "Kong et al. (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Kong et al. (2006)"}, {"color": "#6FA8DC", "id": "viewpoint invariance in crowd counting", "label": "viewpoint invariance in crowd counting", "shape": "dot", "size": 10.178571428571429, "title": "viewpoint invariance in crowd counting"}, {"color": "#6FA8DC", "id": "practical consideration", "label": "practical consideration", "shape": "dot", "size": 10.089285714285714, "title": "practical consideration"}, {"color": "#6FA8DC", "id": "Jing et al. (2015)", "label": "Jing et al. (2015)", "shape": "dot", "size": 10.089285714285714, "title": "Jing et al. (2015)"}, {"color": "#6FA8DC", "id": "deep learning for attribute extraction", "label": "deep learning for attribute extraction", "shape": "dot", "size": 10.089285714285714, "title": "deep learning for attribute extraction"}, {"color": "#6FA8DC", "id": "attribute extraction", "label": "attribute extraction", "shape": "dot", "size": 10.089285714285714, "title": "attribute extraction"}, {"color": "#6FA8DC", "id": "crowd scene understanding", "label": "crowd scene understanding", "shape": "dot", "size": 10.089285714285714, "title": "crowd scene understanding"}, {"color": "#6FA8DC", "id": "Fiaschi et al. (2012)", "label": "Fiaschi et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Fiaschi et al. (2012)"}, {"color": "#6FA8DC", "id": "regression forest for counting", "label": "regression forest for counting", "shape": "dot", "size": 10.178571428571429, "title": "regression forest for counting"}, {"color": "#6FA8DC", "id": "neural networks", "label": "neural networks", "shape": "dot", "size": 10.178571428571429, "title": "neural networks"}, {"color": "#6FA8DC", "id": "Loy et al. (2013)", "label": "Loy et al. (2013)", "shape": "dot", "size": 10.178571428571429, "title": "Loy et al. (2013)"}, {"color": "#6FA8DC", "id": "semi-supervised learning for crowd counting", "label": "semi-supervised learning for crowd counting", "shape": "dot", "size": 10.089285714285714, "title": "semi-supervised learning for crowd counting"}, {"color": "#6FA8DC", "id": "transfer learning for crowd counting", "label": "transfer learning for crowd counting", "shape": "dot", "size": 10.089285714285714, "title": "transfer learning for crowd counting"}, {"color": "#6FA8DC", "id": "ICPR", "label": "ICPR", "shape": "dot", "size": 10.178571428571429, "title": "ICPR"}, {"color": "#6FA8DC", "id": "conference", "label": "conference", "shape": "dot", "size": 10.625, "title": "conference"}, {"color": "#6FA8DC", "id": "ICCV", "label": "ICCV", "shape": "dot", "size": 11.428571428571429, "title": "ICCV"}, {"color": "#6FA8DC", "id": "Gong, S.", "label": "Gong, S.", "shape": "dot", "size": 10.089285714285714, "title": "Gong, S."}, {"color": "#6FA8DC", "id": "From semi-supervised to transfer counting of crowds", "label": "From semi-supervised to transfer counting of crowds", "shape": "dot", "size": 10.178571428571429, "title": "From semi-supervised to transfer counting of crowds"}, {"color": "#6FA8DC", "id": "Xiang, T.", "label": "Xiang, T.", "shape": "dot", "size": 10.089285714285714, "title": "Xiang, T."}, {"color": "#6FA8DC", "id": "Lowe, D. G.", "label": "Lowe, D. G.", "shape": "dot", "size": 10.089285714285714, "title": "Lowe, D. G."}, {"color": "#6FA8DC", "id": "Distinctive image features from scale-invariant keypoints", "label": "Distinctive image features from scale-invariant keypoints", "shape": "dot", "size": 10.267857142857142, "title": "Distinctive image features from scale-invariant keypoints"}, {"color": "#6FA8DC", "id": "SIFT features", "label": "SIFT features", "shape": "dot", "size": 11.160714285714286, "title": "SIFT features"}, {"color": "#6FA8DC", "id": "crowd analysis", "label": "crowd analysis", "shape": "dot", "size": 10.089285714285714, "title": "crowd analysis"}, {"color": "#6FA8DC", "id": "Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University", "label": "Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University", "shape": "dot", "size": 10.178571428571429, "title": "Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University"}, {"color": "#6FA8DC", "id": "Department of Electronic Engineering, The Chinese University of Hong Kong", "label": "Department of Electronic Engineering, The Chinese University of Hong Kong", "shape": "dot", "size": 10.178571428571429, "title": "Department of Electronic Engineering, The Chinese University of Hong Kong"}, {"color": "#6FA8DC", "id": "Chinese University of Hong Kong", "label": "Chinese University of Hong Kong", "shape": "dot", "size": 10.089285714285714, "title": "Chinese University of Hong Kong"}, {"color": "#6FA8DC", "id": "xgwang@ee.cuhk.edu.hk", "label": "xgwang@ee.cuhk.edu.hk", "shape": "dot", "size": 10.089285714285714, "title": "xgwang@ee.cuhk.edu.hk"}, {"color": "#6FA8DC", "id": "Yongzhen Huang", "label": "Yongzhen Huang", "shape": "dot", "size": 10.178571428571429, "title": "Yongzhen Huang"}, {"color": "#6FA8DC", "id": "Deep SemanticRanking Based Hashing", "label": "Deep SemanticRanking Based Hashing", "shape": "dot", "size": 10.089285714285714, "title": "Deep SemanticRanking Based Hashing"}, {"color": "#6FA8DC", "id": "Liang Wang", "label": "Liang Wang", "shape": "dot", "size": 10.178571428571429, "title": "Liang Wang"}, {"color": "#6FA8DC", "id": "Deep Semantic Ranking Based Hashing", "label": "Deep Semantic Ranking Based Hashing", "shape": "dot", "size": 10.357142857142858, "title": "Deep Semantic Ranking Based Hashing"}, {"color": "#6FA8DC", "id": "Tieniu Tan", "label": "Tieniu Tan", "shape": "dot", "size": 10.178571428571429, "title": "Tieniu Tan"}, {"color": "#6FA8DC", "id": "Institute of Image Communication and Network Engineering", "label": "Institute of Image Communication and Network Engineering", "shape": "dot", "size": 10.089285714285714, "title": "Institute of Image Communication and Network Engineering"}, {"color": "#6FA8DC", "id": "Shanghai Jiao Tong University", "label": "Shanghai Jiao Tong University", "shape": "dot", "size": 10.089285714285714, "title": "Shanghai Jiao Tong University"}, {"color": "#6FA8DC", "id": "xk yang@sjtu.edu.cn", "label": "xk yang@sjtu.edu.cn", "shape": "dot", "size": 10.089285714285714, "title": "xk yang@sjtu.edu.cn"}, {"color": "#6FA8DC", "id": "Multi-Label Image Retrieval", "label": "Multi-Label Image Retrieval", "shape": "dot", "size": 10.089285714285714, "title": "Multi-Label Image Retrieval"}, {"color": "#6FA8DC", "id": "deep hash functions", "label": "deep hash functions", "shape": "dot", "size": 10.178571428571429, "title": "deep hash functions"}, {"color": "#6FA8DC", "id": "hand-crafted features", "label": "hand-crafted features", "shape": "dot", "size": 10.357142857142858, "title": "hand-crafted features"}, {"color": "#6FA8DC", "id": "ranking list", "label": "ranking list", "shape": "dot", "size": 10.267857142857142, "title": "ranking list"}, {"color": "#6FA8DC", "id": "multilevel similarity information", "label": "multilevel similarity information", "shape": "dot", "size": 10.178571428571429, "title": "multilevel similarity information"}, {"color": "#6FA8DC", "id": "state-of-the-art hashing methods", "label": "state-of-the-art hashing methods", "shape": "dot", "size": 10.178571428571429, "title": "state-of-the-art hashing methods"}, {"color": "#6FA8DC", "id": "semantic representation", "label": "semantic representation", "shape": "dot", "size": 10.178571428571429, "title": "semantic representation"}, {"color": "#6FA8DC", "id": "hash codes", "label": "hash codes", "shape": "dot", "size": 10.089285714285714, "title": "hash codes"}, {"color": "#6FA8DC", "id": "Deep Hash Functions", "label": "Deep Hash Functions", "shape": "dot", "size": 10.089285714285714, "title": "Deep Hash Functions"}, {"color": "#6FA8DC", "id": "Similarity Information", "label": "Similarity Information", "shape": "dot", "size": 10.089285714285714, "title": "Similarity Information"}, {"color": "#6FA8DC", "id": "Proposed Approach", "label": "Proposed Approach", "shape": "dot", "size": 10.089285714285714, "title": "Proposed Approach"}, {"color": "#6FA8DC", "id": "Hashing Methods", "label": "Hashing Methods", "shape": "dot", "size": 10.089285714285714, "title": "Hashing Methods"}, {"color": "#6FA8DC", "id": "ImageNet Classification", "label": "ImageNet Classification", "shape": "dot", "size": 10.267857142857142, "title": "ImageNet Classification"}, {"color": "#6FA8DC", "id": "Deep Convolutional Ranking", "label": "Deep Convolutional Ranking", "shape": "dot", "size": 10.178571428571429, "title": "Deep Convolutional Ranking"}, {"color": "#6FA8DC", "id": "Multi-label Image Annotation", "label": "Multi-label Image Annotation", "shape": "dot", "size": 10.089285714285714, "title": "Multi-label Image Annotation"}, {"color": "#6FA8DC", "id": "Iterative Quantization", "label": "Iterative Quantization", "shape": "dot", "size": 10.178571428571429, "title": "Iterative Quantization"}, {"color": "#6FA8DC", "id": "Binary Codes", "label": "Binary Codes", "shape": "dot", "size": 10.178571428571429, "title": "Binary Codes"}, {"color": "#6FA8DC", "id": "Image Retrieval", "label": "Image Retrieval", "shape": "dot", "size": 10.178571428571429, "title": "Image Retrieval"}, {"color": "#6FA8DC", "id": "Krizhevsky", "label": "Krizhevsky", "shape": "dot", "size": 10.267857142857142, "title": "Krizhevsky"}, {"color": "#6FA8DC", "id": "Gong", "label": "Gong", "shape": "dot", "size": 10.446428571428571, "title": "Gong"}, {"color": "#6FA8DC", "id": "Perronnin", "label": "Perronnin", "shape": "dot", "size": 10.089285714285714, "title": "Perronnin"}, {"color": "#6FA8DC", "id": "Iterative quantization", "label": "Iterative quantization", "shape": "dot", "size": 10.178571428571429, "title": "Iterative quantization"}, {"color": "#6FA8DC", "id": "binary codes", "label": "binary codes", "shape": "dot", "size": 10.357142857142858, "title": "binary codes"}, {"color": "#6FA8DC", "id": "Norouzi", "label": "Norouzi", "shape": "dot", "size": 10.178571428571429, "title": "Norouzi"}, {"color": "#6FA8DC", "id": "Hamming distance metric learning", "label": "Hamming distance metric learning", "shape": "dot", "size": 10.178571428571429, "title": "Hamming distance metric learning"}, {"color": "#6FA8DC", "id": "Semi-supervised hashing", "label": "Semi-supervised hashing", "shape": "dot", "size": 10.535714285714286, "title": "Semi-supervised hashing"}, {"color": "#6FA8DC", "id": "scalable image retrieval", "label": "scalable image retrieval", "shape": "dot", "size": 10.089285714285714, "title": "scalable image retrieval"}, {"color": "#6FA8DC", "id": "Torralba", "label": "Torralba", "shape": "dot", "size": 10.178571428571429, "title": "Torralba"}, {"color": "#6FA8DC", "id": "Small codes", "label": "Small codes", "shape": "dot", "size": 10.178571428571429, "title": "Small codes"}, {"color": "#6FA8DC", "id": "image databases", "label": "image databases", "shape": "dot", "size": 10.089285714285714, "title": "image databases"}, {"color": "#6FA8DC", "id": "Deep convolutional ranking", "label": "Deep convolutional ranking", "shape": "dot", "size": 10.357142857142858, "title": "Deep convolutional ranking"}, {"color": "#6FA8DC", "id": "multilabel image annotation", "label": "multilabel image annotation", "shape": "dot", "size": 10.089285714285714, "title": "multilabel image annotation"}, {"color": "#6FA8DC", "id": "Gong, Y.", "label": "Gong, Y.", "shape": "dot", "size": 10.089285714285714, "title": "Gong, Y."}, {"color": "#6FA8DC", "id": "multilable image annotation", "label": "multilable image annotation", "shape": "dot", "size": 10.089285714285714, "title": "multilable image annotation"}, {"color": "#6FA8DC", "id": "Krizhevsky, A.", "label": "Krizhevsky, A.", "shape": "dot", "size": 10.535714285714286, "title": "Krizhevsky, A."}, {"color": "#6FA8DC", "id": "One weird trick", "label": "One weird trick", "shape": "dot", "size": 10.178571428571429, "title": "One weird trick"}, {"color": "#6FA8DC", "id": "parallelizing convolutional neural networks", "label": "parallelizing convolutional neural networks", "shape": "dot", "size": 10.089285714285714, "title": "parallelizing convolutional neural networks"}, {"color": "#6FA8DC", "id": "Minimal loss hashing", "label": "Minimal loss hashing", "shape": "dot", "size": 10.267857142857142, "title": "Minimal loss hashing"}, {"color": "#6FA8DC", "id": "compact binary codes", "label": "compact binary codes", "shape": "dot", "size": 10.446428571428571, "title": "compact binary codes"}, {"color": "#6FA8DC", "id": "Lin, G.", "label": "Lin, G.", "shape": "dot", "size": 10.089285714285714, "title": "Lin, G."}, {"color": "#6FA8DC", "id": "Optimizing ranking measures", "label": "Optimizing ranking measures", "shape": "dot", "size": 10.178571428571429, "title": "Optimizing ranking measures"}, {"color": "#6FA8DC", "id": "compact binary code learning", "label": "compact binary code learning", "shape": "dot", "size": 10.089285714285714, "title": "compact binary code learning"}, {"color": "#6FA8DC", "id": "Fang Zhao", "label": "Fang Zhao", "shape": "dot", "size": 10.089285714285714, "title": "Fang Zhao"}, {"color": "#6FA8DC", "id": "Center for Research on Intelligent Perception and Computing", "label": "Center for Research on Intelligent Perception and Computing", "shape": "dot", "size": 10.535714285714286, "title": "Center for Research on Intelligent Perception and Computing"}, {"color": "#6FA8DC", "id": "Institute of Automation", "label": "Institute of Automation", "shape": "dot", "size": 10.357142857142858, "title": "Institute of Automation"}, {"color": "#6FA8DC", "id": "David Perra", "label": "David Perra", "shape": "dot", "size": 10.178571428571429, "title": "David Perra"}, {"color": "#6FA8DC", "id": "Adaptive Eye-Camera Calibration", "label": "Adaptive Eye-Camera Calibration", "shape": "dot", "size": 10.267857142857142, "title": "Adaptive Eye-Camera Calibration"}, {"color": "#6FA8DC", "id": "Rohit Kumar Gupta", "label": "Rohit Kumar Gupta", "shape": "dot", "size": 10.267857142857142, "title": "Rohit Kumar Gupta"}, {"color": "#6FA8DC", "id": "fang.zhao@nlpr.ia.ac.cn", "label": "fang.zhao@nlpr.ia.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "fang.zhao@nlpr.ia.ac.cn"}, {"color": "#6FA8DC", "id": "Perra_Adaptive_Eye-Camera_Calibration_2015_CVPR_paper.pdf", "label": "Perra_Adaptive_Eye-Camera_Calibration_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Perra_Adaptive_Eye-Camera_Calibration_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "calibration scheme", "label": "calibration scheme", "shape": "dot", "size": 10.714285714285714, "title": "calibration scheme"}, {"color": "#6FA8DC", "id": "globally optimal model", "label": "globally optimal model", "shape": "dot", "size": 10.089285714285714, "title": "globally optimal model"}, {"color": "#6FA8DC", "id": "calibration schemes", "label": "calibration schemes", "shape": "dot", "size": 10.089285714285714, "title": "calibration schemes"}, {"color": "#6FA8DC", "id": "per-user basis", "label": "per-user basis", "shape": "dot", "size": 10.089285714285714, "title": "per-user basis"}, {"color": "#6FA8DC", "id": "changes in calibration", "label": "changes in calibration", "shape": "dot", "size": 10.089285714285714, "title": "changes in calibration"}, {"color": "#6FA8DC", "id": "locally optimal eye-device transformation", "label": "locally optimal eye-device transformation", "shape": "dot", "size": 10.089285714285714, "title": "locally optimal eye-device transformation"}, {"color": "#6FA8DC", "id": "local window of previous frames", "label": "local window of previous frames", "shape": "dot", "size": 10.089285714285714, "title": "local window of previous frames"}, {"color": "#6FA8DC", "id": "interest regions", "label": "interest regions", "shape": "dot", "size": 10.178571428571429, "title": "interest regions"}, {"color": "#6FA8DC", "id": "user\u0027s passive participation", "label": "user\u0027s passive participation", "shape": "dot", "size": 10.089285714285714, "title": "user\u0027s passive participation"}, {"color": "#6FA8DC", "id": "continuous", "label": "continuous", "shape": "dot", "size": 10.178571428571429, "title": "continuous"}, {"color": "#6FA8DC", "id": "locally optimal", "label": "locally optimal", "shape": "dot", "size": 10.178571428571429, "title": "locally optimal"}, {"color": "#6FA8DC", "id": "eye-device transformation", "label": "eye-device transformation", "shape": "dot", "size": 10.089285714285714, "title": "eye-device transformation"}, {"color": "#6FA8DC", "id": "user\u2019s environment", "label": "user\u2019s environment", "shape": "dot", "size": 10.089285714285714, "title": "user\u2019s environment"}, {"color": "#6FA8DC", "id": "without user participation", "label": "without user participation", "shape": "dot", "size": 10.089285714285714, "title": "without user participation"}, {"color": "#6FA8DC", "id": "proposed calibration scheme", "label": "proposed calibration scheme", "shape": "dot", "size": 10.267857142857142, "title": "proposed calibration scheme"}, {"color": "#6FA8DC", "id": "existing state of the art systems", "label": "existing state of the art systems", "shape": "dot", "size": 10.089285714285714, "title": "existing state of the art systems"}, {"color": "#6FA8DC", "id": "less restrictive", "label": "less restrictive", "shape": "dot", "size": 10.089285714285714, "title": "less restrictive"}, {"color": "#6FA8DC", "id": "environment", "label": "environment", "shape": "dot", "size": 10.178571428571429, "title": "environment"}, {"color": "#6FA8DC", "id": "calibration", "label": "calibration", "shape": "dot", "size": 10.089285714285714, "title": "calibration"}, {"color": "#6FA8DC", "id": "state of the art systems", "label": "state of the art systems", "shape": "dot", "size": 10.089285714285714, "title": "state of the art systems"}, {"color": "#6FA8DC", "id": "Alnajar et al.", "label": "Alnajar et al.", "shape": "dot", "size": 10.089285714285714, "title": "Alnajar et al."}, {"color": "#6FA8DC", "id": "Calibration-free gaze estimation", "label": "Calibration-free gaze estimation", "shape": "dot", "size": 10.178571428571429, "title": "Calibration-free gaze estimation"}, {"color": "#6FA8DC", "id": "Chen and Ji", "label": "Chen and Ji", "shape": "dot", "size": 10.089285714285714, "title": "Chen and Ji"}, {"color": "#6FA8DC", "id": "Probabilistic gaze estimation", "label": "Probabilistic gaze estimation", "shape": "dot", "size": 10.178571428571429, "title": "Probabilistic gaze estimation"}, {"color": "#6FA8DC", "id": "Corno et al.", "label": "Corno et al.", "shape": "dot", "size": 10.089285714285714, "title": "Corno et al."}, {"color": "#6FA8DC", "id": "cost-effective solution", "label": "cost-effective solution", "shape": "dot", "size": 10.178571428571429, "title": "cost-effective solution"}, {"color": "#6FA8DC", "id": "human gaze patterns", "label": "human gaze patterns", "shape": "dot", "size": 10.089285714285714, "title": "human gaze patterns"}, {"color": "#6FA8DC", "id": "active personal calibration", "label": "active personal calibration", "shape": "dot", "size": 10.089285714285714, "title": "active personal calibration"}, {"color": "#6FA8DC", "id": "eye-gaze assistive technology", "label": "eye-gaze assistive technology", "shape": "dot", "size": 10.089285714285714, "title": "eye-gaze assistive technology"}, {"color": "#6FA8DC", "id": "eye-camera calibration", "label": "eye-camera calibration", "shape": "dot", "size": 10.089285714285714, "title": "eye-camera calibration"}, {"color": "#6FA8DC", "id": "gaze tracking", "label": "gaze tracking", "shape": "dot", "size": 10.089285714285714, "title": "gaze tracking"}, {"color": "#6FA8DC", "id": "F. Corno", "label": "F. Corno", "shape": "dot", "size": 10.089285714285714, "title": "F. Corno"}, {"color": "#6FA8DC", "id": "IEEE International Conference on Multimedia and Expo", "label": "IEEE International Conference on Multimedia and Expo", "shape": "dot", "size": 10.178571428571429, "title": "IEEE International Conference on Multimedia and Expo"}, {"color": "#6FA8DC", "id": "E. Guestrin", "label": "E. Guestrin", "shape": "dot", "size": 10.089285714285714, "title": "E. Guestrin"}, {"color": "#6FA8DC", "id": "remote gaze estimation", "label": "remote gaze estimation", "shape": "dot", "size": 10.178571428571429, "title": "remote gaze estimation"}, {"color": "#6FA8DC", "id": "D. Hansen", "label": "D. Hansen", "shape": "dot", "size": 10.089285714285714, "title": "D. Hansen"}, {"color": "#6FA8DC", "id": "models for eyes and gaze", "label": "models for eyes and gaze", "shape": "dot", "size": 10.089285714285714, "title": "models for eyes and gaze"}, {"color": "#6FA8DC", "id": "J. Harel", "label": "J. Harel", "shape": "dot", "size": 10.178571428571429, "title": "J. Harel"}, {"color": "#6FA8DC", "id": "graph-based visual saliency", "label": "graph-based visual saliency", "shape": "dot", "size": 10.178571428571429, "title": "graph-based visual saliency"}, {"color": "#6FA8DC", "id": "X. Hou", "label": "X. Hou", "shape": "dot", "size": 10.178571428571429, "title": "X. Hou"}, {"color": "#6FA8DC", "id": "image signature", "label": "image signature", "shape": "dot", "size": 10.178571428571429, "title": "image signature"}, {"color": "#6FA8DC", "id": "pupil center", "label": "pupil center", "shape": "dot", "size": 10.089285714285714, "title": "pupil center"}, {"color": "#6FA8DC", "id": "neural processing method", "label": "neural processing method", "shape": "dot", "size": 10.089285714285714, "title": "neural processing method"}, {"color": "#6FA8DC", "id": "sparse salient regions", "label": "sparse salient regions", "shape": "dot", "size": 10.089285714285714, "title": "sparse salient regions"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Biomedical Engineering", "label": "IEEE Transactions on Biomedical Engineering", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Transactions on Biomedical Engineering"}, {"color": "#6FA8DC", "id": "research on remote gaze estimation", "label": "research on remote gaze estimation", "shape": "dot", "size": 10.089285714285714, "title": "research on remote gaze estimation"}, {"color": "#6FA8DC", "id": "research on assistive technology", "label": "research on assistive technology", "shape": "dot", "size": 10.089285714285714, "title": "research on assistive technology"}, {"color": "#6FA8DC", "id": "U. Lahiri", "label": "U. Lahiri", "shape": "dot", "size": 10.357142857142858, "title": "U. Lahiri"}, {"color": "#6FA8DC", "id": "Neural Systems and Rehabilitation Engineering, IEEE Transactions on", "label": "Neural Systems and Rehabilitation Engineering, IEEE Transactions on", "shape": "dot", "size": 10.089285714285714, "title": "Neural Systems and Rehabilitation Engineering, IEEE Transactions on"}, {"color": "#6FA8DC", "id": "Virtual Rehabilitation (ICVR)", "label": "Virtual Rehabilitation (ICVR)", "shape": "dot", "size": 10.089285714285714, "title": "Virtual Rehabilitation (ICVR)"}, {"color": "#6FA8DC", "id": "R. Kumar", "label": "R. Kumar", "shape": "dot", "size": 10.089285714285714, "title": "R. Kumar"}, {"color": "#6FA8DC", "id": "Computer Vision and Pattern Recognition", "label": "Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "Google Inc.", "label": "Google Inc.", "shape": "dot", "size": 10.089285714285714, "title": "Google Inc."}, {"color": "#6FA8DC", "id": "The University of North Carolina at Chapel Hill", "label": "The University of North Carolina at Chapel Hill", "shape": "dot", "size": 10.178571428571429, "title": "The University of North Carolina at Chapel Hill"}, {"color": "#6FA8DC", "id": "Jan-Micheal Frahm", "label": "Jan-Micheal Frahm", "shape": "dot", "size": 10.267857142857142, "title": "Jan-Micheal Frahm"}, {"color": "#6FA8DC", "id": "The University of North Carolian at Chapel Hill", "label": "The University of North Carolian at Chapel Hill", "shape": "dot", "size": 10.089285714285714, "title": "The University of North Carolian at Chapel Hill"}, {"color": "#6FA8DC", "id": "children with autism", "label": "children with autism", "shape": "dot", "size": 10.089285714285714, "title": "children with autism"}, {"color": "#6FA8DC", "id": "social communication", "label": "social communication", "shape": "dot", "size": 10.089285714285714, "title": "social communication"}, {"color": "#6FA8DC", "id": "rkgupta@cs.unc.edu", "label": "rkgupta@cs.unc.edu", "shape": "dot", "size": 10.089285714285714, "title": "rkgupta@cs.unc.edu"}, {"color": "#6FA8DC", "id": "jmf@cs.unc.edu", "label": "jmf@cs.unc.edu", "shape": "dot", "size": 10.089285714285714, "title": "jmf@cs.unc.edu"}, {"color": "#6FA8DC", "id": "Nianuan Jiang", "label": "Nianuan Jiang", "shape": "dot", "size": 10.267857142857142, "title": "Nianuan Jiang"}, {"color": "#6FA8DC", "id": "Direct Structure Estimation for 3D Reconstruction", "label": "Direct Structure Estimation for 3D Reconstruction", "shape": "dot", "size": 10.446428571428571, "title": "Direct Structure Estimation for 3D Reconstruction"}, {"color": "#6FA8DC", "id": "Wen-Yan Lin", "label": "Wen-Yan Lin", "shape": "dot", "size": 10.267857142857142, "title": "Wen-Yan Lin"}, {"color": "#6FA8DC", "id": "Direct Structure Estimated for 3D Reconstruction", "label": "Direct Structure Estimated for 3D Reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "Direct Structure Estimated for 3D Reconstruction"}, {"color": "#6FA8DC", "id": "Minh N. Do", "label": "Minh N. Do", "shape": "dot", "size": 10.267857142857142, "title": "Minh N. Do"}, {"color": "#6FA8DC", "id": "Jiangbo Lu", "label": "Jiangbo Lu", "shape": "dot", "size": 10.178571428571429, "title": "Jiangbo Lu"}, {"color": "#6FA8DC", "id": "Jiang_Direct_Structure_Estimation_2015_CVPR_paper.pdf", "label": "Jiang_Direct_Structure_Estimation_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Jiang_Direct_Structure_Estimation_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Structure from Motion (SFM)", "label": "Structure from Motion (SFM)", "shape": "dot", "size": 10.535714285714286, "title": "Structure from Motion (SFM)"}, {"color": "#6FA8DC", "id": "camera pose estimation", "label": "camera pose estimation", "shape": "dot", "size": 10.357142857142858, "title": "camera pose estimation"}, {"color": "#6FA8DC", "id": "Euclidean Rigidity", "label": "Euclidean Rigidity", "shape": "dot", "size": 10.178571428571429, "title": "Euclidean Rigidity"}, {"color": "#6FA8DC", "id": "Direct StructureEstimation (DSE)", "label": "Direct StructureEstimation (DSE)", "shape": "dot", "size": 10.089285714285714, "title": "Direct StructureEstimation (DSE)"}, {"color": "#6FA8DC", "id": "homography estimation", "label": "homography estimation", "shape": "dot", "size": 10.089285714285714, "title": "homography estimation"}, {"color": "#6FA8DC", "id": "Direct Structure Estimation (DSE)", "label": "Direct Structure Estimation (DSE)", "shape": "dot", "size": 10.357142857142858, "title": "Direct Structure Estimation (DSE)"}, {"color": "#6FA8DC", "id": "formulation for scene structure recovery", "label": "formulation for scene structure recovery", "shape": "dot", "size": 10.089285714285714, "title": "formulation for scene structure recovery"}, {"color": "#6FA8DC", "id": "scene structure recovery", "label": "scene structure recovery", "shape": "dot", "size": 10.089285714285714, "title": "scene structure recovery"}, {"color": "#6FA8DC", "id": "recovering scene structure", "label": "recovering scene structure", "shape": "dot", "size": 10.089285714285714, "title": "recovering scene structure"}, {"color": "#6FA8DC", "id": "recovering camera poses", "label": "recovering camera poses", "shape": "dot", "size": 10.089285714285714, "title": "recovering camera poses"}, {"color": "#6FA8DC", "id": "scene structure", "label": "scene structure", "shape": "dot", "size": 10.178571428571429, "title": "scene structure"}, {"color": "#6FA8DC", "id": "sideway motion", "label": "sideway motion", "shape": "dot", "size": 10.089285714285714, "title": "sideway motion"}, {"color": "#6FA8DC", "id": "planar or general man-made scenes", "label": "planar or general man-made scenes", "shape": "dot", "size": 10.089285714285714, "title": "planar or general man-made scenes"}, {"color": "#6FA8DC", "id": "scene reconstruction", "label": "scene reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "scene reconstruction"}, {"color": "#6FA8DC", "id": "Homography Estimation", "label": "Homography Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Homography Estimation"}, {"color": "#6FA8DC", "id": "Camera Pose Estimation", "label": "Camera Pose Estimation", "shape": "dot", "size": 10.178571428571429, "title": "Camera Pose Estimation"}, {"color": "#6FA8DC", "id": "D. Nist\u00e9r", "label": "D. Nist\u00e9r", "shape": "dot", "size": 10.089285714285714, "title": "D. Nist\u00e9r"}, {"color": "#6FA8DC", "id": "solution to five-point relative pose problem", "label": "solution to five-point relative pose problem", "shape": "dot", "size": 10.089285714285714, "title": "solution to five-point relative pose problem"}, {"color": "#6FA8DC", "id": "D. G. Aliaga", "label": "D. G. Aliaga", "shape": "dot", "size": 10.089285714285714, "title": "D. G. Aliaga"}, {"color": "#6FA8DC", "id": "simplifying reconstruction of 3d models", "label": "simplifying reconstruction of 3d models", "shape": "dot", "size": 10.089285714285714, "title": "simplifying reconstruction of 3d models"}, {"color": "#6FA8DC", "id": "K. S. Arun", "label": "K. S. Arun", "shape": "dot", "size": 10.089285714285714, "title": "K. S. Arun"}, {"color": "#6FA8DC", "id": "least-squares fitting of two 3-d point sets", "label": "least-squares fitting of two 3-d point sets", "shape": "dot", "size": 10.089285714285714, "title": "least-squares fitting of two 3-d point sets"}, {"color": "#6FA8DC", "id": "D. Crandall", "label": "D. Crandall", "shape": "dot", "size": 10.089285714285714, "title": "D. Crandall"}, {"color": "#6FA8DC", "id": "discrete-continuous optimization", "label": "discrete-continuous optimization", "shape": "dot", "size": 10.089285714285714, "title": "discrete-continuous optimization"}, {"color": "#6FA8DC", "id": "D. W. Eggert", "label": "D. W. Eggert", "shape": "dot", "size": 10.178571428571429, "title": "D. W. Eggert"}, {"color": "#6FA8DC", "id": "comparison of four major algorithms", "label": "comparison of four major algorithms", "shape": "dot", "size": 10.089285714285714, "title": "comparison of four major algorithms"}, {"color": "#6FA8DC", "id": "least-squares fitting", "label": "least-squares fitting", "shape": "dot", "size": 10.089285714285714, "title": "least-squares fitting"}, {"color": "#6FA8DC", "id": "3d point set alignment", "label": "3d point set alignment", "shape": "dot", "size": 10.089285714285714, "title": "3d point set alignment"}, {"color": "#6FA8DC", "id": "Estimating 3-d rigid body transformations", "label": "Estimating 3-d rigid body transformations", "shape": "dot", "size": 10.089285714285714, "title": "Estimating 3-d rigid body transformations"}, {"color": "#6FA8DC", "id": "M. A. Fischler", "label": "M. A. Fischler", "shape": "dot", "size": 10.089285714285714, "title": "M. A. Fischler"}, {"color": "#6FA8DC", "id": "Random sample consensus", "label": "Random sample consensus", "shape": "dot", "size": 10.535714285714286, "title": "Random sample consensus"}, {"color": "#6FA8DC", "id": "Communications of the ACM", "label": "Communications of the ACM", "shape": "dot", "size": 10.089285714285714, "title": "Communications of the ACM"}, {"color": "#6FA8DC", "id": "Advanced Digital Sciences Center", "label": "Advanced Digital Sciences Center", "shape": "dot", "size": 10.535714285714286, "title": "Advanced Digital Sciences Center"}, {"color": "#6FA8DC", "id": "Structure from motion", "label": "Structure from motion", "shape": "dot", "size": 10.089285714285714, "title": "Structure from motion"}, {"color": "#6FA8DC", "id": "R. Hartley", "label": "R. Hartley", "shape": "dot", "size": 10.089285714285714, "title": "R. Hartley"}, {"color": "#6FA8DC", "id": "In defense of the eight-point algorithm", "label": "In defense of the eight-point algorithm", "shape": "dot", "size": 10.089285714285714, "title": "In defense of the eight-point algorithm"}, {"color": "#6FA8DC", "id": "H. Isack", "label": "H. Isack", "shape": "dot", "size": 10.089285714285714, "title": "H. Isack"}, {"color": "#6FA8DC", "id": "Energy-based geometric multi-model fitting", "label": "Energy-based geometric multi-model fitting", "shape": "dot", "size": 10.089285714285714, "title": "Energy-based geometric multi-model fitting"}, {"color": "#6FA8DC", "id": "N. Jiang", "label": "N. Jiang", "shape": "dot", "size": 10.089285714285714, "title": "N. Jiang"}, {"color": "#6FA8DC", "id": "A global linear method for camera pose registration", "label": "A global linear method for camera pose registration", "shape": "dot", "size": 10.089285714285714, "title": "A global linear method for camera pose registration"}, {"color": "#6FA8DC", "id": "Advanced Digital Sciences Center, Singapore", "label": "Advanced Digital Sciences Center, Singapore", "shape": "dot", "size": 10.267857142857142, "title": "Advanced Digital Sciences Center, Singapore"}, {"color": "#6FA8DC", "id": "University of Illinois at Urbana-Champaign", "label": "University of Illinois at Urbana-Champaign", "shape": "dot", "size": 10.535714285714286, "title": "University of Illinois at Urbana-Champaign"}, {"color": "#6FA8DC", "id": "Stefan Roth", "label": "Stefan Roth", "shape": "dot", "size": 10.625, "title": "Stefan Roth"}, {"color": "#6FA8DC", "id": "Richter_Discriminative_Shape_From_2015_CVPR_supplemental", "label": "Richter_Discriminative_Shape_From_2015_CVPR_supplemental", "shape": "dot", "size": 10.357142857142858, "title": "Richter_Discriminative_Shape_From_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "Discriminative Shape from Shading", "label": "Discriminative Shape from Shading", "shape": "dot", "size": 10.089285714285714, "title": "Discriminative Shape from Shading"}, {"color": "#6FA8DC", "id": "Shape from shading method", "label": "Shape from shading method", "shape": "dot", "size": 10.446428571428571, "title": "Shape from shading method"}, {"color": "#6FA8DC", "id": "other approaches", "label": "other approaches", "shape": "dot", "size": 10.089285714285714, "title": "other approaches"}, {"color": "#6FA8DC", "id": "local context", "label": "local context", "shape": "dot", "size": 10.178571428571429, "title": "local context"}, {"color": "#6FA8DC", "id": "learning framework", "label": "learning framework", "shape": "dot", "size": 10.089285714285714, "title": "learning framework"}, {"color": "#6FA8DC", "id": "improved reconstructions", "label": "improved reconstructions", "shape": "dot", "size": 10.089285714285714, "title": "improved reconstructions"}, {"color": "#6FA8DC", "id": "smooth local context", "label": "smooth local context", "shape": "dot", "size": 10.089285714285714, "title": "smooth local context"}, {"color": "#6FA8DC", "id": "Results", "label": "Results", "shape": "dot", "size": 10.089285714285714, "title": "Results"}, {"color": "#6FA8DC", "id": "real images", "label": "real images", "shape": "dot", "size": 10.089285714285714, "title": "real images"}, {"color": "#6FA8DC", "id": "unknown reflectance maps", "label": "unknown reflectance maps", "shape": "dot", "size": 10.089285714285714, "title": "unknown reflectance maps"}, {"color": "#6FA8DC", "id": "fine detail", "label": "fine detail", "shape": "dot", "size": 10.089285714285714, "title": "fine detail"}, {"color": "#6FA8DC", "id": "Dataset", "label": "Dataset", "shape": "dot", "size": 10.267857142857142, "title": "Dataset"}, {"color": "#6FA8DC", "id": "ground truth dataset", "label": "ground truth dataset", "shape": "dot", "size": 10.089285714285714, "title": "ground truth dataset"}, {"color": "#6FA8DC", "id": "real objects", "label": "real objects", "shape": "dot", "size": 10.089285714285714, "title": "real objects"}, {"color": "#6FA8DC", "id": "Shape from Shading", "label": "Shape from Shading", "shape": "dot", "size": 10.535714285714286, "title": "Shape from Shading"}, {"color": "#6FA8DC", "id": "Surface Reconstruction", "label": "Surface Reconstruction", "shape": "dot", "size": 10.446428571428571, "title": "Surface Reconstruction"}, {"color": "#6FA8DC", "id": "Illumination Estimation", "label": "Illumination Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Illumination Estimation"}, {"color": "#6FA8DC", "id": "Local and Global Context", "label": "Local and Global Context", "shape": "dot", "size": 10.089285714285714, "title": "Local and Global Context"}, {"color": "#6FA8DC", "id": "Machine Learning", "label": "Machine Learning", "shape": "dot", "size": 10.803571428571429, "title": "Machine Learning"}, {"color": "#6FA8DC", "id": "Barron, J. T., \u0026 Malik, J.", "label": "Barron, J. T., \u0026 Malik, J.", "shape": "dot", "size": 10.089285714285714, "title": "Barron, J. T., \u0026 Malik, J."}, {"color": "#6FA8DC", "id": "Color Constancy", "label": "Color Constancy", "shape": "dot", "size": 10.089285714285714, "title": "Color Constancy"}, {"color": "#6FA8DC", "id": "Johnson, M. K., \u0026 Adelson, E. H.", "label": "Johnson, M. K., \u0026 Adelson, E. H.", "shape": "dot", "size": 10.178571428571429, "title": "Johnson, M. K., \u0026 Adelson, E. H."}, {"color": "#6FA8DC", "id": "Shape Estimation", "label": "Shape Estimation", "shape": "dot", "size": 10.267857142857142, "title": "Shape Estimation"}, {"color": "#6FA8DC", "id": "Natural Illumination", "label": "Natural Illumination", "shape": "dot", "size": 10.089285714285714, "title": "Natural Illumination"}, {"color": "#6FA8DC", "id": "Reflectance Maps", "label": "Reflectance Maps", "shape": "dot", "size": 10.089285714285714, "title": "Reflectance Maps"}, {"color": "#6FA8DC", "id": "Fine Detail", "label": "Fine Detail", "shape": "dot", "size": 10.089285714285714, "title": "Fine Detail"}, {"color": "#6FA8DC", "id": "Real Objects", "label": "Real Objects", "shape": "dot", "size": 10.089285714285714, "title": "Real Objects"}, {"color": "#6FA8DC", "id": "Johnson \u0026 Adelson (2011) paper", "label": "Johnson \u0026 Adelson (2011) paper", "shape": "dot", "size": 10.089285714285714, "title": "Johnson \u0026 Adelson (2011) paper"}, {"color": "#6FA8DC", "id": "reference [4]", "label": "reference [4]", "shape": "dot", "size": 10.267857142857142, "title": "reference [4]"}, {"color": "#6FA8DC", "id": "reference [3]", "label": "reference [3]", "shape": "dot", "size": 10.089285714285714, "title": "reference [3]"}, {"color": "#6FA8DC", "id": "reference [1]", "label": "reference [1]", "shape": "dot", "size": 10.089285714285714, "title": "reference [1]"}, {"color": "#6FA8DC", "id": "Jacobs, D. W.", "label": "Jacobs, D. W.", "shape": "dot", "size": 10.089285714285714, "title": "Jacobs, D. W."}, {"color": "#6FA8DC", "id": "Basri, R.", "label": "Basri, R.", "shape": "dot", "size": 10.089285714285714, "title": "Basri, R."}, {"color": "#6FA8DC", "id": "Stephan R. Richter", "label": "Stephan R. Richter", "shape": "dot", "size": 10.535714285714286, "title": "Stephan R. Richter"}, {"color": "#6FA8DC", "id": "Department of Computer Science, TU Darmstadt", "label": "Department of Computer Science, TU Darmstadt", "shape": "dot", "size": 10.357142857142858, "title": "Department of Computer Science, TU Darmstadt"}, {"color": "#6FA8DC", "id": "TU Darmstadt", "label": "TU Darmstadt", "shape": "dot", "size": 10.267857142857142, "title": "TU Darmstadt"}, {"color": "#6FA8DC", "id": "Andr\u00e1s B\u00f3dis-Sz\u0151m\u0151ru", "label": "Andr\u00e1s B\u00f3dis-Sz\u0151m\u0151ru", "shape": "dot", "size": 10.089285714285714, "title": "Andr\u00e1s B\u00f3dis-Sz\u0151m\u0151ru"}, {"color": "#6FA8DC", "id": "Superpixel Meshes", "label": "Superpixel Meshes", "shape": "dot", "size": 10.625, "title": "Superpixel Meshes"}, {"color": "#6FA8DC", "id": "Hayko Riemenschneider", "label": "Hayko Riemenschneider", "shape": "dot", "size": 10.178571428571429, "title": "Hayko Riemenschneider"}, {"color": "#6FA8DC", "id": "Superpixel Meses", "label": "Superpixel Meses", "shape": "dot", "size": 10.089285714285714, "title": "Superpixel Meses"}, {"color": "#6FA8DC", "id": "Luc Van Gool", "label": "Luc Van Gool", "shape": "dot", "size": 10.535714285714286, "title": "Luc Van Gool"}, {"color": "#6FA8DC", "id": "surface reconstruction", "label": "surface reconstruction", "shape": "dot", "size": 10.267857142857142, "title": "surface reconstruction"}, {"color": "#6FA8DC", "id": "edges", "label": "edges", "shape": "dot", "size": 10.089285714285714, "title": "edges"}, {"color": "#6FA8DC", "id": "Bodis-Szomoru_Superpixel_Meshes_for_2015_CVPR_supplemental.pdf", "label": "Bodis-Szomoru_Superpixel_Meshes_for_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Bodis-Szomoru_Superpixel_Meshes_for_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Multi-View-Stereo methods", "label": "Multi-View-Stereo methods", "shape": "dot", "size": 10.089285714285714, "title": "Multi-View-Stereo methods"}, {"color": "#6FA8DC", "id": "highest detail", "label": "highest detail", "shape": "dot", "size": 10.089285714285714, "title": "highest detail"}, {"color": "#6FA8DC", "id": "surface reconstruction method", "label": "surface reconstruction method", "shape": "dot", "size": 10.178571428571429, "title": "surface reconstruction method"}, {"color": "#6FA8DC", "id": "image edges", "label": "image edges", "shape": "dot", "size": 10.089285714285714, "title": "image edges"}, {"color": "#6FA8DC", "id": "second-order smoothness constraints", "label": "second-order smoothness constraints", "shape": "dot", "size": 10.089285714285714, "title": "second-order smoothness constraints"}, {"color": "#6FA8DC", "id": "meshes", "label": "meshes", "shape": "dot", "size": 10.357142857142858, "title": "meshes"}, {"color": "#6FA8DC", "id": "classic MVS surfaces", "label": "classic MVS surfaces", "shape": "dot", "size": 10.089285714285714, "title": "classic MVS surfaces"}, {"color": "#6FA8DC", "id": "dense depth optimization", "label": "dense depth optimization", "shape": "dot", "size": 10.178571428571429, "title": "dense depth optimization"}, {"color": "#6FA8DC", "id": "Ground Control Points", "label": "Ground Control Points", "shape": "dot", "size": 10.089285714285714, "title": "Ground Control Points"}, {"color": "#6FA8DC", "id": "view pairing", "label": "view pairing", "shape": "dot", "size": 10.089285714285714, "title": "view pairing"}, {"color": "#6FA8DC", "id": "stereo depth estimation", "label": "stereo depth estimation", "shape": "dot", "size": 10.089285714285714, "title": "stereo depth estimation"}, {"color": "#6FA8DC", "id": "per-image paralleization", "label": "per-image paralleization", "shape": "dot", "size": 10.089285714285714, "title": "per-image paralleization"}, {"color": "#6FA8DC", "id": "SfM points", "label": "SfM points", "shape": "dot", "size": 10.178571428571429, "title": "SfM points"}, {"color": "#6FA8DC", "id": "GCPs", "label": "GCPs", "shape": "dot", "size": 10.357142857142858, "title": "GCPs"}, {"color": "#6FA8DC", "id": "LiDAR", "label": "LiDAR", "shape": "dot", "size": 10.089285714285714, "title": "LiDAR"}, {"color": "#6FA8DC", "id": "RGB-D", "label": "RGB-D", "shape": "dot", "size": 10.089285714285714, "title": "RGB-D"}, {"color": "#6FA8DC", "id": "edge-aligned", "label": "edge-aligned", "shape": "dot", "size": 10.089285714285714, "title": "edge-aligned"}, {"color": "#6FA8DC", "id": "Structure-from-Motion (SfM) points", "label": "Structure-from-Motion (SfM) points", "shape": "dot", "size": 10.089285714285714, "title": "Structure-from-Motion (SfM) points"}, {"color": "#6FA8DC", "id": "compact", "label": "compact", "shape": "dot", "size": 10.089285714285714, "title": "compact"}, {"color": "#6FA8DC", "id": "image gradients", "label": "image gradients", "shape": "dot", "size": 10.089285714285714, "title": "image gradients"}, {"color": "#6FA8DC", "id": "renderings", "label": "renderings", "shape": "dot", "size": 10.178571428571429, "title": "renderings"}, {"color": "#6FA8DC", "id": "lightweight", "label": "lightweight", "shape": "dot", "size": 10.089285714285714, "title": "lightweight"}, {"color": "#6FA8DC", "id": "per-face flat", "label": "per-face flat", "shape": "dot", "size": 10.089285714285714, "title": "per-face flat"}, {"color": "#6FA8DC", "id": "superiority in speed", "label": "superiority in speed", "shape": "dot", "size": 10.089285714285714, "title": "superiority in speed"}, {"color": "#6FA8DC", "id": "competitive surface quality", "label": "competitive surface quality", "shape": "dot", "size": 10.089285714285714, "title": "competitive surface quality"}, {"color": "#6FA8DC", "id": "Zhang_Light_Field_From_2015_CVPR_paper", "label": "Zhang_Light_Field_From_2015_CVPR_paper", "shape": "dot", "size": 10.535714285714286, "title": "Zhang_Light_Field_From_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Superpixels", "label": "Superpixels", "shape": "dot", "size": 10.178571428571429, "title": "Superpixels"}, {"color": "#6FA8DC", "id": "Zhang_Light_Light_Field_From_2015_CVPR_paper", "label": "Zhang_Light_Light_Field_From_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Zhang_Light_Light_Field_From_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Structure-from-Motion (SfM)", "label": "Structure-from-Motion (SfM)", "shape": "dot", "size": 10.089285714285714, "title": "Structure-from-Motion (SfM)"}, {"color": "#6FA8DC", "id": "Mesh Generation", "label": "Mesh Generation", "shape": "dot", "size": 10.089285714285714, "title": "Mesh Generation"}, {"color": "#6FA8DC", "id": "Edge-Preerving Methods", "label": "Edge-Preerving Methods", "shape": "dot", "size": 10.089285714285714, "title": "Edge-Preerving Methods"}, {"color": "#6FA8DC", "id": "Andr\u00b4as B\u00b4odis-Szomor\u00b4u", "label": "Andr\u00b4as B\u00b4odis-Szomor\u00b4u", "shape": "dot", "size": 10.089285714285714, "title": "Andr\u00b4as B\u00b4odis-Szomor\u00b4u"}, {"color": "#6FA8DC", "id": "ETH Zurich, Computer Vision Lab", "label": "ETH Zurich, Computer Vision Lab", "shape": "dot", "size": 10.178571428571429, "title": "ETH Zurich, Computer Vision Lab"}, {"color": "#6FA8DC", "id": "PSI-VISICS, KU Leuven", "label": "PSI-VISICS, KU Leuven", "shape": "dot", "size": 10.089285714285714, "title": "PSI-VISICS, KU Leuven"}, {"color": "#6FA8DC", "id": "Didyk et.al", "label": "Didyk et.al", "shape": "dot", "size": 10.089285714285714, "title": "Didyk et.al"}, {"color": "#6FA8DC", "id": "surface quality", "label": "surface quality", "shape": "dot", "size": 10.089285714285714, "title": "surface quality"}, {"color": "#6FA8DC", "id": "depth estimation", "label": "depth estimation", "shape": "dot", "size": 10.089285714285714, "title": "depth estimation"}, {"color": "#6FA8DC", "id": "synthesizing intermediate views", "label": "synthesizing intermediate views", "shape": "dot", "size": 10.089285714285714, "title": "synthesizing intermediate views"}, {"color": "#6FA8DC", "id": "intermediate views", "label": "intermediate views", "shape": "dot", "size": 10.089285714285714, "title": "intermediate views"}, {"color": "#6FA8DC", "id": "light field synthesis", "label": "light field synthesis", "shape": "dot", "size": 10.089285714285714, "title": "light field synthesis"}, {"color": "#6FA8DC", "id": "work on depth", "label": "work on depth", "shape": "dot", "size": 10.089285714285714, "title": "work on depth"}, {"color": "#6FA8DC", "id": "synthesized right views", "label": "synthesized right views", "shape": "dot", "size": 10.089285714285714, "title": "synthesized right views"}, {"color": "#6FA8DC", "id": "disparity refinement", "label": "disparity refinement", "shape": "dot", "size": 10.089285714285714, "title": "disparity refinement"}, {"color": "#6FA8DC", "id": "depth perception", "label": "depth perception", "shape": "dot", "size": 10.089285714285714, "title": "depth perception"}, {"color": "#6FA8DC", "id": "improvements", "label": "improvements", "shape": "dot", "size": 10.178571428571429, "title": "improvements"}, {"color": "#6FA8DC", "id": "Depth Estimation", "label": "Depth Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Depth Estimation"}, {"color": "#6FA8DC", "id": "existing methods", "label": "existing methods", "shape": "dot", "size": 10.446428571428571, "title": "existing methods"}, {"color": "#6FA8DC", "id": "View Synthesis", "label": "View Synthesis", "shape": "dot", "size": 10.089285714285714, "title": "View Synthesis"}, {"color": "#6FA8DC", "id": "Light Field Reconstruction", "label": "Light Field Reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "Light Field Reconstruction"}, {"color": "#6FA8DC", "id": "Disparity Refinement", "label": "Disparity Refinement", "shape": "dot", "size": 10.089285714285714, "title": "Disparity Refinement"}, {"color": "#6FA8DC", "id": "Iterative View Generation", "label": "Iterative View Generation", "shape": "dot", "size": 10.089285714285714, "title": "Iterative View Generation"}, {"color": "#6FA8DC", "id": "Jan Hosang", "label": "Jan Hosang", "shape": "dot", "size": 10.089285714285714, "title": "Jan Hosang"}, {"color": "#6FA8DC", "id": "Taking a Deeper Look at Pedestrians", "label": "Taking a Deeper Look at Pedestrians", "shape": "dot", "size": 10.446428571428571, "title": "Taking a Deeper Look at Pedestrians"}, {"color": "#6FA8DC", "id": "Mohamed Omran", "label": "Mohamed Omran", "shape": "dot", "size": 10.178571428571429, "title": "Mohamed Omran"}, {"color": "#6FA8DC", "id": "impact of parameters", "label": "impact of parameters", "shape": "dot", "size": 10.089285714285714, "title": "impact of parameters"}, {"color": "#6FA8DC", "id": "CifarNet", "label": "CifarNet", "shape": "dot", "size": 10.089285714285714, "title": "CifarNet"}, {"color": "#6FA8DC", "id": "AlexNet", "label": "AlexNet", "shape": "dot", "size": 10.982142857142858, "title": "AlexNet"}, {"color": "#6FA8DC", "id": "filter size", "label": "filter size", "shape": "dot", "size": 10.089285714285714, "title": "filter size"}, {"color": "#6FA8DC", "id": "layer width", "label": "layer width", "shape": "dot", "size": 10.089285714285714, "title": "layer width"}, {"color": "#6FA8DC", "id": "learning rate policies", "label": "learning rate policies", "shape": "dot", "size": 10.089285714285714, "title": "learning rate policies"}, {"color": "#6FA8DC", "id": "pedestrian heights", "label": "pedestrian heights", "shape": "dot", "size": 10.267857142857142, "title": "pedestrian heights"}, {"color": "#6FA8DC", "id": "Calttech dataset", "label": "Calttech dataset", "shape": "dot", "size": 10.089285714285714, "title": "Calttech dataset"}, {"color": "#6FA8DC", "id": "KITTI dataset", "label": "KITTI dataset", "shape": "dot", "size": 10.535714285714286, "title": "KITTI dataset"}, {"color": "#6FA8DC", "id": "transferability", "label": "transferability", "shape": "dot", "size": 10.089285714285714, "title": "transferability"}, {"color": "#6FA8DC", "id": "neural network training", "label": "neural network training", "shape": "dot", "size": 10.089285714285714, "title": "neural network training"}, {"color": "#6FA8DC", "id": "parameter choices", "label": "parameter choices", "shape": "dot", "size": 10.089285714285714, "title": "parameter choices"}, {"color": "#6FA8DC", "id": "parameter optimization", "label": "parameter optimization", "shape": "dot", "size": 10.089285714285714, "title": "parameter optimization"}, {"color": "#6FA8DC", "id": "optimal results", "label": "optimal results", "shape": "dot", "size": 10.178571428571429, "title": "optimal results"}, {"color": "#6FA8DC", "id": "Pedestrian Detection", "label": "Pedestrian Detection", "shape": "dot", "size": 10.178571428571429, "title": "Pedestrian Detection"}, {"color": "#6FA8DC", "id": "Neural Network Training", "label": "Neural Network Training", "shape": "dot", "size": 10.267857142857142, "title": "Neural Network Training"}, {"color": "#6FA8DC", "id": "Parameter Optimization", "label": "Parameter Optimization", "shape": "dot", "size": 10.178571428571429, "title": "Parameter Optimization"}, {"color": "#6FA8DC", "id": "Dataset Analysis", "label": "Dataset Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Dataset Analysis"}, {"color": "#6FA8DC", "id": "Transfer Learning", "label": "Transfer Learning", "shape": "dot", "size": 10.089285714285714, "title": "Transfer Learning"}, {"color": "#6FA8DC", "id": "Benenson, R.", "label": "Benenson, R.", "shape": "dot", "size": 10.178571428571429, "title": "Benenson, R."}, {"color": "#6FA8DC", "id": "Max Planck Institute for Informatics", "label": "Max Planck Institute for Informatics", "shape": "dot", "size": 10.982142857142858, "title": "Max Planck Institute for Informatics"}, {"color": "#6FA8DC", "id": "Omran, M.", "label": "Omran, M.", "shape": "dot", "size": 10.178571428571429, "title": "Omran, M."}, {"color": "#6FA8DC", "id": "Schiele, B.", "label": "Schiele, B.", "shape": "dot", "size": 10.178571428571429, "title": "Schiele, B."}, {"color": "#6FA8DC", "id": "Hosang, J.", "label": "Hosang, J.", "shape": "dot", "size": 10.089285714285714, "title": "Hosang, J."}, {"color": "#6FA8DC", "id": "jan.hosang@mpi-inf.mpg.de", "label": "jan.hosang@mpi-inf.mpg.de", "shape": "dot", "size": 10.089285714285714, "title": "jan.hosang@mpi-inf.mpg.de"}, {"color": "#6FA8DC", "id": "mohamed.omran@mpi-inf.mpg.de", "label": "mohamed.omran@mpi-inf.mpg.de", "shape": "dot", "size": 10.089285714285714, "title": "mohamed.omran@mpi-inf.mpg.de"}, {"color": "#6FA8DC", "id": "rodrigo.benenson@mpi-inf.mpg.de", "label": "rodrigo.benenson@mpi-inf.mpg.de", "shape": "dot", "size": 10.089285714285714, "title": "rodrigo.benenson@mpi-inf.mpg.de"}, {"color": "#6FA8DC", "id": "unspecified", "label": "unspecified", "shape": "dot", "size": 10.089285714285714, "title": "unspecified"}, {"color": "#6FA8DC", "id": "Kiyoshi Matsuo", "label": "Kiyoshi Matsuo", "shape": "dot", "size": 10.178571428571429, "title": "Kiyoshi Matsuo"}, {"color": "#6FA8DC", "id": "Depth Image Enhancement Using Local Tangent Plane Approximations", "label": "Depth Image Enhancement Using Local Tangent Plane Approximations", "shape": "dot", "size": 10.357142857142858, "title": "Depth Image Enhancement Using Local Tangent Plane Approximations"}, {"color": "#6FA8DC", "id": "informatics", "label": "informatics", "shape": "dot", "size": 10.089285714285714, "title": "informatics"}, {"color": "#6FA8DC", "id": "Yoshimitsu Aoki", "label": "Yoshimitsu Aoki", "shape": "dot", "size": 10.178571428571429, "title": "Yoshimitsu Aoki"}, {"color": "#6FA8DC", "id": "depth image enhancement method", "label": "depth image enhancement method", "shape": "dot", "size": 10.178571428571429, "title": "depth image enhancement method"}, {"color": "#6FA8DC", "id": "consumer RGB-D cameras", "label": "consumer RGB-D cameras", "shape": "dot", "size": 10.089285714285714, "title": "consumer RGB-D cameras"}, {"color": "#6FA8DC", "id": "pixel-coordinates", "label": "pixel-coordinates", "shape": "dot", "size": 10.178571428571429, "title": "pixel-coordinates"}, {"color": "#6FA8DC", "id": "handling local geometries", "label": "handling local geometries", "shape": "dot", "size": 10.089285714285714, "title": "handling local geometries"}, {"color": "#6FA8DC", "id": "local tangent planes", "label": "local tangent planes", "shape": "dot", "size": 10.089285714285714, "title": "local tangent planes"}, {"color": "#6FA8DC", "id": "two steps", "label": "two steps", "shape": "dot", "size": 10.267857142857142, "title": "two steps"}, {"color": "#6FA8DC", "id": "calculation of local tangents", "label": "calculation of local tangents", "shape": "dot", "size": 10.089285714285714, "title": "calculation of local tangents"}, {"color": "#6FA8DC", "id": "depth image enhancement", "label": "depth image enhancement", "shape": "dot", "size": 10.089285714285714, "title": "depth image enhancement"}, {"color": "#6FA8DC", "id": "local geometries", "label": "local geometries", "shape": "dot", "size": 10.089285714285714, "title": "local geometries"}, {"color": "#6FA8DC", "id": "high completion rate", "label": "high completion rate", "shape": "dot", "size": 10.178571428571429, "title": "high completion rate"}, {"color": "#6FA8DC", "id": "lowest errors", "label": "lowest errors", "shape": "dot", "size": 10.178571428571429, "title": "lowest errors"}, {"color": "#6FA8DC", "id": "noisy cases", "label": "noisy cases", "shape": "dot", "size": 10.089285714285714, "title": "noisy cases"}, {"color": "#6FA8DC", "id": "Local Tangent Planes", "label": "Local Tangent Planes", "shape": "dot", "size": 10.089285714285714, "title": "Local Tangent Planes"}, {"color": "#6FA8DC", "id": "Depth Image Enhancement", "label": "Depth Image Enhancement", "shape": "dot", "size": 10.089285714285714, "title": "Depth Image Enhancement"}, {"color": "#6FA8DC", "id": "RGB-D Cameras", "label": "RGB-D Cameras", "shape": "dot", "size": 10.267857142857142, "title": "RGB-D Cameras"}, {"color": "#6FA8DC", "id": "Noise Reduction", "label": "Noise Reduction", "shape": "dot", "size": 10.089285714285714, "title": "Noise Reduction"}, {"color": "#6FA8DC", "id": "Completion Rate", "label": "Completion Rate", "shape": "dot", "size": 10.089285714285714, "title": "Completion Rate"}, {"color": "#6FA8DC", "id": "Asus Xtion Pro Live", "label": "Asus Xtion Pro Live", "shape": "dot", "size": 10.089285714285714, "title": "Asus Xtion Pro Live"}, {"color": "#6FA8DC", "id": "Kim et al. (2013)", "label": "Kim et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Kim et al. (2013)"}, {"color": "#6FA8DC", "id": "joint intensity and depth analysis model", "label": "joint intensity and depth analysis model", "shape": "dot", "size": 10.089285714285714, "title": "joint intensity and depth analysis model"}, {"color": "#6FA8DC", "id": "Kim et al. (2014)", "label": "Kim et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Kim et al. (2014)"}, {"color": "#6FA8DC", "id": "depth map upsampling", "label": "depth map upsampling", "shape": "dot", "size": 10.089285714285714, "title": "depth map upsampling"}, {"color": "#6FA8DC", "id": "Lee et al.", "label": "Lee et al.", "shape": "dot", "size": 10.089285714285714, "title": "Lee et al."}, {"color": "#6FA8DC", "id": "Journal of Signal Processing Systems", "label": "Journal of Signal Processing Systems", "shape": "dot", "size": 10.089285714285714, "title": "Journal of Signal Processing Systems"}, {"color": "#6FA8DC", "id": "depth map upsampling method", "label": "depth map upsampling method", "shape": "dot", "size": 10.089285714285714, "title": "depth map upsampling method"}, {"color": "#6FA8DC", "id": "misalignment of depth and color boundaries", "label": "misalignment of depth and color boundaries", "shape": "dot", "size": 10.089285714285714, "title": "misalignment of depth and color boundaries"}, {"color": "#6FA8DC", "id": "Kopf et al.", "label": "Kopf et al.", "shape": "dot", "size": 10.089285714285714, "title": "Kopf et al."}, {"color": "#6FA8DC", "id": "Joint bilateral upsampling", "label": "Joint bilateral upsampling", "shape": "dot", "size": 10.178571428571429, "title": "Joint bilateral upsampling"}, {"color": "#6FA8DC", "id": "Li et al.", "label": "Li et al.", "shape": "dot", "size": 10.089285714285714, "title": "Li et al."}, {"color": "#6FA8DC", "id": "Joint example-based depth map super-resolution", "label": "Joint example-based depth map super-resolution", "shape": "dot", "size": 10.178571428571429, "title": "Joint example-based depth map super-resolution"}, {"color": "#6FA8DC", "id": "Lu et al.", "label": "Lu et al.", "shape": "dot", "size": 10.089285714285714, "title": "Lu et al."}, {"color": "#6FA8DC", "id": "Depth enhancement", "label": "Depth enhancement", "shape": "dot", "size": 10.178571428571429, "title": "Depth enhancement"}, {"color": "#6FA8DC", "id": "low-rank matrix completion", "label": "low-rank matrix completion", "shape": "dot", "size": 10.089285714285714, "title": "low-rank matrix completion"}, {"color": "#6FA8DC", "id": "upsampling method", "label": "upsampling method", "shape": "dot", "size": 10.089285714285714, "title": "upsampling method"}, {"color": "#6FA8DC", "id": "depth map resolution", "label": "depth map resolution", "shape": "dot", "size": 10.089285714285714, "title": "depth map resolution"}, {"color": "#6FA8DC", "id": "Joint geodesic up-sampling", "label": "Joint geodesic up-sampling", "shape": "dot", "size": 10.089285714285714, "title": "Joint geodesic up-sampling"}, {"color": "#6FA8DC", "id": "depth images", "label": "depth images", "shape": "dot", "size": 10.089285714285714, "title": "depth images"}, {"color": "#6FA8DC", "id": "S. Lu", "label": "S. Lu", "shape": "dot", "size": 10.178571428571429, "title": "S. Lu"}, {"color": "#6FA8DC", "id": "Depth enhancement via low-rank matrix completion", "label": "Depth enhancement via low-rank matrix completion", "shape": "dot", "size": 10.089285714285714, "title": "Depth enhancement via low-rank matrix completion"}, {"color": "#6FA8DC", "id": "CVPR 2014", "label": "CVPR 2014", "shape": "dot", "size": 10.089285714285714, "title": "CVPR 2014"}, {"color": "#6FA8DC", "id": "D. Scharstein", "label": "D. Scharstein", "shape": "dot", "size": 10.089285714285714, "title": "D. Scharstein"}, {"color": "#6FA8DC", "id": "Learning conditional random fields for stereo", "label": "Learning conditional random fields for stereo", "shape": "dot", "size": 10.089285714285714, "title": "Learning conditional random fields for stereo"}, {"color": "#6FA8DC", "id": "J. Papon", "label": "J. Papon", "shape": "dot", "size": 10.178571428571429, "title": "J. Papon"}, {"color": "#6FA8DC", "id": "Point cloud video object segmentation", "label": "Point cloud video object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Point cloud video object segmentation"}, {"color": "#6FA8DC", "id": "IROS 2013", "label": "IROS 2013", "shape": "dot", "size": 10.089285714285714, "title": "IROS 2013"}, {"color": "#6FA8DC", "id": "Keio University", "label": "Keio University", "shape": "dot", "size": 10.089285714285714, "title": "Keio University"}, {"color": "#6FA8DC", "id": "Hokuyo Automatic Co., LTD.", "label": "Hokuyo Automatic Co., LTD.", "shape": "dot", "size": 10.089285714285714, "title": "Hokuyo Automatic Co., LTD."}, {"color": "#6FA8DC", "id": "Sean Bell", "label": "Sean Bell", "shape": "dot", "size": 10.625, "title": "Sean Bell"}, {"color": "#6FA8DC", "id": "Material Recognition in the Wild", "label": "Material Recognition in the Wild", "shape": "dot", "size": 10.267857142857142, "title": "Material Recognition in the Wild"}, {"color": "#6FA8DC", "id": "Paul Upchurch", "label": "Paul Upchurch", "shape": "dot", "size": 10.357142857142858, "title": "Paul Upchurch"}, {"color": "#6FA8DC", "id": "Materials in Context Database", "label": "Materials in Context Database", "shape": "dot", "size": 10.178571428571429, "title": "Materials in Context Database"}, {"color": "#6FA8DC", "id": "Material Recognition in 2015 CVPR paper", "label": "Material Recognition in 2015 CVPR paper", "shape": "dot", "size": 10.535714285714286, "title": "Material Recognition in 2015 CVPR paper"}, {"color": "#6FA8DC", "id": "Noah Snavely", "label": "Noah Snavely", "shape": "dot", "size": 10.357142857142858, "title": "Noah Snavely"}, {"color": "#6FA8DC", "id": "Material recognition in 2015 CVPR paper", "label": "Material recognition in 2015 CVPR paper", "shape": "dot", "size": 10.089285714285714, "title": "Material recognition in 2015 CVPR paper"}, {"color": "#6FA8DC", "id": "Material Recognition", "label": "Material Recognition", "shape": "dot", "size": 10.357142857142858, "title": "Material Recognition"}, {"color": "#6FA8DC", "id": "Bell_Material_Recognition_in_2015_CVPR_paper", "label": "Bell_Material_Recognition_in_2015_CVPR_paper", "shape": "dot", "size": 10.267857142857142, "title": "Bell_Material_Recognition_in_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Bell_Material_Detection_in_2015_CVPR_paper", "label": "Bell_Material_Detection_in_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Bell_Material_Detection_in_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "material recognition", "label": "material recognition", "shape": "dot", "size": 10.357142857142858, "title": "material recognition"}, {"color": "#6FA8DC", "id": "rich surface texture", "label": "rich surface texture", "shape": "dot", "size": 10.089285714285714, "title": "rich surface texture"}, {"color": "#6FA8DC", "id": "lighting conditions", "label": "lighting conditions", "shape": "dot", "size": 10.089285714285714, "title": "lighting conditions"}, {"color": "#6FA8DC", "id": "MINC", "label": "MINC", "shape": "dot", "size": 10.357142857142858, "title": "MINC"}, {"color": "#6FA8DC", "id": "large-scale", "label": "large-scale", "shape": "dot", "size": 10.089285714285714, "title": "large-scale"}, {"color": "#6FA8DC", "id": "open", "label": "open", "shape": "dot", "size": 10.089285714285714, "title": "open"}, {"color": "#6FA8DC", "id": "CNNs", "label": "CNNs", "shape": "dot", "size": 10.267857142857142, "title": "CNNs"}, {"color": "#6FA8DC", "id": "material classification", "label": "material classification", "shape": "dot", "size": 10.089285714285714, "title": "material classification"}, {"color": "#6FA8DC", "id": "material segmentation", "label": "material segmentation", "shape": "dot", "size": 10.089285714285714, "title": "material segmentation"}, {"color": "#6FA8DC", "id": "patch-based classification", "label": "patch-based classification", "shape": "dot", "size": 10.089285714285714, "title": "patch-based classification"}, {"color": "#6FA8DC", "id": "85.2% mean class accuracy", "label": "85.2% mean class accuracy", "shape": "dot", "size": 10.089285714285714, "title": "85.2% mean class accuracy"}, {"color": "#6FA8DC", "id": "full image segmentation", "label": "full image segmentation", "shape": "dot", "size": 10.089285714285714, "title": "full image segmentation"}, {"color": "#6FA8DC", "id": "73.1% mean class accuracy", "label": "73.1% mean class accuracy", "shape": "dot", "size": 10.178571428571429, "title": "73.1% mean class accuracy"}, {"color": "#6FA8DC", "id": "large, well-sampled datasets", "label": "large, well-sampled datasets", "shape": "dot", "size": 10.089285714285714, "title": "large, well-sampled datasets"}, {"color": "#6FA8DC", "id": "Dataset Creation", "label": "Dataset Creation", "shape": "dot", "size": 10.178571428571429, "title": "Dataset Creation"}, {"color": "#6FA8DC", "id": "G. Patterson et al.", "label": "G. Patterson et al.", "shape": "dot", "size": 10.089285714285714, "title": "G. Patterson et al."}, {"color": "#6FA8DC", "id": "The SUN Attribute Database", "label": "The SUN Attribute Database", "shape": "dot", "size": 10.178571428571429, "title": "The SUN Attribute Database"}, {"color": "#6FA8DC", "id": "Deeper Scene Understanding", "label": "Deeper Scene Understanding", "shape": "dot", "size": 10.089285714285714, "title": "Deeper Scene Understanding"}, {"color": "#6FA8DC", "id": "S. Bell et al.", "label": "S. Bell et al.", "shape": "dot", "size": 10.089285714285714, "title": "S. Bell et al."}, {"color": "#6FA8DC", "id": "OpenSurposes", "label": "OpenSurposes", "shape": "dot", "size": 10.089285714285714, "title": "OpenSurposes"}, {"color": "#6FA8DC", "id": "OpenSurfaces", "label": "OpenSurfaces", "shape": "dot", "size": 10.089285714285714, "title": "OpenSurfaces"}, {"color": "#6FA8DC", "id": "richly annotated catalog", "label": "richly annotated catalog", "shape": "dot", "size": 10.089285714285714, "title": "richly annotated catalog"}, {"color": "#6FA8DC", "id": "X. Qi et al.", "label": "X. Qi et al.", "shape": "dot", "size": 10.089285714285714, "title": "X. Qi et al."}, {"color": "#6FA8DC", "id": "Pairwise rotation invariant co-occurrence local binary pattern", "label": "Pairwise rotation invariant co-occurrence local binary pattern", "shape": "dot", "size": 10.089285714285714, "title": "Pairwise rotation invariant co-occurrence local binary pattern"}, {"color": "#6FA8DC", "id": "B. Caputo et al.", "label": "B. Caputo et al.", "shape": "dot", "size": 10.089285714285714, "title": "B. Caputo et al."}, {"color": "#6FA8DC", "id": "Class-speci\ufb01c material categorisation", "label": "Class-speci\ufb01c material categorisation", "shape": "dot", "size": 10.089285714285714, "title": "Class-speci\ufb01c material categorisation"}, {"color": "#6FA8DC", "id": "variant co-occurrence local binary pattern", "label": "variant co-occurrence local binary pattern", "shape": "dot", "size": 10.178571428571429, "title": "variant co-occurrence local binary pattern"}, {"color": "#6FA8DC", "id": "Class-specific material categorisation", "label": "Class-specific material categorisation", "shape": "dot", "size": 10.089285714285714, "title": "Class-specific material categorisation"}, {"color": "#6FA8DC", "id": "ImageNet Large Scale Visual Recognition Challenge", "label": "ImageNet Large Scale Visual Recognition Challenge", "shape": "dot", "size": 10.178571428571429, "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"color": "#6FA8DC", "id": "visual recognition", "label": "visual recognition", "shape": "dot", "size": 10.089285714285714, "title": "visual recognition"}, {"color": "#6FA8DC", "id": "ACM Transactions on Graphics (TOG)", "label": "ACM Transactions on Graphics (TOG)", "shape": "dot", "size": 10.357142857142858, "title": "ACM Transactions on Graphics (TOG)"}, {"color": "#6FA8DC", "id": "Re\ufb02ectence and texture of real-world surfaces", "label": "Re\ufb02ectence and texture of real-world surfaces", "shape": "dot", "size": 10.089285714285714, "title": "Re\ufb02ectence and texture of real-world surfaces"}, {"color": "#6FA8DC", "id": "LabelMe", "label": "LabelMe", "shape": "dot", "size": 10.089285714285714, "title": "LabelMe"}, {"color": "#6FA8DC", "id": "Re\ufb02ectance", "label": "Re\ufb02ectance", "shape": "dot", "size": 10.089285714285714, "title": "Re\ufb02ectance"}, {"color": "#6FA8DC", "id": "real-world surfaces", "label": "real-world surfaces", "shape": "dot", "size": 10.178571428571429, "title": "real-world surfaces"}, {"color": "#6FA8DC", "id": "texture", "label": "texture", "shape": "dot", "size": 10.178571428571429, "title": "texture"}, {"color": "#6FA8DC", "id": "Describing textures in the wild", "label": "Describing textures in the wild", "shape": "dot", "size": 10.089285714285714, "title": "Describing textures in the wild"}, {"color": "#6FA8DC", "id": "image processing", "label": "image processing", "shape": "dot", "size": 10.178571428571429, "title": "image processing"}, {"color": "#6FA8DC", "id": "TOG", "label": "TOG", "shape": "dot", "size": 10.089285714285714, "title": "TOG"}, {"color": "#6FA8DC", "id": "Graphics", "label": "Graphics", "shape": "dot", "size": 10.089285714285714, "title": "Graphics"}, {"color": "#6FA8DC", "id": "Pascal VOC Challenge", "label": "Pascal VOC Challenge", "shape": "dot", "size": 10.089285714285714, "title": "Pascal VOC Challenge"}, {"color": "#6FA8DC", "id": "Visual Object Classes", "label": "Visual Object Classes", "shape": "dot", "size": 10.089285714285714, "title": "Visual Object Classes"}, {"color": "#6FA8DC", "id": "Department of Computer Science, Cornell University", "label": "Department of Computer Science, Cornell University", "shape": "dot", "size": 10.267857142857142, "title": "Department of Computer Science, Cornell University"}, {"color": "#6FA8DC", "id": "sbell@cs.cornell.edu", "label": "sbell@cs.cornell.edu", "shape": "dot", "size": 10.089285714285714, "title": "sbell@cs.cornell.edu"}, {"color": "#6FA8DC", "id": "paulu@cs.cornell.edu", "label": "paulu@cs.cornell.edu", "shape": "dot", "size": 10.089285714285714, "title": "paulu@cs.cornell.edu"}, {"color": "#6FA8DC", "id": "snavely@cs.cornell.edu", "label": "snavely@cs.cornell.edu", "shape": "dot", "size": 10.089285714285714, "title": "snavely@cs.cornell.edu"}, {"color": "#6FA8DC", "id": "kb@cs.cornell.edu", "label": "kb@cs.cornell.edu", "shape": "dot", "size": 10.089285714285714, "title": "kb@cs.cornell.edu"}, {"color": "#6FA8DC", "id": "Department of Computer Science", "label": "Department of Computer Science", "shape": "dot", "size": 10.714285714285714, "title": "Department of Computer Science"}, {"color": "#6FA8DC", "id": "Wonmin Byeon", "label": "Wonmin Byeon", "shape": "dot", "size": 10.178571428571429, "title": "Wonmin Byeon"}, {"color": "#6FA8DC", "id": "Scene Labeling with LSTM Recurrent Neural Networks", "label": "Scene Labeling with LSTM Recurrent Neural Networks", "shape": "dot", "size": 10.446428571428571, "title": "Scene Labeling with LSTM Recurrent Neural Networks"}, {"color": "#6FA8DC", "id": "Thomas M. Breuel", "label": "Thomas M. Breuel", "shape": "dot", "size": 10.178571428571429, "title": "Thomas M. Breuel"}, {"color": "#6FA8DC", "id": "Federico Raue", "label": "Federico Raue", "shape": "dot", "size": 10.178571428571429, "title": "Federico Raue"}, {"color": "#6FA8DC", "id": "Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf", "label": "Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Accurate scene labeling", "label": "Accurate scene labeling", "shape": "dot", "size": 10.089285714285714, "title": "Accurate scene labeling"}, {"color": "#6FA8DC", "id": "image understanding", "label": "image understanding", "shape": "dot", "size": 10.089285714285714, "title": "image understanding"}, {"color": "#6FA8DC", "id": "pixel-level segmentation", "label": "pixel-level segmentation", "shape": "dot", "size": 10.089285714285714, "title": "pixel-level segmentation"}, {"color": "#6FA8DC", "id": "Long Short Term Memory (LSTM) recurrent neural networks", "label": "Long Short Term Memory (LSTM) recurrent neural networks", "shape": "dot", "size": 10.089285714285714, "title": "Long Short Term Memory (LSTM) recurrent neural networks"}, {"color": "#6FA8DC", "id": "LSTM recurrent neural networks", "label": "LSTM recurrent neural networks", "shape": "dot", "size": 10.089285714285714, "title": "LSTM recurrent neural networks"}, {"color": "#6FA8DC", "id": "lower computational complexity", "label": "lower computational complexity", "shape": "dot", "size": 10.089285714285714, "title": "lower computational complexity"}, {"color": "#6FA8DC", "id": "state-of-the-art performance", "label": "state-of-the-art performance", "shape": "dot", "size": 10.803571428571429, "title": "state-of-the-art performance"}, {"color": "#6FA8DC", "id": "Stanford Background dataset", "label": "Stanford Background dataset", "shape": "dot", "size": 10.089285714285714, "title": "Stanford Background dataset"}, {"color": "#6FA8DC", "id": "SIFT Flow datasets", "label": "SIFT Flow datasets", "shape": "dot", "size": 10.089285714285714, "title": "SIFT Flow datasets"}, {"color": "#6FA8DC", "id": "local contextual information", "label": "local contextual information", "shape": "dot", "size": 10.178571428571429, "title": "local contextual information"}, {"color": "#6FA8DC", "id": "global contextual information", "label": "global contextual information", "shape": "dot", "size": 10.178571428571429, "title": "global contextual information"}, {"color": "#6FA8DC", "id": "RGB values", "label": "RGB values", "shape": "dot", "size": 10.089285714285714, "title": "RGB values"}, {"color": "#6FA8DC", "id": "Networks", "label": "Networks", "shape": "dot", "size": 10.357142857142858, "title": "Networks"}, {"color": "#6FA8DC", "id": "raw RGB values", "label": "raw RGB values", "shape": "dot", "size": 10.089285714285714, "title": "raw RGB values"}, {"color": "#6FA8DC", "id": "complex scene images", "label": "complex scene images", "shape": "dot", "size": 10.089285714285714, "title": "complex scene images"}, {"color": "#6FA8DC", "id": "German Research Center for Arti\ufb01cial Intelligence (DFKI)", "label": "German Research Center for Arti\ufb01cial Intelligence (DFKI)", "shape": "dot", "size": 10.178571428571429, "title": "German Research Center for Arti\ufb01cial Intelligence (DFKI)"}, {"color": "#6FA8DC", "id": "University of Kaiserslautern", "label": "University of Kaiserslautern", "shape": "dot", "size": 10.089285714285714, "title": "University of Kaiserslautern"}, {"color": "#6FA8DC", "id": "Thalaiyasingam Ajanthan", "label": "Thalaiyasingam Ajanthan", "shape": "dot", "size": 10.178571428571429, "title": "Thalaiyasingam Ajanthan"}, {"color": "#6FA8DC", "id": "Iteratively Reweighted Graph Cut", "label": "Iteratively Reweighted Graph Cut", "shape": "dot", "size": 10.178571428571429, "title": "Iteratively Reweighted Graph Cut"}, {"color": "#6FA8DC", "id": "Multi-label MRFs", "label": "Multi-label MRFs", "shape": "dot", "size": 10.089285714285714, "title": "Multi-label MRFs"}, {"color": "#6FA8DC", "id": "energy", "label": "energy", "shape": "dot", "size": 10.357142857142858, "title": "energy"}, {"color": "#6FA8DC", "id": "Multi-label Markov Random Fields (MRFs)", "label": "Multi-label Markov Random Fields (MRFs)", "shape": "dot", "size": 10.089285714285714, "title": "Multi-label Markov Random Fields (MRFs)"}, {"color": "#6FA8DC", "id": "multi-label graph cut algorithm", "label": "multi-label graph cut algorithm", "shape": "dot", "size": 10.089285714285714, "title": "multi-label graph cut algorithm"}, {"color": "#6FA8DC", "id": "Iterively Reweighted Least Squares (IRLS) algorithm", "label": "Iterively Reweighted Least Squares (IRLS) algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Iterively Reweighted Least Squares (IRLS) algorithm"}, {"color": "#6FA8DC", "id": "stereo correspondence estimation", "label": "stereo correspondence estimation", "shape": "dot", "size": 10.089285714285714, "title": "stereo correspondence estimation"}, {"color": "#6FA8DC", "id": "image inpainting problems", "label": "image inpainting problems", "shape": "dot", "size": 10.089285714285714, "title": "image inpainting problems"}, {"color": "#6FA8DC", "id": "graph-cut-based algorithms", "label": "graph-cut-based algorithms", "shape": "dot", "size": 10.178571428571429, "title": "graph-cut-based algorithms"}, {"color": "#6FA8DC", "id": "lower energy values", "label": "lower energy values", "shape": "dot", "size": 10.178571428571429, "title": "lower energy values"}, {"color": "#6FA8DC", "id": "MRFs", "label": "MRFs", "shape": "dot", "size": 10.089285714285714, "title": "MRFs"}, {"color": "#6FA8DC", "id": "Non-convex Priors", "label": "Non-convex Priors", "shape": "dot", "size": 10.089285714285714, "title": "Non-convex Priors"}, {"color": "#6FA8DC", "id": "Multi-label Markov Random Fields", "label": "Multi-label Markov Random Fields", "shape": "dot", "size": 10.267857142857142, "title": "Multi-label Markov Random Fields"}, {"color": "#6FA8DC", "id": "Graph Cut Optimization", "label": "Graph Cut Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Graph Cut Optimization"}, {"color": "#6FA8DC", "id": "Ishikawa, H.", "label": "Ishikawa, H.", "shape": "dot", "size": 10.178571428571429, "title": "Ishikawa, H."}, {"color": "#6FA8DC", "id": "Exact optimization for Markov random fields with convex priors", "label": "Exact optimization for Markov random fields with convex priors", "shape": "dot", "size": 10.089285714285714, "title": "Exact optimization for Markov random fields with convex priors"}, {"color": "#6FA8DC", "id": "MRF optimization", "label": "MRF optimization", "shape": "dot", "size": 10.089285714285714, "title": "MRF optimization"}, {"color": "#6FA8DC", "id": "Boykov, Y.", "label": "Boykov, Y.", "shape": "dot", "size": 10.267857142857142, "title": "Boykov, Y."}, {"color": "#6FA8DC", "id": "Fast approximate energy minimization via graph cuts", "label": "Fast approximate energy minimization via graph cuts", "shape": "dot", "size": 10.357142857142858, "title": "Fast approximate energy minimization via graph cuts"}, {"color": "#6FA8DC", "id": "graph cut methods", "label": "graph cut methods", "shape": "dot", "size": 10.089285714285714, "title": "graph cut methods"}, {"color": "#6FA8DC", "id": "Kolmogorov, V.", "label": "Kolmogorov, V.", "shape": "dot", "size": 10.178571428571429, "title": "Kolmogorov, V."}, {"color": "#6FA8DC", "id": "Convergent tree-reweighted message passing", "label": "Convergent tree-reweighted message passing", "shape": "dot", "size": 10.089285714285714, "title": "Convergent tree-reweighted message passing"}, {"color": "#6FA8DC", "id": "reweighted message passing", "label": "reweighted message passing", "shape": "dot", "size": 10.267857142857142, "title": "reweighted message passing"}, {"color": "#6FA8DC", "id": "Iteratively Reweighted Algorithms", "label": "Iteratively Reweighted Algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Iteratively Reweighted Algorithms"}, {"color": "#6FA8DC", "id": "Stereo/Inpainting", "label": "Stereo/Inpainting", "shape": "dot", "size": 10.089285714285714, "title": "Stereo/Inpainting"}, {"color": "#6FA8DC", "id": "energy minimization", "label": "energy minimization", "shape": "dot", "size": 10.357142857142858, "title": "energy minimization"}, {"color": "#6FA8DC", "id": "geometric relationships", "label": "geometric relationships", "shape": "dot", "size": 10.178571428571429, "title": "geometric relationships"}, {"color": "#6FA8DC", "id": "energy minimization techniques", "label": "energy minimization techniques", "shape": "dot", "size": 10.267857142857142, "title": "energy minimization techniques"}, {"color": "#6FA8DC", "id": "comparative study", "label": "comparative study", "shape": "dot", "size": 10.446428571428571, "title": "comparative study"}, {"color": "#6FA8DC", "id": "Markov random fields", "label": "Markov random fields", "shape": "dot", "size": 10.178571428571429, "title": "Markov random fields"}, {"color": "#6FA8DC", "id": "energy minimization methods", "label": "energy minimization methods", "shape": "dot", "size": 10.089285714285714, "title": "energy minimization methods"}, {"color": "#6FA8DC", "id": "smoothness-based priors", "label": "smoothness-based priors", "shape": "dot", "size": 10.178571428571429, "title": "smoothness-based priors"}, {"color": "#6FA8DC", "id": "pattern analysis", "label": "pattern analysis", "shape": "dot", "size": 10.089285714285714, "title": "pattern analysis"}, {"color": "#6FA8DC", "id": "Pattern Analysis and Machine Intelligence", "label": "Pattern Analysis and Machine Intelligence", "shape": "dot", "size": 10.178571428571429, "title": "Pattern Analysis and Machine Intelligence"}, {"color": "#6FA8DC", "id": "ds with smoothness-based priors", "label": "ds with smoothness-based priors", "shape": "dot", "size": 10.178571428571429, "title": "ds with smoothness-based priors"}, {"color": "#6FA8DC", "id": "Boykov et al.", "label": "Boykov et al.", "shape": "dot", "size": 10.267857142857142, "title": "Boykov et al."}, {"color": "#6FA8DC", "id": "An experimental comparison", "label": "An experimental comparison", "shape": "dot", "size": 10.178571428571429, "title": "An experimental comparison"}, {"color": "#6FA8DC", "id": "min-cut/max-flow algorithms", "label": "min-cut/max-flow algorithms", "shape": "dot", "size": 10.178571428571429, "title": "min-cut/max-flow algorithms"}, {"color": "#6FA8DC", "id": "Pock et al.", "label": "Pock et al.", "shape": "dot", "size": 10.178571428571429, "title": "Pock et al."}, {"color": "#6FA8DC", "id": "convex formulation", "label": "convex formulation", "shape": "dot", "size": 10.446428571428571, "title": "convex formulation"}, {"color": "#6FA8DC", "id": "multi-label problems", "label": "multi-label problems", "shape": "dot", "size": 10.178571428571429, "title": "multi-label problems"}, {"color": "#6FA8DC", "id": "Computer Vision\u2013ECCV 2008", "label": "Computer Vision\u2013ECCV 2008", "shape": "dot", "size": 10.178571428571429, "title": "Computer Vision\u2013ECCV 2008"}, {"color": "#6FA8DC", "id": "H. f.", "label": "H. f.", "shape": "dot", "size": 10.089285714285714, "title": "H. f."}, {"color": "#6FA8DC", "id": "Kappes et al.", "label": "Kappes et al.", "shape": "dot", "size": 10.089285714285714, "title": "Kappes et al."}, {"color": "#6FA8DC", "id": "inference techniques", "label": "inference techniques", "shape": "dot", "size": 10.089285714285714, "title": "inference techniques"}, {"color": "#6FA8DC", "id": "Scharstein \u0026 Szeliski", "label": "Scharstein \u0026 Szeliski", "shape": "dot", "size": 10.089285714285714, "title": "Scharstein \u0026 Szeliski"}, {"color": "#6FA8DC", "id": "dense two-frame stereo correspondence algorithms", "label": "dense two-frame stereo correspondence algorithms", "shape": "dot", "size": 10.178571428571429, "title": "dense two-frame stereo correspondence algorithms"}, {"color": "#6FA8DC", "id": "understanding", "label": "understanding", "shape": "dot", "size": 10.089285714285714, "title": "understanding"}, {"color": "#6FA8DC", "id": "taxonomies", "label": "taxonomies", "shape": "dot", "size": 10.089285714285714, "title": "taxonomies"}, {"color": "#6FA8DC", "id": "stereo correspondence algorithms", "label": "stereo correspondence algorithms", "shape": "dot", "size": 10.089285714285714, "title": "stereo correspondence algorithms"}, {"color": "#6FA8DC", "id": "Vekler", "label": "Vekler", "shape": "dot", "size": 10.089285714285714, "title": "Vekler"}, {"color": "#6FA8DC", "id": "Multi-label moves for mrfs", "label": "Multi-label moves for mrfs", "shape": "dot", "size": 10.178571428571429, "title": "Multi-label moves for mrfs"}, {"color": "#6FA8DC", "id": "truncated convex priors", "label": "truncated convex priors", "shape": "dot", "size": 10.089285714285714, "title": "truncated convex priors"}, {"color": "#6FA8DC", "id": "Australian National University", "label": "Australian National University", "shape": "dot", "size": 10.535714285714286, "title": "Australian National University"}, {"color": "#6FA8DC", "id": "Mathieu Salzmann", "label": "Mathieu Salzmann", "shape": "dot", "size": 10.267857142857142, "title": "Mathieu Salzmann"}, {"color": "#6FA8DC", "id": "Hongdong Li", "label": "Hongdong Li", "shape": "dot", "size": 10.446428571428571, "title": "Hongdong Li"}, {"color": "#6FA8DC", "id": "Rui Zhao", "label": "Rui Zhao", "shape": "dot", "size": 10.178571428571429, "title": "Rui Zhao"}, {"color": "#6FA8DC", "id": "Saliency Detection by Multi-Context Deep Learning", "label": "Saliency Detection by Multi-Context Deep Learning", "shape": "dot", "size": 10.357142857142858, "title": "Saliency Detection by Multi-Context Deep Learning"}, {"color": "#6FA8DC", "id": "Wanli Ouyang", "label": "Wanli Ouyang", "shape": "dot", "size": 10.267857142857142, "title": "Wanli Ouyang"}, {"color": "#6FA8DC", "id": "Saliency Detection by Multi-Content Deep Learning", "label": "Saliency Detection by Multi-Content Deep Learning", "shape": "dot", "size": 10.089285714285714, "title": "Saliency Detection by Multi-Content Deep Learning"}, {"color": "#6FA8DC", "id": "Multi-Context Deep Learning", "label": "Multi-Context Deep Learning", "shape": "dot", "size": 10.089285714285714, "title": "Multi-Context Deep Learning"}, {"color": "#6FA8DC", "id": "Image salience detection", "label": "Image salience detection", "shape": "dot", "size": 10.089285714285714, "title": "Image salience detection"}, {"color": "#6FA8DC", "id": "highlight visually salient regions", "label": "highlight visually salient regions", "shape": "dot", "size": 10.089285714285714, "title": "highlight visually salient regions"}, {"color": "#6FA8DC", "id": "Conventional approaches", "label": "Conventional approaches", "shape": "dot", "size": 10.089285714285714, "title": "Conventional approaches"}, {"color": "#6FA8DC", "id": "salient objects in low-contrast backgrounds", "label": "salient objects in low-contrast backgrounds", "shape": "dot", "size": 10.089285714285714, "title": "salient objects in low-contrast backgrounds"}, {"color": "#6FA8DC", "id": "multi-context deep learning framework", "label": "multi-context deep learning framework", "shape": "dot", "size": 10.267857142857142, "title": "multi-context deep learning framework"}, {"color": "#6FA8DC", "id": "salience", "label": "salience", "shape": "dot", "size": 10.535714285714286, "title": "salience"}, {"color": "#6FA8DC", "id": "global context", "label": "global context", "shape": "dot", "size": 10.089285714285714, "title": "global context"}, {"color": "#6FA8DC", "id": "pre-training scheme", "label": "pre-training scheme", "shape": "dot", "size": 10.178571428571429, "title": "pre-training scheme"}, {"color": "#6FA8DC", "id": "Task-specific pre-training scheme", "label": "Task-specific pre-training scheme", "shape": "dot", "size": 10.089285714285714, "title": "Task-specific pre-training scheme"}, {"color": "#6FA8DC", "id": "Frequency-tuned salient region detection", "label": "Frequency-tuned salient region detection", "shape": "dot", "size": 10.178571428571429, "title": "Frequency-tuned salient region detection"}, {"color": "#6FA8DC", "id": "Training products of experts", "label": "Training products of experts", "shape": "dot", "size": 10.089285714285714, "title": "Training products of experts"}, {"color": "#6FA8DC", "id": "Neural computation", "label": "Neural computation", "shape": "dot", "size": 10.089285714285714, "title": "Neural computation"}, {"color": "#6FA8DC", "id": "Saliency detection", "label": "Saliency detection", "shape": "dot", "size": 10.089285714285714, "title": "Saliency detection"}, {"color": "#6FA8DC", "id": "Category-independent object-level saliency detection", "label": "Category-independent object-level saliency detection", "shape": "dot", "size": 10.089285714285714, "title": "Category-independent object-level saliency detection"}, {"color": "#6FA8DC", "id": "arXiv preprint", "label": "arXiv preprint", "shape": "dot", "size": 10.535714285714286, "title": "arXiv preprint"}, {"color": "#6FA8DC", "id": "Graph-based visual saliency", "label": "Graph-based visual saliency", "shape": "dot", "size": 10.089285714285714, "title": "Graph-based visual saliency"}, {"color": "#6FA8DC", "id": "Salient Object Detection", "label": "Salient Object Detection", "shape": "dot", "size": 11.607142857142858, "title": "Salient Object Detection"}, {"color": "#6FA8DC", "id": "Multi-Context Modeling", "label": "Multi-Context Modeling", "shape": "dot", "size": 10.089285714285714, "title": "Multi-Context Modeling"}, {"color": "#6FA8DC", "id": "ik", "label": "ik", "shape": "dot", "size": 10.267857142857142, "title": "ik"}, {"color": "#6FA8DC", "id": "arXiv", "label": "arXiv", "shape": "dot", "size": 10.089285714285714, "title": "arXiv"}, {"color": "#6FA8DC", "id": "Graph-based visual salience", "label": "Graph-based visual salience", "shape": "dot", "size": 10.089285714285714, "title": "Graph-based visual salience"}, {"color": "#6FA8DC", "id": "A. Borji", "label": "A. Borji", "shape": "dot", "size": 10.267857142857142, "title": "A. Borji"}, {"color": "#6FA8DC", "id": "Boosting bottom-up and top-down visual features", "label": "Boosting bottom-up and top-down visual features", "shape": "dot", "size": 10.089285714285714, "title": "Boosting bottom-up and top-down visual features"}, {"color": "#6FA8DC", "id": "M.-M. Cheng", "label": "M.-M. Cheng", "shape": "dot", "size": 10.089285714285714, "title": "M.-M. Cheng"}, {"color": "#6FA8DC", "id": "Global contrast based salient region detection", "label": "Global contrast based salient region detection", "shape": "dot", "size": 10.357142857142858, "title": "Global contrast based salient region detection"}, {"color": "#6FA8DC", "id": "R. Mairon", "label": "R. Mairon", "shape": "dot", "size": 10.089285714285714, "title": "R. Mairon"}, {"color": "#6FA8DC", "id": "A closer look at context", "label": "A closer look at context", "shape": "dot", "size": 10.089285714285714, "title": "A closer look at context"}, {"color": "#6FA8DC", "id": "Shenzhen Institutes of Advanced Technology", "label": "Shenzhen Institutes of Advanced Technology", "shape": "dot", "size": 10.446428571428571, "title": "Shenzhen Institutes of Advanced Technology"}, {"color": "#6FA8DC", "id": "Department of Electronic Engineering", "label": "Department of Electronic Engineering", "shape": "dot", "size": 10.357142857142858, "title": "Department of Electronic Engineering"}, {"color": "#6FA8DC", "id": "wlouyang@ee.cuhk.edu.hk", "label": "wlouyang@ee.cuhk.edu.hk", "shape": "dot", "size": 10.089285714285714, "title": "wlouyang@ee.cuhk.edu.hk"}, {"color": "#6FA8DC", "id": "hsli@ee.cuhk.edu.hk", "label": "hsli@ee.cuhk.edu.hk", "shape": "dot", "size": 10.089285714285714, "title": "hsli@ee.cuhk.edu.hk"}, {"color": "#6FA8DC", "id": "Advanced Technology", "label": "Advanced Technology", "shape": "dot", "size": 10.089285714285714, "title": "Advanced Technology"}, {"color": "#6FA8DC", "id": "Baohua Li", "label": "Baohua Li", "shape": "dot", "size": 10.178571428571429, "title": "Baohua Li"}, {"color": "#6FA8DC", "id": "Subspace Clustering by Mixture of Gaussian Regression", "label": "Subspace Clustering by Mixture of Gaussian Regression", "shape": "dot", "size": 10.357142857142858, "title": "Subspace Clustering by Mixture of Gaussian Regression"}, {"color": "#6FA8DC", "id": "Ying Zhang", "label": "Ying Zhang", "shape": "dot", "size": 10.267857142857142, "title": "Ying Zhang"}, {"color": "#6FA8DC", "id": "Zhouchen Lin", "label": "Zhouchen Lin", "shape": "dot", "size": 10.267857142857142, "title": "Zhouchen Lin"}, {"color": "#6FA8DC", "id": "Subclone Clustering by Mixture of Gaussian Regression", "label": "Subclone Clustering by Mixture of Gaussian Regression", "shape": "dot", "size": 10.089285714285714, "title": "Subclone Clustering by Mixture of Gaussian Regression"}, {"color": "#6FA8DC", "id": "Huchuan Lu", "label": "Huchuan Lu", "shape": "dot", "size": 10.446428571428571, "title": "Huchuan Lu"}, {"color": "#6FA8DC", "id": "Subspace clustering", "label": "Subspace clustering", "shape": "dot", "size": 10.267857142857142, "title": "Subspace clustering"}, {"color": "#6FA8DC", "id": "multi-subspace representation", "label": "multi-subspace representation", "shape": "dot", "size": 10.089285714285714, "title": "multi-subspace representation"}, {"color": "#6FA8DC", "id": "high-dimensional space", "label": "high-dimensional space", "shape": "dot", "size": 10.089285714285714, "title": "high-dimensional space"}, {"color": "#6FA8DC", "id": "Existing methods", "label": "Existing methods", "shape": "dot", "size": 10.089285714285714, "title": "Existing methods"}, {"color": "#6FA8DC", "id": "norms", "label": "norms", "shape": "dot", "size": 10.089285714285714, "title": "norms"}, {"color": "#6FA8DC", "id": "MoG Regression", "label": "MoG Regression", "shape": "dot", "size": 10.357142857142858, "title": "MoG Regression"}, {"color": "#6FA8DC", "id": "subspace clustering", "label": "subspace clustering", "shape": "dot", "size": 10.089285714285714, "title": "subspace clustering"}, {"color": "#6FA8DC", "id": "Mixture of Gausians (MoG)", "label": "Mixture of Gausians (MoG)", "shape": "dot", "size": 10.089285714285714, "title": "Mixture of Gausians (MoG)"}, {"color": "#6FA8DC", "id": "affinity matrix", "label": "affinity matrix", "shape": "dot", "size": 10.089285714285714, "title": "affinity matrix"}, {"color": "#6FA8DC", "id": "clustering performance", "label": "clustering performance", "shape": "dot", "size": 10.089285714285714, "title": "clustering performance"}, {"color": "#6FA8DC", "id": "MoG Regression outperforms subspace clustering methods", "label": "MoG Regression outperforms subspace clustering methods", "shape": "dot", "size": 10.089285714285714, "title": "MoG Regression outperforms subspace clustering methods"}, {"color": "#6FA8DC", "id": "noise distributions", "label": "noise distributions", "shape": "dot", "size": 10.089285714285714, "title": "noise distributions"}, {"color": "#6FA8DC", "id": "Noise Modeling", "label": "Noise Modeling", "shape": "dot", "size": 10.178571428571429, "title": "Noise Modeling"}, {"color": "#6FA8DC", "id": "Subspace Clustering", "label": "Subspace Clustering", "shape": "dot", "size": 10.089285714285714, "title": "Subspace Clustering"}, {"color": "#6FA8DC", "id": "state-of-the-art subspace clustering methods", "label": "state-of-the-art subspace clustering methods", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art subspace clustering methods"}, {"color": "#6FA8DC", "id": "K-plane clustering", "label": "K-plane clustering", "shape": "dot", "size": 10.178571428571429, "title": "K-plane clustering"}, {"color": "#6FA8DC", "id": "segmentation", "label": "segmentation", "shape": "dot", "size": 10.714285714285714, "title": "segmentation"}, {"color": "#6FA8DC", "id": "graph-based image segmentation", "label": "graph-based image segmentation", "shape": "dot", "size": 10.089285714285714, "title": "graph-based image segmentation"}, {"color": "#6FA8DC", "id": "power factorization", "label": "power factorization", "shape": "dot", "size": 10.178571428571429, "title": "power factorization"}, {"color": "#6FA8DC", "id": "motion segmentation", "label": "motion segmentation", "shape": "dot", "size": 10.446428571428571, "title": "motion segmentation"}, {"color": "#6FA8DC", "id": "GPCA", "label": "GPCA", "shape": "dot", "size": 10.357142857142858, "title": "GPCA"}, {"color": "#6FA8DC", "id": "Mixture of Gaussian Regression", "label": "Mixture of Gaussian Regression", "shape": "dot", "size": 10.089285714285714, "title": "Mixture of Gaussian Regression"}, {"color": "#6FA8DC", "id": "clustering", "label": "clustering", "shape": "dot", "size": 10.357142857142858, "title": "clustering"}, {"color": "#6FA8DC", "id": "Affinity Matrix Construction", "label": "Affinity Matrix Construction", "shape": "dot", "size": 10.089285714285714, "title": "Affinity Matrix Construction"}, {"color": "#6FA8DC", "id": "Journal of Global Optimization", "label": "Journal of Global Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Journal of Global Optimization"}, {"color": "#6FA8DC", "id": "referenced papers", "label": "referenced papers", "shape": "dot", "size": 10.089285714285714, "title": "referenced papers"}, {"color": "#6FA8DC", "id": "Spectral clustering", "label": "Spectral clustering", "shape": "dot", "size": 10.178571428571429, "title": "Spectral clustering"}, {"color": "#6FA8DC", "id": "tutorial", "label": "tutorial", "shape": "dot", "size": 10.178571428571429, "title": "tutorial"}, {"color": "#6FA8DC", "id": "Sparse representation", "label": "Sparse representation", "shape": "dot", "size": 10.446428571428571, "title": "Sparse representation"}, {"color": "#6FA8DC", "id": "Wright et al.", "label": "Wright et al.", "shape": "dot", "size": 10.089285714285714, "title": "Wright et al."}, {"color": "#6FA8DC", "id": "face recognition approach", "label": "face recognition approach", "shape": "dot", "size": 10.178571428571429, "title": "face recognition approach"}, {"color": "#6FA8DC", "id": "Approaches", "label": "Approaches", "shape": "dot", "size": 10.089285714285714, "title": "Approaches"}, {"color": "#6FA8DC", "id": "EM algorithm", "label": "EM algorithm", "shape": "dot", "size": 10.267857142857142, "title": "EM algorithm"}, {"color": "#6FA8DC", "id": "Convergence properties", "label": "Convergence properties", "shape": "dot", "size": 10.089285714285714, "title": "Convergence properties"}, {"color": "#6FA8DC", "id": "Motion segmentation", "label": "Motion segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Motion segmentation"}, {"color": "#6FA8DC", "id": "Framework", "label": "Framework", "shape": "dot", "size": 10.357142857142858, "title": "Framework"}, {"color": "#6FA8DC", "id": "Types of motion", "label": "Types of motion", "shape": "dot", "size": 10.089285714285714, "title": "Types of motion"}, {"color": "#6FA8DC", "id": "Gaussian mixtures", "label": "Gaussian mixtures", "shape": "dot", "size": 10.089285714285714, "title": "Gaussian mixtures"}, {"color": "#6FA8DC", "id": "Pattern Analysis", "label": "Pattern Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Pattern Analysis"}, {"color": "#6FA8DC", "id": "various types of motion", "label": "various types of motion", "shape": "dot", "size": 10.089285714285714, "title": "various types of motion"}, {"color": "#6FA8DC", "id": "lossy data compression", "label": "lossy data compression", "shape": "dot", "size": 10.178571428571429, "title": "lossy data compression"}, {"color": "#6FA8DC", "id": "Dalian University of Technology", "label": "Dalian University of Technology", "shape": "dot", "size": 10.446428571428571, "title": "Dalian University of Technology"}, {"color": "#6FA8DC", "id": "Dalian\u003c0xC2\u003e\u003c0xA0\u003eUniversity of Technology", "label": "Dalian\u003c0xC2\u003e\u003c0xA0\u003eUniversity of Technology", "shape": "dot", "size": 10.089285714285714, "title": "Dalian\u003c0xC2\u003e\u003c0xA0\u003eUniversity of Technology"}, {"color": "#6FA8DC", "id": "robust PCA", "label": "robust PCA", "shape": "dot", "size": 10.089285714285714, "title": "robust PCA"}, {"color": "#6FA8DC", "id": "broad framework", "label": "broad framework", "shape": "dot", "size": 10.089285714285714, "title": "broad framework"}, {"color": "#6FA8DC", "id": "School of EECS", "label": "School of EECS", "shape": "dot", "size": 10.089285714285714, "title": "School of EECS"}, {"color": "#6FA8DC", "id": "A Convolutional Neural Network Cascade", "label": "A Convolutional Neural Network Cascade", "shape": "dot", "size": 10.625, "title": "A Convolutional Neural Network Cascade"}, {"color": "#6FA8DC", "id": "Face Detection", "label": "Face Detection", "shape": "dot", "size": 10.625, "title": "Face Detection"}, {"color": "#6FA8DC", "id": "Haoxiang Li", "label": "Haoxiang Li", "shape": "dot", "size": 10.357142857142858, "title": "Haoxiang Li"}, {"color": "#6FA8DC", "id": "Zhe Lin", "label": "Zhe Lin", "shape": "dot", "size": 10.267857142857142, "title": "Zhe Lin"}, {"color": "#6FA8DC", "id": "Jonathan Brandt", "label": "Jonathan Brandt", "shape": "dot", "size": 10.089285714285714, "title": "Jonathan Brandt"}, {"color": "#6FA8DC", "id": "Gang Hua", "label": "Gang Hua", "shape": "dot", "size": 10.357142857142858, "title": "Gang Hua"}, {"color": "#6FA8DC", "id": "Face detection", "label": "Face detection", "shape": "dot", "size": 10.178571428571429, "title": "Face detection"}, {"color": "#6FA8DC", "id": "large visual variations", "label": "large visual variations", "shape": "dot", "size": 10.089285714285714, "title": "large visual variations"}, {"color": "#6FA8DC", "id": "large search space", "label": "large search space", "shape": "dot", "size": 10.089285714285714, "title": "large search space"}, {"color": "#6FA8DC", "id": "Advanced models", "label": "Advanced models", "shape": "dot", "size": 10.178571428571429, "title": "Advanced models"}, {"color": "#6FA8DC", "id": "visual variations", "label": "visual variations", "shape": "dot", "size": 10.089285714285714, "title": "visual variations"}, {"color": "#6FA8DC", "id": "computationally expensive", "label": "computationally expensive", "shape": "dot", "size": 10.178571428571429, "title": "computationally expensive"}, {"color": "#6FA8DC", "id": "Paper", "label": "Paper", "shape": "dot", "size": 10.625, "title": "Paper"}, {"color": "#6FA8DC", "id": "CNN cascade architecture", "label": "CNN cascade architecture", "shape": "dot", "size": 10.178571428571429, "title": "CNN cascade architecture"}, {"color": "#6FA8DC", "id": "conflicting demands", "label": "conflicting demands", "shape": "dot", "size": 10.089285714285714, "title": "conflicting demands"}, {"color": "#6FA8DC", "id": "Cascade", "label": "Cascade", "shape": "dot", "size": 10.089285714285714, "title": "Cascade"}, {"color": "#6FA8DC", "id": "background regions", "label": "background regions", "shape": "dot", "size": 10.089285714285714, "title": "background regions"}, {"color": "#6FA8DC", "id": "CNN-based calibration stage", "label": "CNN-based calibration stage", "shape": "dot", "size": 10.089285714285714, "title": "CNN-based calibration stage"}, {"color": "#6FA8DC", "id": "localization effectiveness", "label": "localization effectiveness", "shape": "dot", "size": 10.089285714285714, "title": "localization effectiveness"}, {"color": "#6FA8DC", "id": "state-of-the-art detection performance", "label": "state-of-the-art detection performance", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art detection performance"}, {"color": "#6FA8DC", "id": "14 FPS", "label": "14 FPS", "shape": "dot", "size": 10.178571428571429, "title": "14 FPS"}, {"color": "#6FA8DC", "id": "100 FPS", "label": "100 FPS", "shape": "dot", "size": 10.267857142857142, "title": "100 FPS"}, {"color": "#6FA8DC", "id": "Real-time Performance", "label": "Real-time Performance", "shape": "dot", "size": 10.178571428571429, "title": "Real-time Performance"}, {"color": "#6FA8DC", "id": "Cascade Architecture", "label": "Cascade Architecture", "shape": "dot", "size": 10.178571428571429, "title": "Cascade Architecture"}, {"color": "#6FA8DC", "id": "Bounding Box Calibration", "label": "Bounding Box Calibration", "shape": "dot", "size": 10.178571428571429, "title": "Bounding Box Calibration"}, {"color": "#6FA8DC", "id": "GPU", "label": "GPU", "shape": "dot", "size": 10.089285714285714, "title": "GPU"}, {"color": "#6FA8DC", "id": "Rapid object detection", "label": "Rapid object detection", "shape": "dot", "size": 10.089285714285714, "title": "Rapid object detection"}, {"color": "#6FA8DC", "id": "LeCun", "label": "LeCun", "shape": "dot", "size": 10.089285714285714, "title": "LeCun"}, {"color": "#6FA8DC", "id": "Convolutional networks", "label": "Convolutional networks", "shape": "dot", "size": 10.178571428571429, "title": "Convolutional networks"}, {"color": "#6FA8DC", "id": "speech", "label": "speech", "shape": "dot", "size": 10.089285714285714, "title": "speech"}, {"color": "#6FA8DC", "id": "Rowley", "label": "Rowley", "shape": "dot", "size": 10.089285714285714, "title": "Rowley"}, {"color": "#6FA8DC", "id": "Neural network-based face detection", "label": "Neural network-based face detection", "shape": "dot", "size": 10.089285714285714, "title": "Neural network-based face detection"}, {"color": "#6FA8DC", "id": "Felzenszwalb", "label": "Felzenszwalb", "shape": "dot", "size": 10.089285714285714, "title": "Felzenszwalb"}, {"color": "#6FA8DC", "id": "part-based models", "label": "part-based models", "shape": "dot", "size": 10.267857142857142, "title": "part-based models"}, {"color": "#6FA8DC", "id": "P. F.", "label": "P. F.", "shape": "dot", "size": 10.267857142857142, "title": "P. F."}, {"color": "#6FA8DC", "id": "Object detection with discriminatatively trained part-based models", "label": "Object detection with discriminatatively trained part-based models", "shape": "dot", "size": 10.089285714285714, "title": "Object detection with discriminatatively trained part-based models"}, {"color": "#6FA8DC", "id": "Object detection with discriminatively trained part-based models", "label": "Object detection with discriminatively trained part-based models", "shape": "dot", "size": 10.446428571428571, "title": "Object detection with discriminatively trained part-based models"}, {"color": "#6FA8DC", "id": "Jain, V.", "label": "Jain, V.", "shape": "dot", "size": 10.089285714285714, "title": "Jain, V."}, {"color": "#6FA8DC", "id": "Fddb: A benchmark for face detection in unconstrained settings", "label": "Fddb: A benchmark for face detection in unconstrained settings", "shape": "dot", "size": 10.178571428571429, "title": "Fddb: A benchmark for face detection in unconstrained settings"}, {"color": "#6FA8DC", "id": "Rich feature hierarchies for accurate object detection and semantic segmentation", "label": "Rich feature hierarchies for accurate object detection and semantic segmentation", "shape": "dot", "size": 10.178571428571429, "title": "Rich feature hierarchies for accurate object detection and semantic segmentation"}, {"color": "#6FA8DC", "id": "ImageNet classification with deep convolutional neural networks", "label": "ImageNet classification with deep convolutional neural networks", "shape": "dot", "size": 10.178571428571429, "title": "ImageNet classification with deep convolutional neural networks"}, {"color": "#6FA8DC", "id": "Jia, Y.", "label": "Jia, Y.", "shape": "dot", "size": 10.089285714285714, "title": "Jia, Y."}, {"color": "#6FA8DC", "id": "Caffe: Convolutional architecture for fast feature embedding", "label": "Caffe: Convolutional architecture for fast feature embedding", "shape": "dot", "size": 10.089285714285714, "title": "Caffe: Convolutional architecture for fast feature embedding"}, {"color": "#6FA8DC", "id": "fast feature embedding", "label": "fast feature embedding", "shape": "dot", "size": 10.089285714285714, "title": "fast feature embedding"}, {"color": "#6FA8DC", "id": "University of Massachusetts, Amherst", "label": "University of Massachusetts, Amherst", "shape": "dot", "size": 10.178571428571429, "title": "University of Massachusetts, Amherst"}, {"color": "#6FA8DC", "id": "arXiv preprint arXiv:1311.2524", "label": "arXiv preprint arXiv:1311.2524", "shape": "dot", "size": 10.089285714285714, "title": "arXiv preprint arXiv:1311.2524"}, {"color": "#6FA8DC", "id": "Advances in neural information processing systems", "label": "Advances in neural information processing systems", "shape": "dot", "size": 10.178571428571429, "title": "Advances in neural information processing systems"}, {"color": "#6FA8DC", "id": "helhamer, E.", "label": "helhamer, E.", "shape": "dot", "size": 10.089285714285714, "title": "helhamer, E."}, {"color": "#6FA8DC", "id": "Vaillant, R.", "label": "Vaillant, R.", "shape": "dot", "size": 10.089285714285714, "title": "Vaillant, R."}, {"color": "#6FA8DC", "id": "object localization approach", "label": "object localization approach", "shape": "dot", "size": 10.089285714285714, "title": "object localization approach"}, {"color": "#6FA8DC", "id": "Yang, B.", "label": "Yang, B.", "shape": "dot", "size": 10.089285714285714, "title": "Yang, B."}, {"color": "#6FA8DC", "id": "multi-view face detection method", "label": "multi-view face detection method", "shape": "dot", "size": 10.089285714285714, "title": "multi-view face detection method"}, {"color": "#6FA8DC", "id": "bootstrap learning", "label": "bootstrap learning", "shape": "dot", "size": 10.089285714285714, "title": "bootstrap learning"}, {"color": "#6FA8DC", "id": "Stevens Institute of Technology", "label": "Stevens Institute of Technology", "shape": "dot", "size": 10.357142857142858, "title": "Stevens Institute of Technology"}, {"color": "#6FA8DC", "id": "Na Tong", "label": "Na Tong", "shape": "dot", "size": 10.178571428571429, "title": "Na Tong"}, {"color": "#6FA8DC", "id": "Salient Object Detectio", "label": "Salient Object Detectio", "shape": "dot", "size": 10.089285714285714, "title": "Salient Object Detectio"}, {"color": "#6FA8DC", "id": "Xiang Ruan", "label": "Xiang Ruan", "shape": "dot", "size": 10.357142857142858, "title": "Xiang Ruan"}, {"color": "#6FA8DC", "id": "Ming-Hsuan Yang", "label": "Ming-Hsuan Yang", "shape": "dot", "size": 10.625, "title": "Ming-Hsuan Yang"}, {"color": "#6FA8DC", "id": "Bootstrap Learning", "label": "Bootstrap Learning", "shape": "dot", "size": 10.178571428571429, "title": "Bootstrap Learning"}, {"color": "#6FA8DC", "id": "Tong_Salient_Object_Detection_2015_CVPR_paper.pdf", "label": "Tong_Salient_Object_Detection_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Tong_Salient_Object_Detection_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "bootstrap learning algorithm", "label": "bootstrap learning algorithm", "shape": "dot", "size": 10.267857142857142, "title": "bootstrap learning algorithm"}, {"color": "#6FA8DC", "id": "weak models", "label": "weak models", "shape": "dot", "size": 10.089285714285714, "title": "weak models"}, {"color": "#6FA8DC", "id": "strong models", "label": "strong models", "shape": "dot", "size": 10.089285714285714, "title": "strong models"}, {"color": "#6FA8DC", "id": "weak salience map", "label": "weak salience map", "shape": "dot", "size": 10.178571428571429, "title": "weak salience map"}, {"color": "#6FA8DC", "id": "image priors", "label": "image priors", "shape": "dot", "size": 10.089285714285714, "title": "image priors"}, {"color": "#6FA8DC", "id": "training samples", "label": "training samples", "shape": "dot", "size": 10.089285714285714, "title": "training samples"}, {"color": "#6FA8DC", "id": "strong classi\ufb01er", "label": "strong classi\ufb01er", "shape": "dot", "size": 10.178571428571429, "title": "strong classi\ufb01er"}, {"color": "#6FA8DC", "id": "salient pixels", "label": "salient pixels", "shape": "dot", "size": 10.089285714285714, "title": "salient pixels"}, {"color": "#6FA8DC", "id": "input image", "label": "input image", "shape": "dot", "size": 10.089285714285714, "title": "input image"}, {"color": "#6FA8DC", "id": "multiscale salience maps", "label": "multiscale salience maps", "shape": "dot", "size": 10.089285714285714, "title": "multiscale salience maps"}, {"color": "#6FA8DC", "id": "state-of-the-art salience detection methods", "label": "state-of-the-art salience detection methods", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art salience detection methods"}, {"color": "#6FA8DC", "id": "bootstrap learning approach", "label": "bootstrap learning approach", "shape": "dot", "size": 10.089285714285714, "title": "bootstrap learning approach"}, {"color": "#6FA8DC", "id": "signi\ufb01cant improvement", "label": "signi\ufb01cant improvement", "shape": "dot", "size": 10.089285714285714, "title": "signi\ufb01cant improvement"}, {"color": "#6FA8DC", "id": "Salieny Detection Methods", "label": "Salieny Detection Methods", "shape": "dot", "size": 10.089285714285714, "title": "Salieny Detection Methods"}, {"color": "#6FA8DC", "id": "Bootstrap Learning Approach", "label": "Bootstrap Learning Approach", "shape": "dot", "size": 10.089285714285714, "title": "Bootstrap Learning Approach"}, {"color": "#6FA8DC", "id": "Bottom-up Salieny Models", "label": "Bottom-up Salieny Models", "shape": "dot", "size": 10.089285714285714, "title": "Bottom-up Salieny Models"}, {"color": "#6FA8DC", "id": "Li et al. (2014)", "label": "Li et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Li et al. (2014)"}, {"color": "#6FA8DC", "id": "Salient Object Segmentation", "label": "Salient Object Segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Salient Object Segmentation"}, {"color": "#6FA8DC", "id": "Achanta et al. (2009)", "label": "Achanta et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Achanta et al. (2009)"}, {"color": "#6FA8DC", "id": "Frequency-tuned Salient Region Detection", "label": "Frequency-tuned Salient Region Detection", "shape": "dot", "size": 10.089285714285714, "title": "Frequency-tuned Salient Region Detection"}, {"color": "#6FA8DC", "id": "Movahedi \u0026 Elder (2010)", "label": "Movahedi \u0026 Elder (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Movahedi \u0026 Elder (2010)"}, {"color": "#6FA8DC", "id": "Performance Measures", "label": "Performance Measures", "shape": "dot", "size": 10.178571428571429, "title": "Performance Measures"}, {"color": "#6FA8DC", "id": "Achanta et al. (2010)", "label": "Achanta et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Achanta et al. (2010)"}, {"color": "#6FA8DC", "id": "Slic Superpixels", "label": "Slic Superpixels", "shape": "dot", "size": 10.089285714285714, "title": "Slic Superpixels"}, {"color": "#6FA8DC", "id": "Achanta, R.", "label": "Achanta, R.", "shape": "dot", "size": 10.089285714285714, "title": "Achanta, R."}, {"color": "#6FA8DC", "id": "Ojala, T.", "label": "Ojala, T.", "shape": "dot", "size": 10.089285714285714, "title": "Ojala, T."}, {"color": "#6FA8DC", "id": "Multiresolution gray-scale texture classification", "label": "Multiresolution gray-scale texture classification", "shape": "dot", "size": 10.089285714285714, "title": "Multiresolution gray-scale texture classification"}, {"color": "#6FA8DC", "id": "Bach, F. R.", "label": "Bach, F. R.", "shape": "dot", "size": 10.089285714285714, "title": "Bach, F. R."}, {"color": "#6FA8DC", "id": "Multiple kernel learning", "label": "Multiple kernel learning", "shape": "dot", "size": 10.178571428571429, "title": "Multiple kernel learning"}, {"color": "#6FA8DC", "id": "Perazzi, F.", "label": "Perazzi, F.", "shape": "dot", "size": 10.089285714285714, "title": "Perazzi, F."}, {"color": "#6FA8DC", "id": "Saliency filters", "label": "Saliency filters", "shape": "dot", "size": 10.089285714285714, "title": "Saliency filters"}, {"color": "#6FA8DC", "id": "Borji, A.", "label": "Borji, A.", "shape": "dot", "size": 10.178571428571429, "title": "Borji, A."}, {"color": "#6FA8DC", "id": "Salient object detection benchmark", "label": "Salient object detection benchmark", "shape": "dot", "size": 10.089285714285714, "title": "Salient object detection benchmark"}, {"color": "#6FA8DC", "id": "authored", "label": "authored", "shape": "dot", "size": 10.089285714285714, "title": "authored"}, {"color": "#6FA8DC", "id": "Rahtu, E.", "label": "Rahtu, E.", "shape": "dot", "size": 10.089285714285714, "title": "Rahtu, E."}, {"color": "#6FA8DC", "id": "Salient object segmentation", "label": "Salient object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Salient object segmentation"}, {"color": "#6FA8DC", "id": "performance measures", "label": "performance measures", "shape": "dot", "size": 10.357142857142858, "title": "performance measures"}, {"color": "#6FA8DC", "id": "superpixels", "label": "superpixels", "shape": "dot", "size": 10.357142857142858, "title": "superpixels"}, {"color": "#6FA8DC", "id": "Local binary patterns", "label": "Local binary patterns", "shape": "dot", "size": 10.089285714285714, "title": "Local binary patterns"}, {"color": "#6FA8DC", "id": "SMO algorithm", "label": "SMO algorithm", "shape": "dot", "size": 10.089285714285714, "title": "SMO algorithm"}, {"color": "#6FA8DC", "id": "J. Heikkil\u00e4", "label": "J. Heikkil\u00e4", "shape": "dot", "size": 10.089285714285714, "title": "J. Heikkil\u00e4"}, {"color": "#6FA8DC", "id": "Segmenting salient objects from images and videos", "label": "Segmenting salient objects from images and videos", "shape": "dot", "size": 10.178571428571429, "title": "Segmenting salient objects from images and videos"}, {"color": "#6FA8DC", "id": "Kaiming He", "label": "Kaiming He", "shape": "dot", "size": 10.535714285714286, "title": "Kaiming He"}, {"color": "#6FA8DC", "id": "Convolutional Neural Networks at Constrained Time Cost", "label": "Convolutional Neural Networks at Constrained Time Cost", "shape": "dot", "size": 10.178571428571429, "title": "Convolutional Neural Networks at Constrained Time Cost"}, {"color": "#6FA8DC", "id": "Convolutional Neural Networks at Constained Time Cost", "label": "Convolutional Neural Networks at Constained Time Cost", "shape": "dot", "size": 10.089285714285714, "title": "Convolutional Neural Networks at Constained Time Cost"}, {"color": "#6FA8DC", "id": "OMRON Corporation", "label": "OMRON Corporation", "shape": "dot", "size": 10.089285714285714, "title": "OMRON Corporation"}, {"color": "#6FA8DC", "id": "University of California at Merced", "label": "University of California at Merced", "shape": "dot", "size": 10.178571428571429, "title": "University of California at Merced"}, {"color": "#6FA8DC", "id": "image recognition accuracy", "label": "image recognition accuracy", "shape": "dot", "size": 10.089285714285714, "title": "image recognition accuracy"}, {"color": "#6FA8DC", "id": "complex", "label": "complex", "shape": "dot", "size": 10.089285714285714, "title": "complex"}, {"color": "#6FA8DC", "id": "time-consuming", "label": "time-consuming", "shape": "dot", "size": 10.089285714285714, "title": "time-consuming"}, {"color": "#6FA8DC", "id": "CNN architectures", "label": "CNN architectures", "shape": "dot", "size": 10.089285714285714, "title": "CNN architectures"}, {"color": "#6FA8DC", "id": "architecture", "label": "architecture", "shape": "dot", "size": 10.535714285714286, "title": "architecture"}, {"color": "#6FA8DC", "id": "competitive accuracy", "label": "competitive accuracy", "shape": "dot", "size": 10.089285714285714, "title": "competitive accuracy"}, {"color": "#6FA8DC", "id": "20% faster than AlexNet", "label": "20% faster than AlexNet", "shape": "dot", "size": 10.089285714285714, "title": "20% faster than AlexNet"}, {"color": "#6FA8DC", "id": "time constraints during offline training", "label": "time constraints during offline training", "shape": "dot", "size": 10.089285714285714, "title": "time constraints during offline training"}, {"color": "#6FA8DC", "id": "accuracy improvements", "label": "accuracy improvements", "shape": "dot", "size": 10.089285714285714, "title": "accuracy improvements"}, {"color": "#6FA8DC", "id": "factors", "label": "factors", "shape": "dot", "size": 10.089285714285714, "title": "factors"}, {"color": "#6FA8DC", "id": "ImageNet dataset", "label": "ImageNet dataset", "shape": "dot", "size": 10.089285714285714, "title": "ImageNet dataset"}, {"color": "#6FA8DC", "id": "11.8% top-5 error", "label": "11.8% top-5 error", "shape": "dot", "size": 10.089285714285714, "title": "11.8% top-5 error"}, {"color": "#6FA8DC", "id": "Offline Training", "label": "Offline Training", "shape": "dot", "size": 10.089285714285714, "title": "Offline Training"}, {"color": "#6FA8DC", "id": "Time Constraints", "label": "Time Constraints", "shape": "dot", "size": 10.089285714285714, "title": "Time Constraints"}, {"color": "#6FA8DC", "id": "Accuracy Improvements", "label": "Accuracy Improvements", "shape": "dot", "size": 10.178571428571429, "title": "Accuracy Improvements"}, {"color": "#6FA8DC", "id": "Factors", "label": "Factors", "shape": "dot", "size": 10.089285714285714, "title": "Factors"}, {"color": "#6FA8DC", "id": "Architecture", "label": "Architecture", "shape": "dot", "size": 10.446428571428571, "title": "Architecture"}, {"color": "#6FA8DC", "id": "ImageNet Dataset", "label": "ImageNet Dataset", "shape": "dot", "size": 10.267857142857142, "title": "ImageNet Dataset"}, {"color": "#6FA8DC", "id": "Computer Vision Tasks", "label": "Computer Vision Tasks", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision Tasks"}, {"color": "#6FA8DC", "id": "Deng et al. (2009)", "label": "Deng et al. (2009)", "shape": "dot", "size": 10.178571428571429, "title": "Deng et al. (2009)"}, {"color": "#6FA8DC", "id": "Limited Time Budget", "label": "Limited Time Budget", "shape": "dot", "size": 10.089285714285714, "title": "Limited Time Budget"}, {"color": "#6FA8DC", "id": "Layer Replacement", "label": "Layer Replacement", "shape": "dot", "size": 10.089285714285714, "title": "Layer Replacement"}, {"color": "#6FA8DC", "id": "Architecture Optimization", "label": "Architecture Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Architecture Optimization"}, {"color": "#6FA8DC", "id": "Image Database", "label": "Image Database", "shape": "dot", "size": 10.089285714285714, "title": "Image Database"}, {"color": "#6FA8DC", "id": "ImageNet", "label": "ImageNet", "shape": "dot", "size": 11.339285714285715, "title": "ImageNet"}, {"color": "#6FA8DC", "id": "computer vision tasks", "label": "computer vision tasks", "shape": "dot", "size": 10.178571428571429, "title": "computer vision tasks"}, {"color": "#6FA8DC", "id": "hierarchical image database", "label": "hierarchical image database", "shape": "dot", "size": 10.178571428571429, "title": "hierarchical image database"}, {"color": "#6FA8DC", "id": "very deep convolutional networks", "label": "very deep convolutional networks", "shape": "dot", "size": 10.178571428571429, "title": "very deep convolutional networks"}, {"color": "#6FA8DC", "id": "development", "label": "development", "shape": "dot", "size": 10.089285714285714, "title": "development"}, {"color": "#6FA8DC", "id": "multi-column deep neural networks", "label": "multi-column deep neural networks", "shape": "dot", "size": 10.357142857142858, "title": "multi-column deep neural networks"}, {"color": "#6FA8DC", "id": "power of deep learning", "label": "power of deep learning", "shape": "dot", "size": 10.089285714285714, "title": "power of deep learning"}, {"color": "#6FA8DC", "id": "image classification", "label": "image classification", "shape": "dot", "size": 10.178571428571429, "title": "image classification"}, {"color": "#6FA8DC", "id": "rich feature hierarchies", "label": "rich feature hierarchies", "shape": "dot", "size": 10.267857142857142, "title": "rich feature hierarchies"}, {"color": "#6FA8DC", "id": "network architecture", "label": "network architecture", "shape": "dot", "size": 10.089285714285714, "title": "network architecture"}, {"color": "#6FA8DC", "id": "deep learning", "label": "deep learning", "shape": "dot", "size": 10.446428571428571, "title": "deep learning"}, {"color": "#6FA8DC", "id": "Malik et al. (2014)", "label": "Malik et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Malik et al. (2014)"}, {"color": "#6FA8DC", "id": "Zeiler et al. (2014)", "label": "Zeiler et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Zeiler et al. (2014)"}, {"color": "#6FA8DC", "id": "convolutional neural networks", "label": "convolutional neural networks", "shape": "dot", "size": 10.267857142857142, "title": "convolutional neural networks"}, {"color": "#6FA8DC", "id": "interpretability", "label": "interpretability", "shape": "dot", "size": 10.089285714285714, "title": "interpretability"}, {"color": "#6FA8DC", "id": "Eigen et al. (2013)", "label": "Eigen et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Eigen et al. (2013)"}, {"color": "#6FA8DC", "id": "deep architectures", "label": "deep architectures", "shape": "dot", "size": 10.446428571428571, "title": "deep architectures"}, {"color": "#6FA8DC", "id": "recursive convolutional networks", "label": "recursive convolutional networks", "shape": "dot", "size": 10.178571428571429, "title": "recursive convolutional networks"}, {"color": "#6FA8DC", "id": "Chatfield et al. (2014)", "label": "Chatfield et al. (2014)", "shape": "dot", "size": 10.178571428571429, "title": "Chatfield et al. (2014)"}, {"color": "#6FA8DC", "id": "convolutional networks", "label": "convolutional networks", "shape": "dot", "size": 10.535714285714286, "title": "convolutional networks"}, {"color": "#6FA8DC", "id": "details", "label": "details", "shape": "dot", "size": 10.178571428571429, "title": "details"}, {"color": "#6FA8DC", "id": "Return of the devil in the details", "label": "Return of the devil in the details", "shape": "dot", "size": 10.178571428571429, "title": "Return of the devil in the details"}, {"color": "#6FA8DC", "id": "Overfeat", "label": "Overfeat", "shape": "dot", "size": 10.089285714285714, "title": "Overfeat"}, {"color": "#6FA8DC", "id": "integrated recognition, localization, and detection system", "label": "integrated recognition, localization, and detection system", "shape": "dot", "size": 10.089285714285714, "title": "integrated recognition, localization, and detection system"}, {"color": "#6FA8DC", "id": "Going deeper with convolutions", "label": "Going deeper with convolutions", "shape": "dot", "size": 10.089285714285714, "title": "Going deeper with convolutions"}, {"color": "#6FA8DC", "id": "convolutions", "label": "convolutions", "shape": "dot", "size": 10.089285714285714, "title": "convolutions"}, {"color": "#6FA8DC", "id": "Lei Zhang", "label": "Lei Zhang", "shape": "dot", "size": 10.089285714285714, "title": "Lei Zhang"}, {"color": "#6FA8DC", "id": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing", "label": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing", "shape": "dot", "size": 10.446428571428571, "title": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing"}, {"color": "#6FA8DC", "id": "Yanning Zhang", "label": "Yanning Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Yanning Zhang"}, {"color": "#6FA8DC", "id": "Chunna Tian", "label": "Chunna Tian", "shape": "dot", "size": 10.267857142857142, "title": "Chunna Tian"}, {"color": "#6FA8DC", "id": "Fei Li", "label": "Fei Li", "shape": "dot", "size": 10.267857142857142, "title": "Fei Li"}, {"color": "#6FA8DC", "id": "Wei Wei", "label": "Wei Wei", "shape": "dot", "size": 10.089285714285714, "title": "Wei Wei"}, {"color": "#6FA8DC", "id": "Reweighted Laplace Prior Based Hyperspectra Compressives Sensing", "label": "Reweighted Laplace Prior Based Hyperspectra Compressives Sensing", "shape": "dot", "size": 10.089285714285714, "title": "Reweighted Laplace Prior Based Hyperspectra Compressives Sensing"}, {"color": "#6FA8DC", "id": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing", "label": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing", "shape": "dot", "size": 10.446428571428571, "title": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing"}, {"color": "#6FA8DC", "id": "Hyperspectral Compressives Sensing", "label": "Hyperspectral Compressives Sensing", "shape": "dot", "size": 10.089285714285714, "title": "Hyperspectral Compressives Sensing"}, {"color": "#6FA8DC", "id": "Laplace Prior", "label": "Laplace Prior", "shape": "dot", "size": 10.089285714285714, "title": "Laplace Prior"}, {"color": "#6FA8DC", "id": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf", "label": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.446428571428571, "title": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Zhang_Reweighted_Lapless_Prior_2015_CVPR_supplemental.pdf", "label": "Zhang_Reweighted_Lapless_Prior_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Zhang_Reweighted_Lapless_Prior_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "hyperspectral compressive sensing method", "label": "hyperspectral compressive sensing method", "shape": "dot", "size": 10.178571428571429, "title": "hyperspectral compressive sensing method"}, {"color": "#6FA8DC", "id": "reweighted Laplace prior", "label": "reweighted Laplace prior", "shape": "dot", "size": 10.089285714285714, "title": "reweighted Laplace prior"}, {"color": "#6FA8DC", "id": "unknown sparsity", "label": "unknown sparsity", "shape": "dot", "size": 10.089285714285714, "title": "unknown sparsity"}, {"color": "#6FA8DC", "id": "optimization procedure", "label": "optimization procedure", "shape": "dot", "size": 10.357142857142858, "title": "optimization procedure"}, {"color": "#6FA8DC", "id": "matrix algebra manipulations", "label": "matrix algebra manipulations", "shape": "dot", "size": 10.089285714285714, "title": "matrix algebra manipulations"}, {"color": "#6FA8DC", "id": "conjugate functions", "label": "conjugate functions", "shape": "dot", "size": 10.178571428571429, "title": "conjugate functions"}, {"color": "#6FA8DC", "id": "non-convex optimization problems", "label": "non-convex optimization problems", "shape": "dot", "size": 10.089285714285714, "title": "non-convex optimization problems"}, {"color": "#6FA8DC", "id": "sparsity learning over \u03b3", "label": "sparsity learning over \u03b3", "shape": "dot", "size": 10.089285714285714, "title": "sparsity learning over \u03b3"}, {"color": "#6FA8DC", "id": "noise estimation over \u03bb", "label": "noise estimation over \u03bb", "shape": "dot", "size": 10.089285714285714, "title": "noise estimation over \u03bb"}, {"color": "#6FA8DC", "id": "Hyberspectral Compressive Sensing", "label": "Hyberspectral Compressive Sensing", "shape": "dot", "size": 10.089285714285714, "title": "Hyberspectral Compressive Sensing"}, {"color": "#6FA8DC", "id": "Reweighted Laplace Prior", "label": "Reweighted Laplace Prior", "shape": "dot", "size": 10.089285714285714, "title": "Reweighted Laplace Prior"}, {"color": "#6FA8DC", "id": "optimization technique", "label": "optimization technique", "shape": "dot", "size": 10.535714285714286, "title": "optimization technique"}, {"color": "#6FA8DC", "id": "Sparsity Learning", "label": "Sparsity Learning", "shape": "dot", "size": 10.089285714285714, "title": "Sparsity Learning"}, {"color": "#6FA8DC", "id": "Noise Estimation", "label": "Noise Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Noise Estimation"}, {"color": "#6FA8DC", "id": "Fang_Collaborative_Feature_Learning_2015_CVPR_paper", "label": "Fang_Collaborative_Feature_Learning_2015_CVPR_paper", "shape": "dot", "size": 10.178571428571429, "title": "Fang_Collaborative_Feature_Learning_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "research paper", "label": "research paper", "shape": "dot", "size": 10.625, "title": "research paper"}, {"color": "#6FA8DC", "id": "Paper Abstract", "label": "Paper Abstract", "shape": "dot", "size": 10.089285714285714, "title": "Paper Abstract"}, {"color": "#6FA8DC", "id": "readable text", "label": "readable text", "shape": "dot", "size": 10.089285714285714, "title": "readable text"}, {"color": "#6FA8DC", "id": "Research", "label": "Research", "shape": "dot", "size": 10.625, "title": "Research"}, {"color": "#6FA8DC", "id": "Data Encoding/Decoding", "label": "Data Encoding/Decoding", "shape": "dot", "size": 10.089285714285714, "title": "Data Encoding/Decoding"}, {"color": "#6FA8DC", "id": "Text Corruption/Error Correction", "label": "Text Corruption/Error Correction", "shape": "dot", "size": 10.089285714285714, "title": "Text Corruption/Error Correction"}, {"color": "#6FA8DC", "id": "Information Retrieval", "label": "Information Retrieval", "shape": "dot", "size": 10.089285714285714, "title": "Information Retrieval"}, {"color": "#6FA8DC", "id": "Victor Escorcia", "label": "Victor Escorcia", "shape": "dot", "size": 10.357142857142858, "title": "Victor Escorcia"}, {"color": "#6FA8DC", "id": "On the Relationship between Visual Attributes and Convolutional Networks", "label": "On the Relationship between Visual Attributes and Convolutional Networks", "shape": "dot", "size": 10.267857142857142, "title": "On the Relationship between Visual Attributes and Convolutional Networks"}, {"color": "#6FA8DC", "id": "Juan Carlos Niebles", "label": "Juan Carlos Niebles", "shape": "dot", "size": 10.357142857142858, "title": "Juan Carlos Niebles"}, {"color": "#6FA8DC", "id": "Bernard Ghanem", "label": "Bernard Ghanem", "shape": "dot", "size": 10.625, "title": "Bernard Ghanem"}, {"color": "#6FA8DC", "id": "Convolutional Networks", "label": "Convolutional Networks", "shape": "dot", "size": 10.178571428571429, "title": "Convolutional Networks"}, {"color": "#6FA8DC", "id": "Visual Attributes", "label": "Visual Attributes", "shape": "dot", "size": 10.178571428571429, "title": "Visual Attributes"}, {"color": "#6FA8DC", "id": "visual attributes", "label": "visual attributes", "shape": "dot", "size": 10.178571428571429, "title": "visual attributes"}, {"color": "#6FA8DC", "id": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf", "label": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.446428571428571, "title": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucomaa/LLM/Ollama_pdf_handle/cvpr_papers", "label": "/mnt/DATA/Glucomaa/LLM/Ollama_pdf_handle/cvpr_papers", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucomaa/LLM/Ollama_pdf_handle/cvpr_papers"}, {"color": "#6FA8DC", "id": "conv-nets", "label": "conv-nets", "shape": "dot", "size": 10.178571428571429, "title": "conv-nets"}, {"color": "#6FA8DC", "id": "abstract concepts", "label": "abstract concepts", "shape": "dot", "size": 10.178571428571429, "title": "abstract concepts"}, {"color": "#6FA8DC", "id": "objects in images", "label": "objects in images", "shape": "dot", "size": 10.089285714285714, "title": "objects in images"}, {"color": "#6FA8DC", "id": "semantic visual attributes", "label": "semantic visual attributes", "shape": "dot", "size": 10.178571428571429, "title": "semantic visual attributes"}, {"color": "#6FA8DC", "id": "object description", "label": "object description", "shape": "dot", "size": 10.089285714285714, "title": "object description"}, {"color": "#6FA8DC", "id": "Attribute Centric Nodes (ACNs)", "label": "Attribute Centric Nodes (ACNs)", "shape": "dot", "size": 10.267857142857142, "title": "Attribute Centric Nodes (ACNs)"}, {"color": "#6FA8DC", "id": "conv-net", "label": "conv-net", "shape": "dot", "size": 10.357142857142858, "title": "conv-net"}, {"color": "#6FA8DC", "id": "objects", "label": "objects", "shape": "dot", "size": 10.178571428571429, "title": "objects"}, {"color": "#6FA8DC", "id": "visual attribute representation", "label": "visual attribute representation", "shape": "dot", "size": 10.178571428571429, "title": "visual attribute representation"}, {"color": "#6FA8DC", "id": "discrimination", "label": "discrimination", "shape": "dot", "size": 10.089285714285714, "title": "discrimination"}, {"color": "#6FA8DC", "id": "conv-net nodes", "label": "conv-net nodes", "shape": "dot", "size": 10.535714285714286, "title": "conv-net nodes"}, {"color": "#6FA8DC", "id": "information", "label": "information", "shape": "dot", "size": 10.178571428571429, "title": "information"}, {"color": "#6FA8DC", "id": "layers", "label": "layers", "shape": "dot", "size": 10.089285714285714, "title": "layers"}, {"color": "#6FA8DC", "id": "sparsely distributed", "label": "sparsely distributed", "shape": "dot", "size": 10.089285714285714, "title": "sparsely distributed"}, {"color": "#6FA8DC", "id": "unevenly distributed", "label": "unevenly distributed", "shape": "dot", "size": 10.089285714285714, "title": "unevenly distributed"}, {"color": "#6FA8DC", "id": "visual attribute representation and discrimination", "label": "visual attribute representation and discrimination", "shape": "dot", "size": 10.089285714285714, "title": "visual attribute representation and discrimination"}, {"color": "#6FA8DC", "id": "conv-net based object recognition", "label": "conv-net based object recognition", "shape": "dot", "size": 10.089285714285714, "title": "conv-net based object recognition"}, {"color": "#6FA8DC", "id": "Zero-Shot Object Recognition", "label": "Zero-Shot Object Recognition", "shape": "dot", "size": 10.267857142857142, "title": "Zero-Shot Object Recognition"}, {"color": "#6FA8DC", "id": "Semantic Manifold Distance", "label": "Semantic Manifold Distance", "shape": "dot", "size": 10.089285714285714, "title": "Semantic Manifold Distance"}, {"color": "#6FA8DC", "id": "Zhenyong Fu", "label": "Zhenyong Fu", "shape": "dot", "size": 10.178571428571429, "title": "Zhenyong Fu"}, {"color": "#6FA8DC", "id": "Tao Xiang", "label": "Tao Xiang", "shape": "dot", "size": 10.267857142857142, "title": "Tao Xiang"}, {"color": "#6FA8DC", "id": "Elyor Kodirov", "label": "Elyor Kodirov", "shape": "dot", "size": 10.178571428571429, "title": "Elyor Kodirov"}, {"color": "#6FA8DC", "id": "Zero-Shot Object Research", "label": "Zero-Shot Object Research", "shape": "dot", "size": 10.178571428571429, "title": "Zero-Shot Object Research"}, {"color": "#6FA8DC", "id": "Shaogang Gong", "label": "Shaogang Gong", "shape": "dot", "size": 10.089285714285714, "title": "Shaogang Gong"}, {"color": "#6FA8DC", "id": "King Abdullah University of Science and Technology", "label": "King Abdullah University of Science and Technology", "shape": "dot", "size": 10.178571428571429, "title": "King Abdullah University of Science and Technology"}, {"color": "#6FA8DC", "id": "Universidad del Norte", "label": "Universidad del Norte", "shape": "dot", "size": 10.089285714285714, "title": "Universidad del Norte"}, {"color": "#6FA8DC", "id": "Zero-shot learning", "label": "Zero-shot learning", "shape": "dot", "size": 10.178571428571429, "title": "Zero-shot learning"}, {"color": "#6FA8DC", "id": "recognise objects", "label": "recognise objects", "shape": "dot", "size": 10.089285714285714, "title": "recognise objects"}, {"color": "#6FA8DC", "id": "knowledge transfer", "label": "knowledge transfer", "shape": "dot", "size": 10.178571428571429, "title": "knowledge transfer"}, {"color": "#6FA8DC", "id": "existing works", "label": "existing works", "shape": "dot", "size": 10.089285714285714, "title": "existing works"}, {"color": "#6FA8DC", "id": "similarity", "label": "similarity", "shape": "dot", "size": 10.178571428571429, "title": "similarity"}, {"color": "#6FA8DC", "id": "semantic embedding space", "label": "semantic embedding space", "shape": "dot", "size": 10.178571428571429, "title": "semantic embedding space"}, {"color": "#6FA8DC", "id": "distance metrics", "label": "distance metrics", "shape": "dot", "size": 10.178571428571429, "title": "distance metrics"}, {"color": "#6FA8DC", "id": "intrinsic structure", "label": "intrinsic structure", "shape": "dot", "size": 10.178571428571429, "title": "intrinsic structure"}, {"color": "#6FA8DC", "id": "semantic categories", "label": "semantic categories", "shape": "dot", "size": 10.089285714285714, "title": "semantic categories"}, {"color": "#6FA8DC", "id": "semantic class label graph", "label": "semantic class label graph", "shape": "dot", "size": 10.089285714285714, "title": "semantic class label graph"}, {"color": "#6FA8DC", "id": "absorbing Markov chain process", "label": "absorbing Markov chain process", "shape": "dot", "size": 10.178571428571429, "title": "absorbing Markov chain process"}, {"color": "#6FA8DC", "id": "semantic manifold distance", "label": "semantic manifold distance", "shape": "dot", "size": 10.178571428571429, "title": "semantic manifold distance"}, {"color": "#6FA8DC", "id": "existing ZSL algorithms", "label": "existing ZSL algorithms", "shape": "dot", "size": 10.089285714285714, "title": "existing ZSL algorithms"}, {"color": "#6FA8DC", "id": "performance gains", "label": "performance gains", "shape": "dot", "size": 10.357142857142858, "title": "performance gains"}, {"color": "#6FA8DC", "id": "AwA datasets", "label": "AwA datasets", "shape": "dot", "size": 10.089285714285714, "title": "AwA datasets"}, {"color": "#6FA8DC", "id": "proposed model", "label": "proposed model", "shape": "dot", "size": 10.178571428571429, "title": "proposed model"}, {"color": "#6FA8DC", "id": "ZSL algorithms", "label": "ZSL algorithms", "shape": "dot", "size": 10.089285714285714, "title": "ZSL algorithms"}, {"color": "#6FA8DC", "id": "semantic manifold", "label": "semantic manifold", "shape": "dot", "size": 10.089285714285714, "title": "semantic manifold"}, {"color": "#6FA8DC", "id": "AMP", "label": "AMP", "shape": "dot", "size": 10.178571428571429, "title": "AMP"}, {"color": "#6FA8DC", "id": "Label-embedding", "label": "Label-embedding", "shape": "dot", "size": 10.178571428571429, "title": "Label-embedding"}, {"color": "#6FA8DC", "id": "Akata et al. (2013)", "label": "Akata et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Akata et al. (2013)"}, {"color": "#6FA8DC", "id": "Single-example learning", "label": "Single-example learning", "shape": "dot", "size": 10.089285714285714, "title": "Single-example learning"}, {"color": "#6FA8DC", "id": "Bart \u0026 Ullman (2005)", "label": "Bart \u0026 Ullman (2005)", "shape": "dot", "size": 10.089285714285714, "title": "Bart \u0026 Ullman (2005)"}, {"color": "#6FA8DC", "id": "Cluster kernels", "label": "Cluster kernels", "shape": "dot", "size": 10.357142857142858, "title": "Cluster kernels"}, {"color": "#6FA8DC", "id": "Chapelle et al. (2002)", "label": "Chapelle et al. (2002)", "shape": "dot", "size": 10.089285714285714, "title": "Chapelle et al. (2002)"}, {"color": "#6FA8DC", "id": "Zero-shot learning (ZSL)", "label": "Zero-shot learning (ZSL)", "shape": "dot", "size": 10.089285714285714, "title": "Zero-shot learning (ZSL)"}, {"color": "#6FA8DC", "id": "Chapelle", "label": "Chapelle", "shape": "dot", "size": 10.089285714285714, "title": "Chapelle"}, {"color": "#6FA8DC", "id": "Weston", "label": "Weston", "shape": "dot", "size": 10.089285714285714, "title": "Weston"}, {"color": "#6FA8DC", "id": "Sch\u00f6lkopf", "label": "Sch\u00f6lkopf", "shape": "dot", "size": 10.089285714285714, "title": "Sch\u00f6lkopf"}, {"color": "#6FA8DC", "id": "Deng", "label": "Deng", "shape": "dot", "size": 10.178571428571429, "title": "Deng"}, {"color": "#6FA8DC", "id": "Large-scale object classification", "label": "Large-scale object classification", "shape": "dot", "size": 10.357142857142858, "title": "Large-scale object classification"}, {"color": "#6FA8DC", "id": "Ding", "label": "Ding", "shape": "dot", "size": 10.267857142857142, "title": "Ding"}, {"color": "#6FA8DC", "id": "Label relation graphs", "label": "Label relation graphs", "shape": "dot", "size": 10.089285714285714, "title": "Label relation graphs"}, {"color": "#6FA8DC", "id": "Dong", "label": "Dong", "shape": "dot", "size": 10.089285714285714, "title": "Dong"}, {"color": "#6FA8DC", "id": "Frome", "label": "Frome", "shape": "dot", "size": 10.089285714285714, "title": "Frome"}, {"color": "#6FA8DC", "id": "Devise", "label": "Devise", "shape": "dot", "size": 10.357142857142858, "title": "Devise"}, {"color": "#6FA8DC", "id": "embedding model", "label": "embedding model", "shape": "dot", "size": 10.089285714285714, "title": "embedding model"}, {"color": "#6FA8DC", "id": "Transductive multi-view embedding", "label": "Transductive multi-view embedding", "shape": "dot", "size": 10.178571428571429, "title": "Transductive multi-view embedding"}, {"color": "#6FA8DC", "id": "Zero shot recognition with unreliable attributes", "label": "Zero shot recognition with unreliable attributes", "shape": "dot", "size": 10.089285714285714, "title": "Zero shot recognition with unreliable attributes"}, {"color": "#6FA8DC", "id": "ImageNet classification", "label": "ImageNet classification", "shape": "dot", "size": 10.625, "title": "ImageNet classification"}, {"color": "#6FA8DC", "id": "Efficient estimation of word representations", "label": "Efficient estimation of word representations", "shape": "dot", "size": 10.089285714285714, "title": "Efficient estimation of word representations"}, {"color": "#6FA8DC", "id": "Queen Mary, University of London", "label": "Queen Mary, University of London", "shape": "dot", "size": 10.267857142857142, "title": "Queen Mary, University of London"}, {"color": "#6FA8DC", "id": "visual-semantic embedding", "label": "visual-semantic embedding", "shape": "dot", "size": 10.089285714285714, "title": "visual-semantic embedding"}, {"color": "#6FA8DC", "id": "zero-shot recognition", "label": "zero-shot recognition", "shape": "dot", "size": 10.089285714285714, "title": "zero-shot recognition"}, {"color": "#6FA8DC", "id": "QueenMary, University of London", "label": "QueenMary, University of London", "shape": "dot", "size": 10.089285714285714, "title": "QueenMary, University of London"}, {"color": "#6FA8DC", "id": "Sakrapee Paisitkriangkrai", "label": "Sakrapee Paisitkriangkrai", "shape": "dot", "size": 10.267857142857142, "title": "Sakrapee Paisitkriangkrai"}, {"color": "#6FA8DC", "id": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "label": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "shape": "dot", "size": 10.535714285714286, "title": "Learning to rank in person re-identi\ufb01cation with metric ensembles"}, {"color": "#6FA8DC", "id": "Chunhua Shen", "label": "Chunhua Shen", "shape": "dot", "size": 10.714285714285714, "title": "Chunhua Shen"}, {"color": "#6FA8DC", "id": "Anton van den Hengel", "label": "Anton van den Hengel", "shape": "dot", "size": 10.625, "title": "Anton van den Hengel"}, {"color": "#6FA8DC", "id": "Paisitkriangrai_Learning_to_Rank_2015_CVPR_paper.pdf", "label": "Paisitkriangrai_Learning_to_Rank_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Paisitkriangrai_Learning_to_Rank_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "match pedestrian images", "label": "match pedestrian images", "shape": "dot", "size": 10.089285714285714, "title": "match pedestrian images"}, {"color": "#6FA8DC", "id": "predefined weights", "label": "predefined weights", "shape": "dot", "size": 10.178571428571429, "title": "predefined weights"}, {"color": "#6FA8DC", "id": "not adaptable", "label": "not adaptable", "shape": "dot", "size": 10.089285714285714, "title": "not adaptable"}, {"color": "#6FA8DC", "id": "two principled approaches", "label": "two principled approaches", "shape": "dot", "size": 10.267857142857142, "title": "two principled approaches"}, {"color": "#6FA8DC", "id": "relative distance", "label": "relative distance", "shape": "dot", "size": 10.089285714285714, "title": "relative distance"}, {"color": "#6FA8DC", "id": "average rank-k recognition rate", "label": "average rank-k recognition rate", "shape": "dot", "size": 10.089285714285714, "title": "average rank-k recognition rate"}, {"color": "#6FA8DC", "id": "multiple visual features", "label": "multiple visual features", "shape": "dot", "size": 10.089285714285714, "title": "multiple visual features"}, {"color": "#6FA8DC", "id": "flexible", "label": "flexible", "shape": "dot", "size": 10.178571428571429, "title": "flexible"}, {"color": "#6FA8DC", "id": "RMS methods", "label": "RMS methods", "shape": "dot", "size": 10.089285714285714, "title": "RMS methods"}, {"color": "#6FA8DC", "id": "rank-1 recognition rates", "label": "rank-1 recognition rates", "shape": "dot", "size": 10.089285714285714, "title": "rank-1 recognition rates"}, {"color": "#6FA8DC", "id": "Ensemble-based approaches", "label": "Ensemble-based approaches", "shape": "dot", "size": 10.267857142857142, "title": "Ensemble-based approaches"}, {"color": "#6FA8DC", "id": "linear metrics", "label": "linear metrics", "shape": "dot", "size": 10.089285714285714, "title": "linear metrics"}, {"color": "#6FA8DC", "id": "non-linear metrics", "label": "non-linear metrics", "shape": "dot", "size": 10.089285714285714, "title": "non-linear metrics"}, {"color": "#6FA8DC", "id": "Similarity metric", "label": "Similarity metric", "shape": "dot", "size": 10.178571428571429, "title": "Similarity metric"}, {"color": "#6FA8DC", "id": "Person Re-Identification", "label": "Person Re-Identification", "shape": "dot", "size": 10.267857142857142, "title": "Person Re-Identification"}, {"color": "#6FA8DC", "id": "Gong et al. (2014)", "label": "Gong et al. (2014)", "shape": "dot", "size": 10.178571428571429, "title": "Gong et al. (2014)"}, {"color": "#6FA8DC", "id": "techniques", "label": "techniques", "shape": "dot", "size": 10.357142857142858, "title": "techniques"}, {"color": "#6FA8DC", "id": "Gong, S., Crisitan, M., Yan, S., and Loy, C. C.", "label": "Gong, S., Crisitan, M., Yan, S., and Loy, C. C.", "shape": "dot", "size": 10.178571428571429, "title": "Gong, S., Crisitan, M., Yan, S., and Loy, C. C."}, {"color": "#6FA8DC", "id": "support vector method", "label": "support vector method", "shape": "dot", "size": 10.178571428571429, "title": "support vector method"}, {"color": "#6FA8DC", "id": "Joachims, T.", "label": "Joachims, T.", "shape": "dot", "size": 10.089285714285714, "title": "Joachims, T."}, {"color": "#6FA8DC", "id": "Krizhevsky, A., Sutskever, I., and Hinton, G. E.", "label": "Krizhevsky, A., Sutskever, I., and Hinton, G. E.", "shape": "dot", "size": 10.089285714285714, "title": "Krizhevsky, A., Sutskever, I., and Hinton, G. E."}, {"color": "#6FA8DC", "id": "re-identification models", "label": "re-identification models", "shape": "dot", "size": 10.178571428571429, "title": "re-identification models"}, {"color": "#6FA8DC", "id": "re-identification systems", "label": "re-identification systems", "shape": "dot", "size": 10.089285714285714, "title": "re-identification systems"}, {"color": "#6FA8DC", "id": "Imaginet classification", "label": "Imaginet classification", "shape": "dot", "size": 10.089285714285714, "title": "Imaginet classification"}, {"color": "#6FA8DC", "id": "deep convolutional neural networks", "label": "deep convolutional neural networks", "shape": "dot", "size": 10.446428571428571, "title": "deep convolutional neural networks"}, {"color": "#6FA8DC", "id": "Mahalanobis distance", "label": "Mahalanobis distance", "shape": "dot", "size": 10.267857142857142, "title": "Mahalanobis distance"}, {"color": "#6FA8DC", "id": "metric learning", "label": "metric learning", "shape": "dot", "size": 10.267857142857142, "title": "metric learning"}, {"color": "#6FA8DC", "id": "scalability", "label": "scalability", "shape": "dot", "size": 10.267857142857142, "title": "scalability"}, {"color": "#6FA8DC", "id": "distance metric learning", "label": "distance metric learning", "shape": "dot", "size": 10.178571428571429, "title": "distance metric learning"}, {"color": "#6FA8DC", "id": "computational challenges", "label": "computational challenges", "shape": "dot", "size": 10.178571428571429, "title": "computational challenges"}, {"color": "#6FA8DC", "id": "paper (Felzenszwalb et al., 2010)", "label": "paper (Felzenszwalb et al., 2010)", "shape": "dot", "size": 10.178571428571429, "title": "paper (Felzenszwalb et al., 2010)"}, {"color": "#6FA8DC", "id": "part-based model", "label": "part-based model", "shape": "dot", "size": 10.178571428571429, "title": "part-based model"}, {"color": "#6FA8DC", "id": "re-identification", "label": "re-identification", "shape": "dot", "size": 10.178571428571429, "title": "re-identification"}, {"color": "#6FA8DC", "id": "image representation techniques", "label": "image representation techniques", "shape": "dot", "size": 10.178571428571429, "title": "image representation techniques"}, {"color": "#6FA8DC", "id": "shape and appearance information", "label": "shape and appearance information", "shape": "dot", "size": 10.089285714285714, "title": "shape and appearance information"}, {"color": "#6FA8DC", "id": "robust re-identification", "label": "robust re-identification", "shape": "dot", "size": 10.089285714285714, "title": "robust re-identification"}, {"color": "#6FA8DC", "id": "kernel methods", "label": "kernel methods", "shape": "dot", "size": 10.446428571428571, "title": "kernel methods"}, {"color": "#6FA8DC", "id": "The University of Adelaide", "label": "The University of Adelaide", "shape": "dot", "size": 10.178571428571429, "title": "The University of Adelaide"}, {"color": "#6FA8DC", "id": "Australian Centre for Robotic Vision", "label": "Australian Centre for Robotic Vision", "shape": "dot", "size": 10.446428571428571, "title": "Australian Centre for Robotic Vision"}, {"color": "#6FA8DC", "id": "keypoints", "label": "keypoints", "shape": "dot", "size": 10.178571428571429, "title": "keypoints"}, {"color": "#6FA8DC", "id": "Adelaide, Australia", "label": "Adelaide, Australia", "shape": "dot", "size": 10.089285714285714, "title": "Adelaide, Australia"}, {"color": "#6FA8DC", "id": "The University of Adelaide, Australia", "label": "The University of Adelaide, Australia", "shape": "dot", "size": 10.267857142857142, "title": "The University of Adelaide, Australia"}, {"color": "#6FA8DC", "id": "Dengxin Dai", "label": "Dengxin Dai", "shape": "dot", "size": 10.178571428571429, "title": "Dengxin Dai"}, {"color": "#6FA8DC", "id": "Metric imitation by manifold transfer", "label": "Metric imitation by manifold transfer", "shape": "dot", "size": 10.446428571428571, "title": "Metric imitation by manifold transfer"}, {"color": "#6FA8DC", "id": "Till Kroeger", "label": "Till Kroeger", "shape": "dot", "size": 10.089285714285714, "title": "Till Kroeger"}, {"color": "#6FA8DC", "id": "Radu Timofte", "label": "Radu Timofte", "shape": "dot", "size": 10.178571428571429, "title": "Radu Timofte"}, {"color": "#6FA8DC", "id": "efficient vision applications", "label": "efficient vision applications", "shape": "dot", "size": 10.089285714285714, "title": "efficient vision applications"}, {"color": "#6FA8DC", "id": "Metric Imitation", "label": "Metric Imitation", "shape": "dot", "size": 10.625, "title": "Metric Imitation"}, {"color": "#6FA8DC", "id": "improve performance", "label": "improve performance", "shape": "dot", "size": 10.089285714285714, "title": "improve performance"}, {"color": "#6FA8DC", "id": "manifold structure", "label": "manifold structure", "shape": "dot", "size": 10.089285714285714, "title": "manifold structure"}, {"color": "#6FA8DC", "id": "vision applications", "label": "vision applications", "shape": "dot", "size": 10.089285714285714, "title": "vision applications"}, {"color": "#6FA8DC", "id": "GIST features", "label": "GIST features", "shape": "dot", "size": 10.089285714285714, "title": "GIST features"}, {"color": "#6FA8DC", "id": "target features", "label": "target features", "shape": "dot", "size": 10.089285714285714, "title": "target features"}, {"color": "#6FA8DC", "id": "SIFT-llc", "label": "SIFT-llc", "shape": "dot", "size": 10.089285714285714, "title": "SIFT-llc"}, {"color": "#6FA8DC", "id": "source features", "label": "source features", "shape": "dot", "size": 10.267857142857142, "title": "source features"}, {"color": "#6FA8DC", "id": "object-bank", "label": "object-bank", "shape": "dot", "size": 10.089285714285714, "title": "object-bank"}, {"color": "#6FA8DC", "id": "CNN features", "label": "CNN features", "shape": "dot", "size": 10.178571428571429, "title": "CNN features"}, {"color": "#6FA8DC", "id": "instance-based object retrieval", "label": "instance-based object retrieval", "shape": "dot", "size": 10.089285714285714, "title": "instance-based object retrieval"}, {"color": "#6FA8DC", "id": "image clustering", "label": "image clustering", "shape": "dot", "size": 10.089285714285714, "title": "image clustering"}, {"color": "#6FA8DC", "id": "category-based image retrieval", "label": "category-based image retrieval", "shape": "dot", "size": 10.089285714285714, "title": "category-based image retrieval"}, {"color": "#6FA8DC", "id": "better performance", "label": "better performance", "shape": "dot", "size": 10.178571428571429, "title": "better performance"}, {"color": "#6FA8DC", "id": "Metric Imitation (MI)", "label": "Metric Imitation (MI)", "shape": "dot", "size": 10.178571428571429, "title": "Metric Imitation (MI)"}, {"color": "#6FA8DC", "id": "original target features", "label": "original target features", "shape": "dot", "size": 10.089285714285714, "title": "original target features"}, {"color": "#6FA8DC", "id": "Bosch, A.", "label": "Bosch, A.", "shape": "dot", "size": 10.089285714285714, "title": "Bosch, A."}, {"color": "#6FA8DC", "id": "Image classification using random forests and ferns", "label": "Image classification using random forests and ferns", "shape": "dot", "size": 10.089285714285714, "title": "Image classification using random forests and ferns"}, {"color": "#6FA8DC", "id": "Chatfield, K.", "label": "Chatfield, K.", "shape": "dot", "size": 10.089285714285714, "title": "Chatfield, K."}, {"color": "#6FA8DC", "id": "Dai, D.", "label": "Dai, D.", "shape": "dot", "size": 10.089285714285714, "title": "Dai, D."}, {"color": "#6FA8DC", "id": "Ensemble partitioning", "label": "Ensemble partitioning", "shape": "dot", "size": 10.178571428571429, "title": "Ensemble partitioning"}, {"color": "#6FA8DC", "id": "llc", "label": "llc", "shape": "dot", "size": 10.089285714285714, "title": "llc"}, {"color": "#6FA8DC", "id": "Object Retrieval", "label": "Object Retrieval", "shape": "dot", "size": 10.089285714285714, "title": "Object Retrieval"}, {"color": "#6FA8DC", "id": "Object-bank (OB)", "label": "Object-bank (OB)", "shape": "dot", "size": 10.089285714285714, "title": "Object-bank (OB)"}, {"color": "#6FA8DC", "id": "Image Clustering", "label": "Image Clustering", "shape": "dot", "size": 10.089285714285714, "title": "Image Clustering"}, {"color": "#6FA8DC", "id": "Dana et al.", "label": "Dana et al.", "shape": "dot", "size": 10.089285714285714, "title": "Dana et al."}, {"color": "#6FA8DC", "id": "Reflectance and texture of real-world surfaces", "label": "Reflectance and texture of real-world surfaces", "shape": "dot", "size": 10.178571428571429, "title": "Reflectance and texture of real-world surfaces"}, {"color": "#6FA8DC", "id": "*ACM Trans. Graph.*", "label": "*ACM Trans. Graph.*", "shape": "dot", "size": 10.089285714285714, "title": "*ACM Trans. Graph.*"}, {"color": "#6FA8DC", "id": "Fei-Fei et al.", "label": "Fei-Fei et al.", "shape": "dot", "size": 10.089285714285714, "title": "Fei-Fei et al."}, {"color": "#6FA8DC", "id": "Learning generative visual models", "label": "Learning generative visual models", "shape": "dot", "size": 10.178571428571429, "title": "Learning generative visual models"}, {"color": "#6FA8DC", "id": "Workshop on Generative-Model Based Vision", "label": "Workshop on Generative-Model Based Vision", "shape": "dot", "size": 10.089285714285714, "title": "Workshop on Generative-Model Based Vision"}, {"color": "#6FA8DC", "id": "Lazebnik et al.", "label": "Lazebnik et al.", "shape": "dot", "size": 10.089285714285714, "title": "Lazebnik et al."}, {"color": "#6FA8DC", "id": "Spatial pyramid matching", "label": "Spatial pyramid matching", "shape": "dot", "size": 10.178571428571429, "title": "Spatial pyramid matching"}, {"color": "#6FA8DC", "id": "recognizing natural scene categories", "label": "recognizing natural scene categories", "shape": "dot", "size": 10.089285714285714, "title": "recognizing natural scene categories"}, {"color": "#6FA8DC", "id": "Li \u0026 Fei-Fei", "label": "Li \u0026 Fei-Fei", "shape": "dot", "size": 10.089285714285714, "title": "Li \u0026 Fei-Fei"}, {"color": "#6FA8DC", "id": "What, where and who?", "label": "What, where and who?", "shape": "dot", "size": 10.267857142857142, "title": "What, where and who?"}, {"color": "#6FA8DC", "id": "Li et al. (2010)", "label": "Li et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Li et al. (2010)"}, {"color": "#6FA8DC", "id": "Object bank", "label": "Object bank", "shape": "dot", "size": 10.357142857142858, "title": "Object bank"}, {"color": "#6FA8DC", "id": "scene classification", "label": "scene classification", "shape": "dot", "size": 10.178571428571429, "title": "scene classification"}, {"color": "#6FA8DC", "id": "Li, L.-J. et al. (2010)", "label": "Li, L.-J. et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Li, L.-J. et al. (2010)"}, {"color": "#6FA8DC", "id": "*NIPS*", "label": "*NIPS*", "shape": "dot", "size": 10.089285714285714, "title": "*NIPS*"}, {"color": "#6FA8DC", "id": "Nist\u00b4er, D. \u0026 Stew\u00b4enius, H. (2006)", "label": "Nist\u00b4er, D. \u0026 Stew\u00b4enius, H. (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Nist\u00b4er, D. \u0026 Stew\u00b4enius, H. (2006)"}, {"color": "#6FA8DC", "id": "*CVPR*", "label": "*CVPR*", "shape": "dot", "size": 10.267857142857142, "title": "*CVPR*"}, {"color": "#6FA8DC", "id": "Vocabulary tree", "label": "Vocabulary tree", "shape": "dot", "size": 10.089285714285714, "title": "Vocabulary tree"}, {"color": "#6FA8DC", "id": "scalable recognition", "label": "scalable recognition", "shape": "dot", "size": 10.178571428571429, "title": "scalable recognition"}, {"color": "#6FA8DC", "id": "Oliva, A. \u0026 Torralba, A. (2001)", "label": "Oliva, A. \u0026 Torralba, A. (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Oliva, A. \u0026 Torralba, A. (2001)"}, {"color": "#6FA8DC", "id": "*IJCV*", "label": "*IJCV*", "shape": "dot", "size": 10.089285714285714, "title": "*IJCV*"}, {"color": "#6FA8DC", "id": "Spatial envelope", "label": "Spatial envelope", "shape": "dot", "size": 10.089285714285714, "title": "Spatial envelope"}, {"color": "#6FA8DC", "id": "shape of the scene", "label": "shape of the scene", "shape": "dot", "size": 10.089285714285714, "title": "shape of the scene"}, {"color": "#6FA8DC", "id": "Tuytelaars, T. et al. (2009)", "label": "Tuytelaars, T. et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Tuytelaars, T. et al. (2009)"}, {"color": "#6FA8DC", "id": "*IJCLP*", "label": "*IJCLP*", "shape": "dot", "size": 10.089285714285714, "title": "*IJCLP*"}, {"color": "#6FA8DC", "id": "Object discovery", "label": "Object discovery", "shape": "dot", "size": 10.089285714285714, "title": "Object discovery"}, {"color": "#6FA8DC", "id": "unsupervised", "label": "unsupervised", "shape": "dot", "size": 10.089285714285714, "title": "unsupervised"}, {"color": "#6FA8DC", "id": "Wang, J. et al. (2010)", "label": "Wang, J. et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Wang, J. et al. (2010)"}, {"color": "#6FA8DC", "id": "Locality-constrained linear coding", "label": "Locality-constrained linear coding", "shape": "dot", "size": 10.089285714285714, "title": "Locality-constrained linear coding"}, {"color": "#6FA8DC", "id": "Computer Vision Lab, ETH Zurich", "label": "Computer Vision Lab, ETH Zurich", "shape": "dot", "size": 10.535714285714286, "title": "Computer Vision Lab, ETH Zurich"}, {"color": "#6FA8DC", "id": "ETH Zurich", "label": "ETH Zurich", "shape": "dot", "size": 10.089285714285714, "title": "ETH Zurich"}, {"color": "#6FA8DC", "id": "VISICS, ESAT/PSI, KU Leuven", "label": "VISICS, ESAT/PSI, KU Leuven", "shape": "dot", "size": 10.089285714285714, "title": "VISICS, ESAT/PSI, KU Leuven"}, {"color": "#6FA8DC", "id": "Francesco Pittaluca", "label": "Francesco Pittaluca", "shape": "dot", "size": 10.178571428571429, "title": "Francesco Pittaluca"}, {"color": "#6FA8DC", "id": "Sanjeev J. Koppal", "label": "Sanjeev J. Koppal", "shape": "dot", "size": 10.178571428571429, "title": "Sanjeev J. Koppal"}, {"color": "#6FA8DC", "id": "Pittaluga_Privacy_Preserving_Optics_2015_CVPR_supplemental.pdf", "label": "Pittaluga_Privacy_Preserving_Optics_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Pittaluga_Privacy_Preserving_Optics_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Privacy Preserving Optics for Miniature Vision Sensors", "label": "Privacy Preserving Optics for Miniature Vision Sensors", "shape": "dot", "size": 10.357142857142858, "title": "Privacy Preserving Optics for Miniature Vision Sensors"}, {"color": "#6FA8DC", "id": "Privacy Preseving Optics for Miniature Vision Sensors", "label": "Privacy Preseving Optics for Miniature Vision Sensors", "shape": "dot", "size": 10.089285714285714, "title": "Privacy Preseving Optics for Miniature Vision Sensors"}, {"color": "#6FA8DC", "id": "supplementary material", "label": "supplementary material", "shape": "dot", "size": 10.178571428571429, "title": "supplementary material"}, {"color": "#6FA8DC", "id": "privacy-preserving optics", "label": "privacy-preserving optics", "shape": "dot", "size": 10.178571428571429, "title": "privacy-preserving optics"}, {"color": "#6FA8DC", "id": "minature vision sensors", "label": "minature vision sensors", "shape": "dot", "size": 10.089285714285714, "title": "minature vision sensors"}, {"color": "#6FA8DC", "id": "impact of defocusing optics", "label": "impact of defocusing optics", "shape": "dot", "size": 10.089285714285714, "title": "impact of defocusing optics"}, {"color": "#6FA8DC", "id": "performance of face recognition algorithms", "label": "performance of face recognition algorithms", "shape": "dot", "size": 10.089285714285714, "title": "performance of face recognition algorithms"}, {"color": "#6FA8DC", "id": "angular support", "label": "angular support", "shape": "dot", "size": 10.267857142857142, "title": "angular support"}, {"color": "#6FA8DC", "id": "FLIR One thermal sensor", "label": "FLIR One thermal sensor", "shape": "dot", "size": 10.178571428571429, "title": "FLIR One thermal sensor"}, {"color": "#6FA8DC", "id": "Kinect time-of-flight sensor", "label": "Kinect time-of-flight sensor", "shape": "dot", "size": 10.178571428571429, "title": "Kinect time-of-flight sensor"}, {"color": "#6FA8DC", "id": "effect of blur", "label": "effect of blur", "shape": "dot", "size": 10.178571428571429, "title": "effect of blur"}, {"color": "#6FA8DC", "id": "face recognition rates", "label": "face recognition rates", "shape": "dot", "size": 10.089285714285714, "title": "face recognition rates"}, {"color": "#6FA8DC", "id": "geometric derivations", "label": "geometric derivations", "shape": "dot", "size": 10.178571428571429, "title": "geometric derivations"}, {"color": "#6FA8DC", "id": "determining angular support", "label": "determining angular support", "shape": "dot", "size": 10.089285714285714, "title": "determining angular support"}, {"color": "#6FA8DC", "id": "Privacy-preserving optics", "label": "Privacy-preserving optics", "shape": "dot", "size": 10.089285714285714, "title": "Privacy-preserving optics"}, {"color": "#6FA8DC", "id": "Facial images", "label": "Facial images", "shape": "dot", "size": 10.089285714285714, "title": "Facial images"}, {"color": "#6FA8DC", "id": "Feret methodology", "label": "Feret methodology", "shape": "dot", "size": 10.178571428571429, "title": "Feret methodology"}, {"color": "#6FA8DC", "id": "CSU face identification evaluation system", "label": "CSU face identification evaluation system", "shape": "dot", "size": 10.178571428571429, "title": "CSU face identification evaluation system"}, {"color": "#6FA8DC", "id": "Face identification", "label": "Face identification", "shape": "dot", "size": 10.089285714285714, "title": "Face identification"}, {"color": "#6FA8DC", "id": "Angular support derivation", "label": "Angular support derivation", "shape": "dot", "size": 10.267857142857142, "title": "Angular support derivation"}, {"color": "#6FA8DC", "id": "Bolme, D. S. et al.", "label": "Bolme, D. S. et al.", "shape": "dot", "size": 10.089285714285714, "title": "Bolme, D. S. et al."}, {"color": "#6FA8DC", "id": "Newton, E. et al.", "label": "Newton, E. et al.", "shape": "dot", "size": 10.089285714285714, "title": "Newton, E. et al."}, {"color": "#6FA8DC", "id": "Privacy-preserving techniques", "label": "Privacy-preserving techniques", "shape": "dot", "size": 10.089285714285714, "title": "Privacy-preserving techniques"}, {"color": "#6FA8DC", "id": "Phillips, P. J. et al.", "label": "Phillips, P. J. et al.", "shape": "dot", "size": 10.089285714285714, "title": "Phillips, P. J. et al."}, {"color": "#6FA8DC", "id": "Feret evaluation methodology", "label": "Feret evaluation methodology", "shape": "dot", "size": 10.178571428571429, "title": "Feret evaluation methodology"}, {"color": "#6FA8DC", "id": "Face recognition evaluation", "label": "Face recognition evaluation", "shape": "dot", "size": 10.089285714285714, "title": "Face recognition evaluation"}, {"color": "#6FA8DC", "id": "Sensor positioning", "label": "Sensor positioning", "shape": "dot", "size": 10.089285714285714, "title": "Sensor positioning"}, {"color": "#6FA8DC", "id": "face recognition evaluation", "label": "face recognition evaluation", "shape": "dot", "size": 10.089285714285714, "title": "face recognition evaluation"}, {"color": "#6FA8DC", "id": "Park, Min-Gyu", "label": "Park, Min-Gyu", "shape": "dot", "size": 10.178571428571429, "title": "Park, Min-Gyu"}, {"color": "#6FA8DC", "id": "Leveraging Stereo Matching with Learning-based Con\ufb01dence Measures", "label": "Leveraging Stereo Matching with Learning-based Con\ufb01dence Measures", "shape": "dot", "size": 10.089285714285714, "title": "Leveraging Stereo Matching with Learning-based Con\ufb01dence Measures"}, {"color": "#6FA8DC", "id": "Yoon, Kuk-Jin", "label": "Yoon, Kuk-Jin", "shape": "dot", "size": 10.089285714285714, "title": "Yoon, Kuk-Jin"}, {"color": "#6FA8DC", "id": "Leverging Stereo Matching with Learning-based Con\ufb01dence Measures", "label": "Leverging Stereo Matching with Learning-based Con\ufb01dence Measures", "shape": "dot", "size": 10.089285714285714, "title": "Leverging Stereo Matching with Learning-based Con\ufb01dence Measures"}, {"color": "#6FA8DC", "id": "Pittaluga, Francesco", "label": "Pittaluga, Francesco", "shape": "dot", "size": 10.178571428571429, "title": "Pittaluga, Francesco"}, {"color": "#6FA8DC", "id": "P. J. The furet evaluation methodology", "label": "P. J. The furet evaluation methodology", "shape": "dot", "size": 10.089285714285714, "title": "P. J. The furet evaluation methodology"}, {"color": "#6FA8DC", "id": "Random Forests", "label": "Random Forests", "shape": "dot", "size": 10.446428571428571, "title": "Random Forests"}, {"color": "#6FA8DC", "id": "Breiman, L.", "label": "Breiman, L.", "shape": "dot", "size": 10.178571428571429, "title": "Breiman, L."}, {"color": "#6FA8DC", "id": "Random forests", "label": "Random forests", "shape": "dot", "size": 10.267857142857142, "title": "Random forests"}, {"color": "#6FA8DC", "id": "University of Florida", "label": "University of Florida", "shape": "dot", "size": 10.267857142857142, "title": "University of Florida"}, {"color": "#6FA8DC", "id": "Koppal, Sanjeev J.", "label": "Koppal, Sanjeev J.", "shape": "dot", "size": 10.089285714285714, "title": "Koppal, Sanjeev J."}, {"color": "#6FA8DC", "id": "Breiman", "label": "Breiman", "shape": "dot", "size": 10.089285714285714, "title": "Breiman"}, {"color": "#6FA8DC", "id": "stereo confidence metric", "label": "stereo confidence metric", "shape": "dot", "size": 10.267857142857142, "title": "stereo confidence metric"}, {"color": "#6FA8DC", "id": "key aspect of stereo vision", "label": "key aspect of stereo vision", "shape": "dot", "size": 10.089285714285714, "title": "key aspect of stereo vision"}, {"color": "#6FA8DC", "id": "Egnal", "label": "Egnal", "shape": "dot", "size": 10.089285714285714, "title": "Egnal"}, {"color": "#6FA8DC", "id": "Hirschm\u00fcller", "label": "Hirschm\u00fcller", "shape": "dot", "size": 10.089285714285714, "title": "Hirschm\u00fcller"}, {"color": "#6FA8DC", "id": "semiglobal matching", "label": "semiglobal matching", "shape": "dot", "size": 10.446428571428571, "title": "semiglobal matching"}, {"color": "#6FA8DC", "id": "mutual information", "label": "mutual information", "shape": "dot", "size": 10.267857142857142, "title": "mutual information"}, {"color": "#6FA8DC", "id": "stereo vision", "label": "stereo vision", "shape": "dot", "size": 10.267857142857142, "title": "stereo vision"}, {"color": "#6FA8DC", "id": "stereo processing", "label": "stereo processing", "shape": "dot", "size": 10.089285714285714, "title": "stereo processing"}, {"color": "#6FA8DC", "id": "stereo matching", "label": "stereo matching", "shape": "dot", "size": 10.089285714285714, "title": "stereo matching"}, {"color": "#6FA8DC", "id": "ground control points", "label": "ground control points", "shape": "dot", "size": 10.089285714285714, "title": "ground control points"}, {"color": "#6FA8DC", "id": "benchmark", "label": "benchmark", "shape": "dot", "size": 10.178571428571429, "title": "benchmark"}, {"color": "#6FA8DC", "id": "vision", "label": "vision", "shape": "dot", "size": 10.089285714285714, "title": "vision"}, {"color": "#6FA8DC", "id": "robotics", "label": "robotics", "shape": "dot", "size": 10.089285714285714, "title": "robotics"}, {"color": "#6FA8DC", "id": "vision and robotics", "label": "vision and robotics", "shape": "dot", "size": 10.089285714285714, "title": "vision and robotics"}, {"color": "#6FA8DC", "id": "Hu, X.", "label": "Hu, X.", "shape": "dot", "size": 10.089285714285714, "title": "Hu, X."}, {"color": "#6FA8DC", "id": "quantitative evaluation", "label": "quantitative evaluation", "shape": "dot", "size": 10.178571428571429, "title": "quantitative evaluation"}, {"color": "#6FA8DC", "id": "confidence measures", "label": "confidence measures", "shape": "dot", "size": 10.267857142857142, "title": "confidence measures"}, {"color": "#6FA8DC", "id": "dense matching", "label": "dense matching", "shape": "dot", "size": 10.089285714285714, "title": "dense matching"}, {"color": "#6FA8DC", "id": "complex scenes", "label": "complex scenes", "shape": "dot", "size": 10.089285714285714, "title": "complex scenes"}, {"color": "#6FA8DC", "id": "Manduchi, R.", "label": "Manduchi, R.", "shape": "dot", "size": 10.089285714285714, "title": "Manduchi, R."}, {"color": "#6FA8DC", "id": "distinctiveness maps", "label": "distinctiveness maps", "shape": "dot", "size": 10.267857142857142, "title": "distinctiveness maps"}, {"color": "#6FA8DC", "id": "image matching", "label": "image matching", "shape": "dot", "size": 10.178571428571429, "title": "image matching"}, {"color": "#6FA8DC", "id": "pose estimation", "label": "pose estimation", "shape": "dot", "size": 10.535714285714286, "title": "pose estimation"}, {"color": "#6FA8DC", "id": "determining viewpoint", "label": "determining viewpoint", "shape": "dot", "size": 10.089285714285714, "title": "determining viewpoint"}, {"color": "#6FA8DC", "id": "viewpoint", "label": "viewpoint", "shape": "dot", "size": 10.089285714285714, "title": "viewpoint"}, {"color": "#6FA8DC", "id": "coarse pose", "label": "coarse pose", "shape": "dot", "size": 10.089285714285714, "title": "coarse pose"}, {"color": "#6FA8DC", "id": "keypoint prediction", "label": "keypoint prediction", "shape": "dot", "size": 10.089285714285714, "title": "keypoint prediction"}, {"color": "#6FA8DC", "id": "finer details", "label": "finer details", "shape": "dot", "size": 10.089285714285714, "title": "finer details"}, {"color": "#6FA8DC", "id": "constrained setting", "label": "constrained setting", "shape": "dot", "size": 10.178571428571429, "title": "constrained setting"}, {"color": "#6FA8DC", "id": "bounding boxes", "label": "bounding boxes", "shape": "dot", "size": 10.089285714285714, "title": "bounding boxes"}, {"color": "#6FA8DC", "id": "detection setting", "label": "detection setting", "shape": "dot", "size": 10.089285714285714, "title": "detection setting"}, {"color": "#6FA8DC", "id": "viewpoint estimates", "label": "viewpoint estimates", "shape": "dot", "size": 10.089285714285714, "title": "viewpoint estimates"}, {"color": "#6FA8DC", "id": "keypoint predictions", "label": "keypoint predictions", "shape": "dot", "size": 10.089285714285714, "title": "keypoint predictions"}, {"color": "#6FA8DC", "id": "object characteristics", "label": "object characteristics", "shape": "dot", "size": 10.178571428571429, "title": "object characteristics"}, {"color": "#6FA8DC", "id": "Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper", "label": "Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper", "shape": "dot", "size": 10.178571428571429, "title": "Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Shubham Tulsiani", "label": "Shubham Tulsiani", "shape": "dot", "size": 10.267857142857142, "title": "Shubham Tulsiani"}, {"color": "#6FA8DC", "id": "Jitendra Malik", "label": "Jitendra Malik", "shape": "dot", "size": 10.357142857142858, "title": "Jitendra Malik"}, {"color": "#6FA8DC", "id": "effort", "label": "effort", "shape": "dot", "size": 10.089285714285714, "title": "effort"}, {"color": "#6FA8DC", "id": "future efforts", "label": "future efforts", "shape": "dot", "size": 10.089285714285714, "title": "future efforts"}, {"color": "#6FA8DC", "id": "analysis", "label": "analysis", "shape": "dot", "size": 10.267857142857142, "title": "analysis"}, {"color": "#6FA8DC", "id": "error modes", "label": "error modes", "shape": "dot", "size": 10.089285714285714, "title": "error modes"}, {"color": "#6FA8DC", "id": "effect", "label": "effect", "shape": "dot", "size": 10.089285714285714, "title": "effect"}, {"color": "#6FA8DC", "id": "Pose Estimation", "label": "Pose Estimation", "shape": "dot", "size": 10.446428571428571, "title": "Pose Estimation"}, {"color": "#6FA8DC", "id": "University of California, Berkeley", "label": "University of California, Berkeley", "shape": "dot", "size": 10.535714285714286, "title": "University of California, Berkeley"}, {"color": "#6FA8DC", "id": "Song_Joint_Multi-Feature_Spatial_2015_CVPR_paper", "label": "Song_Joint_Multi-Feature_Spatial_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Song_Joint_Multi-Feature_Spatial_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Abed Malti", "label": "Abed Malti", "shape": "dot", "size": 10.267857142857142, "title": "Abed Malti"}, {"color": "#6FA8DC", "id": "Malti_A_Linear_Least-Squares_2015_CVPR_paper", "label": "Malti_A_Linear_Least-Squares_2015_CVPR_paper", "shape": "dot", "size": 10.178571428571429, "title": "Malti_A_Linear_Least-Squares_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Adrien Bartoli", "label": "Adrien Bartoli", "shape": "dot", "size": 10.178571428571429, "title": "Adrien Bartoli"}, {"color": "#6FA8DC", "id": "Maiti_A_Linear_Least-Squares_2015_CVPR_paper", "label": "Maiti_A_Linear_Least-Squares_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Maiti_A_Linear_Least-Squares_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Richard Hartley", "label": "Richard Hartley", "shape": "dot", "size": 10.267857142857142, "title": "Richard Hartley"}, {"color": "#6FA8DC", "id": "Keypoint Prediction", "label": "Keypoint Prediction", "shape": "dot", "size": 10.089285714285714, "title": "Keypoint Prediction"}, {"color": "#6FA8DC", "id": "Viewpoint Prediction", "label": "Viewpoint Prediction", "shape": "dot", "size": 10.089285714285714, "title": "Viewpoint Prediction"}, {"color": "#6FA8DC", "id": "Shape-from-Template methods", "label": "Shape-from-Template methods", "shape": "dot", "size": 10.089285714285714, "title": "Shape-from-Template methods"}, {"color": "#6FA8DC", "id": "balancing accuracy, speed, and robustness", "label": "balancing accuracy, speed, and robustness", "shape": "dot", "size": 10.089285714285714, "title": "balancing accuracy, speed, and robustness"}, {"color": "#6FA8DC", "id": "non-linear optimization", "label": "non-linear optimization", "shape": "dot", "size": 10.089285714285714, "title": "non-linear optimization"}, {"color": "#6FA8DC", "id": "existing approach", "label": "existing approach", "shape": "dot", "size": 10.178571428571429, "title": "existing approach"}, {"color": "#6FA8DC", "id": "Kalman filtering", "label": "Kalman filtering", "shape": "dot", "size": 10.089285714285714, "title": "Kalman filtering"}, {"color": "#6FA8DC", "id": "computational cost", "label": "computational cost", "shape": "dot", "size": 10.178571428571429, "title": "computational cost"}, {"color": "#6FA8DC", "id": "initialization", "label": "initialization", "shape": "dot", "size": 10.178571428571429, "title": "initialization"}, {"color": "#6FA8DC", "id": "error accumulation", "label": "error accumulation", "shape": "dot", "size": 10.089285714285714, "title": "error accumulation"}, {"color": "#6FA8DC", "id": "proposed solution", "label": "proposed solution", "shape": "dot", "size": 10.446428571428571, "title": "proposed solution"}, {"color": "#6FA8DC", "id": "mechanical constraints", "label": "mechanical constraints", "shape": "dot", "size": 10.089285714285714, "title": "mechanical constraints"}, {"color": "#6FA8DC", "id": "finite element methods", "label": "finite element methods", "shape": "dot", "size": 10.267857142857142, "title": "finite element methods"}, {"color": "#6FA8DC", "id": "surface", "label": "surface", "shape": "dot", "size": 10.089285714285714, "title": "surface"}, {"color": "#6FA8DC", "id": "deformation", "label": "deformation", "shape": "dot", "size": 10.089285714285714, "title": "deformation"}, {"color": "#6FA8DC", "id": "accurate reconstruction", "label": "accurate reconstruction", "shape": "dot", "size": 10.178571428571429, "title": "accurate reconstruction"}, {"color": "#6FA8DC", "id": "efficient reconstruction", "label": "efficient reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "efficient reconstruction"}, {"color": "#6FA8DC", "id": "linear least-squares SfT method", "label": "linear least-squares SfT method", "shape": "dot", "size": 10.089285714285714, "title": "linear least-squares SfT method"}, {"color": "#6FA8DC", "id": "Shape-from-Template (SfT)", "label": "Shape-from-Template (SfT)", "shape": "dot", "size": 10.178571428571429, "title": "Shape-from-Template (SfT)"}, {"color": "#6FA8DC", "id": "elastic deformations", "label": "elastic deformations", "shape": "dot", "size": 10.267857142857142, "title": "elastic deformations"}, {"color": "#6FA8DC", "id": "linear least-squares estimation", "label": "linear least-squares estimation", "shape": "dot", "size": 10.089285714285714, "title": "linear least-squares estimation"}, {"color": "#6FA8DC", "id": "Finite Element Methods (FEM)", "label": "Finite Element Methods (FEM)", "shape": "dot", "size": 10.178571428571429, "title": "Finite Element Methods (FEM)"}, {"color": "#6FA8DC", "id": "non-rigid EKF monocular SLAM", "label": "non-rigid EKF monocular SLAM", "shape": "dot", "size": 10.089285714285714, "title": "non-rigid EKF monocular SLAM"}, {"color": "#6FA8DC", "id": "sequential bayesian non-rigid structure from motion", "label": "sequential bayesian non-rigid structure from motion", "shape": "dot", "size": 10.089285714285714, "title": "sequential bayesian non-rigid structure from motion"}, {"color": "#6FA8DC", "id": "Agudo, A.", "label": "Agudo, A.", "shape": "dot", "size": 10.178571428571429, "title": "Agudo, A."}, {"color": "#6FA8DC", "id": "FEM models to code non-rigid EKF monocular SLAM", "label": "FEM models to code non-rigid EKF monocular SLAM", "shape": "dot", "size": 10.089285714285714, "title": "FEM models to code non-rigid EKF monocular SLAM"}, {"color": "#6FA8DC", "id": "Finite element based sequential bayesian non-rigid structure from motion", "label": "Finite element based sequential bayesian non-rigid structure from motion", "shape": "dot", "size": 10.178571428571429, "title": "Finite element based sequential bayesian non-rigid structure from motion"}, {"color": "#6FA8DC", "id": "FEM models", "label": "FEM models", "shape": "dot", "size": 10.089285714285714, "title": "FEM models"}, {"color": "#6FA8DC", "id": "frequently", "label": "frequently", "shape": "dot", "size": 10.178571428571429, "title": "frequently"}, {"color": "#6FA8DC", "id": "fully linear least-squares SfT method", "label": "fully linear least-squares SfT method", "shape": "dot", "size": 10.089285714285714, "title": "fully linear least-squares SfT method"}, {"color": "#6FA8DC", "id": "Agudo et al.", "label": "Agudo et al.", "shape": "dot", "size": 10.178571428571429, "title": "Agudo et al."}, {"color": "#6FA8DC", "id": "related work", "label": "related work", "shape": "dot", "size": 10.089285714285714, "title": "related work"}, {"color": "#6FA8DC", "id": "Bartoli et al.", "label": "Bartoli et al.", "shape": "dot", "size": 10.178571428571429, "title": "Bartoli et al."}, {"color": "#6FA8DC", "id": "methodology", "label": "methodology", "shape": "dot", "size": 10.089285714285714, "title": "methodology"}, {"color": "#6FA8DC", "id": "Salzmann and Urtasun", "label": "Salzmann and Urtasun", "shape": "dot", "size": 10.089285714285714, "title": "Salzmann and Urtasun"}, {"color": "#6FA8DC", "id": "Moreno-Noguer and Porta", "label": "Moreno-Noguer and Porta", "shape": "dot", "size": 10.178571428571429, "title": "Moreno-Noguer and Porta"}, {"color": "#6FA8DC", "id": "Finite Element Methods", "label": "Finite Element Methods", "shape": "dot", "size": 10.089285714285714, "title": "Finite Element Methods"}, {"color": "#6FA8DC", "id": "Chaskalovic", "label": "Chaskalovic", "shape": "dot", "size": 10.089285714285714, "title": "Chaskalovic"}, {"color": "#6FA8DC", "id": "structure from motion", "label": "structure from motion", "shape": "dot", "size": 10.089285714285714, "title": "structure from motion"}, {"color": "#6FA8DC", "id": "Salzmann and Urutasun", "label": "Salzmann and Urutasun", "shape": "dot", "size": 10.089285714285714, "title": "Salzmann and Urutasun"}, {"color": "#6FA8DC", "id": "3D reconstruction", "label": "3D reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "3D reconstruction"}, {"color": "#6FA8DC", "id": "shape recovery", "label": "shape recovery", "shape": "dot", "size": 10.089285714285714, "title": "shape recovery"}, {"color": "#6FA8DC", "id": "ape recovery", "label": "ape recovery", "shape": "dot", "size": 10.089285714285714, "title": "ape recovery"}, {"color": "#6FA8DC", "id": "Chaskaloric", "label": "Chaskaloric", "shape": "dot", "size": 10.089285714285714, "title": "Chaskaloric"}, {"color": "#6FA8DC", "id": "Finite Elements Methods for Engineering Sciences", "label": "Finite Elements Methods for Engineering Sciences", "shape": "dot", "size": 10.178571428571429, "title": "Finite Elements Methods for Engineering Sciences"}, {"color": "#6FA8DC", "id": "background knowledge", "label": "background knowledge", "shape": "dot", "size": 10.178571428571429, "title": "background knowledge"}, {"color": "#6FA8DC", "id": "Reconstructing sharply folding surfaces", "label": "Reconstructing sharply folding surfaces", "shape": "dot", "size": 10.089285714285714, "title": "Reconstructing sharply folding surfaces"}, {"color": "#6FA8DC", "id": "feature extraction", "label": "feature extraction", "shape": "dot", "size": 10.089285714285714, "title": "feature extraction"}, {"color": "#6FA8DC", "id": "Salzmann, M., and Fua, P.", "label": "Salzmann, M., and Fua, P.", "shape": "dot", "size": 10.089285714285714, "title": "Salzmann, M., and Fua, P."}, {"color": "#6FA8DC", "id": "Linear local models for monocular reconstruction", "label": "Linear local models for monocular reconstruction", "shape": "dot", "size": 10.178571428571429, "title": "Linear local models for monocular reconstruction"}, {"color": "#6FA8DC", "id": "Matthews, I., and Baker, S.", "label": "Matthews, I., and Baker, S.", "shape": "dot", "size": 10.089285714285714, "title": "Matthews, I., and Baker, S."}, {"color": "#6FA8DC", "id": "Active appearance models revisited", "label": "Active appearance models revisited", "shape": "dot", "size": 10.178571428571429, "title": "Active appearance models revisited"}, {"color": "#6FA8DC", "id": "modeling techniques", "label": "modeling techniques", "shape": "dot", "size": 10.089285714285714, "title": "modeling techniques"}, {"color": "#6FA8DC", "id": "Fluminance/INRIA", "label": "Fluminance/INRIA", "shape": "dot", "size": 10.089285714285714, "title": "Fluminance/INRIA"}, {"color": "#6FA8DC", "id": "appearance models", "label": "appearance models", "shape": "dot", "size": 10.357142857142858, "title": "appearance models"}, {"color": "#6FA8DC", "id": "Fuminance/INRIA", "label": "Fuminance/INRIA", "shape": "dot", "size": 10.089285714285714, "title": "Fuminance/INRIA"}, {"color": "#6FA8DC", "id": "ALCoV/ISIT", "label": "ALCoV/ISIT", "shape": "dot", "size": 10.089285714285714, "title": "ALCoV/ISIT"}, {"color": "#6FA8DC", "id": "NICTA", "label": "NICTA", "shape": "dot", "size": 10.267857142857142, "title": "NICTA"}, {"color": "#6FA8DC", "id": "Riemannian Coding", "label": "Riemannian Coding", "shape": "dot", "size": 10.089285714285714, "title": "Riemannian Coding"}, {"color": "#6FA8DC", "id": "Kernels", "label": "Kernels", "shape": "dot", "size": 10.089285714285714, "title": "Kernels"}, {"color": "#6FA8DC", "id": "Mehrtash Harandi", "label": "Mehrtash Harandi", "shape": "dot", "size": 10.089285714285714, "title": "Mehrtash Harandi"}, {"color": "#6FA8DC", "id": "Riemannian Coding and Dictionary Learning", "label": "Riemannian Coding and Dictionary Learning", "shape": "dot", "size": 10.178571428571429, "title": "Riemannian Coding and Dictionary Learning"}, {"color": "#6FA8DC", "id": "coding and dictionary learning", "label": "coding and dictionary learning", "shape": "dot", "size": 10.089285714285714, "title": "coding and dictionary learning"}, {"color": "#6FA8DC", "id": "covariance descriptors", "label": "covariance descriptors", "shape": "dot", "size": 10.089285714285714, "title": "covariance descriptors"}, {"color": "#6FA8DC", "id": "Riemannian manifolds", "label": "Riemannian manifolds", "shape": "dot", "size": 10.357142857142858, "title": "Riemannian manifolds"}, {"color": "#6FA8DC", "id": "normalized histograms", "label": "normalized histograms", "shape": "dot", "size": 10.089285714285714, "title": "normalized histograms"}, {"color": "#6FA8DC", "id": "linear subspaces", "label": "linear subspaces", "shape": "dot", "size": 10.089285714285714, "title": "linear subspaces"}, {"color": "#6FA8DC", "id": "Riemannianmanifolds", "label": "Riemannianmanifolds", "shape": "dot", "size": 10.089285714285714, "title": "Riemannianmanifolds"}, {"color": "#6FA8DC", "id": "2D shape outlines", "label": "2D shape outlines", "shape": "dot", "size": 10.089285714285714, "title": "2D shape outlines"}, {"color": "#6FA8DC", "id": "existing solutions", "label": "existing solutions", "shape": "dot", "size": 10.178571428571429, "title": "existing solutions"}, {"color": "#6FA8DC", "id": "dedicated to specific manifolds", "label": "dedicated to specific manifolds", "shape": "dot", "size": 10.089285714285714, "title": "dedicated to specific manifolds"}, {"color": "#6FA8DC", "id": "optimization problems", "label": "optimization problems", "shape": "dot", "size": 10.178571428571429, "title": "optimization problems"}, {"color": "#6FA8DC", "id": "difficult to solve", "label": "difficult to solve", "shape": "dot", "size": 10.089285714285714, "title": "difficult to solve"}, {"color": "#6FA8DC", "id": "kernels", "label": "kernels", "shape": "dot", "size": 10.089285714285714, "title": "kernels"}, {"color": "#6FA8DC", "id": "general Riemannian coding framework", "label": "general Riemannian coding framework", "shape": "dot", "size": 10.178571428571429, "title": "general Riemannian coding framework"}, {"color": "#6FA8DC", "id": "kernel-based counterpart", "label": "kernel-based counterpart", "shape": "dot", "size": 10.357142857142858, "title": "kernel-based counterpart"}, {"color": "#6FA8DC", "id": "generalization beyond sparse coding", "label": "generalization beyond sparse coding", "shape": "dot", "size": 10.178571428571429, "title": "generalization beyond sparse coding"}, {"color": "#6FA8DC", "id": "Riemannian coding framework", "label": "Riemannian coding framework", "shape": "dot", "size": 10.357142857142858, "title": "Riemannian coding framework"}, {"color": "#6FA8DC", "id": "learning of kernel parameters", "label": "learning of kernel parameters", "shape": "dot", "size": 10.089285714285714, "title": "learning of kernel parameters"}, {"color": "#6FA8DC", "id": "dictionary learning", "label": "dictionary learning", "shape": "dot", "size": 10.089285714285714, "title": "dictionary learning"}, {"color": "#6FA8DC", "id": "non-flat manifolds", "label": "non-flat manifolds", "shape": "dot", "size": 10.089285714285714, "title": "non-flat manifolds"}, {"color": "#6FA8DC", "id": "Euclidean spaces", "label": "Euclidean spaces", "shape": "dot", "size": 10.089285714285714, "title": "Euclidean spaces"}, {"color": "#6FA8DC", "id": "kernel parameters", "label": "kernel parameters", "shape": "dot", "size": 10.089285714285714, "title": "kernel parameters"}, {"color": "#6FA8DC", "id": "sparse coding", "label": "sparse coding", "shape": "dot", "size": 10.089285714285714, "title": "sparse coding"}, {"color": "#6FA8DC", "id": "flat data", "label": "flat data", "shape": "dot", "size": 10.089285714285714, "title": "flat data"}, {"color": "#6FA8DC", "id": "coding schemes", "label": "coding schemes", "shape": "dot", "size": 10.089285714285714, "title": "coding schemes"}, {"color": "#6FA8DC", "id": "efficient solutions", "label": "efficient solutions", "shape": "dot", "size": 10.089285714285714, "title": "efficient solutions"}, {"color": "#6FA8DC", "id": "Riemannian Manifolds", "label": "Riemannian Manifolds", "shape": "dot", "size": 10.089285714285714, "title": "Riemannian Manifolds"}, {"color": "#6FA8DC", "id": "Dictionary Learning", "label": "Dictionary Learning", "shape": "dot", "size": 10.089285714285714, "title": "Dictionary Learning"}, {"color": "#6FA8DC", "id": "Coding Theory", "label": "Coding Theory", "shape": "dot", "size": 10.089285714285714, "title": "Coding Theory"}, {"color": "#6FA8DC", "id": "Mehrtas Harandi", "label": "Mehrtas Harandi", "shape": "dot", "size": 10.178571428571429, "title": "Mehrtas Harandi"}, {"color": "#6FA8DC", "id": "NICITA", "label": "NICITA", "shape": "dot", "size": 10.178571428571429, "title": "NICITA"}, {"color": "#6FA8DC", "id": "Yuting Zhang", "label": "Yuting Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Yuting Zhang"}, {"color": "#6FA8DC", "id": "Improving Object Detection", "label": "Improving Object Detection", "shape": "dot", "size": 10.446428571428571, "title": "Improving Object Detection"}, {"color": "#6FA8DC", "id": "Kihyuk Sohn", "label": "Kihyuk Sohn", "shape": "dot", "size": 10.178571428571429, "title": "Kihyuk Sohn"}, {"color": "#6FA8DC", "id": "Improving ObjectDetection", "label": "Improving ObjectDetection", "shape": "dot", "size": 10.089285714285714, "title": "Improving ObjectDetection"}, {"color": "#6FA8DC", "id": "Ruben Villegas", "label": "Ruben Villegas", "shape": "dot", "size": 10.178571428571429, "title": "Ruben Villegas"}, {"color": "#6FA8DC", "id": "Gang Pan", "label": "Gang Pan", "shape": "dot", "size": 10.178571428571429, "title": "Gang Pan"}, {"color": "#6FA8DC", "id": "Honglak Lee", "label": "Honglak Lee", "shape": "dot", "size": 10.178571428571429, "title": "Honglak Lee"}, {"color": "#6FA8DC", "id": "object detection benchmarks", "label": "object detection benchmarks", "shape": "dot", "size": 10.089285714285714, "title": "object detection benchmarks"}, {"color": "#6FA8DC", "id": "discriminative for categorization", "label": "discriminative for categorization", "shape": "dot", "size": 10.089285714285714, "title": "discriminative for categorization"}, {"color": "#6FA8DC", "id": "inaccurate localization", "label": "inaccurate localization", "shape": "dot", "size": 10.089285714285714, "title": "inaccurate localization"}, {"color": "#6FA8DC", "id": "major source of error", "label": "major source of error", "shape": "dot", "size": 10.089285714285714, "title": "major source of error"}, {"color": "#6FA8DC", "id": "search algorithm", "label": "search algorithm", "shape": "dot", "size": 10.178571428571429, "title": "search algorithm"}, {"color": "#6FA8DC", "id": "Bayesian optimization", "label": "Bayesian optimization", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian optimization"}, {"color": "#6FA8DC", "id": "candidate regions", "label": "candidate regions", "shape": "dot", "size": 10.089285714285714, "title": "candidate regions"}, {"color": "#6FA8DC", "id": "structured loss", "label": "structured loss", "shape": "dot", "size": 10.178571428571429, "title": "structured loss"}, {"color": "#6FA8DC", "id": "localization inaccuracy", "label": "localization inaccuracy", "shape": "dot", "size": 10.178571428571429, "title": "localization inaccuracy"}, {"color": "#6FA8DC", "id": "methods", "label": "methods", "shape": "dot", "size": 10.535714285714286, "title": "methods"}, {"color": "#6FA8DC", "id": "baseline method", "label": "baseline method", "shape": "dot", "size": 10.178571428571429, "title": "baseline method"}, {"color": "#6FA8DC", "id": "PASPAL VOC 2", "label": "PASPAL VOC 2", "shape": "dot", "size": 10.089285714285714, "title": "PASPAL VOC 2"}, {"color": "#6FA8DC", "id": "loss", "label": "loss", "shape": "dot", "size": 10.178571428571429, "title": "loss"}, {"color": "#6FA8DC", "id": "proposed methods", "label": "proposed methods", "shape": "dot", "size": 10.267857142857142, "title": "proposed methods"}, {"color": "#6FA8DC", "id": "PASPAL VOC 2007", "label": "PASPAL VOC 2007", "shape": "dot", "size": 10.089285714285714, "title": "PASPAL VOC 2007"}, {"color": "#6FA8DC", "id": "two methods", "label": "two methods", "shape": "dot", "size": 10.089285714285714, "title": "two methods"}, {"color": "#6FA8DC", "id": "complementary", "label": "complementary", "shape": "dot", "size": 10.089285714285714, "title": "complementary"}, {"color": "#6FA8DC", "id": "combined methods", "label": "combined methods", "shape": "dot", "size": 10.089285714285714, "title": "combined methods"}, {"color": "#6FA8DC", "id": "PASCAL VOC 2007", "label": "PASCAL VOC 2007", "shape": "dot", "size": 10.089285714285714, "title": "PASCAL VOC 2007"}, {"color": "#6FA8DC", "id": "PASCUAL VOC 2012", "label": "PASCUAL VOC 2012", "shape": "dot", "size": 10.089285714285714, "title": "PASCUAL VOC 2012"}, {"color": "#6FA8DC", "id": "Dimensionality Reduction", "label": "Dimensionality Reduction", "shape": "dot", "size": 10.089285714285714, "title": "Dimensionality Reduction"}, {"color": "#6FA8DC", "id": "Bayesian Optimization", "label": "Bayesian Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian Optimization"}, {"color": "#6FA8DC", "id": "Structured Prediction (Structured SVM)", "label": "Structured Prediction (Structured SVM)", "shape": "dot", "size": 10.089285714285714, "title": "Structured Prediction (Structured SVM)"}, {"color": "#6FA8DC", "id": "Localization Accuracy", "label": "Localization Accuracy", "shape": "dot", "size": 10.089285714285714, "title": "Localization Accuracy"}, {"color": "#6FA8DC", "id": "Deep Networks", "label": "Deep Networks", "shape": "dot", "size": 10.357142857142858, "title": "Deep Networks"}, {"color": "#6FA8DC", "id": "Greedy Layer-Wise Training", "label": "Greedy Layer-Wise Training", "shape": "dot", "size": 10.089285714285714, "title": "Greedy Layer-Wise Training"}, {"color": "#6FA8DC", "id": "Local Binary Patterns", "label": "Local Binary Patterns", "shape": "dot", "size": 10.178571428571429, "title": "Local Binary Patterns"}, {"color": "#6FA8DC", "id": "Representation Learning", "label": "Representation Learning", "shape": "dot", "size": 10.178571428571429, "title": "Representation Learning"}, {"color": "#6FA8DC", "id": "Bengio, Y.", "label": "Bengio, Y.", "shape": "dot", "size": 10.178571428571429, "title": "Bengio, Y."}, {"color": "#6FA8DC", "id": "Girschick, R.", "label": "Girschick, R.", "shape": "dot", "size": 10.089285714285714, "title": "Girschick, R."}, {"color": "#6FA8DC", "id": "Rich Feature Hierarchies", "label": "Rich Feature Hierarchies", "shape": "dot", "size": 10.357142857142858, "title": "Rich Feature Hierarchies"}, {"color": "#6FA8DC", "id": "Everingham, M.", "label": "Everingham, M.", "shape": "dot", "size": 10.178571428571429, "title": "Everingham, M."}, {"color": "#6FA8DC", "id": "VOC2007", "label": "VOC2007", "shape": "dot", "size": 10.267857142857142, "title": "VOC2007"}, {"color": "#6FA8DC", "id": "Deng, J.", "label": "Deng, J.", "shape": "dot", "size": 10.089285714285714, "title": "Deng, J."}, {"color": "#6FA8DC", "id": "Hierarchical Image Database", "label": "Hierarchical Image Database", "shape": "dot", "size": 10.089285714285714, "title": "Hierarchical Image Database"}, {"color": "#6FA8DC", "id": "Donahue, J.", "label": "Donahue, J.", "shape": "dot", "size": 10.178571428571429, "title": "Donahue, J."}, {"color": "#6FA8DC", "id": "DeCAF", "label": "DeCAF", "shape": "dot", "size": 10.357142857142858, "title": "DeCAF"}, {"color": "#6FA8DC", "id": "Visual Recognition", "label": "Visual Recognition", "shape": "dot", "size": 10.267857142857142, "title": "Visual Recognition"}, {"color": "#6FA8DC", "id": "CoRR", "label": "CoRR", "shape": "dot", "size": 10.089285714285714, "title": "CoRR"}, {"color": "#6FA8DC", "id": "Erhan", "label": "Erhan", "shape": "dot", "size": 10.178571428571429, "title": "Erhan"}, {"color": "#6FA8DC", "id": "Erhan, D.", "label": "Erhan, D.", "shape": "dot", "size": 10.089285714285714, "title": "Erhan, D."}, {"color": "#6FA8DC", "id": "Department of Computer Science, Zhejiang University", "label": "Department of Computer Science, Zhejiang University", "shape": "dot", "size": 10.178571428571429, "title": "Department of Computer Science, Zhejiang University"}, {"color": "#6FA8DC", "id": "Department of Electrical Engineering and Computer Science, University of Michigan", "label": "Department of Electrical Engineering and Computer Science, University of Michigan", "shape": "dot", "size": 10.267857142857142, "title": "Department of Electrical Engineering and Computer Science, University of Michigan"}, {"color": "#6FA8DC", "id": "Dongping Li", "label": "Dongping Li", "shape": "dot", "size": 10.267857142857142, "title": "Dongping Li"}, {"color": "#6FA8DC", "id": "A Geodesic-Prepreserving Method for Image Warping", "label": "A Geodesic-Prepreserving Method for Image Warping", "shape": "dot", "size": 10.178571428571429, "title": "A Geodesic-Prepreserving Method for Image Warping"}, {"color": "#6FA8DC", "id": "Department of Electrical Engineering and Computer Science", "label": "Department of Electrical Engineering and Computer Science", "shape": "dot", "size": 10.089285714285714, "title": "Department of Electrical Engineering and Computer Science"}, {"color": "#6FA8DC", "id": "University of Michigan", "label": "University of Michigan", "shape": "dot", "size": 10.178571428571429, "title": "University of Michigan"}, {"color": "#6FA8DC", "id": "A Geodesic-Preserving Method for Image Warping", "label": "A Geodesic-Preserving Method for Image Warping", "shape": "dot", "size": 10.535714285714286, "title": "A Geodesic-Preserving Method for Image Warping"}, {"color": "#6FA8DC", "id": "A Geolesic-Preerving Method for Image Warping", "label": "A Geolesic-Preerving Method for Image Warping", "shape": "dot", "size": 10.089285714285714, "title": "A Geolesic-Preerving Method for Image Warping"}, {"color": "#6FA8DC", "id": "Kun Zhou", "label": "Kun Zhou", "shape": "dot", "size": 10.178571428571429, "title": "Kun Zhou"}, {"color": "#6FA8DC", "id": "honglak@umich.edu", "label": "honglak@umich.edu", "shape": "dot", "size": 10.089285714285714, "title": "honglak@umich.edu"}, {"color": "#6FA8DC", "id": "Li_A_Geodesic-Preserving_Method_2015_CVPR_supplemental.pdf", "label": "Li_A_Geodesic-Preserving_Method_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Li_A_Geodesic-Preserving_Method_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Image Warping", "label": "Image Warping", "shape": "dot", "size": 10.357142857142858, "title": "Image Warping"}, {"color": "#6FA8DC", "id": "geodesic-preserving method", "label": "geodesic-preserving method", "shape": "dot", "size": 10.267857142857142, "title": "geodesic-preserving method"}, {"color": "#6FA8DC", "id": "maintain shape", "label": "maintain shape", "shape": "dot", "size": 10.089285714285714, "title": "maintain shape"}, {"color": "#6FA8DC", "id": "distortions", "label": "distortions", "shape": "dot", "size": 10.089285714285714, "title": "distortions"}, {"color": "#6FA8DC", "id": "core of method", "label": "core of method", "shape": "dot", "size": 10.089285714285714, "title": "core of method"}, {"color": "#6FA8DC", "id": "preserving geodesic distances", "label": "preserving geodesic distances", "shape": "dot", "size": 10.267857142857142, "title": "preserving geodesic distances"}, {"color": "#6FA8DC", "id": "local smoothness", "label": "local smoothness", "shape": "dot", "size": 10.089285714285714, "title": "local smoothness"}, {"color": "#6FA8DC", "id": "unwanted artifacts", "label": "unwanted artifacts", "shape": "dot", "size": 10.089285714285714, "title": "unwanted artifacts"}, {"color": "#6FA8DC", "id": "energy function", "label": "energy function", "shape": "dot", "size": 10.357142857142858, "title": "energy function"}, {"color": "#6FA8DC", "id": "shape preservation terms", "label": "shape preservation terms", "shape": "dot", "size": 10.089285714285714, "title": "shape preservation terms"}, {"color": "#6FA8DC", "id": "boundary preservation terms", "label": "boundary preservation terms", "shape": "dot", "size": 10.089285714285714, "title": "boundary preservation terms"}, {"color": "#6FA8DC", "id": "geodesic preservation terms", "label": "geodesic preservation terms", "shape": "dot", "size": 10.089285714285714, "title": "geodesic preservation terms"}, {"color": "#6FA8DC", "id": "Gauss-Newton method", "label": "Gauss-Newton method", "shape": "dot", "size": 10.178571428571429, "title": "Gauss-Newton method"}, {"color": "#6FA8DC", "id": "high-quality warped images", "label": "high-quality warped images", "shape": "dot", "size": 10.089285714285714, "title": "high-quality warped images"}, {"color": "#6FA8DC", "id": "Shape and Boundary Preservation", "label": "Shape and Boundary Preservation", "shape": "dot", "size": 10.178571428571429, "title": "Shape and Boundary Preservation"}, {"color": "#6FA8DC", "id": "Energy Minimization", "label": "Energy Minimization", "shape": "dot", "size": 10.267857142857142, "title": "Energy Minimization"}, {"color": "#6FA8DC", "id": "Gausss-Newton Method", "label": "Gausss-Newton Method", "shape": "dot", "size": 10.089285714285714, "title": "Gausss-Newton Method"}, {"color": "#6FA8DC", "id": "Zhang, G. et al.", "label": "Zhang, G. et al.", "shape": "dot", "size": 10.089285714285714, "title": "Zhang, G. et al."}, {"color": "#6FA8DC", "id": "A shape-preserving approach to image resizing", "label": "A shape-preserving approach to image resizing", "shape": "dot", "size": 10.178571428571429, "title": "A shape-preserving approach to image resizing"}, {"color": "#6FA8DC", "id": "A shape-preserivng approach to image resizing", "label": "A shape-preserivng approach to image resizing", "shape": "dot", "size": 10.089285714285714, "title": "A shape-preserivng approach to image resizing"}, {"color": "#6FA8DC", "id": "Rotation matrix R\u03b8,\u03c6", "label": "Rotation matrix R\u03b8,\u03c6", "shape": "dot", "size": 10.089285714285714, "title": "Rotation matrix R\u03b8,\u03c6"}, {"color": "#6FA8DC", "id": "Eqn. (1)", "label": "Eqn. (1)", "shape": "dot", "size": 10.089285714285714, "title": "Eqn. (1)"}, {"color": "#6FA8DC", "id": "Shape-preserving term ES(V)", "label": "Shape-preserving term ES(V)", "shape": "dot", "size": 10.089285714285714, "title": "Shape-preserving term ES(V)"}, {"color": "#6FA8DC", "id": "Eqn. (7)", "label": "Eqn. (7)", "shape": "dot", "size": 10.089285714285714, "title": "Eqn. (7)"}, {"color": "#6FA8DC", "id": "shape-preserving approach", "label": "shape-preserving approach", "shape": "dot", "size": 10.178571428571429, "title": "shape-preserving approach"}, {"color": "#6FA8DC", "id": "Eqn. (7) - Shape-preserving term ES(V)", "label": "Eqn. (7) - Shape-preserving term ES(V)", "shape": "dot", "size": 10.178571428571429, "title": "Eqn. (7) - Shape-preserving term ES(V)"}, {"color": "#6FA8DC", "id": "local smoothness preservation", "label": "local smoothness preservation", "shape": "dot", "size": 10.178571428571429, "title": "local smoothness preservation"}, {"color": "#6FA8DC", "id": "Eqn. (4) - Local smoothness preservation EC(V)", "label": "Eqn. (4) - Local smoothness preservation EC(V)", "shape": "dot", "size": 10.178571428571429, "title": "Eqn. (4) - Local smoothness preservation EC(V)"}, {"color": "#6FA8DC", "id": "Eqn. (5) - Combined energy function E(V)", "label": "Eqn. (5) - Combined energy function E(V)", "shape": "dot", "size": 10.089285714285714, "title": "Eqn. (5) - Combined energy function E(V)"}, {"color": "#6FA8DC", "id": "overall energy function", "label": "overall energy function", "shape": "dot", "size": 10.089285714285714, "title": "overall energy function"}, {"color": "#6FA8DC", "id": "Q", "label": "Q", "shape": "dot", "size": 10.089285714285714, "title": "Q"}, {"color": "#6FA8DC", "id": "orthogonal matrices", "label": "orthogonal matrices", "shape": "dot", "size": 10.267857142857142, "title": "orthogonal matrices"}, {"color": "#6FA8DC", "id": "mathematical concept", "label": "mathematical concept", "shape": "dot", "size": 10.089285714285714, "title": "mathematical concept"}, {"color": "#6FA8DC", "id": "E(V)", "label": "E(V)", "shape": "dot", "size": 10.089285714285714, "title": "E(V)"}, {"color": "#6FA8DC", "id": "various terms", "label": "various terms", "shape": "dot", "size": 10.089285714285714, "title": "various terms"}, {"color": "#6FA8DC", "id": "geodesic-preserving term", "label": "geodesic-preserving term", "shape": "dot", "size": 10.089285714285714, "title": "geodesic-preserving term"}, {"color": "#6FA8DC", "id": "Antonio Agudo", "label": "Antonio Agudo", "shape": "dot", "size": 10.267857142857142, "title": "Antonio Agudo"}, {"color": "#6FA8DC", "id": "Francesc Moreno-Noguer", "label": "Francesc Moreno-Noguer", "shape": "dot", "size": 10.267857142857142, "title": "Francesc Moreno-Noguer"}, {"color": "#6FA8DC", "id": "Zhejiang University", "label": "Zhejiang University", "shape": "dot", "size": 10.267857142857142, "title": "Zhejiang University"}, {"color": "#6FA8DC", "id": "Simultaneous Pose and Non-Rigid Shape", "label": "Simultaneous Pose and Non-Rigid Shape", "shape": "dot", "size": 10.178571428571429, "title": "Simultaneous Pose and Non-Rigid Shape"}, {"color": "#6FA8DC", "id": "particle dynamics", "label": "particle dynamics", "shape": "dot", "size": 10.357142857142858, "title": "particle dynamics"}, {"color": "#6FA8DC", "id": "mathematics", "label": "mathematics", "shape": "dot", "size": 10.089285714285714, "title": "mathematics"}, {"color": "#6FA8DC", "id": "geodesic preservation", "label": "geodesic preservation", "shape": "dot", "size": 10.089285714285714, "title": "geodesic preservation"}, {"color": "#6FA8DC", "id": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "label": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "shape": "dot", "size": 10.625, "title": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics"}, {"color": "#6FA8DC", "id": "non-rigid shape", "label": "non-rigid shape", "shape": "dot", "size": 10.178571428571429, "title": "non-rigid shape"}, {"color": "#6FA8DC", "id": "simultaneous pose", "label": "simultaneous pose", "shape": "dot", "size": 10.089285714285714, "title": "simultaneous pose"}, {"color": "#6FA8DC", "id": "solution", "label": "solution", "shape": "dot", "size": 10.982142857142858, "title": "solution"}, {"color": "#6FA8DC", "id": "camera pose", "label": "camera pose", "shape": "dot", "size": 10.089285714285714, "title": "camera pose"}, {"color": "#6FA8DC", "id": "global representations", "label": "global representations", "shape": "dot", "size": 10.089285714285714, "title": "global representations"}, {"color": "#6FA8DC", "id": "object", "label": "object", "shape": "dot", "size": 10.446428571428571, "title": "object"}, {"color": "#6FA8DC", "id": "ensemble of particles", "label": "ensemble of particles", "shape": "dot", "size": 10.089285714285714, "title": "ensemble of particles"}, {"color": "#6FA8DC", "id": "particle", "label": "particle", "shape": "dot", "size": 10.089285714285714, "title": "particle"}, {"color": "#6FA8DC", "id": "Newton\u2019s second law of motion", "label": "Newton\u2019s second law of motion", "shape": "dot", "size": 10.089285714285714, "title": "Newton\u2019s second law of motion"}, {"color": "#6FA8DC", "id": "dynamic model", "label": "dynamic model", "shape": "dot", "size": 10.089285714285714, "title": "dynamic model"}, {"color": "#6FA8DC", "id": "bundle adjustment framework", "label": "bundle adjustment framework", "shape": "dot", "size": 10.089285714285714, "title": "bundle adjustment framework"}, {"color": "#6FA8DC", "id": "noisy data", "label": "noisy data", "shape": "dot", "size": 10.178571428571429, "title": "noisy data"}, {"color": "#6FA8DC", "id": "missing data", "label": "missing data", "shape": "dot", "size": 10.178571428571429, "title": "missing data"}, {"color": "#6FA8DC", "id": "sudden camera motions", "label": "sudden camera motions", "shape": "dot", "size": 10.178571428571429, "title": "sudden camera motions"}, {"color": "#6FA8DC", "id": "training data", "label": "training data", "shape": "dot", "size": 10.089285714285714, "title": "training data"}, {"color": "#6FA8DC", "id": "efficient", "label": "efficient", "shape": "dot", "size": 10.178571428571429, "title": "efficient"}, {"color": "#6FA8DC", "id": "no training data", "label": "no training data", "shape": "dot", "size": 10.089285714285714, "title": "no training data"}, {"color": "#6FA8DC", "id": "validation", "label": "validation", "shape": "dot", "size": 10.089285714285714, "title": "validation"}, {"color": "#6FA8DC", "id": "real video sequences", "label": "real video sequences", "shape": "dot", "size": 10.089285714285714, "title": "real video sequences"}, {"color": "#6FA8DC", "id": "motion", "label": "motion", "shape": "dot", "size": 10.178571428571429, "title": "motion"}, {"color": "#6FA8DC", "id": "articulated", "label": "articulated", "shape": "dot", "size": 10.089285714285714, "title": "articulated"}, {"color": "#6FA8DC", "id": "non-rigid", "label": "non-rigid", "shape": "dot", "size": 10.089285714285714, "title": "non-rigid"}, {"color": "#6FA8DC", "id": "shapes", "label": "shapes", "shape": "dot", "size": 10.178571428571429, "title": "shapes"}, {"color": "#6FA8DC", "id": "discontinuous", "label": "discontinuous", "shape": "dot", "size": 10.089285714285714, "title": "discontinuous"}, {"color": "#6FA8DC", "id": "comparably to batch methods", "label": "comparably to batch methods", "shape": "dot", "size": 10.089285714285714, "title": "comparably to batch methods"}, {"color": "#6FA8DC", "id": "batch methods", "label": "batch methods", "shape": "dot", "size": 10.089285714285714, "title": "batch methods"}, {"color": "#6FA8DC", "id": "sequential methods", "label": "sequential methods", "shape": "dot", "size": 10.089285714285714, "title": "sequential methods"}, {"color": "#6FA8DC", "id": "System", "label": "System", "shape": "dot", "size": 10.267857142857142, "title": "System"}, {"color": "#6FA8DC", "id": "Competing Batch Methods", "label": "Competing Batch Methods", "shape": "dot", "size": 10.089285714285714, "title": "Competing Batch Methods"}, {"color": "#6FA8DC", "id": "Non-Rigid Structure from Motion", "label": "Non-Rigid Structure from Motion", "shape": "dot", "size": 10.446428571428571, "title": "Non-Rigid Structure from Motion"}, {"color": "#6FA8DC", "id": "Particle Dynamics", "label": "Particle Dynamics", "shape": "dot", "size": 10.089285714285714, "title": "Particle Dynamics"}, {"color": "#6FA8DC", "id": "Bundle Adjustment", "label": "Bundle Adjustment", "shape": "dot", "size": 10.089285714285714, "title": "Bundle Adjustment"}, {"color": "#6FA8DC", "id": "Monocular Video Analysis", "label": "Monocular Video Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Monocular Video Analysis"}, {"color": "#6FA8DC", "id": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3A)", "label": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3A)", "shape": "dot", "size": 10.089285714285714, "title": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3A)"}, {"color": "#6FA8DC", "id": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3a)", "label": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3a)", "shape": "dot", "size": 10.089285714285714, "title": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3a)"}, {"color": "#6FA8DC", "id": "Universidad de Zaragoza", "label": "Universidad de Zaragoza", "shape": "dot", "size": 10.089285714285714, "title": "Universidad de Zaragoza"}, {"color": "#6FA8DC", "id": "Institut de Rob`otica i Inform`atica Industrial (CSI-UPC)", "label": "Institut de Rob`otica i Inform`atica Industrial (CSI-UPC)", "shape": "dot", "size": 10.089285714285714, "title": "Institut de Rob`otica i Inform`atica Industrial (CSI-UPC)"}, {"color": "#6FA8DC", "id": "Simone Frintrop", "label": "Simone Frintrop", "shape": "dot", "size": 10.357142857142858, "title": "Simone Frintrop"}, {"color": "#6FA8DC", "id": "Thomas Werner", "label": "Thomas Werner", "shape": "dot", "size": 10.267857142857142, "title": "Thomas Werner"}, {"color": "#6FA8DC", "id": "Germ\u00e1n M. Garc\u00eda", "label": "Germ\u00e1n M. Garc\u00eda", "shape": "dot", "size": 10.178571428571429, "title": "Germ\u00e1n M. Garc\u00eda"}, {"color": "#6FA8DC", "id": "salience model", "label": "salience model", "shape": "dot", "size": 10.178571428571429, "title": "salience model"}, {"color": "#6FA8DC", "id": "Itti et al.", "label": "Itti et al.", "shape": "dot", "size": 10.089285714285714, "title": "Itti et al."}, {"color": "#6FA8DC", "id": "adaptations", "label": "adaptations", "shape": "dot", "size": 10.089285714285714, "title": "adaptations"}, {"color": "#6FA8DC", "id": "scale-space structure", "label": "scale-space structure", "shape": "dot", "size": 10.178571428571429, "title": "scale-space structure"}, {"color": "#6FA8DC", "id": "twin pyramid", "label": "twin pyramid", "shape": "dot", "size": 10.089285714285714, "title": "twin pyramid"}, {"color": "#6FA8DC", "id": "elegant structure", "label": "elegant structure", "shape": "dot", "size": 10.089285714285714, "title": "elegant structure"}, {"color": "#6FA8DC", "id": "speed", "label": "speed", "shape": "dot", "size": 10.178571428571429, "title": "speed"}, {"color": "#6FA8DC", "id": "pixel-level salience computation", "label": "pixel-level salience computation", "shape": "dot", "size": 10.089285714285714, "title": "pixel-level salience computation"}, {"color": "#6FA8DC", "id": "object proposal generation framework", "label": "object proposal generation framework", "shape": "dot", "size": 10.089285714285714, "title": "object proposal generation framework"}, {"color": "#6FA8DC", "id": "foundational approaches", "label": "foundational approaches", "shape": "dot", "size": 10.178571428571429, "title": "foundational approaches"}, {"color": "#6FA8DC", "id": "VOCUS2", "label": "VOCUS2", "shape": "dot", "size": 10.089285714285714, "title": "VOCUS2"}, {"color": "#6FA8DC", "id": "ration framework", "label": "ration framework", "shape": "dot", "size": 10.178571428571429, "title": "ration framework"}, {"color": "#6FA8DC", "id": "segment-based salience maps", "label": "segment-based salience maps", "shape": "dot", "size": 10.267857142857142, "title": "segment-based salience maps"}, {"color": "#6FA8DC", "id": "benchmark datasets", "label": "benchmark datasets", "shape": "dot", "size": 10.089285714285714, "title": "benchmark datasets"}, {"color": "#6FA8DC", "id": "importance", "label": "importance", "shape": "dot", "size": 10.178571428571429, "title": "importance"}, {"color": "#6FA8DC", "id": "revisiting foundational approaches", "label": "revisiting foundational approaches", "shape": "dot", "size": 10.089285714285714, "title": "revisiting foundational approaches"}, {"color": "#6FA8DC", "id": "adaptation", "label": "adaptation", "shape": "dot", "size": 10.178571428571429, "title": "adaptation"}, {"color": "#6FA8DC", "id": "modern applications", "label": "modern applications", "shape": "dot", "size": 10.178571428571429, "title": "modern applications"}, {"color": "#6FA8DC", "id": "t-based salience maps", "label": "t-based salience maps", "shape": "dot", "size": 10.089285714285714, "title": "t-based salience maps"}, {"color": "#6FA8DC", "id": "Saliency Models", "label": "Saliency Models", "shape": "dot", "size": 10.089285714285714, "title": "Saliency Models"}, {"color": "#6FA8DC", "id": "Itti Model", "label": "Itti Model", "shape": "dot", "size": 10.178571428571429, "title": "Itti Model"}, {"color": "#6FA8DC", "id": "A cognitive approach for object discovery", "label": "A cognitive approach for object discovery", "shape": "dot", "size": 10.089285714285714, "title": "A cognitive approach for object discovery"}, {"color": "#6FA8DC", "id": "Discriminant salieny", "label": "Discriminant salieny", "shape": "dot", "size": 10.089285714285714, "title": "Discriminant salieny"}, {"color": "#6FA8DC", "id": "TPAMI", "label": "TPAMI", "shape": "dot", "size": 10.089285714285714, "title": "TPAMI"}, {"color": "#6FA8DC", "id": "probabilistic bottom-up aggregation", "label": "probabilistic bottom-up aggregation", "shape": "dot", "size": 10.089285714285714, "title": "probabilistic bottom-up aggregation"}, {"color": "#6FA8DC", "id": "State-of-the-art in visual attention modeling", "label": "State-of-the-art in visual attention modeling", "shape": "dot", "size": 10.178571428571429, "title": "State-of-the-art in visual attention modeling"}, {"color": "#6FA8DC", "id": "Scale-space representation", "label": "Scale-space representation", "shape": "dot", "size": 10.089285714285714, "title": "Scale-space representation"}, {"color": "#6FA8DC", "id": "asri", "label": "asri", "shape": "dot", "size": 10.089285714285714, "title": "asri"}, {"color": "#6FA8DC", "id": "visual attention modeling", "label": "visual attention modeling", "shape": "dot", "size": 10.089285714285714, "title": "visual attention modeling"}, {"color": "#6FA8DC", "id": "L. Itti", "label": "L. Itti", "shape": "dot", "size": 10.089285714285714, "title": "L. Itti"}, {"color": "#6FA8DC", "id": "salienicy-based visual attention model", "label": "salienicy-based visual attention model", "shape": "dot", "size": 10.089285714285714, "title": "salienicy-based visual attention model"}, {"color": "#6FA8DC", "id": "N. D. B. Bruce", "label": "N. D. B. Bruce", "shape": "dot", "size": 10.089285714285714, "title": "N. D. B. Bruce"}, {"color": "#6FA8DC", "id": "information theoretic approach", "label": "information theoretic approach", "shape": "dot", "size": 10.089285714285714, "title": "information theoretic approach"}, {"color": "#6FA8DC", "id": "L. Hurvich", "label": "L. Hurvich", "shape": "dot", "size": 10.089285714285714, "title": "L. Hurvich"}, {"color": "#6FA8DC", "id": "opponent-process theory", "label": "opponent-process theory", "shape": "dot", "size": 10.089285714285714, "title": "opponent-process theory"}, {"color": "#6FA8DC", "id": "Rheinische Friedrich-Wilhelms-Universit\u00a8at Bonn", "label": "Rheinische Friedrich-Wilhelms-Universit\u00a8at Bonn", "shape": "dot", "size": 10.178571428571429, "title": "Rheinische Friedrich-Wilhelms-Universit\u00a8at Bonn"}, {"color": "#6FA8DC", "id": "Rheinische Friedrich-Wilhelms-Universit\u00e4t Bonn", "label": "Rheinische Friedrich-Wilhelms-Universit\u00e4t Bonn", "shape": "dot", "size": 10.357142857142858, "title": "Rheinische Friedrich-Wilhelms-Universit\u00e4t Bonn"}, {"color": "#6FA8DC", "id": "Jiaolong Yang", "label": "Jiaolong Yang", "shape": "dot", "size": 10.267857142857142, "title": "Jiaolong Yang"}, {"color": "#6FA8DC", "id": "Dense, Accurate Optical Flow Estimation", "label": "Dense, Accurate Optical Flow Estimation", "shape": "dot", "size": 10.357142857142858, "title": "Dense, Accurate Optical Flow Estimation"}, {"color": "#6FA8DC", "id": "Yang_Dense_Accurate_Optical_2015_CVPR_paper", "label": "Yang_Dense_Accurate_Optical_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Yang_Dense_Accurate_Optical_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "frintrop@iai.uni-bonn.de", "label": "frintrop@iai.uni-bonn.de", "shape": "dot", "size": 10.089285714285714, "title": "frintrop@iai.uni-bonn.de"}, {"color": "#6FA8DC", "id": "Bonn", "label": "Bonn", "shape": "dot", "size": 10.089285714285714, "title": "Bonn"}, {"color": "#6FA8DC", "id": "optical flow field", "label": "optical flow field", "shape": "dot", "size": 10.089285714285714, "title": "optical flow field"}, {"color": "#6FA8DC", "id": "piecewise parametric flow model", "label": "piecewise parametric flow model", "shape": "dot", "size": 10.089285714285714, "title": "piecewise parametric flow model"}, {"color": "#6FA8DC", "id": "multi-model fitting scheme", "label": "multi-model fitting scheme", "shape": "dot", "size": 10.089285714285714, "title": "multi-model fitting scheme"}, {"color": "#6FA8DC", "id": "piecewise constant model assumption", "label": "piecewise constant model assumption", "shape": "dot", "size": 10.089285714285714, "title": "piecewise constant model assumption"}, {"color": "#6FA8DC", "id": "flow field continuity constraint", "label": "flow field continuity constraint", "shape": "dot", "size": 10.089285714285714, "title": "flow field continuity constraint"}, {"color": "#6FA8DC", "id": "homogeneous motions", "label": "homogeneous motions", "shape": "dot", "size": 10.178571428571429, "title": "homogeneous motions"}, {"color": "#6FA8DC", "id": "complex motions", "label": "complex motions", "shape": "dot", "size": 10.178571428571429, "title": "complex motions"}, {"color": "#6FA8DC", "id": "KITTI benchmark", "label": "KITTI benchmark", "shape": "dot", "size": 10.178571428571429, "title": "KITTI benchmark"}, {"color": "#6FA8DC", "id": "MPI Sintel benchmark", "label": "MPI Sintel benchmark", "shape": "dot", "size": 10.178571428571429, "title": "MPI Sintel benchmark"}, {"color": "#6FA8DC", "id": "Middlebury benchmark", "label": "Middlebury benchmark", "shape": "dot", "size": 10.178571428571429, "title": "Middlebury benchmark"}, {"color": "#6FA8DC", "id": "top-tier performances", "label": "top-tier performances", "shape": "dot", "size": 10.178571428571429, "title": "top-tier performances"}, {"color": "#6FA8DC", "id": "state of the art", "label": "state of the art", "shape": "dot", "size": 10.357142857142858, "title": "state of the art"}, {"color": "#6FA8DC", "id": "equity constraint", "label": "equity constraint", "shape": "dot", "size": 10.089285714285714, "title": "equity constraint"}, {"color": "#6FA8DC", "id": "Optical flow benchmarks", "label": "Optical flow benchmarks", "shape": "dot", "size": 10.267857142857142, "title": "Optical flow benchmarks"}, {"color": "#6FA8DC", "id": "KITTI", "label": "KITTI", "shape": "dot", "size": 10.267857142857142, "title": "KITTI"}, {"color": "#6FA8DC", "id": "MPI Sintel", "label": "MPI Sintel", "shape": "dot", "size": 10.089285714285714, "title": "MPI Sintel"}, {"color": "#6FA8DC", "id": "Optical flow estimation", "label": "Optical flow estimation", "shape": "dot", "size": 10.357142857142858, "title": "Optical flow estimation"}, {"color": "#6FA8DC", "id": "Piecewise parametric models", "label": "Piecewise parametric models", "shape": "dot", "size": 10.089285714285714, "title": "Piecewise parametric models"}, {"color": "#6FA8DC", "id": "Energy minimization", "label": "Energy minimization", "shape": "dot", "size": 10.089285714285714, "title": "Energy minimization"}, {"color": "#6FA8DC", "id": "Homography transformation", "label": "Homography transformation", "shape": "dot", "size": 10.089285714285714, "title": "Homography transformation"}, {"color": "#6FA8DC", "id": "Baker et al. (2011)", "label": "Baker et al. (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Baker et al. (2011)"}, {"color": "#6FA8DC", "id": "database and evaluation methodology", "label": "database and evaluation methodology", "shape": "dot", "size": 10.089285714285714, "title": "database and evaluation methodology"}, {"color": "#6FA8DC", "id": "Bao et al. (2014)", "label": "Bao et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Bao et al. (2014)"}, {"color": "#6FA8DC", "id": "Fast edge-preserving patchmatch", "label": "Fast edge-preserving patchmatch", "shape": "dot", "size": 10.089285714285714, "title": "Fast edge-preserving patchmatch"}, {"color": "#6FA8DC", "id": "Barnes et al. (2009)", "label": "Barnes et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Barnes et al. (2009)"}, {"color": "#6FA8DC", "id": "PatchMatch", "label": "PatchMatch", "shape": "dot", "size": 10.267857142857142, "title": "PatchMatch"}, {"color": "#6FA8DC", "id": "structural image editing", "label": "structural image editing", "shape": "dot", "size": 10.089285714285714, "title": "structural image editing"}, {"color": "#6FA8DC", "id": "Piecewise image registration", "label": "Piecewise image registration", "shape": "dot", "size": 10.089285714285714, "title": "Piecewise image registration"}, {"color": "#6FA8DC", "id": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "label": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"}, {"color": "#6FA8DC", "id": "Multiway cut", "label": "Multiway cut", "shape": "dot", "size": 10.178571428571429, "title": "Multiway cut"}, {"color": "#6FA8DC", "id": "stereo and motion", "label": "stereo and motion", "shape": "dot", "size": 10.089285714285714, "title": "stereo and motion"}, {"color": "#6FA8DC", "id": "slanted surfaces", "label": "slanted surfaces", "shape": "dot", "size": 10.089285714285714, "title": "slanted surfaces"}, {"color": "#6FA8DC", "id": "robust estimation", "label": "robust estimation", "shape": "dot", "size": 10.267857142857142, "title": "robust estimation"}, {"color": "#6FA8DC", "id": "multiple motions", "label": "multiple motions", "shape": "dot", "size": 10.089285714285714, "title": "multiple motions"}, {"color": "#6FA8DC", "id": "Black", "label": "Black", "shape": "dot", "size": 10.089285714285714, "title": "Black"}, {"color": "#6FA8DC", "id": "Anandan", "label": "Anandan", "shape": "dot", "size": 10.089285714285714, "title": "Anandan"}, {"color": "#6FA8DC", "id": "parametric flow fields", "label": "parametric flow fields", "shape": "dot", "size": 10.089285714285714, "title": "parametric flow fields"}, {"color": "#6FA8DC", "id": "piecewise-smooth flow fields", "label": "piecewise-smooth flow fields", "shape": "dot", "size": 10.089285714285714, "title": "piecewise-smooth flow fields"}, {"color": "#6FA8DC", "id": "Black, M. J.", "label": "Black, M. J.", "shape": "dot", "size": 10.178571428571429, "title": "Black, M. J."}, {"color": "#6FA8DC", "id": "The robust estimation of multiple motions", "label": "The robust estimation of multiple motions", "shape": "dot", "size": 10.178571428571429, "title": "The robust estimation of multiple motions"}, {"color": "#6FA8DC", "id": "Estimating optical flow in segmented images", "label": "Estimating optical flow in segmented images", "shape": "dot", "size": 10.178571428571429, "title": "Estimating optical flow in segmented images"}, {"color": "#6FA8DC", "id": "Anandan, P.", "label": "Anandan, P.", "shape": "dot", "size": 10.089285714285714, "title": "Anandan, P."}, {"color": "#6FA8DC", "id": "Jepson, A. D.", "label": "Jepson, A. D.", "shape": "dot", "size": 10.089285714285714, "title": "Jepson, A. D."}, {"color": "#6FA8DC", "id": "Bleyer, M.", "label": "Bleyer, M.", "shape": "dot", "size": 10.089285714285714, "title": "Bleyer, M."}, {"color": "#6FA8DC", "id": "PatchMatch Stereo", "label": "PatchMatch Stereo", "shape": "dot", "size": 10.178571428571429, "title": "PatchMatch Stereo"}, {"color": "#6FA8DC", "id": "Rhemann, C.", "label": "Rhemann, C.", "shape": "dot", "size": 10.089285714285714, "title": "Rhemann, C."}, {"color": "#6FA8DC", "id": "Rother, C.", "label": "Rother, C.", "shape": "dot", "size": 10.089285714285714, "title": "Rother, C."}, {"color": "#6FA8DC", "id": "PatchMatch Stere", "label": "PatchMatch Stere", "shape": "dot", "size": 10.089285714285714, "title": "PatchMatch Stere"}, {"color": "#6FA8DC", "id": "Fast approximate energy minimization", "label": "Fast approximate energy minimization", "shape": "dot", "size": 10.089285714285714, "title": "Fast approximate energy minimization"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)", "label": "IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)"}, {"color": "#6FA8DC", "id": "Braux-Zin et al.", "label": "Braux-Zin et al.", "shape": "dot", "size": 10.089285714285714, "title": "Braux-Zin et al."}, {"color": "#6FA8DC", "id": "A general dense image matching framework", "label": "A general dense image matching framework", "shape": "dot", "size": 10.089285714285714, "title": "A general dense image matching framework"}, {"color": "#6FA8DC", "id": "Beijing Lab of Intelligent Information Technology", "label": "Beijing Lab of Intelligent Information Technology", "shape": "dot", "size": 10.357142857142858, "title": "Beijing Lab of Intelligent Information Technology"}, {"color": "#6FA8DC", "id": "Beijing Institute of Technology", "label": "Beijing Institute of Technology", "shape": "dot", "size": 10.357142857142858, "title": "Beijing Institute of Technology"}, {"color": "#6FA8DC", "id": "Research School of Engineering", "label": "Research School of Engineering", "shape": "dot", "size": 10.178571428571429, "title": "Research School of Engineering"}, {"color": "#6FA8DC", "id": "The Australian National University (ANU)", "label": "The Australian National University (ANU)", "shape": "dot", "size": 10.089285714285714, "title": "The Australian National University (ANU)"}, {"color": "#6FA8DC", "id": "Thomas Mauthner", "label": "Thomas Mauthner", "shape": "dot", "size": 10.089285714285714, "title": "Thomas Mauthner"}, {"color": "#6FA8DC", "id": "Encoding Based Saliency Detection for Videos and Images", "label": "Encoding Based Saliency Detection for Videos and Images", "shape": "dot", "size": 10.357142857142858, "title": "Encoding Based Saliency Detection for Videos and Images"}, {"color": "#6FA8DC", "id": "Horst Possegger", "label": "Horst Possegger", "shape": "dot", "size": 10.178571428571429, "title": "Horst Possegger"}, {"color": "#6FA8DC", "id": "Georg Waltner", "label": "Georg Waltner", "shape": "dot", "size": 10.357142857142858, "title": "Georg Waltner"}, {"color": "#6FA8DC", "id": "Horst Bischof", "label": "Horst Bischof", "shape": "dot", "size": 10.267857142857142, "title": "Horst Bischof"}, {"color": "#6FA8DC", "id": "Mauthner_Encoding_Based_Saliency_2015_CVPR_paper", "label": "Mauthner_Encoding_Based_Saliency_2015_CVPR_paper", "shape": "dot", "size": 10.178571428571429, "title": "Mauthner_Encoding_Based_Saliency_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Mauthner_Encoding_Based_Salieney_2015_CVPR_paper", "label": "Mauthner_Encoding_Based_Salieney_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Mauthner_Encoding_Based_Salieney_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Mauthne_Encoding_Based_Salieney_2015_CVPR_paper", "label": "Mauthne_Encoding_Based_Salieney_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Mauthne_Encoding_Based_Salieney_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "predicting human gaze", "label": "predicting human gaze", "shape": "dot", "size": 10.178571428571429, "title": "predicting human gaze"}, {"color": "#6FA8DC", "id": "eye-traking data", "label": "eye-traking data", "shape": "dot", "size": 10.089285714285714, "title": "eye-traking data"}, {"color": "#6FA8DC", "id": "reliance on human gaze", "label": "reliance on human gaze", "shape": "dot", "size": 10.089285714285714, "title": "reliance on human gaze"}, {"color": "#6FA8DC", "id": "bias", "label": "bias", "shape": "dot", "size": 10.089285714285714, "title": "bias"}, {"color": "#6FA8DC", "id": "unsupervised video salieny detection method", "label": "unsupervised video salieny detection method", "shape": "dot", "size": 10.089285714285714, "title": "unsupervised video salieny detection method"}, {"color": "#6FA8DC", "id": "human activity recognition", "label": "human activity recognition", "shape": "dot", "size": 10.089285714285714, "title": "human activity recognition"}, {"color": "#6FA8DC", "id": "training of activity detection algorithms", "label": "training of activity detection algorithms", "shape": "dot", "size": 10.089285714285714, "title": "training of activity detection algorithms"}, {"color": "#6FA8DC", "id": "encoding method", "label": "encoding method", "shape": "dot", "size": 10.178571428571429, "title": "encoding method"}, {"color": "#6FA8DC", "id": "joint feature distributions", "label": "joint feature distributions", "shape": "dot", "size": 10.089285714285714, "title": "joint feature distributions"}, {"color": "#6FA8DC", "id": "salience computation", "label": "salience computation", "shape": "dot", "size": 10.178571428571429, "title": "salience computation"}, {"color": "#6FA8DC", "id": "Gestalt principle of figure-ground segregation", "label": "Gestalt principle of figure-ground segregation", "shape": "dot", "size": 10.089285714285714, "title": "Gestalt principle of figure-ground segregation"}, {"color": "#6FA8DC", "id": "challenging datasets", "label": "challenging datasets", "shape": "dot", "size": 10.178571428571429, "title": "challenging datasets"}, {"color": "#6FA8DC", "id": "favorable performance", "label": "favorable performance", "shape": "dot", "size": 10.089285714285714, "title": "favorable performance"}, {"color": "#6FA8DC", "id": "ground-truth eye-gaze", "label": "ground-truth eye-gaze", "shape": "dot", "size": 10.089285714285714, "title": "ground-truth eye-gaze"}, {"color": "#6FA8DC", "id": "re-ground segregation", "label": "re-ground segregation", "shape": "dot", "size": 10.089285714285714, "title": "re-ground segregation"}, {"color": "#6FA8DC", "id": "Video Salience Detection", "label": "Video Salience Detection", "shape": "dot", "size": 10.267857142857142, "title": "Video Salience Detection"}, {"color": "#6FA8DC", "id": "Gestalt Principles", "label": "Gestalt Principles", "shape": "dot", "size": 10.089285714285714, "title": "Gestalt Principles"}, {"color": "#6FA8DC", "id": "Encoding Methods", "label": "Encoding Methods", "shape": "dot", "size": 10.089285714285714, "title": "Encoding Methods"}, {"color": "#6FA8DC", "id": "Itti, L.", "label": "Itti, L.", "shape": "dot", "size": 10.089285714285714, "title": "Itti, L."}, {"color": "#6FA8DC", "id": "model of salience-based visual attention", "label": "model of salience-based visual attention", "shape": "dot", "size": 10.089285714285714, "title": "model of salience-based visual attention"}, {"color": "#6FA8DC", "id": "Alexe, B.", "label": "Alexe, B.", "shape": "dot", "size": 10.089285714285714, "title": "Alexe, B."}, {"color": "#6FA8DC", "id": "What is an object?", "label": "What is an object?", "shape": "dot", "size": 10.089285714285714, "title": "What is an object?"}, {"color": "#6FA8DC", "id": "Liu, T.", "label": "Liu, T.", "shape": "dot", "size": 10.089285714285714, "title": "Liu, T."}, {"color": "#6FA8DC", "id": "Learning to Detect A Salient Object", "label": "Learning to Detect A Salient Object", "shape": "dot", "size": 10.089285714285714, "title": "Learning to Detect A Salient Object"}, {"color": "#6FA8DC", "id": "Johansson, G.", "label": "Johansson, G.", "shape": "dot", "size": 10.089285714285714, "title": "Johansson, G."}, {"color": "#6FA8DC", "id": "model for analysis of biological motion", "label": "model for analysis of biological motion", "shape": "dot", "size": 10.089285714285714, "title": "model for analysis of biological motion"}, {"color": "#6FA8DC", "id": "Gorelick, L.", "label": "Gorelick, L.", "shape": "dot", "size": 10.089285714285714, "title": "Gorelick, L."}, {"color": "#6FA8DC", "id": "Actions as Space-Time Shapes", "label": "Actions as Space-Time Shapes", "shape": "dot", "size": 10.535714285714286, "title": "Actions as Space-Time Shapes"}, {"color": "#6FA8DC", "id": "Salient Object Detection: A Benchmark", "label": "Salient Object Detection: A Benchmark", "shape": "dot", "size": 10.267857142857142, "title": "Salient Object Detection: A Benchmark"}, {"color": "#6FA8DC", "id": "Human Activity Recognition", "label": "Human Activity Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Human Activity Recognition"}, {"color": "#6FA8DC", "id": "Gorelick", "label": "Gorelick", "shape": "dot", "size": 10.089285714285714, "title": "Gorelick"}, {"color": "#6FA8DC", "id": "Blank", "label": "Blank", "shape": "dot", "size": 10.089285714285714, "title": "Blank"}, {"color": "#6FA8DC", "id": "Shechtman", "label": "Shechtman", "shape": "dot", "size": 10.089285714285714, "title": "Shechtman"}, {"color": "#6FA8DC", "id": "Irani", "label": "Irani", "shape": "dot", "size": 10.089285714285714, "title": "Irani"}, {"color": "#6FA8DC", "id": "Basri", "label": "Basri", "shape": "dot", "size": 10.089285714285714, "title": "Basri"}, {"color": "#6FA8DC", "id": "Borji", "label": "Borji", "shape": "dot", "size": 10.089285714285714, "title": "Borji"}, {"color": "#6FA8DC", "id": "Sihte", "label": "Sihte", "shape": "dot", "size": 10.089285714285714, "title": "Sihte"}, {"color": "#6FA8DC", "id": "Salient Object Determination: A Benchmark", "label": "Salient Object Determination: A Benchmark", "shape": "dot", "size": 10.089285714285714, "title": "Salient Object Determination: A Benchmark"}, {"color": "#6FA8DC", "id": "Itti", "label": "Itti", "shape": "dot", "size": 10.089285714285714, "title": "Itti"}, {"color": "#6FA8DC", "id": "Guo", "label": "Guo", "shape": "dot", "size": 10.089285714285714, "title": "Guo"}, {"color": "#6FA8DC", "id": "Spatio-temporal Saliency detection", "label": "Spatio-temporal Saliency detection", "shape": "dot", "size": 10.178571428571429, "title": "Spatio-temporal Saliency detection"}, {"color": "#6FA8DC", "id": "Zhang", "label": "Zhang", "shape": "dot", "size": 10.089285714285714, "title": "Zhang"}, {"color": "#6FA8DC", "id": "Judd", "label": "Judd", "shape": "dot", "size": 10.089285714285714, "title": "Judd"}, {"color": "#6FA8DC", "id": "Learning to Predict Where Humans Look", "label": "Learning to Predict Where Humans Look", "shape": "dot", "size": 10.357142857142858, "title": "Learning to Predict Where Humans Look"}, {"color": "#6FA8DC", "id": "Ehinger", "label": "Ehinger", "shape": "dot", "size": 10.089285714285714, "title": "Ehinger"}, {"color": "#6FA8DC", "id": "Durand", "label": "Durand", "shape": "dot", "size": 10.089285714285714, "title": "Durand"}, {"color": "#6FA8DC", "id": "Harel", "label": "Harel", "shape": "dot", "size": 10.089285714285714, "title": "Harel"}, {"color": "#6FA8DC", "id": "Graph-based Visual Saliency", "label": "Graph-based Visual Saliency", "shape": "dot", "size": 10.267857142857142, "title": "Graph-based Visual Saliency"}, {"color": "#6FA8DC", "id": "Koch", "label": "Koch", "shape": "dot", "size": 10.089285714285714, "title": "Koch"}, {"color": "#6FA8DC", "id": "Perona", "label": "Perona", "shape": "dot", "size": 10.178571428571429, "title": "Perona"}, {"color": "#6FA8DC", "id": "Rahtu", "label": "Rahtu", "shape": "dot", "size": 10.089285714285714, "title": "Rahtu"}, {"color": "#6FA8DC", "id": "Segmenting Salient Objects from Images and Videos", "label": "Segmenting Salient Objects from Images and Videos", "shape": "dot", "size": 10.357142857142858, "title": "Segmenting Salient Objects from Images and Videos"}, {"color": "#6FA8DC", "id": "Kannala", "label": "Kannala", "shape": "dot", "size": 10.089285714285714, "title": "Kannala"}, {"color": "#6FA8DC", "id": "Salo", "label": "Salo", "shape": "dot", "size": 10.089285714285714, "title": "Salo"}, {"color": "#6FA8DC", "id": "Heikkil\u00a8a", "label": "Heikkil\u00a8a", "shape": "dot", "size": 10.089285714285714, "title": "Heikkil\u00a8a"}, {"color": "#6FA8DC", "id": "Mauthner", "label": "Mauthner", "shape": "dot", "size": 10.089285714285714, "title": "Mauthner"}, {"color": "#6FA8DC", "id": "Institute for Computer Graphics and Vision, Graz University of Technology", "label": "Institute for Computer Graphics and Vision, Graz University of Technology", "shape": "dot", "size": 10.357142857142858, "title": "Institute for Computer Graphics and Vision, Graz University of Technology"}, {"color": "#6FA8DC", "id": "Possegger", "label": "Possegger", "shape": "dot", "size": 10.089285714285714, "title": "Possegger"}, {"color": "#6FA8DC", "id": "Waltner", "label": "Waltner", "shape": "dot", "size": 10.089285714285714, "title": "Waltner"}, {"color": "#6FA8DC", "id": "Institute for Computer Graphics and Vision", "label": "Institute for Computer Graphics and Vision", "shape": "dot", "size": 10.357142857142858, "title": "Institute for Computer Graphics and Vision"}, {"color": "#6FA8DC", "id": "Guanbin Li", "label": "Guanbin Li", "shape": "dot", "size": 10.089285714285714, "title": "Guanbin Li"}, {"color": "#6FA8DC", "id": "Visual Saliency Based on Multiscale Deep Features", "label": "Visual Saliency Based on Multiscale Deep Features", "shape": "dot", "size": 10.267857142857142, "title": "Visual Saliency Based on Multiscale Deep Features"}, {"color": "#6FA8DC", "id": "Yizhou Yu", "label": "Yizhou Yu", "shape": "dot", "size": 10.089285714285714, "title": "Yizhou Yu"}, {"color": "#6FA8DC", "id": "possegger@icg.tugraz.at", "label": "possegger@icg.tugraz.at", "shape": "dot", "size": 10.089285714285714, "title": "possegger@icg.tugraz.at"}, {"color": "#6FA8DC", "id": "waltner@icg.tugraz.at", "label": "waltner@icg.tugraz.at", "shape": "dot", "size": 10.089285714285714, "title": "waltner@icg.tugraz.at"}, {"color": "#6FA8DC", "id": "bischof@icg.tugraz.at", "label": "bischof@icg.tugraz.at", "shape": "dot", "size": 10.089285714285714, "title": "bischof@icg.tugraz.at"}, {"color": "#6FA8DC", "id": "Deep Features", "label": "Deep Features", "shape": "dot", "size": 10.178571428571429, "title": "Deep Features"}, {"color": "#6FA8DC", "id": "Multiple Scales", "label": "Multiple Scales", "shape": "dot", "size": 10.089285714285714, "title": "Multiple Scales"}, {"color": "#6FA8DC", "id": "SED dataset", "label": "SED dataset", "shape": "dot", "size": 10.089285714285714, "title": "SED dataset"}, {"color": "#6FA8DC", "id": "HKU-IS dataset", "label": "HKU-IS dataset", "shape": "dot", "size": 10.089285714285714, "title": "HKU-IS dataset"}, {"color": "#6FA8DC", "id": "Superior Performance", "label": "Superior Performance", "shape": "dot", "size": 10.089285714285714, "title": "Superior Performance"}, {"color": "#6FA8DC", "id": "Precision", "label": "Precision", "shape": "dot", "size": 10.089285714285714, "title": "Precision"}, {"color": "#6FA8DC", "id": "Recall", "label": "Recall", "shape": "dot", "size": 10.089285714285714, "title": "Recall"}, {"color": "#6FA8DC", "id": "F-measure", "label": "F-measure", "shape": "dot", "size": 10.089285714285714, "title": "F-measure"}, {"color": "#6FA8DC", "id": "Mean Absolute Error", "label": "Mean Absolute Error", "shape": "dot", "size": 10.089285714285714, "title": "Mean Absolute Error"}, {"color": "#6FA8DC", "id": "MDF approach", "label": "MDF approach", "shape": "dot", "size": 10.178571428571429, "title": "MDF approach"}, {"color": "#6FA8DC", "id": "Salience maps", "label": "Salience maps", "shape": "dot", "size": 10.089285714285714, "title": "Salience maps"}, {"color": "#6FA8DC", "id": "accurate salience maps", "label": "accurate salience maps", "shape": "dot", "size": 10.089285714285714, "title": "accurate salience maps"}, {"color": "#6FA8DC", "id": "Spectral residual approach", "label": "Spectral residual approach", "shape": "dot", "size": 10.089285714285714, "title": "Spectral residual approach"}, {"color": "#6FA8DC", "id": "Salience detection", "label": "Salience detection", "shape": "dot", "size": 10.178571428571429, "title": "Salience detection"}, {"color": "#6FA8DC", "id": "Salient object detection", "label": "Salient object detection", "shape": "dot", "size": 10.267857142857142, "title": "Salient object detection"}, {"color": "#6FA8DC", "id": "Deep Learning Features", "label": "Deep Learning Features", "shape": "dot", "size": 10.089285714285714, "title": "Deep Learning Features"}, {"color": "#6FA8DC", "id": "Multiscale Analysis", "label": "Multiscale Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Multiscale Analysis"}, {"color": "#6FA8DC", "id": "TRAMI", "label": "TRAMI", "shape": "dot", "size": 10.089285714285714, "title": "TRAMI"}, {"color": "#6FA8DC", "id": "Yuan et al. (2013)", "label": "Yuan et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Yuan et al. (2013)"}, {"color": "#6FA8DC", "id": "Perazzi et al. (2012)", "label": "Perazzi et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Perazzi et al. (2012)"}, {"color": "#6FA8DC", "id": "salient region detection", "label": "salient region detection", "shape": "dot", "size": 10.535714285714286, "title": "salient region detection"}, {"color": "#6FA8DC", "id": "Wei et al. (2012)", "label": "Wei et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Wei et al. (2012)"}, {"color": "#6FA8DC", "id": "Yan et al. (2013)", "label": "Yan et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Yan et al. (2013)"}, {"color": "#6FA8DC", "id": "Yang et al. (2013)", "label": "Yang et al. (2013)", "shape": "dot", "size": 10.178571428571429, "title": "Yang et al. (2013)"}, {"color": "#6FA8DC", "id": "Salient region detection", "label": "Salient region detection", "shape": "dot", "size": 10.089285714285714, "title": "Salient region detection"}, {"color": "#6FA8DC", "id": "Salience filters", "label": "Salience filters", "shape": "dot", "size": 10.089285714285714, "title": "Salience filters"}, {"color": "#6FA8DC", "id": "Zhu et al. (2014)", "label": "Zhu et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Zhu et al. (2014)"}, {"color": "#6FA8DC", "id": "Sun et al. (2014)", "label": "Sun et al. (2014)", "shape": "dot", "size": 10.267857142857142, "title": "Sun et al. (2014)"}, {"color": "#6FA8DC", "id": "discriminative manifold-based approach", "label": "discriminative manifold-based approach", "shape": "dot", "size": 10.089285714285714, "title": "discriminative manifold-based approach"}, {"color": "#6FA8DC", "id": "Minsu Cho", "label": "Minsu Cho", "shape": "dot", "size": 10.267857142857142, "title": "Minsu Cho"}, {"color": "#6FA8DC", "id": "Unsupervised Object Discovery and Localization", "label": "Unsupervised Object Discovery and Localization", "shape": "dot", "size": 10.267857142857142, "title": "Unsupervised Object Discovery and Localization"}, {"color": "#6FA8DC", "id": "Suha Kwak", "label": "Suha Kwak", "shape": "dot", "size": 10.357142857142858, "title": "Suha Kwak"}, {"color": "#6FA8DC", "id": "Cordelia Schmid", "label": "Cordelia Schmid", "shape": "dot", "size": 10.267857142857142, "title": "Cordelia Schmid"}, {"color": "#6FA8DC", "id": "Unsupervised Object Detection and Localization", "label": "Unsupervised Object Detection and Localization", "shape": "dot", "size": 10.178571428571429, "title": "Unsupervised Object Detection and Localization"}, {"color": "#6FA8DC", "id": "bottom-up region proposals", "label": "bottom-up region proposals", "shape": "dot", "size": 10.178571428571429, "title": "bottom-up region proposals"}, {"color": "#6FA8DC", "id": "Unsupervised Object Discovery and Localization in the Wild", "label": "Unsupervised Object Discovery and Localization in the Wild", "shape": "dot", "size": 10.625, "title": "Unsupervised Object Discovery and Localization in the Wild"}, {"color": "#6FA8DC", "id": "object discovery", "label": "object discovery", "shape": "dot", "size": 10.267857142857142, "title": "object discovery"}, {"color": "#6FA8DC", "id": "object localization", "label": "object localization", "shape": "dot", "size": 10.089285714285714, "title": "object localization"}, {"color": "#6FA8DC", "id": "part-based matching", "label": "part-based matching", "shape": "dot", "size": 10.089285714285714, "title": "part-based matching"}, {"color": "#6FA8DC", "id": "Unsupervised Object Localization", "label": "Unsupervised Object Localization", "shape": "dot", "size": 10.089285714285714, "title": "Unsupervised Object Localization"}, {"color": "#6FA8DC", "id": "Unsupervised Object Discovery", "label": "Unsupervised Object Discovery", "shape": "dot", "size": 10.089285714285714, "title": "Unsupervised Object Discovery"}, {"color": "#6FA8DC", "id": "discovery problem", "label": "discovery problem", "shape": "dot", "size": 10.089285714285714, "title": "discovery problem"}, {"color": "#6FA8DC", "id": "localization", "label": "localization", "shape": "dot", "size": 10.267857142857142, "title": "localization"}, {"color": "#6FA8DC", "id": "setting", "label": "setting", "shape": "dot", "size": 10.089285714285714, "title": "setting"}, {"color": "#6FA8DC", "id": "fully unsupervised", "label": "fully unsupervised", "shape": "dot", "size": 10.089285714285714, "title": "fully unsupervised"}, {"color": "#6FA8DC", "id": "part-based region matching", "label": "part-based region matching", "shape": "dot", "size": 10.089285714285714, "title": "part-based region matching"}, {"color": "#6FA8DC", "id": "region proposals", "label": "region proposals", "shape": "dot", "size": 10.089285714285714, "title": "region proposals"}, {"color": "#6FA8DC", "id": "candidate bounding boxes", "label": "candidate bounding boxes", "shape": "dot", "size": 10.089285714285714, "title": "candidate bounding boxes"}, {"color": "#6FA8DC", "id": "correspondence", "label": "correspondence", "shape": "dot", "size": 10.089285714285714, "title": "correspondence"}, {"color": "#6FA8DC", "id": "probabilistic Hough transform", "label": "probabilistic Hough transform", "shape": "dot", "size": 10.089285714285714, "title": "probabilistic Hough transform"}, {"color": "#6FA8DC", "id": "Hough transform", "label": "Hough transform", "shape": "dot", "size": 10.178571428571429, "title": "Hough transform"}, {"color": "#6FA8DC", "id": "mixed-class datasets", "label": "mixed-class datasets", "shape": "dot", "size": 10.089285714285714, "title": "mixed-class datasets"}, {"color": "#6FA8DC", "id": "candidate correspondence", "label": "candidate correspondence", "shape": "dot", "size": 10.178571428571429, "title": "candidate correspondence"}, {"color": "#6FA8DC", "id": "dominant objects", "label": "dominant objects", "shape": "dot", "size": 10.267857142857142, "title": "dominant objects"}, {"color": "#6FA8DC", "id": "comparing scores", "label": "comparing scores", "shape": "dot", "size": 10.089285714285714, "title": "comparing scores"}, {"color": "#6FA8DC", "id": "selecting regions", "label": "selecting regions", "shape": "dot", "size": 10.089285714285714, "title": "selecting regions"}, {"color": "#6FA8DC", "id": "regions", "label": "regions", "shape": "dot", "size": 10.178571428571429, "title": "regions"}, {"color": "#6FA8DC", "id": "evaluations", "label": "evaluations", "shape": "dot", "size": 10.178571428571429, "title": "evaluations"}, {"color": "#6FA8DC", "id": "standard benchmarks", "label": "standard benchmarks", "shape": "dot", "size": 10.089285714285714, "title": "standard benchmarks"}, {"color": "#6FA8DC", "id": "current state of the art", "label": "current state of the art", "shape": "dot", "size": 10.089285714285714, "title": "current state of the art"}, {"color": "#6FA8DC", "id": "robust object discovery", "label": "robust object discovery", "shape": "dot", "size": 10.089285714285714, "title": "robust object discovery"}, {"color": "#6FA8DC", "id": "rd benchmarks", "label": "rd benchmarks", "shape": "dot", "size": 10.089285714285714, "title": "rd benchmarks"}, {"color": "#6FA8DC", "id": "Probabiltistic Hough transform", "label": "Probabiltistic Hough transform", "shape": "dot", "size": 10.089285714285714, "title": "Probabiltistic Hough transform"}, {"color": "#6FA8DC", "id": "multiple object detection", "label": "multiple object detection", "shape": "dot", "size": 10.089285714285714, "title": "multiple object detection"}, {"color": "#6FA8DC", "id": "Alexe et al.", "label": "Alexe et al.", "shape": "dot", "size": 10.178571428571429, "title": "Alexe et al."}, {"color": "#6FA8DC", "id": "Measuring the object-ness of image windows", "label": "Measuring the object-ness of image windows", "shape": "dot", "size": 10.089285714285714, "title": "Measuring the object-ness of image windows"}, {"color": "#6FA8DC", "id": "Discriminative decorrelation for clustering and classification", "label": "Discriminative decorrelation for clustering and classification", "shape": "dot", "size": 10.089285714285714, "title": "Discriminative decorrelation for clustering and classification"}, {"color": "#6FA8DC", "id": "Ballard", "label": "Ballard", "shape": "dot", "size": 10.089285714285714, "title": "Ballard"}, {"color": "#6FA8DC", "id": "Generalizing the Hough transform", "label": "Generalizing the Hough transform", "shape": "dot", "size": 10.089285714285714, "title": "Generalizing the Hough transform"}, {"color": "#6FA8DC", "id": "Joulin et al.", "label": "Joulin et al.", "shape": "dot", "size": 10.089285714285714, "title": "Joulin et al."}, {"color": "#6FA8DC", "id": "Discriminative clustering for image co-segmentation", "label": "Discriminative clustering for image co-segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Discriminative clustering for image co-segmentation"}, {"color": "#6FA8DC", "id": "Cho et al.", "label": "Cho et al.", "shape": "dot", "size": 10.089285714285714, "title": "Cho et al."}, {"color": "#6FA8DC", "id": "Learning graphs to match", "label": "Learning graphs to match", "shape": "dot", "size": 10.446428571428571, "title": "Learning graphs to match"}, {"color": "#6FA8DC", "id": "Unsupervised object localization", "label": "Unsupervised object localization", "shape": "dot", "size": 10.089285714285714, "title": "Unsupervised object localization"}, {"color": "#6FA8DC", "id": "Image Co-segmentation", "label": "Image Co-segmentation", "shape": "dot", "size": 10.178571428571429, "title": "Image Co-segmentation"}, {"color": "#6FA8DC", "id": "Inria", "label": "Inria", "shape": "dot", "size": 10.267857142857142, "title": "Inria"}, {"color": "#6FA8DC", "id": "\u00c9cole Normale Sup\u00e9rieure", "label": "\u00c9cole Normale Sup\u00e9rieure", "shape": "dot", "size": 10.089285714285714, "title": "\u00c9cole Normale Sup\u00e9rieure"}, {"color": "#6FA8DC", "id": "Learning Graphs", "label": "Learning Graphs", "shape": "dot", "size": 10.089285714285714, "title": "Learning Graphs"}, {"color": "#6FA8DC", "id": "Efficient Image Localization", "label": "Efficient Image Localization", "shape": "dot", "size": 10.089285714285714, "title": "Efficient Image Localization"}, {"color": "#6FA8DC", "id": "Pictoiral Structures", "label": "Pictoiral Structures", "shape": "dot", "size": 10.089285714285714, "title": "Pictoiral Structures"}, {"color": "#6FA8DC", "id": "IJCV", "label": "IJCV", "shape": "dot", "size": 10.357142857142858, "title": "IJCV"}, {"color": "#6FA8DC", "id": "PSL Research University", "label": "PSL Research University", "shape": "dot", "size": 10.089285714285714, "title": "PSL Research University"}, {"color": "#6FA8DC", "id": "Ijaz Akhter", "label": "Ijaz Akhter", "shape": "dot", "size": 10.267857142857142, "title": "Ijaz Akhter"}, {"color": "#6FA8DC", "id": "Pose-Conditioned Joint Angle Limits", "label": "Pose-Conditioned Joint Angle Limits", "shape": "dot", "size": 10.357142857142858, "title": "Pose-Conditioned Joint Angle Limits"}, {"color": "#6FA8DC", "id": "Michael J. Black", "label": "Michael J. Black", "shape": "dot", "size": 10.267857142857142, "title": "Michael J. Black"}, {"color": "#6FA8DC", "id": "Pose-Conditioning Joint Angle Limits", "label": "Pose-Conditioning Joint Angle Limits", "shape": "dot", "size": 10.089285714285714, "title": "Pose-Conditioning Joint Angle Limits"}, {"color": "#6FA8DC", "id": "Akhter_Pose-Conditioned_Joint_Angle_2015_CVPR_paper.pdf", "label": "Akhter_Pose-Conditioned_Joint_Angle_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Akhter_Pose-Conditioned_Joint_Angle_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "3D human pose estimation", "label": "3D human pose estimation", "shape": "dot", "size": 10.089285714285714, "title": "3D human pose estimation"}, {"color": "#6FA8DC", "id": "analysis of people in images and video", "label": "analysis of people in images and video", "shape": "dot", "size": 10.089285714285714, "title": "analysis of people in images and video"}, {"color": "#6FA8DC", "id": "inherently ill-posed", "label": "inherently ill-posed", "shape": "dot", "size": 10.089285714285714, "title": "inherently ill-posed"}, {"color": "#6FA8DC", "id": "prior over human poses", "label": "prior over human poses", "shape": "dot", "size": 10.089285714285714, "title": "prior over human poses"}, {"color": "#6FA8DC", "id": "joint limits", "label": "joint limits", "shape": "dot", "size": 10.089285714285714, "title": "joint limits"}, {"color": "#6FA8DC", "id": "pose", "label": "pose", "shape": "dot", "size": 10.089285714285714, "title": "pose"}, {"color": "#6FA8DC", "id": "motion capture dataset", "label": "motion capture dataset", "shape": "dot", "size": 10.089285714285714, "title": "motion capture dataset"}, {"color": "#6FA8DC", "id": "range of human poses", "label": "range of human poses", "shape": "dot", "size": 10.089285714285714, "title": "range of human poses"}, {"color": "#6FA8DC", "id": "pose-dependent model of joint limits", "label": "pose-dependent model of joint limits", "shape": "dot", "size": 10.089285714285714, "title": "pose-dependent model of joint limits"}, {"color": "#6FA8DC", "id": "research purposes", "label": "research purposes", "shape": "dot", "size": 10.089285714285714, "title": "research purposes"}, {"color": "#6FA8DC", "id": "3D pose from 2D joint locations", "label": "3D pose from 2D joint locations", "shape": "dot", "size": 10.089285714285714, "title": "3D pose from 2D joint locations"}, {"color": "#6FA8DC", "id": "over-complete dictionary of poses", "label": "over-complete dictionary of poses", "shape": "dot", "size": 10.089285714285714, "title": "over-complete dictionary of poses"}, {"color": "#6FA8DC", "id": "good generalization", "label": "good generalization", "shape": "dot", "size": 10.089285714285714, "title": "good generalization"}, {"color": "#6FA8DC", "id": "body pose", "label": "body pose", "shape": "dot", "size": 10.089285714285714, "title": "body pose"}, {"color": "#6FA8DC", "id": "3D pose", "label": "3D pose", "shape": "dot", "size": 10.178571428571429, "title": "3D pose"}, {"color": "#6FA8DC", "id": "2D joint locations", "label": "2D joint locations", "shape": "dot", "size": 10.089285714285714, "title": "2D joint locations"}, {"color": "#6FA8DC", "id": "over-completes dictionary of poses", "label": "over-completes dictionary of poses", "shape": "dot", "size": 10.089285714285714, "title": "over-completes dictionary of poses"}, {"color": "#6FA8DC", "id": "impossible poses", "label": "impossible poses", "shape": "dot", "size": 10.089285714285714, "title": "impossible poses"}, {"color": "#6FA8DC", "id": "recent work", "label": "recent work", "shape": "dot", "size": 10.089285714285714, "title": "recent work"}, {"color": "#6FA8DC", "id": "CMU mocap dataset", "label": "CMU mocap dataset", "shape": "dot", "size": 10.178571428571429, "title": "CMU mocap dataset"}, {"color": "#6FA8DC", "id": "manual annotations", "label": "manual annotations", "shape": "dot", "size": 10.178571428571429, "title": "manual annotations"}, {"color": "#6FA8DC", "id": "detections", "label": "detections", "shape": "dot", "size": 10.089285714285714, "title": "detections"}, {"color": "#6FA8DC", "id": "Leeds sports pose dataset", "label": "Leeds sports pose dataset", "shape": "dot", "size": 10.178571428571429, "title": "Leeds sports pose dataset"}, {"color": "#6FA8DC", "id": "he-art results", "label": "he-art results", "shape": "dot", "size": 10.178571428571429, "title": "he-art results"}, {"color": "#6FA8DC", "id": "2D to 3D pose estimation", "label": "2D to 3D pose estimation", "shape": "dot", "size": 10.089285714285714, "title": "2D to 3D pose estimation"}, {"color": "#6FA8DC", "id": "superior results", "label": "superior results", "shape": "dot", "size": 10.178571428571429, "title": "superior results"}, {"color": "#6FA8DC", "id": "automatic detections", "label": "automatic detections", "shape": "dot", "size": 10.178571428571429, "title": "automatic detections"}, {"color": "#6FA8DC", "id": "Andriluka, M. et al. (2010)", "label": "Andriluka, M. et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Andriluka, M. et al. (2010)"}, {"color": "#6FA8DC", "id": "monocular 3D pose estimation and tracking", "label": "monocular 3D pose estimation and tracking", "shape": "dot", "size": 10.089285714285714, "title": "monocular 3D pose estimation and tracking"}, {"color": "#6FA8DC", "id": "Barr`on, C. \u0026 Kakadiaris, I. (2001)", "label": "Barr`on, C. \u0026 Kakadiaris, I. (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Barr`on, C. \u0026 Kakadiaris, I. (2001)"}, {"color": "#6FA8DC", "id": "estimating anthropometry and pose", "label": "estimating anthropometry and pose", "shape": "dot", "size": 10.089285714285714, "title": "estimating anthropometry and pose"}, {"color": "#6FA8DC", "id": "BenAbdelkader, C. \u0026 Yacoob, Y. (2008)", "label": "BenAbdelkader, C. \u0026 Yacoob, Y. (2008)", "shape": "dot", "size": 10.089285714285714, "title": "BenAbdelkader, C. \u0026 Yacoob, Y. (2008)"}, {"color": "#6FA8DC", "id": "statistical estimation of human anthropometry", "label": "statistical estimation of human anthropometry", "shape": "dot", "size": 10.089285714285714, "title": "statistical estimation of human anthropometry"}, {"color": "#6FA8DC", "id": "Human Pose Reconstruction", "label": "Human Pose Reconstruction", "shape": "dot", "size": 10.178571428571429, "title": "Human Pose Reconstruction"}, {"color": "#6FA8DC", "id": "Motion Capture Data", "label": "Motion Capture Data", "shape": "dot", "size": 10.089285714285714, "title": "Motion Capture Data"}, {"color": "#6FA8DC", "id": "Prior Models", "label": "Prior Models", "shape": "dot", "size": 10.089285714285714, "title": "Prior Models"}, {"color": "#6FA8DC", "id": "Bourdev \u0026 Malik", "label": "Bourdev \u0026 Malik", "shape": "dot", "size": 10.089285714285714, "title": "Bourdev \u0026 Malik"}, {"color": "#6FA8DC", "id": "International Conference on Computer Vision", "label": "International Conference on Computer Vision", "shape": "dot", "size": 10.267857142857142, "title": "International Conference on Computer Vision"}, {"color": "#6FA8DC", "id": "Poselets", "label": "Poselets", "shape": "dot", "size": 10.178571428571429, "title": "Poselets"}, {"color": "#6FA8DC", "id": "body part detector", "label": "body part detector", "shape": "dot", "size": 10.089285714285714, "title": "body part detector"}, {"color": "#6FA8DC", "id": "3D human pose annotations", "label": "3D human pose annotations", "shape": "dot", "size": 10.089285714285714, "title": "3D human pose annotations"}, {"color": "#6FA8DC", "id": "Chen, Nie, \u0026 Ji", "label": "Chen, Nie, \u0026 Ji", "shape": "dot", "size": 10.089285714285714, "title": "Chen, Nie, \u0026 Ji"}, {"color": "#6FA8DC", "id": "Guan et al.", "label": "Guan et al.", "shape": "dot", "size": 10.089285714285714, "title": "Guan et al."}, {"color": "#6FA8DC", "id": "Int. Conf. on Computer Vision (ICCV)", "label": "Int. Conf. on Computer Vision (ICCV)", "shape": "dot", "size": 10.089285714285714, "title": "Int. Conf. on Computer Vision (ICCV)"}, {"color": "#6FA8DC", "id": "Estimating human shape", "label": "Estimating human shape", "shape": "dot", "size": 10.089285714285714, "title": "Estimating human shape"}, {"color": "#6FA8DC", "id": "single image", "label": "single image", "shape": "dot", "size": 10.178571428571429, "title": "single image"}, {"color": "#6FA8DC", "id": "Grochow et al.", "label": "Grochow et al.", "shape": "dot", "size": 10.178571428571429, "title": "Grochow et al."}, {"color": "#6FA8DC", "id": "Style-based inverse kinematics", "label": "Style-based inverse kinematics", "shape": "dot", "size": 10.267857142857142, "title": "Style-based inverse kinematics"}, {"color": "#6FA8DC", "id": "human anthropometry", "label": "human anthropometry", "shape": "dot", "size": 10.089285714285714, "title": "human anthropometry"}, {"color": "#6FA8DC", "id": "single uncalibrated image", "label": "single uncalibrated image", "shape": "dot", "size": 10.089285714285714, "title": "single uncalibrated image"}, {"color": "#6FA8DC", "id": "Computer Vision Conference", "label": "Computer Vision Conference", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision Conference"}, {"color": "#6FA8DC", "id": "three-dimensional multivariate model", "label": "three-dimensional multivariate model", "shape": "dot", "size": 10.089285714285714, "title": "three-dimensional multivariate model"}, {"color": "#6FA8DC", "id": "Clinical Biomechanics", "label": "Clinical Biomechanics", "shape": "dot", "size": 10.089285714285714, "title": "Clinical Biomechanics"}, {"color": "#6FA8DC", "id": "Herda et al.", "label": "Herda et al.", "shape": "dot", "size": 10.089285714285714, "title": "Herda et al."}, {"color": "#6FA8DC", "id": "Hierarchical implicit surface joint limits", "label": "Hierarchical implicit surface joint limits", "shape": "dot", "size": 10.178571428571429, "title": "Hierarchical implicit surface joint limits"}, {"color": "#6FA8DC", "id": "Lin et al.", "label": "Lin et al.", "shape": "dot", "size": 10.178571428571429, "title": "Lin et al."}, {"color": "#6FA8DC", "id": "sketching interface", "label": "sketching interface", "shape": "dot", "size": 10.178571428571429, "title": "sketching interface"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Visualization and Computer Graphics", "label": "IEEE Transactions on Visualization and Computer Graphics", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Transactions on Visualization and Computer Graphics"}, {"color": "#6FA8DC", "id": "Max Planck Institute for Intelligent Systems", "label": "Max Planck Institute for Intelligent Systems", "shape": "dot", "size": 10.267857142857142, "title": "Max Planck Institute for Intelligent Systems"}, {"color": "#6FA8DC", "id": "ijaz.akhter@tuebingen.mpg.de", "label": "ijaz.akhter@tuebingen.mpg.de", "shape": "dot", "size": 10.089285714285714, "title": "ijaz.akhter@tuebingen.mpg.de"}, {"color": "#6FA8DC", "id": "Ran Tao", "label": "Ran Tao", "shape": "dot", "size": 10.178571428571429, "title": "Ran Tao"}, {"color": "#6FA8DC", "id": "Attributes and Categories for Generic Instance Search from One Example", "label": "Attributes and Categories for Generic Instance Search from One Example", "shape": "dot", "size": 10.446428571428571, "title": "Attributes and Categories for Generic Instance Search from One Example"}, {"color": "#6FA8DC", "id": "Arnold W.M. Smeulders", "label": "Arnold W.M. Smeulders", "shape": "dot", "size": 10.178571428571429, "title": "Arnold W.M. Smeulders"}, {"color": "#6FA8DC", "id": "Tao_Attributes_and_Categories_2015_CVPR_paper", "label": "Tao_Attributes_and_Categories_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Tao_Attributes_and_Categories_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Tuebingen", "label": "Tuebingen", "shape": "dot", "size": 10.089285714285714, "title": "Tuebingen"}, {"color": "#6FA8DC", "id": "generic instance search problem", "label": "generic instance search problem", "shape": "dot", "size": 10.089285714285714, "title": "generic instance search problem"}, {"color": "#6FA8DC", "id": "instance search methods", "label": "instance search methods", "shape": "dot", "size": 10.089285714285714, "title": "instance search methods"}, {"color": "#6FA8DC", "id": "arbitrary 3D objects", "label": "arbitrary 3D objects", "shape": "dot", "size": 10.178571428571429, "title": "arbitrary 3D objects"}, {"color": "#6FA8DC", "id": "shoes", "label": "shoes", "shape": "dot", "size": 10.089285714285714, "title": "shoes"}, {"color": "#6FA8DC", "id": "category-specific attributes", "label": "category-specific attributes", "shape": "dot", "size": 10.267857142857142, "title": "category-specific attributes"}, {"color": "#6FA8DC", "id": "appearance variations", "label": "appearance variations", "shape": "dot", "size": 10.178571428571429, "title": "appearance variations"}, {"color": "#6FA8DC", "id": "object search", "label": "object search", "shape": "dot", "size": 10.089285714285714, "title": "object search"}, {"color": "#6FA8DC", "id": "category-level information", "label": "category-level information", "shape": "dot", "size": 10.089285714285714, "title": "category-level information"}, {"color": "#6FA8DC", "id": "combination", "label": "combination", "shape": "dot", "size": 10.089285714285714, "title": "combination"}, {"color": "#6FA8DC", "id": "approaches relying on low-level features", "label": "approaches relying on low-level features", "shape": "dot", "size": 10.089285714285714, "title": "approaches relying on low-level features"}, {"color": "#6FA8DC", "id": "core challenge", "label": "core challenge", "shape": "dot", "size": 10.178571428571429, "title": "core challenge"}, {"color": "#6FA8DC", "id": "representing query image", "label": "representing query image", "shape": "dot", "size": 10.089285714285714, "title": "representing query image"}, {"color": "#6FA8DC", "id": "query image", "label": "query image", "shape": "dot", "size": 10.089285714285714, "title": "query image"}, {"color": "#6FA8DC", "id": "robust representation", "label": "robust representation", "shape": "dot", "size": 10.446428571428571, "title": "robust representation"}, {"color": "#6FA8DC", "id": "rich representation", "label": "rich representation", "shape": "dot", "size": 10.178571428571429, "title": "rich representation"}, {"color": "#6FA8DC", "id": "distinction from similar instances", "label": "distinction from similar instances", "shape": "dot", "size": 10.089285714285714, "title": "distinction from similar instances"}, {"color": "#6FA8DC", "id": "distinction", "label": "distinction", "shape": "dot", "size": 10.178571428571429, "title": "distinction"}, {"color": "#6FA8DC", "id": "similar instances", "label": "similar instances", "shape": "dot", "size": 10.089285714285714, "title": "similar instances"}, {"color": "#6FA8DC", "id": "Generic Instance Search", "label": "Generic Instance Search", "shape": "dot", "size": 10.089285714285714, "title": "Generic Instance Search"}, {"color": "#6FA8DC", "id": "Core Challenge", "label": "Core Challenge", "shape": "dot", "size": 10.089285714285714, "title": "Core Challenge"}, {"color": "#6FA8DC", "id": "Appearance Variation", "label": "Appearance Variation", "shape": "dot", "size": 10.178571428571429, "title": "Appearance Variation"}, {"color": "#6FA8DC", "id": "Attribute Representation", "label": "Attribute Representation", "shape": "dot", "size": 10.089285714285714, "title": "Attribute Representation"}, {"color": "#6FA8DC", "id": "Large Scale Visual Recognition Challenge", "label": "Large Scale Visual Recognition Challenge", "shape": "dot", "size": 10.089285714285714, "title": "Large Scale Visual Recognition Challenge"}, {"color": "#6FA8DC", "id": "attribute-based classification", "label": "attribute-based classification", "shape": "dot", "size": 10.089285714285714, "title": "attribute-based classification"}, {"color": "#6FA8DC", "id": "Attribute Transfer", "label": "Attribute Transfer", "shape": "dot", "size": 10.089285714285714, "title": "Attribute Transfer"}, {"color": "#6FA8DC", "id": "detecting unseen object classes", "label": "detecting unseen object classes", "shape": "dot", "size": 10.089285714285714, "title": "detecting unseen object classes"}, {"color": "#6FA8DC", "id": "Multiple queries", "label": "Multiple queries", "shape": "dot", "size": 10.267857142857142, "title": "Multiple queries"}, {"color": "#6FA8DC", "id": "large scale specific object retrieval", "label": "large scale specific object retrieval", "shape": "dot", "size": 10.089285714285714, "title": "large scale specific object retrieval"}, {"color": "#6FA8DC", "id": "Aranandjelovic", "label": "Aranandjelovic", "shape": "dot", "size": 10.089285714285714, "title": "Aranandjelovic"}, {"color": "#6FA8DC", "id": "Zisserman", "label": "Zisserman", "shape": "dot", "size": 10.089285714285714, "title": "Zisserman"}, {"color": "#6FA8DC", "id": "Naphade", "label": "Naphade", "shape": "dot", "size": 10.089285714285714, "title": "Naphade"}, {"color": "#6FA8DC", "id": "concept ontology", "label": "concept ontology", "shape": "dot", "size": 10.178571428571429, "title": "concept ontology"}, {"color": "#6FA8DC", "id": "IEEE MultiMedia", "label": "IEEE MultiMedia", "shape": "dot", "size": 10.089285714285714, "title": "IEEE MultiMedia"}, {"color": "#6FA8DC", "id": "Perdoch", "label": "Perdoch", "shape": "dot", "size": 10.089285714285714, "title": "Perdoch"}, {"color": "#6FA8DC", "id": "efficient representation", "label": "efficient representation", "shape": "dot", "size": 10.089285714285714, "title": "efficient representation"}, {"color": "#6FA8DC", "id": "Visual Object Classes Challenge", "label": "Visual Object Classes Challenge", "shape": "dot", "size": 10.089285714285714, "title": "Visual Object Classes Challenge"}, {"color": "#6FA8DC", "id": "Farhad", "label": "Farhad", "shape": "dot", "size": 10.267857142857142, "title": "Farhad"}, {"color": "#6FA8DC", "id": "describing objects", "label": "describing objects", "shape": "dot", "size": 10.178571428571429, "title": "describing objects"}, {"color": "#6FA8DC", "id": "object attributes", "label": "object attributes", "shape": "dot", "size": 10.089285714285714, "title": "object attributes"}, {"color": "#6FA8DC", "id": "Pascal Network", "label": "Pascal Network", "shape": "dot", "size": 10.089285714285714, "title": "Pascal Network"}, {"color": "#6FA8DC", "id": "ISLA", "label": "ISLA", "shape": "dot", "size": 10.089285714285714, "title": "ISLA"}, {"color": "#6FA8DC", "id": "Recognition algorithms", "label": "Recognition algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Recognition algorithms"}, {"color": "#6FA8DC", "id": "output of last layer", "label": "output of last layer", "shape": "dot", "size": 10.089285714285714, "title": "output of last layer"}, {"color": "#6FA8DC", "id": "last layer output", "label": "last layer output", "shape": "dot", "size": 10.178571428571429, "title": "last layer output"}, {"color": "#6FA8DC", "id": "spatially coarse", "label": "spatially coarse", "shape": "dot", "size": 10.089285714285714, "title": "spatially coarse"}, {"color": "#6FA8DC", "id": "earlier layers", "label": "earlier layers", "shape": "dot", "size": 10.178571428571429, "title": "earlier layers"}, {"color": "#6FA8DC", "id": "precise in localization", "label": "precise in localization", "shape": "dot", "size": 10.089285714285714, "title": "precise in localization"}, {"color": "#6FA8DC", "id": "semantics", "label": "semantics", "shape": "dot", "size": 10.089285714285714, "title": "semantics"}, {"color": "#6FA8DC", "id": "hypercolumn", "label": "hypercolumn", "shape": "dot", "size": 10.089285714285714, "title": "hypercolumn"}, {"color": "#6FA8DC", "id": "vector of activations", "label": "vector of activations", "shape": "dot", "size": 10.089285714285714, "title": "vector of activations"}, {"color": "#6FA8DC", "id": "pixel", "label": "pixel", "shape": "dot", "size": 10.089285714285714, "title": "pixel"}, {"color": "#6FA8DC", "id": "CNN units", "label": "CNN units", "shape": "dot", "size": 10.089285714285714, "title": "CNN units"}, {"color": "#6FA8DC", "id": "hypercolumns", "label": "hypercolumns", "shape": "dot", "size": 10.267857142857142, "title": "hypercolumns"}, {"color": "#6FA8DC", "id": "pixel descriptors", "label": "pixel descriptors", "shape": "dot", "size": 10.089285714285714, "title": "pixel descriptors"}, {"color": "#6FA8DC", "id": "simultaneous detection", "label": "simultaneous detection", "shape": "dot", "size": 10.089285714285714, "title": "simultaneous detection"}, {"color": "#6FA8DC", "id": "localization task", "label": "localization task", "shape": "dot", "size": 10.267857142857142, "title": "localization task"}, {"color": "#6FA8DC", "id": "keypoint localization", "label": "keypoint localization", "shape": "dot", "size": 10.089285714285714, "title": "keypoint localization"}, {"color": "#6FA8DC", "id": "part labeling", "label": "part labeling", "shape": "dot", "size": 10.089285714285714, "title": "part labeling"}, {"color": "#6FA8DC", "id": "Fine-grained Localization", "label": "Fine-grained Localization", "shape": "dot", "size": 10.178571428571429, "title": "Fine-grained Localization"}, {"color": "#6FA8DC", "id": "Keypoint Localization", "label": "Keypoint Localization", "shape": "dot", "size": 10.089285714285714, "title": "Keypoint Localization"}, {"color": "#6FA8DC", "id": "Deep Convolutional Networks", "label": "Deep Convolutional Networks", "shape": "dot", "size": 10.089285714285714, "title": "Deep Convolutional Networks"}, {"color": "#6FA8DC", "id": "Spatial Pyramid Pooling", "label": "Spatial Pyramid Pooling", "shape": "dot", "size": 10.178571428571429, "title": "Spatial Pyramid Pooling"}, {"color": "#6FA8DC", "id": "Multi-scale Feature Integration", "label": "Multi-scale Feature Integration", "shape": "dot", "size": 10.089285714285714, "title": "Multi-scale Feature Integration"}, {"color": "#6FA8DC", "id": "Arbel\u00e1ez, P.", "label": "Arbel\u00e1ez, P.", "shape": "dot", "size": 10.089285714285714, "title": "Arbel\u00e1ez, P."}, {"color": "#6FA8DC", "id": "Multiscale Combinatorial Grouping", "label": "Multiscale Combinatorial Grouping", "shape": "dot", "size": 10.089285714285714, "title": "Multiscale Combinatorial Grouping"}, {"color": "#6FA8DC", "id": "He, K.", "label": "He, K.", "shape": "dot", "size": 10.089285714285714, "title": "He, K."}, {"color": "#6FA8DC", "id": "Barron, J. T.", "label": "Barron, J. T.", "shape": "dot", "size": 10.089285714285714, "title": "Barron, J. T."}, {"color": "#6FA8DC", "id": "Volumetric Semantic Segmentation", "label": "Volumetric Semantic Segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Volumetric Semantic Segmentation"}, {"color": "#6FA8DC", "id": "Hypercolumn Representation", "label": "Hypercolumn Representation", "shape": "dot", "size": 10.089285714285714, "title": "Hypercolumn Representation"}, {"color": "#6FA8DC", "id": "Barron et al.", "label": "Barron et al.", "shape": "dot", "size": 10.089285714285714, "title": "Barron et al."}, {"color": "#6FA8DC", "id": "Hubel \u0026 Wiesel", "label": "Hubel \u0026 Wiesel", "shape": "dot", "size": 10.089285714285714, "title": "Hubel \u0026 Wiesel"}, {"color": "#6FA8DC", "id": "The Journal of Physiology", "label": "The Journal of Physiology", "shape": "dot", "size": 10.089285714285714, "title": "The Journal of Physiology"}, {"color": "#6FA8DC", "id": "Bo \u0026 Fowlakes", "label": "Bo \u0026 Fowlakes", "shape": "dot", "size": 10.089285714285714, "title": "Bo \u0026 Fowlakes"}, {"color": "#6FA8DC", "id": "Ionescu et al.", "label": "Ionescu et al.", "shape": "dot", "size": 10.089285714285714, "title": "Ionescu et al."}, {"color": "#6FA8DC", "id": "Jones \u0026 Malik", "label": "Jones \u0026 Malik", "shape": "dot", "size": 10.089285714285714, "title": "Jones \u0026 Malik"}, {"color": "#6FA8DC", "id": "Koenderink \u0026 van Doorn", "label": "Koenderink \u0026 van Doorn", "shape": "dot", "size": 10.089285714285714, "title": "Koenderink \u0026 van Doorn"}, {"color": "#6FA8DC", "id": "Biological Cybernetics", "label": "Biological Cybernetics", "shape": "dot", "size": 10.089285714285714, "title": "Biological Cybernetics"}, {"color": "#6FA8DC", "id": "Volumetric semantic segmentation", "label": "Volumetric semantic segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Volumetric semantic segmentation"}, {"color": "#6FA8DC", "id": "pyramid context features", "label": "pyramid context features", "shape": "dot", "size": 10.089285714285714, "title": "pyramid context features"}, {"color": "#6FA8DC", "id": "Visual cortex", "label": "Visual cortex", "shape": "dot", "size": 10.089285714285714, "title": "Visual cortex"}, {"color": "#6FA8DC", "id": "Hubel \u0026 Wiesel\u0027s work", "label": "Hubel \u0026 Wiesel\u0027s work", "shape": "dot", "size": 10.089285714285714, "title": "Hubel \u0026 Wiesel\u0027s work"}, {"color": "#6FA8DC", "id": "Pedestrian parsing", "label": "Pedestrian parsing", "shape": "dot", "size": 10.089285714285714, "title": "Pedestrian parsing"}, {"color": "#6FA8DC", "id": "shape-based methods", "label": "shape-based methods", "shape": "dot", "size": 10.089285714285714, "title": "shape-based methods"}, {"color": "#6FA8DC", "id": "Biological cybernetics", "label": "Biological cybernetics", "shape": "dot", "size": 10.089285714285714, "title": "Biological cybernetics"}, {"color": "#6FA8DC", "id": "visual system", "label": "visual system", "shape": "dot", "size": 10.089285714285714, "title": "visual system"}, {"color": "#6FA8DC", "id": "Hinton", "label": "Hinton", "shape": "dot", "size": 10.089285714285714, "title": "Hinton"}, {"color": "#6FA8DC", "id": "Universidad de los Andes", "label": "Universidad de los Andes", "shape": "dot", "size": 10.089285714285714, "title": "Universidad de los Andes"}, {"color": "#6FA8DC", "id": "Malik", "label": "Malik", "shape": "dot", "size": 10.089285714285714, "title": "Malik"}, {"color": "#6FA8DC", "id": "Xie", "label": "Xie", "shape": "dot", "size": 10.089285714285714, "title": "Xie"}, {"color": "#6FA8DC", "id": "DeepShape", "label": "DeepShape", "shape": "dot", "size": 10.357142857142858, "title": "DeepShape"}, {"color": "#6FA8DC", "id": "shape descriptor", "label": "shape descriptor", "shape": "dot", "size": 10.535714285714286, "title": "shape descriptor"}, {"color": "#6FA8DC", "id": "3D shape matching", "label": "3D shape matching", "shape": "dot", "size": 10.446428571428571, "title": "3D shape matching"}, {"color": "#6FA8DC", "id": "3D shape retrieval", "label": "3D shape retrieval", "shape": "dot", "size": 10.267857142857142, "title": "3D shape retrieval"}, {"color": "#6FA8DC", "id": "3D model", "label": "3D model", "shape": "dot", "size": 10.089285714285714, "title": "3D model"}, {"color": "#6FA8DC", "id": "3D shape matching and retrieval", "label": "3D shape matching and retrieval", "shape": "dot", "size": 10.267857142857142, "title": "3D shape matching and retrieval"}, {"color": "#6FA8DC", "id": "shape feature learning scheme", "label": "shape feature learning scheme", "shape": "dot", "size": 10.178571428571429, "title": "shape feature learning scheme"}, {"color": "#6FA8DC", "id": "auto-encoder", "label": "auto-encoder", "shape": "dot", "size": 10.178571428571429, "title": "auto-encoder"}, {"color": "#6FA8DC", "id": "discriminative deep auto-encoder", "label": "discriminative deep auto-encoder", "shape": "dot", "size": 10.089285714285714, "title": "discriminative deep auto-encoder"}, {"color": "#6FA8DC", "id": "shape distribution", "label": "shape distribution", "shape": "dot", "size": 10.089285714285714, "title": "shape distribution"}, {"color": "#6FA8DC", "id": "Fisher discrimination criterion", "label": "Fisher discrimination criterion", "shape": "dot", "size": 10.178571428571429, "title": "Fisher discrimination criterion"}, {"color": "#6FA8DC", "id": "neurons", "label": "neurons", "shape": "dot", "size": 10.178571428571429, "title": "neurons"}, {"color": "#6FA8DC", "id": "multiscale shape distribution", "label": "multiscale shape distribution", "shape": "dot", "size": 10.089285714285714, "title": "multiscale shape distribution"}, {"color": "#6FA8DC", "id": "hidden layer neurons", "label": "hidden layer neurons", "shape": "dot", "size": 10.089285714285714, "title": "hidden layer neurons"}, {"color": "#6FA8DC", "id": "multiple discriminative auto-encoders", "label": "multiple discriminative auto-encoders", "shape": "dot", "size": 10.089285714285714, "title": "multiple discriminative auto-encoders"}, {"color": "#6FA8DC", "id": "Mcgill dataset", "label": "Mcgill dataset", "shape": "dot", "size": 10.178571428571429, "title": "Mcgill dataset"}, {"color": "#6FA8DC", "id": "3D models", "label": "3D models", "shape": "dot", "size": 10.178571428571429, "title": "3D models"}, {"color": "#6FA8DC", "id": "geometric variations", "label": "geometric variations", "shape": "dot", "size": 10.089285714285714, "title": "geometric variations"}, {"color": "#6FA8DC", "id": "Proposed Method", "label": "Proposed Method", "shape": "dot", "size": 10.178571428571429, "title": "Proposed Method"}, {"color": "#6FA8DC", "id": "Agathos et al. (2009)", "label": "Agathos et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Agathos et al. (2009)"}, {"color": "#6FA8DC", "id": "Retrieval of 3D articulated objects", "label": "Retrieval of 3D articulated objects", "shape": "dot", "size": 10.089285714285714, "title": "Retrieval of 3D articulated objects"}, {"color": "#6FA8DC", "id": "Assfalg et al. (2007)", "label": "Assfalg et al. (2007)", "shape": "dot", "size": 10.089285714285714, "title": "Assfalg et al. (2007)"}, {"color": "#6FA8DC", "id": "Content-based retrieval of 3D objects", "label": "Content-based retrieval of 3D objects", "shape": "dot", "size": 10.089285714285714, "title": "Content-based retrieval of 3D objects"}, {"color": "#6FA8DC", "id": "Belongie et al. (2000)", "label": "Belongie et al. (2000)", "shape": "dot", "size": 10.178571428571429, "title": "Belongie et al. (2000)"}, {"color": "#6FA8DC", "id": "Shape context", "label": "Shape context", "shape": "dot", "size": 10.178571428571429, "title": "Shape context"}, {"color": "#6FA8DC", "id": "shape matching and object recognition", "label": "shape matching and object recognition", "shape": "dot", "size": 10.089285714285714, "title": "shape matching and object recognition"}, {"color": "#6FA8DC", "id": "Geometric Feature Learning", "label": "Geometric Feature Learning", "shape": "dot", "size": 10.089285714285714, "title": "Geometric Feature Learning"}, {"color": "#6FA8DC", "id": "Deep Auto-encoders", "label": "Deep Auto-encoders", "shape": "dot", "size": 10.089285714285714, "title": "Deep Auto-encoders"}, {"color": "#6FA8DC", "id": "Ric variations", "label": "Ric variations", "shape": "dot", "size": 10.178571428571429, "title": "Ric variations"}, {"color": "#6FA8DC", "id": "SHREC\u002710 Shape dataset", "label": "SHREC\u002710 Shape dataset", "shape": "dot", "size": 10.089285714285714, "title": "SHREC\u002710 Shape dataset"}, {"color": "#6FA8DC", "id": "Shape Context", "label": "Shape Context", "shape": "dot", "size": 10.267857142857142, "title": "Shape Context"}, {"color": "#6FA8DC", "id": "shape matching", "label": "shape matching", "shape": "dot", "size": 10.178571428571429, "title": "shape matching"}, {"color": "#6FA8DC", "id": "Deep Architectures", "label": "Deep Architectures", "shape": "dot", "size": 10.089285714285714, "title": "Deep Architectures"}, {"color": "#6FA8DC", "id": "AI", "label": "AI", "shape": "dot", "size": 10.178571428571429, "title": "AI"}, {"color": "#6FA8DC", "id": "Shape Google", "label": "Shape Google", "shape": "dot", "size": 10.178571428571429, "title": "Shape Google"}, {"color": "#6FA8DC", "id": "geometric words", "label": "geometric words", "shape": "dot", "size": 10.089285714285714, "title": "geometric words"}, {"color": "#6FA8DC", "id": "Isometry-invariant distances", "label": "Isometry-invariant distances", "shape": "dot", "size": 10.089285714285714, "title": "Isometry-invariant distances"}, {"color": "#6FA8DC", "id": "Bronstein et al. (2006)", "label": "Bronstein et al. (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Bronstein et al. (2006)"}, {"color": "#6FA8DC", "id": "Gromov-Hausdorff framework", "label": "Gromov-Hausdorff framework", "shape": "dot", "size": 10.089285714285714, "title": "Gromov-Hausdorff framework"}, {"color": "#6FA8DC", "id": "non-rigid shape matching", "label": "non-rigid shape matching", "shape": "dot", "size": 10.089285714285714, "title": "non-rigid shape matching"}, {"color": "#6FA8DC", "id": "Diffusion geometry", "label": "Diffusion geometry", "shape": "dot", "size": 10.089285714285714, "title": "Diffusion geometry"}, {"color": "#6FA8DC", "id": "topologically-robust matching", "label": "topologically-robust matching", "shape": "dot", "size": 10.089285714285714, "title": "topologically-robust matching"}, {"color": "#6FA8DC", "id": "Bronstein et al. (2011)", "label": "Bronstein et al. (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Bronstein et al. (2011)"}, {"color": "#6FA8DC", "id": "Mahmoudi, M.", "label": "Mahmoudi, M.", "shape": "dot", "size": 10.089285714285714, "title": "Mahmoudi, M."}, {"color": "#6FA8DC", "id": "A Gromov-Hausdorff framework", "label": "A Gromov-Hausdorff framework", "shape": "dot", "size": 10.267857142857142, "title": "A Gromov-Hausdorff framework"}, {"color": "#6FA8DC", "id": "Chen, D.-Y.", "label": "Chen, D.-Y.", "shape": "dot", "size": 10.089285714285714, "title": "Chen, D.-Y."}, {"color": "#6FA8DC", "id": "On visual similarity based 3D model retrieval", "label": "On visual similarity based 3D model retrieval", "shape": "dot", "size": 10.178571428571429, "title": "On visual similarity based 3D model retrieval"}, {"color": "#6FA8DC", "id": "3D model retrieval", "label": "3D model retrieval", "shape": "dot", "size": 10.089285714285714, "title": "3D model retrieval"}, {"color": "#6FA8DC", "id": "Chen, X.", "label": "Chen, X.", "shape": "dot", "size": 10.267857142857142, "title": "Chen, X."}, {"color": "#6FA8DC", "id": "A benchmark for 3D mesh segmentation", "label": "A benchmark for 3D mesh segmentation", "shape": "dot", "size": 10.089285714285714, "title": "A benchmark for 3D mesh segmentation"}, {"color": "#6FA8DC", "id": "A benchmark", "label": "A benchmark", "shape": "dot", "size": 10.089285714285714, "title": "A benchmark"}, {"color": "#6FA8DC", "id": "3D mesh segmentation", "label": "3D mesh segmentation", "shape": "dot", "size": 10.089285714285714, "title": "3D mesh segmentation"}, {"color": "#6FA8DC", "id": "De Goes, F.", "label": "De Goes, F.", "shape": "dot", "size": 10.089285714285714, "title": "De Goes, F."}, {"color": "#6FA8DC", "id": "A hierarchical segmentation", "label": "A hierarchical segmentation", "shape": "dot", "size": 10.178571428571429, "title": "A hierarchical segmentation"}, {"color": "#6FA8DC", "id": "articulated bodies", "label": "articulated bodies", "shape": "dot", "size": 10.089285714285714, "title": "articulated bodies"}, {"color": "#6FA8DC", "id": "Jin Xie", "label": "Jin Xie", "shape": "dot", "size": 10.178571428571429, "title": "Jin Xie"}, {"color": "#6FA8DC", "id": "New York University Abu Dhabi", "label": "New York University Abu Dhabi", "shape": "dot", "size": 10.267857142857142, "title": "New York University Abu Dhabi"}, {"color": "#6FA8DC", "id": "jin.xie@nyu.edu", "label": "jin.xie@nyu.edu", "shape": "dot", "size": 10.089285714285714, "title": "jin.xie@nyu.edu"}, {"color": "#6FA8DC", "id": "Yi Fang", "label": "Yi Fang", "shape": "dot", "size": 10.178571428571429, "title": "Yi Fang"}, {"color": "#6FA8DC", "id": "yfang@nyu.edu", "label": "yfang@nyu.edu", "shape": "dot", "size": 10.089285714285714, "title": "yfang@nyu.edu"}, {"color": "#6FA8DC", "id": "Fan Zhu", "label": "Fan Zhu", "shape": "dot", "size": 10.089285714285714, "title": "Fan Zhu"}, {"color": "#6FA8DC", "id": "Department of Electrical and Computer Engineering", "label": "Department of Electrical and Computer Engineering", "shape": "dot", "size": 10.089285714285714, "title": "Department of Electrical and Computer Engineering"}, {"color": "#6FA8DC", "id": "Department of Electrical and ComputerEngineering", "label": "Department of Electrical and ComputerEngineering", "shape": "dot", "size": 10.089285714285714, "title": "Department of Electrical and ComputerEngineering"}, {"color": "#6FA8DC", "id": "Edward Wong", "label": "Edward Wong", "shape": "dot", "size": 10.089285714285714, "title": "Edward Wong"}, {"color": "#6FA8DC", "id": "Polytechnic School of Engineering", "label": "Polytechnic School of Engineering", "shape": "dot", "size": 10.178571428571429, "title": "Polytechnic School of Engineering"}, {"color": "#6FA8DC", "id": "New York University", "label": "New York University", "shape": "dot", "size": 10.089285714285714, "title": "New York University"}, {"color": "#6FA8DC", "id": "Bingbing Ni", "label": "Bingbing Ni", "shape": "dot", "size": 10.178571428571429, "title": "Bingbing Ni"}, {"color": "#6FA8DC", "id": "Motion Part Regularization", "label": "Motion Part Regularization", "shape": "dot", "size": 10.446428571428571, "title": "Motion Part Regularization"}, {"color": "#6FA8DC", "id": "Pierre Moulin", "label": "Pierre Moulin", "shape": "dot", "size": 10.178571428571429, "title": "Pierre Moulin"}, {"color": "#6FA8DC", "id": "Trajectory Group Selection", "label": "Trajectory Group Selection", "shape": "dot", "size": 10.089285714285714, "title": "Trajectory Group Selection"}, {"color": "#6FA8DC", "id": "golf", "label": "golf", "shape": "dot", "size": 10.089285714285714, "title": "golf"}, {"color": "#6FA8DC", "id": "Action", "label": "Action", "shape": "dot", "size": 10.178571428571429, "title": "Action"}, {"color": "#6FA8DC", "id": "punch", "label": "punch", "shape": "dot", "size": 10.089285714285714, "title": "punch"}, {"color": "#6FA8DC", "id": "Fisher vector", "label": "Fisher vector", "shape": "dot", "size": 10.089285714285714, "title": "Fisher vector"}, {"color": "#6FA8DC", "id": "Ni_Motion_Part_Regularization_2015_CVPR_paper", "label": "Ni_Motion_Part_Regularization_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Ni_Motion_Part_Regularization_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Motion Part Regularization framework", "label": "Motion Part Regularization framework", "shape": "dot", "size": 10.267857142857142, "title": "Motion Part Regularization framework"}, {"color": "#6FA8DC", "id": "action recognition", "label": "action recognition", "shape": "dot", "size": 10.714285714285714, "title": "action recognition"}, {"color": "#6FA8DC", "id": "dense trajectories", "label": "dense trajectories", "shape": "dot", "size": 10.089285714285714, "title": "dense trajectories"}, {"color": "#6FA8DC", "id": "discriminativeness weighted Fisher vector representation", "label": "discriminativeness weighted Fisher vector representation", "shape": "dot", "size": 10.089285714285714, "title": "discriminativeness weighted Fisher vector representation"}, {"color": "#6FA8DC", "id": "traditional Fisher vector", "label": "traditional Fisher vector", "shape": "dot", "size": 10.089285714285714, "title": "traditional Fisher vector"}, {"color": "#6FA8DC", "id": "generating motion part candidates", "label": "generating motion part candidates", "shape": "dot", "size": 10.089285714285714, "title": "generating motion part candidates"}, {"color": "#6FA8DC", "id": "objective function", "label": "objective function", "shape": "dot", "size": 10.357142857142858, "title": "objective function"}, {"color": "#6FA8DC", "id": "sparse selection of trajectory groups", "label": "sparse selection of trajectory groups", "shape": "dot", "size": 10.089285714285714, "title": "sparse selection of trajectory groups"}, {"color": "#6FA8DC", "id": "action class discriminative term", "label": "action class discriminative term", "shape": "dot", "size": 10.089285714285714, "title": "action class discriminative term"}, {"color": "#6FA8DC", "id": "optimization algorithm", "label": "optimization algorithm", "shape": "dot", "size": 10.178571428571429, "title": "optimization algorithm"}, {"color": "#6FA8DC", "id": "auxiliary variables", "label": "auxiliary variables", "shape": "dot", "size": 10.089285714285714, "title": "auxiliary variables"}, {"color": "#6FA8DC", "id": "Optimization Algorithm", "label": "Optimization Algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Optimization Algorithm"}, {"color": "#6FA8DC", "id": "Motion Part", "label": "Motion Part", "shape": "dot", "size": 10.089285714285714, "title": "Motion Part"}, {"color": "#6FA8DC", "id": "Discriminative Weights", "label": "Discriminative Weights", "shape": "dot", "size": 10.089285714285714, "title": "Discriminative Weights"}, {"color": "#6FA8DC", "id": "State-of-the-Art Performance", "label": "State-of-the-Art Performance", "shape": "dot", "size": 10.089285714285714, "title": "State-of-the-Art Performance"}, {"color": "#6FA8DC", "id": "Dense Trajectories", "label": "Dense Trajectories", "shape": "dot", "size": 10.089285714285714, "title": "Dense Trajectories"}, {"color": "#6FA8DC", "id": "Wang et al. (2011)", "label": "Wang et al. (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Wang et al. (2011)"}, {"color": "#6FA8DC", "id": "Behavior Recognition", "label": "Behavior Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Behavior Recognition"}, {"color": "#6FA8DC", "id": "Spatio-Temporal Grouping", "label": "Spatio-Temporal Grouping", "shape": "dot", "size": 10.089285714285714, "title": "Spatio-Temporal Grouping"}, {"color": "#6FA8DC", "id": "LIBSVM", "label": "LIBSVM", "shape": "dot", "size": 10.267857142857142, "title": "LIBSVM"}, {"color": "#6FA8DC", "id": "library", "label": "library", "shape": "dot", "size": 10.178571428571429, "title": "library"}, {"color": "#6FA8DC", "id": "Fisher Vector Representation", "label": "Fisher Vector Representation", "shape": "dot", "size": 10.089285714285714, "title": "Fisher Vector Representation"}, {"color": "#6FA8DC", "id": "Automatic Annotation", "label": "Automatic Annotation", "shape": "dot", "size": 10.089285714285714, "title": "Automatic Annotation"}, {"color": "#6FA8DC", "id": "Human Actions", "label": "Human Actions", "shape": "dot", "size": 10.089285714285714, "title": "Human Actions"}, {"color": "#6FA8DC", "id": "Trajectories", "label": "Trajectories", "shape": "dot", "size": 10.089285714285714, "title": "Trajectories"}, {"color": "#6FA8DC", "id": "O. Duchenne", "label": "O. Duchenne", "shape": "dot", "size": 10.089285714285714, "title": "O. Duchenne"}, {"color": "#6FA8DC", "id": "Automatic annotation of human actions in video", "label": "Automatic annotation of human actions in video", "shape": "dot", "size": 10.357142857142858, "title": "Automatic annotation of human actions in video"}, {"color": "#6FA8DC", "id": "I. Laptev", "label": "I. Laptev", "shape": "dot", "size": 10.089285714285714, "title": "I. Laptev"}, {"color": "#6FA8DC", "id": "J. Sivic", "label": "J. Sivic", "shape": "dot", "size": 10.089285714285714, "title": "J. Sivic"}, {"color": "#6FA8DC", "id": "J. Ponce", "label": "J. Ponce", "shape": "dot", "size": 10.089285714285714, "title": "J. Ponce"}, {"color": "#6FA8DC", "id": "H. Wang", "label": "H. Wang", "shape": "dot", "size": 10.089285714285714, "title": "H. Wang"}, {"color": "#6FA8DC", "id": "Action recognition with improved trajectories", "label": "Action recognition with improved trajectories", "shape": "dot", "size": 10.178571428571429, "title": "Action recognition with improved trajectories"}, {"color": "#6FA8DC", "id": "C. Schmid", "label": "C. Schmid", "shape": "dot", "size": 10.178571428571429, "title": "C. Schmid"}, {"color": "#6FA8DC", "id": "P. Felzenszwalb", "label": "P. Felzenszwalb", "shape": "dot", "size": 10.089285714285714, "title": "P. Felzenszwalb"}, {"color": "#6FA8DC", "id": "Object detection with discriminatively trained part based models", "label": "Object detection with discriminatively trained part based models", "shape": "dot", "size": 10.267857142857142, "title": "Object detection with discriminatively trained part based models"}, {"color": "#6FA8DC", "id": "R. Girshick", "label": "R. Girshick", "shape": "dot", "size": 10.178571428571429, "title": "R. Girshick"}, {"color": "#6FA8DC", "id": "D. McAlleser", "label": "D. McAlleser", "shape": "dot", "size": 10.089285714285714, "title": "D. McAlleser"}, {"color": "#6FA8DC", "id": "D. Ramanan", "label": "D. Ramanan", "shape": "dot", "size": 10.089285714285714, "title": "D. Ramanan"}, {"color": "#6FA8DC", "id": "Object description with discriminatively trained part based models", "label": "Object description with discriminatively trained part based models", "shape": "dot", "size": 10.089285714285714, "title": "Object description with discriminatively trained part based models"}, {"color": "#6FA8DC", "id": "J. Wang", "label": "J. Wang", "shape": "dot", "size": 10.089285714285714, "title": "J. Wang"}, {"color": "#6FA8DC", "id": "Mining actionlet ensemble for action recognition with depth cameras", "label": "Mining actionlet ensemble for action recognition with depth cameras", "shape": "dot", "size": 10.357142857142858, "title": "Mining actionlet ensemble for action recognition with depth cameras"}, {"color": "#6FA8DC", "id": "Z. Liu", "label": "Z. Liu", "shape": "dot", "size": 10.089285714285714, "title": "Z. Liu"}, {"color": "#6FA8DC", "id": "Y. Wu", "label": "Y. Wu", "shape": "dot", "size": 10.089285714285714, "title": "Y. Wu"}, {"color": "#6FA8DC", "id": "J. Yuan", "label": "J. Yuan", "shape": "dot", "size": 10.089285714285714, "title": "J. Yuan"}, {"color": "#6FA8DC", "id": "M. Jain", "label": "M. Jain", "shape": "dot", "size": 10.089285714285714, "title": "M. Jain"}, {"color": "#6FA8DC", "id": "Better exploiting motion for better action recognition", "label": "Better exploiting motion for better action recognition", "shape": "dot", "size": 10.267857142857142, "title": "Better exploiting motion for better action recognition"}, {"color": "#6FA8DC", "id": "H. Jegou", "label": "H. Jegou", "shape": "dot", "size": 10.089285714285714, "title": "H. Jegou"}, {"color": "#6FA8DC", "id": "P. Bouthemy", "label": "P. Bouthemy", "shape": "dot", "size": 10.089285714285714, "title": "P. Bouthemy"}, {"color": "#6FA8DC", "id": "Y.-G. Jiang", "label": "Y.-G. Jiang", "shape": "dot", "size": 10.089285714285714, "title": "Y.-G. Jiang"}, {"color": "#6FA8DC", "id": "Trajectory-based modeling of human actions with motion reference points", "label": "Trajectory-based modeling of human actions with motion reference points", "shape": "dot", "size": 10.446428571428571, "title": "Trajectory-based modeling of human actions with motion reference points"}, {"color": "#6FA8DC", "id": "Q. Dai", "label": "Q. Dai", "shape": "dot", "size": 10.089285714285714, "title": "Q. Dai"}, {"color": "#6FA8DC", "id": "X. Xue", "label": "X. Xue", "shape": "dot", "size": 10.089285714285714, "title": "X. Xue"}, {"color": "#6FA8DC", "id": "W. Liu", "label": "W. Liu", "shape": "dot", "size": 10.089285714285714, "title": "W. Liu"}, {"color": "#6FA8DC", "id": "C.-W. Ngo", "label": "C.-W. Ngo", "shape": "dot", "size": 10.089285714285714, "title": "C.-W. Ngo"}, {"color": "#6FA8DC", "id": "ADSC Singapore", "label": "ADSC Singapore", "shape": "dot", "size": 10.178571428571429, "title": "ADSC Singapore"}, {"color": "#6FA8DC", "id": "Pierre Bounameaux", "label": "Pierre Bounameaux", "shape": "dot", "size": 10.089285714285714, "title": "Pierre Bounameaux"}, {"color": "#6FA8DC", "id": "gaze correction solutions", "label": "gaze correction solutions", "shape": "dot", "size": 10.089285714285714, "title": "gaze correction solutions"}, {"color": "#6FA8DC", "id": "additional hardware", "label": "additional hardware", "shape": "dot", "size": 10.089285714285714, "title": "additional hardware"}, {"color": "#6FA8DC", "id": "supervised machine learning", "label": "supervised machine learning", "shape": "dot", "size": 10.089285714285714, "title": "supervised machine learning"}, {"color": "#6FA8DC", "id": "synthesize images", "label": "synthesize images", "shape": "dot", "size": 10.089285714285714, "title": "synthesize images"}, {"color": "#6FA8DC", "id": "altered gaze direction", "label": "altered gaze direction", "shape": "dot", "size": 10.089285714285714, "title": "altered gaze direction"}, {"color": "#6FA8DC", "id": "redirection of gaze", "label": "redirection of gaze", "shape": "dot", "size": 10.089285714285714, "title": "redirection of gaze"}, {"color": "#6FA8DC", "id": "computationally efficient", "label": "computationally efficient", "shape": "dot", "size": 10.089285714285714, "title": "computationally efficient"}, {"color": "#6FA8DC", "id": "laptop", "label": "laptop", "shape": "dot", "size": 10.089285714285714, "title": "laptop"}, {"color": "#6FA8DC", "id": "uncanny valley effect", "label": "uncanny valley effect", "shape": "dot", "size": 10.089285714285714, "title": "uncanny valley effect"}, {"color": "#6FA8DC", "id": "pixel replacement operations", "label": "pixel replacement operations", "shape": "dot", "size": 10.089285714285714, "title": "pixel replacement operations"}, {"color": "#6FA8DC", "id": "eyes", "label": "eyes", "shape": "dot", "size": 10.089285714285714, "title": "eyes"}, {"color": "#6FA8DC", "id": "system\u0027s performance", "label": "system\u0027s performance", "shape": "dot", "size": 10.089285714285714, "title": "system\u0027s performance"}, {"color": "#6FA8DC", "id": "Monocular Gaze Correction", "label": "Monocular Gaze Correction", "shape": "dot", "size": 10.178571428571429, "title": "Monocular Gaze Correction"}, {"color": "#6FA8DC", "id": "Uncanny Valley Effect", "label": "Uncanny Valley Effect", "shape": "dot", "size": 10.178571428571429, "title": "Uncanny Valley Effect"}, {"color": "#6FA8DC", "id": "Localized Pixel Replacement", "label": "Localized Pixel Replacement", "shape": "dot", "size": 10.089285714285714, "title": "Localized Pixel Replacement"}, {"color": "#6FA8DC", "id": "Amit", "label": "Amit", "shape": "dot", "size": 10.089285714285714, "title": "Amit"}, {"color": "#6FA8DC", "id": "Shape Quantization", "label": "Shape Quantization", "shape": "dot", "size": 10.178571428571429, "title": "Shape Quantization"}, {"color": "#6FA8DC", "id": "Doll\u00e1r", "label": "Doll\u00e1r", "shape": "dot", "size": 10.089285714285714, "title": "Doll\u00e1r"}, {"color": "#6FA8DC", "id": "Structured Forests", "label": "Structured Forests", "shape": "dot", "size": 10.178571428571429, "title": "Structured Forests"}, {"color": "#6FA8DC", "id": "Fast Edge Detection", "label": "Fast Edge Detection", "shape": "dot", "size": 10.089285714285714, "title": "Fast Edge Detection"}, {"color": "#6FA8DC", "id": "Fanelli", "label": "Fanelli", "shape": "dot", "size": 10.089285714285714, "title": "Fanelli"}, {"color": "#6FA8DC", "id": "Random Forests for 3D Face Analysis", "label": "Random Forests for 3D Face Analysis", "shape": "dot", "size": 10.178571428571429, "title": "Random Forests for 3D Face Analysis"}, {"color": "#6FA8DC", "id": "Qualitative Evaluations", "label": "Qualitative Evaluations", "shape": "dot", "size": 10.089285714285714, "title": "Qualitative Evaluations"}, {"color": "#6FA8DC", "id": "1841\u20131848", "label": "1841\u20131848", "shape": "dot", "size": 10.089285714285714, "title": "1841\u20131848"}, {"color": "#6FA8DC", "id": "Fanelli, G.", "label": "Fanelli, G.", "shape": "dot", "size": 10.089285714285714, "title": "Fanelli, G."}, {"color": "#6FA8DC", "id": "Random forests for real time 3d face analysis", "label": "Random forests for real time 3d face analysis", "shape": "dot", "size": 10.089285714285714, "title": "Random forests for real time 3d face analysis"}, {"color": "#6FA8DC", "id": "real time 3d face analysis", "label": "real time 3d face analysis", "shape": "dot", "size": 10.089285714285714, "title": "real time 3d face analysis"}, {"color": "#6FA8DC", "id": "Gaze correction", "label": "Gaze correction", "shape": "dot", "size": 10.178571428571429, "title": "Gaze correction"}, {"color": "#6FA8DC", "id": "single webcam", "label": "single webcam", "shape": "dot", "size": 10.089285714285714, "title": "single webcam"}, {"color": "#6FA8DC", "id": "Gall, J.", "label": "Gall, J.", "shape": "dot", "size": 10.089285714285714, "title": "Gall, J."}, {"color": "#6FA8DC", "id": "Class-specific hough forests for object detection", "label": "Class-specific hough forests for object detection", "shape": "dot", "size": 10.089285714285714, "title": "Class-specific hough forests for object detection"}, {"color": "#6FA8DC", "id": "Hough forests", "label": "Hough forests", "shape": "dot", "size": 10.089285714285714, "title": "Hough forests"}, {"color": "#6FA8DC", "id": "Jones, A.", "label": "Jones, A.", "shape": "dot", "size": 10.089285714285714, "title": "Jones, A."}, {"color": "#6FA8DC", "id": "Achieving eye contact in a one-to-many 3D video teleconferecing system", "label": "Achieving eye contact in a one-to-many 3D video teleconferecing system", "shape": "dot", "size": 10.089285714285714, "title": "Achieving eye contact in a one-to-many 3D video teleconferecing system"}, {"color": "#6FA8DC", "id": "eye contact", "label": "eye contact", "shape": "dot", "size": 10.089285714285714, "title": "eye contact"}, {"color": "#6FA8DC", "id": "3D video teleconferencing system", "label": "3D video teleconferencing system", "shape": "dot", "size": 10.089285714285714, "title": "3D video teleconferencing system"}, {"color": "#6FA8DC", "id": "Kazemi, V.", "label": "Kazemi, V.", "shape": "dot", "size": 10.267857142857142, "title": "Kazemi, V."}, {"color": "#6FA8DC", "id": "One milliseccond face alignment with an ensemble of regression trees", "label": "One milliseccond face alignment with an ensemble of regression trees", "shape": "dot", "size": 10.089285714285714, "title": "One milliseccond face alignment with an ensemble of regression trees"}, {"color": "#6FA8DC", "id": "face alignment", "label": "face alignment", "shape": "dot", "size": 10.089285714285714, "title": "face alignment"}, {"color": "#6FA8DC", "id": "One milliseccond face alignment", "label": "One milliseccond face alignment", "shape": "dot", "size": 10.089285714285714, "title": "One milliseccond face alignment"}, {"color": "#6FA8DC", "id": "Sullivan, J.", "label": "Sullivan, J.", "shape": "dot", "size": 10.089285714285714, "title": "Sullivan, J."}, {"color": "#6FA8DC", "id": "Kuster, C.", "label": "Kuster, C.", "shape": "dot", "size": 10.089285714285714, "title": "Kuster, C."}, {"color": "#6FA8DC", "id": "Ren, S.", "label": "Ren, S.", "shape": "dot", "size": 10.178571428571429, "title": "Ren, S."}, {"color": "#6FA8DC", "id": "Face alignment", "label": "Face alignment", "shape": "dot", "size": 10.089285714285714, "title": "Face alignment"}, {"color": "#6FA8DC", "id": "Cao, X.", "label": "Cao, X.", "shape": "dot", "size": 10.178571428571429, "title": "Cao, X."}, {"color": "#6FA8DC", "id": "Kononenko, Daniil", "label": "Kononenko, Daniil", "shape": "dot", "size": 10.089285714285714, "title": "Kononenko, Daniil"}, {"color": "#6FA8DC", "id": "Skolkovo Institute of Science and Technology (Skoltech)", "label": "Skolkovo Institute of Science and Technology (Skoltech)", "shape": "dot", "size": 10.089285714285714, "title": "Skolkovo Institute of Science and Technology (Skoltech)"}, {"color": "#6FA8DC", "id": "Lempitsky, Victor", "label": "Lempitsky, Victor", "shape": "dot", "size": 10.089285714285714, "title": "Lempitsky, Victor"}, {"color": "#6FA8DC", "id": "Skolkovo Institute of Science and Technology (Skeltech)", "label": "Skolkovo Institute of Science and Technology (Skeltech)", "shape": "dot", "size": 10.089285714285714, "title": "Skolkovo Institute of Science and Technology (Skeltech)"}, {"color": "#6FA8DC", "id": "Zhao, Kaili", "label": "Zhao, Kaili", "shape": "dot", "size": 10.089285714285714, "title": "Zhao, Kaili"}, {"color": "#6FA8DC", "id": "Joint Patch and Multi-label Learning", "label": "Joint Patch and Multi-label Learning", "shape": "dot", "size": 10.267857142857142, "title": "Joint Patch and Multi-label Learning"}, {"color": "#6FA8DC", "id": "Facial Action Unit Detection", "label": "Facial Action Unit Detection", "shape": "dot", "size": 10.089285714285714, "title": "Facial Action Unit Detection"}, {"color": "#6FA8DC", "id": "Zhao_Joint_Patch_and_2015_CVPR_paper.pdf", "label": "Zhao_Joint_Patch_and_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Zhao_Joint_Patch_and_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Facial Action Coding System", "label": "Facial Action Coding System", "shape": "dot", "size": 10.625, "title": "Facial Action Coding System"}, {"color": "#6FA8DC", "id": "describing facial movements", "label": "describing facial movements", "shape": "dot", "size": 10.089285714285714, "title": "describing facial movements"}, {"color": "#6FA8DC", "id": "Action Units", "label": "Action Units", "shape": "dot", "size": 10.089285714285714, "title": "Action Units"}, {"color": "#6FA8DC", "id": "JPML", "label": "JPML", "shape": "dot", "size": 10.357142857142858, "title": "JPML"}, {"color": "#6FA8DC", "id": "Multi-label Learning", "label": "Multi-label Learning", "shape": "dot", "size": 10.089285714285714, "title": "Multi-label Learning"}, {"color": "#6FA8DC", "id": "highest average F1 scores", "label": "highest average F1 scores", "shape": "dot", "size": 10.089285714285714, "title": "highest average F1 scores"}, {"color": "#6FA8DC", "id": "CK+", "label": "CK+", "shape": "dot", "size": 10.089285714285714, "title": "CK+"}, {"color": "#6FA8DC", "id": "BP4D", "label": "BP4D", "shape": "dot", "size": 10.089285714285714, "title": "BP4D"}, {"color": "#6FA8DC", "id": "Machine learning", "label": "Machine learning", "shape": "dot", "size": 10.178571428571429, "title": "Machine learning"}, {"color": "#6FA8DC", "id": "facial expression recognition", "label": "facial expression recognition", "shape": "dot", "size": 10.178571428571429, "title": "facial expression recognition"}, {"color": "#6FA8DC", "id": "FACIAL Action Coding System (FACS)", "label": "FACIAL Action Coding System (FACS)", "shape": "dot", "size": 10.178571428571429, "title": "FACIAL Action Coding System (FACS)"}, {"color": "#6FA8DC", "id": "Action Unit (AU) Detection", "label": "Action Unit (AU) Detection", "shape": "dot", "size": 10.089285714285714, "title": "Action Unit (AU) Detection"}, {"color": "#6FA8DC", "id": "Patch Learning", "label": "Patch Learning", "shape": "dot", "size": 10.089285714285714, "title": "Patch Learning"}, {"color": "#6FA8DC", "id": "Alternating direction method of multipliers", "label": "Alternating direction method of multipliers", "shape": "dot", "size": 10.089285714285714, "title": "Alternating direction method of multipliers"}, {"color": "#6FA8DC", "id": "Alternating Direction Method of Multipliers", "label": "Alternating Direction Method of Multipliers", "shape": "dot", "size": 10.178571428571429, "title": "Alternating Direction Method of Multipliers"}, {"color": "#6FA8DC", "id": "Affective Computing", "label": "Affective Computing", "shape": "dot", "size": 10.089285714285714, "title": "Affective Computing"}, {"color": "#6FA8DC", "id": "Facial Action Unit Event Detection", "label": "Facial Action Unit Event Detection", "shape": "dot", "size": 10.267857142857142, "title": "Facial Action Unit Event Detection"}, {"color": "#6FA8DC", "id": "human face", "label": "human face", "shape": "dot", "size": 10.089285714285714, "title": "human face"}, {"color": "#6FA8DC", "id": "X. Ding", "label": "X. Ding", "shape": "dot", "size": 10.089285714285714, "title": "X. Ding"}, {"color": "#6FA8DC", "id": "cascade of tasks", "label": "cascade of tasks", "shape": "dot", "size": 10.089285714285714, "title": "cascade of tasks"}, {"color": "#6FA8DC", "id": "P. Ekman", "label": "P. Ekman", "shape": "dot", "size": 10.089285714285714, "title": "P. Ekman"}, {"color": "#6FA8DC", "id": "facial action units", "label": "facial action units", "shape": "dot", "size": 10.089285714285714, "title": "facial action units"}, {"color": "#6FA8DC", "id": "F. De la Torre", "label": "F. De la Torre", "shape": "dot", "size": 10.178571428571429, "title": "F. De la Torre"}, {"color": "#6FA8DC", "id": "Intraface", "label": "Intraface", "shape": "dot", "size": 10.089285714285714, "title": "Intraface"}, {"color": "#6FA8DC", "id": "facial action unit detection", "label": "facial action unit detection", "shape": "dot", "size": 10.089285714285714, "title": "facial action unit detection"}, {"color": "#6FA8DC", "id": "J. C. Hager", "label": "J. C. Hager", "shape": "dot", "size": 10.089285714285714, "title": "J. C. Hager"}, {"color": "#6FA8DC", "id": "Selective transfer machine", "label": "Selective transfer machine", "shape": "dot", "size": 10.357142857142858, "title": "Selective transfer machine"}, {"color": "#6FA8DC", "id": "personalization in facial action unit detection", "label": "personalization in facial action unit detection", "shape": "dot", "size": 10.089285714285714, "title": "personalization in facial action unit detection"}, {"color": "#6FA8DC", "id": "W.-S. Chu", "label": "W.-S. Chu", "shape": "dot", "size": 10.089285714285714, "title": "W.-S. Chu"}, {"color": "#6FA8DC", "id": "J. F. Cohn", "label": "J. F. Cohn", "shape": "dot", "size": 10.089285714285714, "title": "J. F. Cohn"}, {"color": "#6FA8DC", "id": "Facing imbalanced data", "label": "Facing imbalanced data", "shape": "dot", "size": 10.178571428571429, "title": "Facing imbalanced data"}, {"color": "#6FA8DC", "id": "imbalanced datasets", "label": "imbalanced datasets", "shape": "dot", "size": 10.089285714285714, "title": "imbalanced datasets"}, {"color": "#6FA8DC", "id": "L. A. Jeni", "label": "L. A. Jeni", "shape": "dot", "size": 10.089285714285714, "title": "L. A. Jeni"}, {"color": "#6FA8DC", "id": "Data-free prior model", "label": "Data-free prior model", "shape": "dot", "size": 10.267857142857142, "title": "Data-free prior model"}, {"color": "#6FA8DC", "id": "data-free approach", "label": "data-free approach", "shape": "dot", "size": 10.089285714285714, "title": "data-free approach"}, {"color": "#6FA8DC", "id": "Y. Li", "label": "Y. Li", "shape": "dot", "size": 10.089285714285714, "title": "Y. Li"}, {"color": "#6FA8DC", "id": "Y. Zhao", "label": "Y. Zhao", "shape": "dot", "size": 10.089285714285714, "title": "Y. Zhao"}, {"color": "#6FA8DC", "id": "School of Comm. and Info. Engineering", "label": "School of Comm. and Info. Engineering", "shape": "dot", "size": 10.267857142857142, "title": "School of Comm. and Info. Engineering"}, {"color": "#6FA8DC", "id": "Beijing University of Posts and Telecom.", "label": "Beijing University of Posts and Telecom.", "shape": "dot", "size": 10.178571428571429, "title": "Beijing University of Posts and Telecom."}, {"color": "#6FA8DC", "id": "Beijing", "label": "Beijing", "shape": "dot", "size": 10.267857142857142, "title": "Beijing"}, {"color": "#6FA8DC", "id": "facial action unit recognition", "label": "facial action unit recognition", "shape": "dot", "size": 10.089285714285714, "title": "facial action unit recognition"}, {"color": "#6FA8DC", "id": "G. Littlewort", "label": "G. Littlewort", "shape": "dot", "size": 10.089285714285714, "title": "G. Littlewort"}, {"color": "#6FA8DC", "id": "Dynamics of facial expression", "label": "Dynamics of facial expression", "shape": "dot", "size": 10.178571428571429, "title": "Dynamics of facial expression"}, {"color": "#6FA8DC", "id": "AU-cascades", "label": "AU-cascades", "shape": "dot", "size": 10.178571428571429, "title": "AU-cascades"}, {"color": "#6FA8DC", "id": "action unit detection", "label": "action unit detection", "shape": "dot", "size": 10.089285714285714, "title": "action unit detection"}, {"color": "#6FA8DC", "id": "Wen-Sheng Chu", "label": "Wen-Sheng Chu", "shape": "dot", "size": 10.089285714285714, "title": "Wen-Sheng Chu"}, {"color": "#6FA8DC", "id": "Robotics Institute", "label": "Robotics Institute", "shape": "dot", "size": 10.357142857142858, "title": "Robotics Institute"}, {"color": "#6FA8DC", "id": "Fernando De la Torre", "label": "Fernando De la Torre", "shape": "dot", "size": 10.089285714285714, "title": "Fernando De la Torre"}, {"color": "#6FA8DC", "id": "Jeffrey F. Cohn", "label": "Jeffrey F. Cohn", "shape": "dot", "size": 10.178571428571429, "title": "Jeffrey F. Cohn"}, {"color": "#6FA8DC", "id": "Robotic Institute", "label": "Robotic Institute", "shape": "dot", "size": 10.089285714285714, "title": "Robotic Institute"}, {"color": "#6FA8DC", "id": "Pittsburgh", "label": "Pittsburgh", "shape": "dot", "size": 10.089285714285714, "title": "Pittsburgh"}, {"color": "#6FA8DC", "id": "Honggang Zhang", "label": "Honggang Zhang", "shape": "dot", "size": 10.089285714285714, "title": "Honggang Zhang"}, {"color": "#6FA8DC", "id": "Beijing University of Posts and Telecom", "label": "Beijing University of Posts and Telecom", "shape": "dot", "size": 10.089285714285714, "title": "Beijing University of Posts and Telecom"}, {"color": "#6FA8DC", "id": "TVSum", "label": "TVSum", "shape": "dot", "size": 11.071428571428571, "title": "TVSum"}, {"color": "#6FA8DC", "id": "Web Videos", "label": "Web Videos", "shape": "dot", "size": 10.089285714285714, "title": "Web Videos"}, {"color": "#6FA8DC", "id": "Titles", "label": "Titles", "shape": "dot", "size": 10.089285714285714, "title": "Titles"}, {"color": "#6FA8DC", "id": "Yale Song", "label": "Yale Song", "shape": "dot", "size": 10.267857142857142, "title": "Yale Song"}, {"color": "#6FA8DC", "id": "Jordi Vallmitjana", "label": "Jordi Vallmitjana", "shape": "dot", "size": 10.178571428571429, "title": "Jordi Vallmitjana"}, {"color": "#6FA8DC", "id": "Amanda Stent", "label": "Amanda Stent", "shape": "dot", "size": 10.178571428571429, "title": "Amanda Stent"}, {"color": "#6FA8DC", "id": "Alejandro Jaimes", "label": "Alejandro Jaimes", "shape": "dot", "size": 10.178571428571429, "title": "Alejandro Jaimes"}, {"color": "#6FA8DC", "id": "Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf", "label": "Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Video summarization", "label": "Video summarization", "shape": "dot", "size": 10.089285714285714, "title": "Video summarization"}, {"color": "#6FA8DC", "id": "need for prior knowledge", "label": "need for prior knowledge", "shape": "dot", "size": 10.089285714285714, "title": "need for prior knowledge"}, {"color": "#6FA8DC", "id": "video summarization framework", "label": "video summarization framework", "shape": "dot", "size": 10.089285714285714, "title": "video summarization framework"}, {"color": "#6FA8DC", "id": "title-based image search results", "label": "title-based image search results", "shape": "dot", "size": 10.089285714285714, "title": "title-based image search results"}, {"color": "#6FA8DC", "id": "video titles", "label": "video titles", "shape": "dot", "size": 10.089285714285714, "title": "video titles"}, {"color": "#6FA8DC", "id": "descriptive", "label": "descriptive", "shape": "dot", "size": 10.089285714285714, "title": "descriptive"}, {"color": "#6FA8DC", "id": "co-archetypal analysis", "label": "co-archetypal analysis", "shape": "dot", "size": 10.178571428571429, "title": "co-archetypal analysis"}, {"color": "#6FA8DC", "id": "novel technique", "label": "novel technique", "shape": "dot", "size": 10.089285714285714, "title": "novel technique"}, {"color": "#6FA8DC", "id": "visual concepts", "label": "visual concepts", "shape": "dot", "size": 10.267857142857142, "title": "visual concepts"}, {"color": "#6FA8DC", "id": "video and images", "label": "video and images", "shape": "dot", "size": 10.089285714285714, "title": "video and images"}, {"color": "#6FA8DC", "id": "TVSum50", "label": "TVSum50", "shape": "dot", "size": 10.267857142857142, "title": "TVSum50"}, {"color": "#6FA8DC", "id": "benchmark dataset", "label": "benchmark dataset", "shape": "dot", "size": 10.089285714285714, "title": "benchmark dataset"}, {"color": "#6FA8DC", "id": "superior quality summaries", "label": "superior quality summaries", "shape": "dot", "size": 10.089285714285714, "title": "superior quality summaries"}, {"color": "#6FA8DC", "id": "image search results", "label": "image search results", "shape": "dot", "size": 10.089285714285714, "title": "image search results"}, {"color": "#6FA8DC", "id": "noise and variance", "label": "noise and variance", "shape": "dot", "size": 10.089285714285714, "title": "noise and variance"}, {"color": "#6FA8DC", "id": "summaries", "label": "summaries", "shape": "dot", "size": 10.089285714285714, "title": "summaries"}, {"color": "#6FA8DC", "id": "superior", "label": "superior", "shape": "dot", "size": 10.089285714285714, "title": "superior"}, {"color": "#6FA8DC", "id": "Co-Archetypal Analysis", "label": "Co-Archetypal Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Co-Archetypal Analysis"}, {"color": "#6FA8DC", "id": "analysis method", "label": "analysis method", "shape": "dot", "size": 10.089285714285714, "title": "analysis method"}, {"color": "#6FA8DC", "id": "Canonical Visual Concepts", "label": "Canonical Visual Concepts", "shape": "dot", "size": 10.089285714285714, "title": "Canonical Visual Concepts"}, {"color": "#6FA8DC", "id": "concept", "label": "concept", "shape": "dot", "size": 10.089285714285714, "title": "concept"}, {"color": "#6FA8DC", "id": "M. Basseville", "label": "M. Basseville", "shape": "dot", "size": 10.089285714285714, "title": "M. Basseville"}, {"color": "#6FA8DC", "id": "Detection of abrupt changes", "label": "Detection of abrupt changes", "shape": "dot", "size": 10.089285714285714, "title": "Detection of abrupt changes"}, {"color": "#6FA8DC", "id": "A. Beck", "label": "A. Beck", "shape": "dot", "size": 10.089285714285714, "title": "A. Beck"}, {"color": "#6FA8DC", "id": "shrinkage-thresholding algorithm", "label": "shrinkage-thresholding algorithm", "shape": "dot", "size": 10.089285714285714, "title": "shrinkage-thresholding algorithm"}, {"color": "#6FA8DC", "id": "K. Bleakley", "label": "K. Bleakley", "shape": "dot", "size": 10.089285714285714, "title": "K. Bleakley"}, {"color": "#6FA8DC", "id": "group fused lasso", "label": "group fused lasso", "shape": "dot", "size": 10.089285714285714, "title": "group fused lasso"}, {"color": "#6FA8DC", "id": "Y. Chen", "label": "Y. Chen", "shape": "dot", "size": 10.089285714285714, "title": "Y. Chen"}, {"color": "#6FA8DC", "id": "archetypal analysis", "label": "archetypal analysis", "shape": "dot", "size": 10.089285714285714, "title": "archetypal analysis"}, {"color": "#6FA8DC", "id": "S. Fidler", "label": "S. Fidler", "shape": "dot", "size": 10.178571428571429, "title": "S. Fidler"}, {"color": "#6FA8DC", "id": "sentence is worth a thousand pixels", "label": "sentence is worth a thousand pixels", "shape": "dot", "size": 10.089285714285714, "title": "sentence is worth a thousand pixels"}, {"color": "#6FA8DC", "id": "Airal", "label": "Airal", "shape": "dot", "size": 10.089285714285714, "title": "Airal"}, {"color": "#6FA8DC", "id": "Fast and robust archetypal analysis", "label": "Fast and robust archetypal analysis", "shape": "dot", "size": 10.178571428571429, "title": "Fast and robust archetypal analysis"}, {"color": "#6FA8DC", "id": "A sentence is worth a thousand pixels", "label": "A sentence is worth a thousand pixels", "shape": "dot", "size": 10.089285714285714, "title": "A sentence is worth a thousand pixels"}, {"color": "#6FA8DC", "id": "M. Gygli", "label": "M. Gygli", "shape": "dot", "size": 10.089285714285714, "title": "M. Gygli"}, {"color": "#6FA8DC", "id": "Creating summaries from user videos", "label": "Creating summaries from user videos", "shape": "dot", "size": 10.178571428571429, "title": "Creating summaries from user videos"}, {"color": "#6FA8DC", "id": "Y. Jia", "label": "Y. Jia", "shape": "dot", "size": 10.089285714285714, "title": "Y. Jia"}, {"color": "#6FA8DC", "id": "Visual concept learning", "label": "Visual concept learning", "shape": "dot", "size": 10.178571428571429, "title": "Visual concept learning"}, {"color": "#6FA8DC", "id": "Y. J. Lee", "label": "Y. J. Lee", "shape": "dot", "size": 10.178571428571429, "title": "Y. J. Lee"}, {"color": "#6FA8DC", "id": "Discovering important people and objects", "label": "Discovering important people and objects", "shape": "dot", "size": 10.178571428571429, "title": "Discovering important people and objects"}, {"color": "#6FA8DC", "id": "L. Li", "label": "L. Li", "shape": "dot", "size": 10.089285714285714, "title": "L. Li"}, {"color": "#6FA8DC", "id": "Video summarization via transferrable structured learning", "label": "Video summarization via transferrable structured learning", "shape": "dot", "size": 10.178571428571429, "title": "Video summarization via transferrable structured learning"}, {"color": "#6FA8DC", "id": "WWW", "label": "WWW", "shape": "dot", "size": 10.089285714285714, "title": "WWW"}, {"color": "#6FA8DC", "id": "D. Lin", "label": "D. Lin", "shape": "dot", "size": 10.089285714285714, "title": "D. Lin"}, {"color": "#6FA8DC", "id": "Visual semantic search", "label": "Visual semantic search", "shape": "dot", "size": 10.446428571428571, "title": "Visual semantic search"}, {"color": "#6FA8DC", "id": "Yahoo Labs", "label": "Yahoo Labs", "shape": "dot", "size": 10.446428571428571, "title": "Yahoo Labs"}, {"color": "#6FA8DC", "id": "Retrieving videos", "label": "Retrieving videos", "shape": "dot", "size": 10.089285714285714, "title": "Retrieving videos"}, {"color": "#6FA8DC", "id": "complex textual queries", "label": "complex textual queries", "shape": "dot", "size": 10.089285714285714, "title": "complex textual queries"}, {"color": "#6FA8DC", "id": "yalessong@yahoo-inc.com", "label": "yalessong@yahoo-inc.com", "shape": "dot", "size": 10.089285714285714, "title": "yalessong@yahoo-inc.com"}, {"color": "#6FA8DC", "id": "research institution", "label": "research institution", "shape": "dot", "size": 10.089285714285714, "title": "research institution"}, {"color": "#6FA8DC", "id": "isual semantic search", "label": "isual semantic search", "shape": "dot", "size": 10.178571428571429, "title": "isual semantic search"}, {"color": "#6FA8DC", "id": "video retrieval", "label": "video retrieval", "shape": "dot", "size": 10.089285714285714, "title": "video retrieval"}, {"color": "#6FA8DC", "id": "Tianjun Xiao", "label": "Tianjun Xiao", "shape": "dot", "size": 10.178571428571429, "title": "Tianjun Xiao"}, {"color": "#6FA8DC", "id": "The Application of Two-level Attention Models", "label": "The Application of Two-level Attention Models", "shape": "dot", "size": 10.535714285714286, "title": "The Application of Two-level Attention Models"}, {"color": "#6FA8DC", "id": "Yichong Xu", "label": "Yichong Xu", "shape": "dot", "size": 10.178571428571429, "title": "Yichong Xu"}, {"color": "#6FA8DC", "id": "Kuiyuan Yang", "label": "Kuiyuan Yang", "shape": "dot", "size": 10.178571428571429, "title": "Kuiyuan Yang"}, {"color": "#6FA8DC", "id": "Jiaxing Zhang", "label": "Jiaxing Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Jiaxing Zhang"}, {"color": "#6FA8DC", "id": "Yuxin Peng", "label": "Yuxin Peng", "shape": "dot", "size": 10.178571428571429, "title": "Yuxin Peng"}, {"color": "#6FA8DC", "id": "The Application of Two-level Attack Models", "label": "The Application of Two-level Attack Models", "shape": "dot", "size": 10.089285714285714, "title": "The Application of Two-level Attack Models"}, {"color": "#6FA8DC", "id": "Zheng Zhang", "label": "Zheng Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Zheng Zhang"}, {"color": "#6FA8DC", "id": "Deep Convolutional Neural Network", "label": "Deep Convolutional Neural Network", "shape": "dot", "size": 10.089285714285714, "title": "Deep Convolutional Neural Network"}, {"color": "#6FA8DC", "id": "Fine-grained classification", "label": "Fine-grained classification", "shape": "dot", "size": 10.089285714285714, "title": "Fine-grained classification"}, {"color": "#6FA8DC", "id": "subtle differences between categories", "label": "subtle differences between categories", "shape": "dot", "size": 10.089285714285714, "title": "subtle differences between categories"}, {"color": "#6FA8DC", "id": "visual attention", "label": "visual attention", "shape": "dot", "size": 10.178571428571429, "title": "visual attention"}, {"color": "#6FA8DC", "id": "deep neural networks", "label": "deep neural networks", "shape": "dot", "size": 10.089285714285714, "title": "deep neural networks"}, {"color": "#6FA8DC", "id": "pipeline", "label": "pipeline", "shape": "dot", "size": 10.267857142857142, "title": "pipeline"}, {"color": "#6FA8DC", "id": "bottom-up attention", "label": "bottom-up attention", "shape": "dot", "size": 10.089285714285714, "title": "bottom-up attention"}, {"color": "#6FA8DC", "id": "object-level top-down attention", "label": "object-level top-down attention", "shape": "dot", "size": 10.089285714285714, "title": "object-level top-down attention"}, {"color": "#6FA8DC", "id": "part-level top-down attention", "label": "part-level top-down attention", "shape": "dot", "size": 10.089285714285714, "title": "part-level top-down attention"}, {"color": "#6FA8DC", "id": "expensive annotations", "label": "expensive annotations", "shape": "dot", "size": 10.089285714285714, "title": "expensive annotations"}, {"color": "#6FA8DC", "id": "significant improvements", "label": "significant improvements", "shape": "dot", "size": 10.089285714285714, "title": "significant improvements"}, {"color": "#6FA8DC", "id": "competitive performance", "label": "competitive performance", "shape": "dot", "size": 10.089285714285714, "title": "competitive performance"}, {"color": "#6FA8DC", "id": "additional annotations", "label": "additional annotations", "shape": "dot", "size": 10.178571428571429, "title": "additional annotations"}, {"color": "#6FA8DC", "id": "Fine-grained image classification", "label": "Fine-grained image classification", "shape": "dot", "size": 10.178571428571429, "title": "Fine-grained image classification"}, {"color": "#6FA8DC", "id": "Visual attention models", "label": "Visual attention models", "shape": "dot", "size": 10.089285714285714, "title": "Visual attention models"}, {"color": "#6FA8DC", "id": "Deep convolutional neural networks", "label": "Deep convolutional neural networks", "shape": "dot", "size": 10.178571428571429, "title": "Deep convolutional neural networks"}, {"color": "#6FA8DC", "id": "Weak supervision", "label": "Weak supervision", "shape": "dot", "size": 10.089285714285714, "title": "Weak supervision"}, {"color": "#6FA8DC", "id": "Institute of Computer Science and Technologies", "label": "Institute of Computer Science and Technologies", "shape": "dot", "size": 10.089285714285714, "title": "Institute of Computer Science and Technologies"}, {"color": "#6FA8DC", "id": "Institute of Computer Science and Technology", "label": "Institute of Computer Science and Technology", "shape": "dot", "size": 10.178571428571429, "title": "Institute of Computer Science and Technology"}, {"color": "#6FA8DC", "id": "New York University Shanghai", "label": "New York University Shanghai", "shape": "dot", "size": 10.089285714285714, "title": "New York University Shanghai"}, {"color": "#6FA8DC", "id": "Geodesic Exponential Kernel", "label": "Geodesic Exponential Kernel", "shape": "dot", "size": 10.357142857142858, "title": "Geodesic Exponential Kernel"}, {"color": "#6FA8DC", "id": "curvature and linearity conflict", "label": "curvature and linearity conflict", "shape": "dot", "size": 10.089285714285714, "title": "curvature and linearity conflict"}, {"color": "#6FA8DC", "id": "Aasa Feragen", "label": "Aasa Feragen", "shape": "dot", "size": 10.178571428571429, "title": "Aasa Feragen"}, {"color": "#6FA8DC", "id": "Fran\u00e7ois Lauze", "label": "Fran\u00e7ois Lauze", "shape": "dot", "size": 10.267857142857142, "title": "Fran\u00e7ois Lauze"}, {"color": "#6FA8DC", "id": "S\u00f8ren Hauberg", "label": "S\u00f8ren Hauberg", "shape": "dot", "size": 10.178571428571429, "title": "S\u00f8ren Hauberg"}, {"color": "#6FA8DC", "id": "geodesic metric spaces", "label": "geodesic metric spaces", "shape": "dot", "size": 10.178571428571429, "title": "geodesic metric spaces"}, {"color": "#6FA8DC", "id": "Gaussian kernel", "label": "Gaussian kernel", "shape": "dot", "size": 10.089285714285714, "title": "Gaussian kernel"}, {"color": "#6FA8DC", "id": "positive definite kernel", "label": "positive definite kernel", "shape": "dot", "size": 10.178571428571429, "title": "positive definite kernel"}, {"color": "#6FA8DC", "id": "flat space", "label": "flat space", "shape": "dot", "size": 10.089285714285714, "title": "flat space"}, {"color": "#6FA8DC", "id": "geodesic Gaussian kernel", "label": "geodesic Gaussian kernel", "shape": "dot", "size": 10.089285714285714, "title": "geodesic Gaussian kernel"}, {"color": "#6FA8DC", "id": "Riemannian manifold is Euclidean", "label": "Riemannian manifold is Euclidean", "shape": "dot", "size": 10.089285714285714, "title": "Riemannian manifold is Euclidean"}, {"color": "#6FA8DC", "id": "geodesic Laplacian kernel", "label": "geodesic Laplacian kernel", "shape": "dot", "size": 10.446428571428571, "title": "geodesic Laplacian kernel"}, {"color": "#6FA8DC", "id": "positive de\ufb01niteness", "label": "positive de\ufb01niteness", "shape": "dot", "size": 10.089285714285714, "title": "positive de\ufb01niteness"}, {"color": "#6FA8DC", "id": "curved spaces", "label": "curved spaces", "shape": "dot", "size": 10.357142857142858, "title": "curved spaces"}, {"color": "#6FA8DC", "id": "spheres", "label": "spheres", "shape": "dot", "size": 10.178571428571429, "title": "spheres"}, {"color": "#6FA8DC", "id": "spaces", "label": "spaces", "shape": "dot", "size": 10.089285714285714, "title": "spaces"}, {"color": "#6FA8DC", "id": "conditionally negative de\ufb01nite distances", "label": "conditionally negative de\ufb01nite distances", "shape": "dot", "size": 10.089285714285714, "title": "conditionally negative de\ufb01nite distances"}, {"color": "#6FA8DC", "id": "Feragen", "label": "Feragen", "shape": "dot", "size": 10.089285714285714, "title": "Feragen"}, {"color": "#6FA8DC", "id": "hyperbolic spaces", "label": "hyperbolic spaces", "shape": "dot", "size": 10.178571428571429, "title": "hyperbolic spaces"}, {"color": "#6FA8DC", "id": "theoretical results", "label": "theoretical results", "shape": "dot", "size": 10.089285714285714, "title": "theoretical results"}, {"color": "#6FA8DC", "id": "empirically", "label": "empirically", "shape": "dot", "size": 10.089285714285714, "title": "empirically"}, {"color": "#6FA8DC", "id": "kernel", "label": "kernel", "shape": "dot", "size": 10.089285714285714, "title": "kernel"}, {"color": "#6FA8DC", "id": "geodesic Laplacian kernels", "label": "geodesic Laplacian kernels", "shape": "dot", "size": 10.357142857142858, "title": "geodesic Laplacian kernels"}, {"color": "#6FA8DC", "id": "Gaussian kernels", "label": "Gaussian kernels", "shape": "dot", "size": 10.089285714285714, "title": "Gaussian kernels"}, {"color": "#6FA8DC", "id": "Laplacian kernels", "label": "Laplacian kernels", "shape": "dot", "size": 10.089285714285714, "title": "Laplacian kernels"}, {"color": "#6FA8DC", "id": "M. Alamgir and U. von Luxburg", "label": "M. Alamgir and U. von Luxburg", "shape": "dot", "size": 10.089285714285714, "title": "M. Alamgir and U. von Luxburg"}, {"color": "#6FA8DC", "id": "Shortest path distance in random k-nearest neighbor graphs", "label": "Shortest path distance in random k-nearest neighbor graphs", "shape": "dot", "size": 10.089285714285714, "title": "Shortest path distance in random k-nearest neighbor graphs"}, {"color": "#6FA8DC", "id": "N. Dalal and B. Triggs", "label": "N. Dalal and B. Triggs", "shape": "dot", "size": 10.089285714285714, "title": "N. Dalal and B. Triggs"}, {"color": "#6FA8DC", "id": "Histograms of oriented gradients for human detection", "label": "Histograms of oriented gradients for human detection", "shape": "dot", "size": 10.089285714285714, "title": "Histograms of oriented gradients for human detection"}, {"color": "#6FA8DC", "id": "S. Amar\u00ed and H. Nagaoka", "label": "S. Amar\u00ed and H. Nagaoka", "shape": "dot", "size": 10.089285714285714, "title": "S. Amar\u00ed and H. Nagaoka"}, {"color": "#6FA8DC", "id": "Methods of information geometry", "label": "Methods of information geometry", "shape": "dot", "size": 10.089285714285714, "title": "Methods of information geometry"}, {"color": "#6FA8DC", "id": "Arsigny et al.", "label": "Arsigny et al.", "shape": "dot", "size": 10.089285714285714, "title": "Arsigny et al."}, {"color": "#6FA8DC", "id": "Fast and simple calculus on tensors", "label": "Fast and simple calculus on tensors", "shape": "dot", "size": 10.178571428571429, "title": "Fast and simple calculus on tensors"}, {"color": "#6FA8DC", "id": "MICCAI", "label": "MICCAI", "shape": "dot", "size": 10.089285714285714, "title": "MICCAI"}, {"color": "#6FA8DC", "id": "Feragen et al.", "label": "Feragen et al.", "shape": "dot", "size": 10.178571428571429, "title": "Feragen et al."}, {"color": "#6FA8DC", "id": "Means in spaces of tree-like shapes", "label": "Means in spaces of tree-like shapes", "shape": "dot", "size": 10.178571428571429, "title": "Means in spaces of tree-like shapes"}, {"color": "#6FA8DC", "id": "Scalable kernels for graphs", "label": "Scalable kernels for graphs", "shape": "dot", "size": 10.178571428571429, "title": "Scalable kernels for graphs"}, {"color": "#6FA8DC", "id": "Bekka and de la Harple", "label": "Bekka and de la Harple", "shape": "dot", "size": 10.089285714285714, "title": "Bekka and de la Harple"}, {"color": "#6FA8DC", "id": "Kazhdan\u2019s Property (T)", "label": "Kazhdan\u2019s Property (T)", "shape": "dot", "size": 10.267857142857142, "title": "Kazhdan\u2019s Property (T)"}, {"color": "#6FA8DC", "id": "Bridson and Hae\ufb02iger", "label": "Bridson and Hae\ufb02iger", "shape": "dot", "size": 10.089285714285714, "title": "Bridson and Hae\ufb02iger"}, {"color": "#6FA8DC", "id": "Metric spaces of non-positive curvature", "label": "Metric spaces of non-positive curvature", "shape": "dot", "size": 10.089285714285714, "title": "Metric spaces of non-positive curvature"}, {"color": "#6FA8DC", "id": "mathematical_property", "label": "mathematical_property", "shape": "dot", "size": 10.089285714285714, "title": "mathematical_property"}, {"color": "#6FA8DC", "id": "New Mathematical Monographs", "label": "New Mathematical Monographs", "shape": "dot", "size": 10.089285714285714, "title": "New Mathematical Monographs"}, {"color": "#6FA8DC", "id": "Ganzhao Yuan", "label": "Ganzhao Yuan", "shape": "dot", "size": 10.357142857142858, "title": "Ganzhao Yuan"}, {"color": "#6FA8DC", "id": "\u21130TV: A New Method", "label": "\u21130TV: A New Method", "shape": "dot", "size": 10.267857142857142, "title": "\u21130TV: A New Method"}, {"color": "#6FA8DC", "id": "Image Restoration", "label": "Image Restoration", "shape": "dot", "size": 10.267857142857142, "title": "Image Restoration"}, {"color": "#6FA8DC", "id": "DIKU, University of Copenhagen", "label": "DIKU, University of Copenhagen", "shape": "dot", "size": 10.178571428571429, "title": "DIKU, University of Copenhagen"}, {"color": "#6FA8DC", "id": "DTU Compute", "label": "DTU Compute", "shape": "dot", "size": 10.089285714285714, "title": "DTU Compute"}, {"color": "#6FA8DC", "id": "Yuan_L0TV_A_New_2015_CVPR_paper", "label": "Yuan_L0TV_A_New_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Yuan_L0TV_A_New_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "image restoration", "label": "image restoration", "shape": "dot", "size": 10.178571428571429, "title": "image restoration"}, {"color": "#6FA8DC", "id": "\u21130TV-PADMM", "label": "\u21130TV-PADMM", "shape": "dot", "size": 10.178571428571429, "title": "\u21130TV-PADMM"}, {"color": "#6FA8DC", "id": "TV-based restoration problem", "label": "TV-based restoration problem", "shape": "dot", "size": 10.178571428571429, "title": "TV-based restoration problem"}, {"color": "#6FA8DC", "id": "\u21130-norm data fidelity", "label": "\u21130-norm data fidelity", "shape": "dot", "size": 10.089285714285714, "title": "\u21130-norm data fidelity"}, {"color": "#6FA8DC", "id": "MPEC", "label": "MPEC", "shape": "dot", "size": 10.089285714285714, "title": "MPEC"}, {"color": "#6FA8DC", "id": "PADMM", "label": "PADMM", "shape": "dot", "size": 10.267857142857142, "title": "PADMM"}, {"color": "#6FA8DC", "id": "state-of-the-art image restoration methods", "label": "state-of-the-art image restoration methods", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art image restoration methods"}, {"color": "#6FA8DC", "id": "Impulse Noise", "label": "Impulse Noise", "shape": "dot", "size": 10.089285714285714, "title": "Impulse Noise"}, {"color": "#6FA8DC", "id": "Total Variation", "label": "Total Variation", "shape": "dot", "size": 10.089285714285714, "title": "Total Variation"}, {"color": "#6FA8DC", "id": "South China University of Technology (SCUT)", "label": "South China University of Technology (SCUT)", "shape": "dot", "size": 10.089285714285714, "title": "South China University of Technology (SCUT)"}, {"color": "#6FA8DC", "id": "yuan Ganzhao@gmail.com", "label": "yuan Ganzhao@gmail.com", "shape": "dot", "size": 10.089285714285714, "title": "yuan Ganzhao@gmail.com"}, {"color": "#6FA8DC", "id": "King Abdullah University of Science and Technology (KAUST)", "label": "King Abdullah University of Science and Technology (KAUST)", "shape": "dot", "size": 10.089285714285714, "title": "King Abdullah University of Science and Technology (KAUST)"}, {"color": "#6FA8DC", "id": "bernard.ghanem@kust.edu.sa", "label": "bernard.ghanem@kust.edu.sa", "shape": "dot", "size": 10.089285714285714, "title": "bernard.ghanem@kust.edu.sa"}, {"color": "#6FA8DC", "id": "Ejaz Ahmed", "label": "Ejaz Ahmed", "shape": "dot", "size": 10.178571428571429, "title": "Ejaz Ahmed"}, {"color": "#6FA8DC", "id": "An Improved Deep Learning Architecture", "label": "An Improved Deep Learning Architecture", "shape": "dot", "size": 10.357142857142858, "title": "An Improved Deep Learning Architecture"}, {"color": "#6FA8DC", "id": "Michael Jones", "label": "Michael Jones", "shape": "dot", "size": 10.178571428571429, "title": "Michael Jones"}, {"color": "#6FA8DC", "id": "Tim K. Marks", "label": "Tim K. Marks", "shape": "dot", "size": 10.178571428571429, "title": "Tim K. Marks"}, {"color": "#6FA8DC", "id": "learning features", "label": "learning features", "shape": "dot", "size": 10.089285714285714, "title": "learning features"}, {"color": "#6FA8DC", "id": "learning similarity metric", "label": "learning similarity metric", "shape": "dot", "size": 10.089285714285714, "title": "learning similarity metric"}, {"color": "#6FA8DC", "id": "similarity value", "label": "similarity value", "shape": "dot", "size": 10.178571428571429, "title": "similarity value"}, {"color": "#6FA8DC", "id": "same person", "label": "same person", "shape": "dot", "size": 10.089285714285714, "title": "same person"}, {"color": "#6FA8DC", "id": "layer", "label": "layer", "shape": "dot", "size": 10.178571428571429, "title": "layer"}, {"color": "#6FA8DC", "id": "cross-input neighborhood differences", "label": "cross-input neighborhood differences", "shape": "dot", "size": 10.178571428571429, "title": "cross-input neighborhood differences"}, {"color": "#6FA8DC", "id": "local relationships", "label": "local relationships", "shape": "dot", "size": 10.178571428571429, "title": "local relationships"}, {"color": "#6FA8DC", "id": "mid-level features", "label": "mid-level features", "shape": "dot", "size": 10.089285714285714, "title": "mid-level features"}, {"color": "#6FA8DC", "id": "patch summary features", "label": "patch summary features", "shape": "dot", "size": 10.089285714285714, "title": "patch summary features"}, {"color": "#6FA8DC", "id": "layer of patch summary features", "label": "layer of patch summary features", "shape": "dot", "size": 10.089285714285714, "title": "layer of patch summary features"}, {"color": "#6FA8DC", "id": "high-level summary", "label": "high-level summary", "shape": "dot", "size": 10.089285714285714, "title": "high-level summary"}, {"color": "#6FA8DC", "id": "over-fitting", "label": "over-fitting", "shape": "dot", "size": 10.089285714285714, "title": "over-fitting"}, {"color": "#6FA8DC", "id": "small target data set", "label": "small target data set", "shape": "dot", "size": 10.089285714285714, "title": "small target data set"}, {"color": "#6FA8DC", "id": "CUHK03", "label": "CUHK03", "shape": "dot", "size": 10.089285714285714, "title": "CUHK03"}, {"color": "#6FA8DC", "id": "large data set", "label": "large data set", "shape": "dot", "size": 10.178571428571429, "title": "large data set"}, {"color": "#6FA8DC", "id": "CUHK01", "label": "CUHK01", "shape": "dot", "size": 10.089285714285714, "title": "CUHK01"}, {"color": "#6FA8DC", "id": "medium-sized data set", "label": "medium-sized data set", "shape": "dot", "size": 10.089285714285714, "title": "medium-sized data set"}, {"color": "#6FA8DC", "id": "VIPeR", "label": "VIPeR", "shape": "dot", "size": 10.089285714285714, "title": "VIPeR"}, {"color": "#6FA8DC", "id": "small data set", "label": "small data set", "shape": "dot", "size": 10.089285714285714, "title": "small data set"}, {"color": "#6FA8DC", "id": "initial training", "label": "initial training", "shape": "dot", "size": 10.089285714285714, "title": "initial training"}, {"color": "#6FA8DC", "id": "fine-tuning", "label": "fine-tuning", "shape": "dot", "size": 10.089285714285714, "title": "fine-tuning"}, {"color": "#6FA8DC", "id": "Deep Convolutional Architecture", "label": "Deep Convolutional Architecture", "shape": "dot", "size": 10.089285714285714, "title": "Deep Convolutional Architecture"}, {"color": "#6FA8DC", "id": "Similarity Metric Learning", "label": "Similarity Metric Learning", "shape": "dot", "size": 10.089285714285714, "title": "Similarity Metric Learning"}, {"color": "#6FA8DC", "id": "Neighborhood Difference Layer", "label": "Neighborhood Difference Layer", "shape": "dot", "size": 10.089285714285714, "title": "Neighborhood Difference Layer"}, {"color": "#6FA8DC", "id": "Metric Learning", "label": "Metric Learning", "shape": "dot", "size": 10.267857142857142, "title": "Metric Learning"}, {"color": "#6FA8DC", "id": "[Li, W., \u0026 Wang, X. (2013)]", "label": "[Li, W., \u0026 Wang, X. (2013)]", "shape": "dot", "size": 10.089285714285714, "title": "[Li, W., \u0026 Wang, X. (2013)]"}, {"color": "#6FA8DC", "id": "person re-identi\ufb01cation", "label": "person re-identi\ufb01cation", "shape": "dot", "size": 10.089285714285714, "title": "person re-identi\ufb01cation"}, {"color": "#6FA8DC", "id": "Li, Z.", "label": "Li, Z.", "shape": "dot", "size": 10.178571428571429, "title": "Li, Z."}, {"color": "#6FA8DC", "id": "Learning locally-adaptive decision functions", "label": "Learning locally-adaptive decision functions", "shape": "dot", "size": 10.089285714285714, "title": "Learning locally-adaptive decision functions"}, {"color": "#6FA8DC", "id": "Bazzani, L.", "label": "Bazzani, L.", "shape": "dot", "size": 10.089285714285714, "title": "Bazzani, L."}, {"color": "#6FA8DC", "id": "Multiple-shot person re-identi\ufb01cation", "label": "Multiple-shot person re-identi\ufb01cation", "shape": "dot", "size": 10.178571428571429, "title": "Multiple-shot person re-identi\ufb01cation"}, {"color": "#6FA8DC", "id": "Bottou, L.", "label": "Bottou, L.", "shape": "dot", "size": 10.089285714285714, "title": "Bottou, L."}, {"color": "#6FA8DC", "id": "Stochastic gradient tricks", "label": "Stochastic gradient tricks", "shape": "dot", "size": 10.089285714285714, "title": "Stochastic gradient tricks"}, {"color": "#6FA8DC", "id": "Davis, J. V.", "label": "Davis, J. V.", "shape": "dot", "size": 10.089285714285714, "title": "Davis, J. V."}, {"color": "#6FA8DC", "id": "Information-theoretic metric learning", "label": "Information-theoretic metric learning", "shape": "dot", "size": 10.089285714285714, "title": "Information-theoretic metric learning"}, {"color": "#6FA8DC", "id": "Farenzena, M.", "label": "Farenzena, M.", "shape": "dot", "size": 10.089285714285714, "title": "Farenzena, M."}, {"color": "#6FA8DC", "id": "Person re-identi\ufb01cation by symmetry-driven accumulation", "label": "Person re-identi\ufb01cation by symmetry-driven accumulation", "shape": "dot", "size": 10.089285714285714, "title": "Person re-identi\ufb01cation by symmetry-driven accumulation"}, {"color": "#6FA8DC", "id": "chromatic analyses", "label": "chromatic analyses", "shape": "dot", "size": 10.089285714285714, "title": "chromatic analyses"}, {"color": "#6FA8DC", "id": "Person re-identi\ufb01cation", "label": "Person re-identi\ufb01cation", "shape": "dot", "size": 10.089285714285714, "title": "Person re-identi\ufb01cation"}, {"color": "#6FA8DC", "id": "local features", "label": "local features", "shape": "dot", "size": 10.267857142857142, "title": "local features"}, {"color": "#6FA8DC", "id": "McAllester, D.", "label": "McAllester, D.", "shape": "dot", "size": 10.089285714285714, "title": "McAllester, D."}, {"color": "#6FA8DC", "id": "IEEE Trans. Pattern Anal. Mach. Intell", "label": "IEEE Trans. Pattern Anal. Mach. Intell", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Trans. Pattern Anal. Mach. Intell"}, {"color": "#6FA8DC", "id": "Mitsubishi Electric Research Labs", "label": "Mitsubishi Electric Research Labs", "shape": "dot", "size": 10.178571428571429, "title": "Mitsubishi Electric Research Labs"}, {"color": "#6FA8DC", "id": "Vassileios Balntas", "label": "Vassileios Balntas", "shape": "dot", "size": 10.178571428571429, "title": "Vassileios Balntas"}, {"color": "#6FA8DC", "id": "BOLD", "label": "BOLD", "shape": "dot", "size": 10.357142857142858, "title": "BOLD"}, {"color": "#6FA8DC", "id": "Lilian Tang", "label": "Lilian Tang", "shape": "dot", "size": 10.178571428571429, "title": "Lilian Tang"}, {"color": "#6FA8DC", "id": "Krystian Mikolajczyk", "label": "Krystian Mikolajczyk", "shape": "dot", "size": 10.178571428571429, "title": "Krystian Mikolajczyk"}, {"color": "#6FA8DC", "id": "Binary Online Learned Descriptor", "label": "Binary Online Learned Descriptor", "shape": "dot", "size": 10.089285714285714, "title": "Binary Online Learned Descriptor"}, {"color": "#6FA8DC", "id": "BOLD (Binary Online Learned Descriptor)", "label": "BOLD (Binary Online Learned Descriptor)", "shape": "dot", "size": 10.267857142857142, "title": "BOLD (Binary Online Learned Descriptor)"}, {"color": "#6FA8DC", "id": "image patch", "label": "image patch", "shape": "dot", "size": 10.089285714285714, "title": "image patch"}, {"color": "#6FA8DC", "id": "linear discriminant embedding", "label": "linear discriminant embedding", "shape": "dot", "size": 10.089285714285714, "title": "linear discriminant embedding"}, {"color": "#6FA8DC", "id": "binary tests", "label": "binary tests", "shape": "dot", "size": 10.089285714285714, "title": "binary tests"}, {"color": "#6FA8DC", "id": "binary strings", "label": "binary strings", "shape": "dot", "size": 10.267857142857142, "title": "binary strings"}, {"color": "#6FA8DC", "id": "test results", "label": "test results", "shape": "dot", "size": 10.089285714285714, "title": "test results"}, {"color": "#6FA8DC", "id": "subset of robust tests", "label": "subset of robust tests", "shape": "dot", "size": 10.089285714285714, "title": "subset of robust tests"}, {"color": "#6FA8DC", "id": "masked Hamming distance calculation", "label": "masked Hamming distance calculation", "shape": "dot", "size": 10.089285714285714, "title": "masked Hamming distance calculation"}, {"color": "#6FA8DC", "id": "per-patch optimization", "label": "per-patch optimization", "shape": "dot", "size": 10.089285714285714, "title": "per-patch optimization"}, {"color": "#6FA8DC", "id": "global optimization", "label": "global optimization", "shape": "dot", "size": 10.089285714285714, "title": "global optimization"}, {"color": "#6FA8DC", "id": "Masked Hamming distance", "label": "Masked Hamming distance", "shape": "dot", "size": 10.089285714285714, "title": "Masked Hamming distance"}, {"color": "#6FA8DC", "id": "tests", "label": "tests", "shape": "dot", "size": 10.089285714285714, "title": "tests"}, {"color": "#6FA8DC", "id": "Per-patch optimization", "label": "Per-patch optimization", "shape": "dot", "size": 10.089285714285714, "title": "Per-patch optimization"}, {"color": "#6FA8DC", "id": "D. G. Lowe", "label": "D. G. Lowe", "shape": "dot", "size": 10.089285714285714, "title": "D. G. Lowe"}, {"color": "#6FA8DC", "id": "IJCV, 60:91\u2013110, 2004", "label": "IJCV, 60:91\u2013110, 2004", "shape": "dot", "size": 10.089285714285714, "title": "IJCV, 60:91\u2013110, 2004"}, {"color": "#6FA8DC", "id": "Local descriptors", "label": "Local descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Local descriptors"}, {"color": "#6FA8DC", "id": "IEEE TPAMI, 27(10):1615\u20131630, 2005", "label": "IEEE TPAMI, 27(10):1615\u20131630, 2005", "shape": "dot", "size": 10.089285714285714, "title": "IEEE TPAMI, 27(10):1615\u20131630, 2005"}, {"color": "#6FA8DC", "id": "SURF descriptor", "label": "SURF descriptor", "shape": "dot", "size": 10.267857142857142, "title": "SURF descriptor"}, {"color": "#6FA8DC", "id": "ECCV, 2006", "label": "ECCV, 2006", "shape": "dot", "size": 10.089285714285714, "title": "ECCV, 2006"}, {"color": "#6FA8DC", "id": "Local image descriptors", "label": "Local image descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Local image descriptors"}, {"color": "#6FA8DC", "id": "Discriminative learning", "label": "Discriminative learning", "shape": "dot", "size": 10.178571428571429, "title": "Discriminative learning"}, {"color": "#6FA8DC", "id": "IEEE TPAMI, 33(1):43\u201357, 2010", "label": "IEEE TPAMI, 33(1):43\u201357, 2010", "shape": "dot", "size": 10.089285714285714, "title": "IEEE TPAMI, 33(1):43\u201357, 2010"}, {"color": "#6FA8DC", "id": "Binary descriptors", "label": "Binary descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Binary descriptors"}, {"color": "#6FA8DC", "id": "Image matching", "label": "Image matching", "shape": "dot", "size": 10.178571428571429, "title": "Image matching"}, {"color": "#6FA8DC", "id": "Online descriptor optimization", "label": "Online descriptor optimization", "shape": "dot", "size": 10.089285714285714, "title": "Online descriptor optimization"}, {"color": "#6FA8DC", "id": "G. H. M. Brown and S. Winder", "label": "G. H. M. Brown and S. Winder", "shape": "dot", "size": 10.178571428571429, "title": "G. H. M. Brown and S. Winder"}, {"color": "#6FA8DC", "id": "discriminative learning", "label": "discriminative learning", "shape": "dot", "size": 10.178571428571429, "title": "discriminative learning"}, {"color": "#6FA8DC", "id": "interest point detection", "label": "interest point detection", "shape": "dot", "size": 10.089285714285714, "title": "interest point detection"}, {"color": "#6FA8DC", "id": "K. Mikolajczyk and C. Schmid", "label": "K. Mikolajczyk and C. Schmid", "shape": "dot", "size": 10.089285714285714, "title": "K. Mikolajczyk and C. Schmid"}, {"color": "#6FA8DC", "id": "tracking applications", "label": "tracking applications", "shape": "dot", "size": 10.089285714285714, "title": "tracking applications"}, {"color": "#6FA8DC", "id": "Struck", "label": "Struck", "shape": "dot", "size": 10.089285714285714, "title": "Struck"}, {"color": "#6FA8DC", "id": "Tracking-learning-detection", "label": "Tracking-learning-detection", "shape": "dot", "size": 10.178571428571429, "title": "Tracking-learning-detection"}, {"color": "#6FA8DC", "id": "integration", "label": "integration", "shape": "dot", "size": 10.089285714285714, "title": "integration"}, {"color": "#6FA8DC", "id": "keypoint recognition", "label": "keypoint recognition", "shape": "dot", "size": 10.178571428571429, "title": "keypoint recognition"}, {"color": "#6FA8DC", "id": "random ferns", "label": "random ferns", "shape": "dot", "size": 10.267857142857142, "title": "random ferns"}, {"color": "#6FA8DC", "id": "M. Ozuysal", "label": "M. Ozuysal", "shape": "dot", "size": 10.178571428571429, "title": "M. Ozuysal"}, {"color": "#6FA8DC", "id": "tracking", "label": "tracking", "shape": "dot", "size": 10.625, "title": "tracking"}, {"color": "#6FA8DC", "id": "Fast keypoint recognition method", "label": "Fast keypoint recognition method", "shape": "dot", "size": 10.178571428571429, "title": "Fast keypoint recognition method"}, {"color": "#6FA8DC", "id": "IEEE TPAMI", "label": "IEEE TPAMI", "shape": "dot", "size": 10.178571428571429, "title": "IEEE TPAMI"}, {"color": "#6FA8DC", "id": "ORB", "label": "ORB", "shape": "dot", "size": 10.178571428571429, "title": "ORB"}, {"color": "#6FA8DC", "id": "SIFT", "label": "SIFT", "shape": "dot", "size": 10.089285714285714, "title": "SIFT"}, {"color": "#6FA8DC", "id": "SURF", "label": "SURF", "shape": "dot", "size": 10.267857142857142, "title": "SURF"}, {"color": "#6FA8DC", "id": "V. L. T. Trzcinski", "label": "V. L. T. Trzcinski", "shape": "dot", "size": 10.089285714285714, "title": "V. L. T. Trzcinski"}, {"color": "#6FA8DC", "id": "Boosting Binary Keypoint Descriptors", "label": "Boosting Binary Keypoint Descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Boosting Binary Keypoint Descriptors"}, {"color": "#6FA8DC", "id": "University of Surrey, UK", "label": "University of Surrey, UK", "shape": "dot", "size": 10.267857142857142, "title": "University of Surrey, UK"}, {"color": "#6FA8DC", "id": "Jiajun Wu", "label": "Jiajun Wu", "shape": "dot", "size": 10.178571428571429, "title": "Jiajun Wu"}, {"color": "#6FA8DC", "id": "Deep Multiple Instance Learning for Image Classi\ufb01cation and Auto-Annotation", "label": "Deep Multiple Instance Learning for Image Classi\ufb01cation and Auto-Annotation", "shape": "dot", "size": 10.178571428571429, "title": "Deep Multiple Instance Learning for Image Classi\ufb01cation and Auto-Annotation"}, {"color": "#6FA8DC", "id": "Deep Multiple Instance Learning", "label": "Deep Multiple Instance Learning", "shape": "dot", "size": 10.625, "title": "Deep Multiple Instance Learning"}, {"color": "#6FA8DC", "id": "Yinan Yu", "label": "Yinan Yu", "shape": "dot", "size": 10.178571428571429, "title": "Yinan Yu"}, {"color": "#6FA8DC", "id": "Kai Yu", "label": "Kai Yu", "shape": "dot", "size": 10.089285714285714, "title": "Kai Yu"}, {"color": "#6FA8DC", "id": "Deep Multiple instance Learning", "label": "Deep Multiple instance Learning", "shape": "dot", "size": 10.089285714285714, "title": "Deep Multiple instance Learning"}, {"color": "#6FA8DC", "id": "Learning Algorithm", "label": "Learning Algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Learning Algorithm"}, {"color": "#6FA8DC", "id": "Wu_Deep_Multiple_Instance_2015_CVPR_paper.pdf", "label": "Wu_Deep_Multiple_Instance_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Wu_Deep_Multiple_Instance_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Deep learning", "label": "Deep learning", "shape": "dot", "size": 10.089285714285714, "title": "Deep learning"}, {"color": "#6FA8DC", "id": "tremendous improvements", "label": "tremendous improvements", "shape": "dot", "size": 10.089285714285714, "title": "tremendous improvements"}, {"color": "#6FA8DC", "id": "early stage", "label": "early stage", "shape": "dot", "size": 10.089285714285714, "title": "early stage"}, {"color": "#6FA8DC", "id": "multiple instance learning framework", "label": "multiple instance learning framework", "shape": "dot", "size": 10.089285714285714, "title": "multiple instance learning framework"}, {"color": "#6FA8DC", "id": "object proposals", "label": "object proposals", "shape": "dot", "size": 10.089285714285714, "title": "object proposals"}, {"color": "#6FA8DC", "id": "instance sets", "label": "instance sets", "shape": "dot", "size": 10.178571428571429, "title": "instance sets"}, {"color": "#6FA8DC", "id": "text annotations", "label": "text annotations", "shape": "dot", "size": 10.089285714285714, "title": "text annotations"}, {"color": "#6FA8DC", "id": "systems", "label": "systems", "shape": "dot", "size": 10.178571428571429, "title": "systems"}, {"color": "#6FA8DC", "id": "MIL property", "label": "MIL property", "shape": "dot", "size": 10.089285714285714, "title": "MIL property"}, {"color": "#6FA8DC", "id": "deep learning strategies", "label": "deep learning strategies", "shape": "dot", "size": 10.089285714285714, "title": "deep learning strategies"}, {"color": "#6FA8DC", "id": "relationship", "label": "relationship", "shape": "dot", "size": 10.089285714285714, "title": "relationship"}, {"color": "#6FA8DC", "id": "region-keyword pairs", "label": "region-keyword pairs", "shape": "dot", "size": 10.267857142857142, "title": "region-keyword pairs"}, {"color": "#6FA8DC", "id": "convincing", "label": "convincing", "shape": "dot", "size": 10.089285714285714, "title": "convincing"}, {"color": "#6FA8DC", "id": "classification", "label": "classification", "shape": "dot", "size": 10.178571428571429, "title": "classification"}, {"color": "#6FA8DC", "id": "extraction", "label": "extraction", "shape": "dot", "size": 10.089285714285714, "title": "extraction"}, {"color": "#6FA8DC", "id": "little supervision", "label": "little supervision", "shape": "dot", "size": 10.178571428571429, "title": "little supervision"}, {"color": "#6FA8DC", "id": "reasonable", "label": "reasonable", "shape": "dot", "size": 10.089285714285714, "title": "reasonable"}, {"color": "#6FA8DC", "id": "annotation proposals", "label": "annotation proposals", "shape": "dot", "size": 10.089285714285714, "title": "annotation proposals"}, {"color": "#6FA8DC", "id": "convincing performance", "label": "convincing performance", "shape": "dot", "size": 10.089285714285714, "title": "convincing performance"}, {"color": "#6FA8DC", "id": "Region-keyword pairs", "label": "Region-keyword pairs", "shape": "dot", "size": 10.089285714285714, "title": "Region-keyword pairs"}, {"color": "#6FA8DC", "id": "Convolutional deep belief networks", "label": "Convolutional deep belief networks", "shape": "dot", "size": 10.089285714285714, "title": "Convolutional deep belief networks"}, {"color": "#6FA8DC", "id": "Multiple Instance Learning (MIL)", "label": "Multiple Instance Learning (MIL)", "shape": "dot", "size": 10.089285714285714, "title": "Multiple Instance Learning (MIL)"}, {"color": "#6FA8DC", "id": "Andrews et al.", "label": "Andrews et al.", "shape": "dot", "size": 10.089285714285714, "title": "Andrews et al."}, {"color": "#6FA8DC", "id": "Support vector machines", "label": "Support vector machines", "shape": "dot", "size": 10.089285714285714, "title": "Support vector machines"}, {"color": "#6FA8DC", "id": "Li \u0026 Wang", "label": "Li \u0026 Wang", "shape": "dot", "size": 10.089285714285714, "title": "Li \u0026 Wang"}, {"color": "#6FA8DC", "id": "computerized annotation", "label": "computerized annotation", "shape": "dot", "size": 10.178571428571429, "title": "computerized annotation"}, {"color": "#6FA8DC", "id": "Barnard et al.", "label": "Barnard et al.", "shape": "dot", "size": 10.089285714285714, "title": "Barnard et al."}, {"color": "#6FA8DC", "id": "Matching words and pictures", "label": "Matching words and pictures", "shape": "dot", "size": 10.267857142857142, "title": "Matching words and pictures"}, {"color": "#6FA8DC", "id": "Image Annotation", "label": "Image Annotation", "shape": "dot", "size": 10.089285714285714, "title": "Image Annotation"}, {"color": "#6FA8DC", "id": "annotation of pictures", "label": "annotation of pictures", "shape": "dot", "size": 10.089285714285714, "title": "annotation of pictures"}, {"color": "#6FA8DC", "id": "Barnard", "label": "Barnard", "shape": "dot", "size": 10.089285714285714, "title": "Barnard"}, {"color": "#6FA8DC", "id": "Li, L.-J.", "label": "Li, L.-J.", "shape": "dot", "size": 10.178571428571429, "title": "Li, L.-J."}, {"color": "#6FA8DC", "id": "Chen", "label": "Chen", "shape": "dot", "size": 10.178571428571429, "title": "Chen"}, {"color": "#6FA8DC", "id": "Hierarchical matching", "label": "Hierarchical matching", "shape": "dot", "size": 10.178571428571429, "title": "Hierarchical matching"}, {"color": "#6FA8DC", "id": "Li, Q.", "label": "Li, Q.", "shape": "dot", "size": 10.089285714285714, "title": "Li, Q."}, {"color": "#6FA8DC", "id": "Harvesting mid-level visual concepts", "label": "Harvesting mid-level visual concepts", "shape": "dot", "size": 10.178571428571429, "title": "Harvesting mid-level visual concepts"}, {"color": "#6FA8DC", "id": "Bing: Binarized normed gradients", "label": "Bing: Binarized normed gradients", "shape": "dot", "size": 10.178571428571429, "title": "Bing: Binarized normed gradients"}, {"color": "#6FA8DC", "id": "Imaginet", "label": "Imaginet", "shape": "dot", "size": 10.446428571428571, "title": "Imaginet"}, {"color": "#6FA8DC", "id": "hierarchical image", "label": "hierarchical image", "shape": "dot", "size": 10.178571428571429, "title": "hierarchical image"}, {"color": "#6FA8DC", "id": "Rochan", "label": "Rochan", "shape": "dot", "size": 10.089285714285714, "title": "Rochan"}, {"color": "#6FA8DC", "id": "Weakly Supervised Localization", "label": "Weakly Supervised Localization", "shape": "dot", "size": 10.267857142857142, "title": "Weakly Supervised Localization"}, {"color": "#6FA8DC", "id": "Mrigank Rochan", "label": "Mrigank Rochan", "shape": "dot", "size": 10.267857142857142, "title": "Mrigank Rochan"}, {"color": "#6FA8DC", "id": "Institute of Deep Learning", "label": "Institute of Deep Learning", "shape": "dot", "size": 10.178571428571429, "title": "Institute of Deep Learning"}, {"color": "#6FA8DC", "id": "Chang Huang", "label": "Chang Huang", "shape": "dot", "size": 10.089285714285714, "title": "Chang Huang"}, {"color": "#6FA8DC", "id": "training images", "label": "training images", "shape": "dot", "size": 10.178571428571429, "title": "training images"}, {"color": "#6FA8DC", "id": "object bounding boxes", "label": "object bounding boxes", "shape": "dot", "size": 10.089285714285714, "title": "object bounding boxes"}, {"color": "#6FA8DC", "id": "weakly labeled data", "label": "weakly labeled data", "shape": "dot", "size": 10.089285714285714, "title": "weakly labeled data"}, {"color": "#6FA8DC", "id": "YouTube videos", "label": "YouTube videos", "shape": "dot", "size": 10.089285714285714, "title": "YouTube videos"}, {"color": "#6FA8DC", "id": "user-generated tags", "label": "user-generated tags", "shape": "dot", "size": 10.089285714285714, "title": "user-generated tags"}, {"color": "#6FA8DC", "id": "image search", "label": "image search", "shape": "dot", "size": 10.089285714285714, "title": "image search"}, {"color": "#6FA8DC", "id": "weakly labeled images", "label": "weakly labeled images", "shape": "dot", "size": 10.089285714285714, "title": "weakly labeled images"}, {"color": "#6FA8DC", "id": "localize object", "label": "localize object", "shape": "dot", "size": 10.089285714285714, "title": "localize object"}, {"color": "#6FA8DC", "id": "collection of images", "label": "collection of images", "shape": "dot", "size": 10.178571428571429, "title": "collection of images"}, {"color": "#6FA8DC", "id": "object category", "label": "object category", "shape": "dot", "size": 10.089285714285714, "title": "object category"}, {"color": "#6FA8DC", "id": "bounding box", "label": "bounding box", "shape": "dot", "size": 10.267857142857142, "title": "bounding box"}, {"color": "#6FA8DC", "id": "videos", "label": "videos", "shape": "dot", "size": 10.089285714285714, "title": "videos"}, {"color": "#6FA8DC", "id": "novel object", "label": "novel object", "shape": "dot", "size": 10.089285714285714, "title": "novel object"}, {"color": "#6FA8DC", "id": "object appearance model", "label": "object appearance model", "shape": "dot", "size": 10.089285714285714, "title": "object appearance model"}, {"color": "#6FA8DC", "id": "familiar objects", "label": "familiar objects", "shape": "dot", "size": 10.178571428571429, "title": "familiar objects"}, {"color": "#6FA8DC", "id": "image datasets", "label": "image datasets", "shape": "dot", "size": 10.267857142857142, "title": "image datasets"}, {"color": "#6FA8DC", "id": "video datasets", "label": "video datasets", "shape": "dot", "size": 10.178571428571429, "title": "video datasets"}, {"color": "#6FA8DC", "id": "unseen objects", "label": "unseen objects", "shape": "dot", "size": 10.089285714285714, "title": "unseen objects"}, {"color": "#6FA8DC", "id": "Lampert et al. (2009)", "label": "Lampert et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Lampert et al. (2009)"}, {"color": "#6FA8DC", "id": "unseen object classes", "label": "unseen object classes", "shape": "dot", "size": 10.089285714285714, "title": "unseen object classes"}, {"color": "#6FA8DC", "id": "Object-graphs for context-aware category discovery", "label": "Object-graphs for context-aware category discovery", "shape": "dot", "size": 10.178571428571429, "title": "Object-graphs for context-aware category discovery"}, {"color": "#6FA8DC", "id": "K. Grauman", "label": "K. Grauman", "shape": "dot", "size": 10.089285714285714, "title": "K. Grauman"}, {"color": "#6FA8DC", "id": "R. G. Cinbis", "label": "R. G. Cinbis", "shape": "dot", "size": 10.089285714285714, "title": "R. G. Cinbis"}, {"color": "#6FA8DC", "id": "Multi-fold mil training", "label": "Multi-fold mil training", "shape": "dot", "size": 10.267857142857142, "title": "Multi-fold mil training"}, {"color": "#6FA8DC", "id": "J. Verbeek", "label": "J. Verbeek", "shape": "dot", "size": 10.089285714285714, "title": "J. Verbeek"}, {"color": "#6FA8DC", "id": "T. Mikolov", "label": "T. Mikolov", "shape": "dot", "size": 10.089285714285714, "title": "T. Mikolov"}, {"color": "#6FA8DC", "id": "Distributed representations of words and phrases", "label": "Distributed representations of words and phrases", "shape": "dot", "size": 10.178571428571429, "title": "Distributed representations of words and phrases"}, {"color": "#6FA8DC", "id": "I. Sutskever", "label": "I. Sutskever", "shape": "dot", "size": 10.089285714285714, "title": "I. Sutskever"}, {"color": "#6FA8DC", "id": "M. H. Nguyen", "label": "M. H. Nguyen", "shape": "dot", "size": 10.089285714285714, "title": "M. H. Nguyen"}, {"color": "#6FA8DC", "id": "Weakly supervised discrimiative localization", "label": "Weakly supervised discrimiative localization", "shape": "dot", "size": 10.089285714285714, "title": "Weakly supervised discrimiative localization"}, {"color": "#6FA8DC", "id": "A. Papazoglou", "label": "A. Papazoglou", "shape": "dot", "size": 10.089285714285714, "title": "A. Papazoglou"}, {"color": "#6FA8DC", "id": "Fast object segmentation", "label": "Fast object segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Fast object segmentation"}, {"color": "#6FA8DC", "id": "V. Ferrari", "label": "V. Ferrari", "shape": "dot", "size": 10.089285714285714, "title": "V. Ferrari"}, {"color": "#6FA8DC", "id": "Object-graphs", "label": "Object-graphs", "shape": "dot", "size": 10.089285714285714, "title": "Object-graphs"}, {"color": "#6FA8DC", "id": "context-aware category discovery", "label": "context-aware category discovery", "shape": "dot", "size": 10.089285714285714, "title": "context-aware category discovery"}, {"color": "#6FA8DC", "id": "Distributed representations", "label": "Distributed representations", "shape": "dot", "size": 10.089285714285714, "title": "Distributed representations"}, {"color": "#6FA8DC", "id": "compositionality", "label": "compositionality", "shape": "dot", "size": 10.089285714285714, "title": "compositionality"}, {"color": "#6FA8DC", "id": "IEEE International Conference on Computer Vision", "label": "IEEE International Conference on Computer Vision", "shape": "dot", "size": 10.357142857142858, "title": "IEEE International Conference on Computer Vision"}, {"color": "#6FA8DC", "id": "A. Prest", "label": "A. Prest", "shape": "dot", "size": 10.089285714285714, "title": "A. Prest"}, {"color": "#6FA8DC", "id": "Learning object class detectors", "label": "Learning object class detectors", "shape": "dot", "size": 10.089285714285714, "title": "Learning object class detectors"}, {"color": "#6FA8DC", "id": "M. Rohrbach", "label": "M. Rohrbach", "shape": "dot", "size": 10.178571428571429, "title": "M. Rohrbach"}, {"color": "#6FA8DC", "id": "Evaluating knowledge transfer", "label": "Evaluating knowledge transfer", "shape": "dot", "size": 10.178571428571429, "title": "Evaluating knowledge transfer"}, {"color": "#6FA8DC", "id": "IEEE Conference on Computer Vision and Pattern Recognition", "label": "IEEE Conference on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.357142857142858, "title": "IEEE Conference on Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "What helps where", "label": "What helps where", "shape": "dot", "size": 10.178571428571429, "title": "What helps where"}, {"color": "#6FA8DC", "id": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition", "label": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "University of Manitoba", "label": "University of Manitoba", "shape": "dot", "size": 10.357142857142858, "title": "University of Manitoba"}, {"color": "#6FA8DC", "id": "Yang Wang", "label": "Yang Wang", "shape": "dot", "size": 10.267857142857142, "title": "Yang Wang"}, {"color": "#6FA8DC", "id": "Mriganka Rochan", "label": "Mriganka Rochan", "shape": "dot", "size": 10.089285714285714, "title": "Mriganka Rochan"}, {"color": "#6FA8DC", "id": "mrochan@cs.umanitoba.ca", "label": "mrochan@cs.umanitoba.ca", "shape": "dot", "size": 10.089285714285714, "title": "mrochan@cs.umanitoba.ca"}, {"color": "#6FA8DC", "id": "Canada", "label": "Canada", "shape": "dot", "size": 10.089285714285714, "title": "Canada"}, {"color": "#6FA8DC", "id": "rigank Rochan", "label": "rigank Rochan", "shape": "dot", "size": 10.089285714285714, "title": "rigank Rochan"}, {"color": "#6FA8DC", "id": "Wei Liu", "label": "Wei Liu", "shape": "dot", "size": 10.446428571428571, "title": "Wei Liu"}, {"color": "#6FA8DC", "id": "Towards 3D Object Detection", "label": "Towards 3D Object Detection", "shape": "dot", "size": 10.357142857142858, "title": "Towards 3D Object Detection"}, {"color": "#6FA8DC", "id": "Rongrong Ji", "label": "Rongrong Ji", "shape": "dot", "size": 10.267857142857142, "title": "Rongrong Ji"}, {"color": "#6FA8DC", "id": "Shaozi Li", "label": "Shaozi Li", "shape": "dot", "size": 10.267857142857142, "title": "Shaozi Li"}, {"color": "#6FA8DC", "id": "ywang@cs.umanitoba.ca", "label": "ywang@cs.umanitoba.ca", "shape": "dot", "size": 10.089285714285714, "title": "ywang@cs.umanitoba.ca"}, {"color": "#6FA8DC", "id": "Towards 3D ObjectDetection", "label": "Towards 3D ObjectDetection", "shape": "dot", "size": 10.089285714285714, "title": "Towards 3D ObjectDetection"}, {"color": "#6FA8DC", "id": "3D scenes", "label": "3D scenes", "shape": "dot", "size": 10.089285714285714, "title": "3D scenes"}, {"color": "#6FA8DC", "id": "accurate detection algorithm", "label": "accurate detection algorithm", "shape": "dot", "size": 10.089285714285714, "title": "accurate detection algorithm"}, {"color": "#6FA8DC", "id": "RGB and depth modalities", "label": "RGB and depth modalities", "shape": "dot", "size": 10.178571428571429, "title": "RGB and depth modalities"}, {"color": "#6FA8DC", "id": "correlated", "label": "correlated", "shape": "dot", "size": 10.089285714285714, "title": "correlated"}, {"color": "#6FA8DC", "id": "cross-modality deep learning framework", "label": "cross-modality deep learning framework", "shape": "dot", "size": 10.178571428571429, "title": "cross-modality deep learning framework"}, {"color": "#6FA8DC", "id": "deep Boltzmann Machines", "label": "deep Boltzmann Machines", "shape": "dot", "size": 10.089285714285714, "title": "deep Boltzmann Machines"}, {"color": "#6FA8DC", "id": "lack of 3D training data", "label": "lack of 3D training data", "shape": "dot", "size": 10.267857142857142, "title": "lack of 3D training data"}, {"color": "#6FA8DC", "id": "labeled 2D samples", "label": "labeled 2D samples", "shape": "dot", "size": 10.267857142857142, "title": "labeled 2D samples"}, {"color": "#6FA8DC", "id": "existing datasets", "label": "existing datasets", "shape": "dot", "size": 10.089285714285714, "title": "existing datasets"}, {"color": "#6FA8DC", "id": "3D CAD models", "label": "3D CAD models", "shape": "dot", "size": 10.357142857142858, "title": "3D CAD models"}, {"color": "#6FA8DC", "id": "RMRC dataset", "label": "RMRC dataset", "shape": "dot", "size": 10.357142857142858, "title": "RMRC dataset"}, {"color": "#6FA8DC", "id": "cross-modality features", "label": "cross-modality features", "shape": "dot", "size": 10.089285714285714, "title": "cross-modality features"}, {"color": "#6FA8DC", "id": "RGBD data", "label": "RGBD data", "shape": "dot", "size": 10.089285714285714, "title": "RGBD data"}, {"color": "#6FA8DC", "id": "models", "label": "models", "shape": "dot", "size": 10.535714285714286, "title": "models"}, {"color": "#6FA8DC", "id": "k", "label": "k", "shape": "dot", "size": 10.267857142857142, "title": "k"}, {"color": "#6FA8DC", "id": "effectiveness of approach", "label": "effectiveness of approach", "shape": "dot", "size": 10.089285714285714, "title": "effectiveness of approach"}, {"color": "#6FA8DC", "id": "Semantic labeling", "label": "Semantic labeling", "shape": "dot", "size": 10.178571428571429, "title": "Semantic labeling"}, {"color": "#6FA8DC", "id": "3d point clouds", "label": "3d point clouds", "shape": "dot", "size": 10.089285714285714, "title": "3d point clouds"}, {"color": "#6FA8DC", "id": "Learning rich features", "label": "Learning rich features", "shape": "dot", "size": 10.178571428571429, "title": "Learning rich features"}, {"color": "#6FA8DC", "id": "RGBD images", "label": "RGBD images", "shape": "dot", "size": 10.089285714285714, "title": "RGBD images"}, {"color": "#6FA8DC", "id": "ILSVRC2012", "label": "ILSVRC2012", "shape": "dot", "size": 10.267857142857142, "title": "ILSVRC2012"}, {"color": "#6FA8DC", "id": "Efficient 3d scene labeling", "label": "Efficient 3d scene labeling", "shape": "dot", "size": 10.267857142857142, "title": "Efficient 3d scene labeling"}, {"color": "#6FA8DC", "id": "field-s of trees", "label": "field-s of trees", "shape": "dot", "size": 10.089285714285714, "title": "field-s of trees"}, {"color": "#6FA8DC", "id": "geNet", "label": "geNet", "shape": "dot", "size": 10.089285714285714, "title": "geNet"}, {"color": "#6FA8DC", "id": "2012", "label": "2012", "shape": "dot", "size": 10.089285714285714, "title": "2012"}, {"color": "#6FA8DC", "id": "O. Kahler", "label": "O. Kahler", "shape": "dot", "size": 10.089285714285714, "title": "O. Kahler"}, {"color": "#6FA8DC", "id": "N. Srivastava", "label": "N. Srivastava", "shape": "dot", "size": 10.089285714285714, "title": "N. Srivastava"}, {"color": "#6FA8DC", "id": "Multimodal learning", "label": "Multimodal learning", "shape": "dot", "size": 10.089285714285714, "title": "Multimodal learning"}, {"color": "#6FA8DC", "id": "K. Lai", "label": "K. Lai", "shape": "dot", "size": 10.089285714285714, "title": "K. Lai"}, {"color": "#6FA8DC", "id": "Detection-based object labeling", "label": "Detection-based object labeling", "shape": "dot", "size": 10.178571428571429, "title": "Detection-based object labeling"}, {"color": "#6FA8DC", "id": "IEEE International Conference on Robotics and Automation", "label": "IEEE International Conference on Robotics and Automation", "shape": "dot", "size": 10.089285714285714, "title": "IEEE International Conference on Robotics and Automation"}, {"color": "#6FA8DC", "id": "L. Bo", "label": "L. Bo", "shape": "dot", "size": 10.089285714285714, "title": "L. Bo"}, {"color": "#6FA8DC", "id": "Unsupervised feature learning", "label": "Unsupervised feature learning", "shape": "dot", "size": 10.178571428571429, "title": "Unsupervised feature learning"}, {"color": "#6FA8DC", "id": "rgb-d based object recognition", "label": "rgb-d based object recognition", "shape": "dot", "size": 10.089285714285714, "title": "rgb-d based object recognition"}, {"color": "#6FA8DC", "id": "X. Xiong", "label": "X. Xiong", "shape": "dot", "size": 10.089285714285714, "title": "X. Xiong"}, {"color": "#6FA8DC", "id": "3-d scene analysis", "label": "3-d scene analysis", "shape": "dot", "size": 10.178571428571429, "title": "3-d scene analysis"}, {"color": "#6FA8DC", "id": "sequenced predictions", "label": "sequenced predictions", "shape": "dot", "size": 10.089285714285714, "title": "sequenced predictions"}, {"color": "#6FA8DC", "id": "A. Wang", "label": "A. Wang", "shape": "dot", "size": 10.089285714285714, "title": "A. Wang"}, {"color": "#6FA8DC", "id": "Multi-modal unsupervised feature learning", "label": "Multi-modal unsupervised feature learning", "shape": "dot", "size": 10.267857142857142, "title": "Multi-modal unsupervised feature learning"}, {"color": "#6FA8DC", "id": "rgb-d scene labeling", "label": "rgb-d scene labeling", "shape": "dot", "size": 10.089285714285714, "title": "rgb-d scene labeling"}, {"color": "#6FA8DC", "id": "Dep. of Cognitive Science", "label": "Dep. of Cognitive Science", "shape": "dot", "size": 10.178571428571429, "title": "Dep. of Cognitive Science"}, {"color": "#6FA8DC", "id": "Xiamen University", "label": "Xiamen University", "shape": "dot", "size": 10.178571428571429, "title": "Xiamen University"}, {"color": "#6FA8DC", "id": "Dep. of Cognitive Space", "label": "Dep. of Cognitive Space", "shape": "dot", "size": 10.089285714285714, "title": "Dep. of Cognitive Space"}, {"color": "#6FA8DC", "id": "Abhishek Sharma", "label": "Abhishek Sharma", "shape": "dot", "size": 10.446428571428571, "title": "Abhishek Sharma"}, {"color": "#6FA8DC", "id": "Deep Hierarchical Parsing", "label": "Deep Hierarchical Parsing", "shape": "dot", "size": 10.357142857142858, "title": "Deep Hierarchical Parsing"}, {"color": "#6FA8DC", "id": "Oncel Tuzel", "label": "Oncel Tuzel", "shape": "dot", "size": 10.267857142857142, "title": "Oncel Tuzel"}, {"color": "#6FA8DC", "id": "David W. Jacobs", "label": "David W. Jacobs", "shape": "dot", "size": 10.357142857142858, "title": "David W. Jacobs"}, {"color": "#6FA8DC", "id": "Sliding shapes", "label": "Sliding shapes", "shape": "dot", "size": 10.089285714285714, "title": "Sliding shapes"}, {"color": "#6FA8DC", "id": "Sharma_Deep_Hierarial_Parsing_2015_CVPR_paper", "label": "Sharma_Deep_Hierarial_Parsing_2015_CVPR_paper", "shape": "dot", "size": 10.357142857142858, "title": "Sharma_Deep_Hierarial_Parsing_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "improvements to RCPN", "label": "improvements to RCPN", "shape": "dot", "size": 10.089285714285714, "title": "improvements to RCPN"}, {"color": "#6FA8DC", "id": "RCPN", "label": "RCPN", "shape": "dot", "size": 10.178571428571429, "title": "RCPN"}, {"color": "#6FA8DC", "id": "deep feed-forward neural network", "label": "deep feed-forward neural network", "shape": "dot", "size": 10.089285714285714, "title": "deep feed-forward neural network"}, {"color": "#6FA8DC", "id": "bypass error paths", "label": "bypass error paths", "shape": "dot", "size": 10.178571428571429, "title": "bypass error paths"}, {"color": "#6FA8DC", "id": "contextual propagation", "label": "contextual propagation", "shape": "dot", "size": 10.089285714285714, "title": "contextual propagation"}, {"color": "#6FA8DC", "id": "modifications", "label": "modifications", "shape": "dot", "size": 10.267857142857142, "title": "modifications"}, {"color": "#6FA8DC", "id": "classification loss", "label": "classification loss", "shape": "dot", "size": 10.178571428571429, "title": "classification loss"}, {"color": "#6FA8DC", "id": "random parse trees", "label": "random parse trees", "shape": "dot", "size": 10.089285714285714, "title": "random parse trees"}, {"color": "#6FA8DC", "id": "tree-style MRF", "label": "tree-style MRF", "shape": "dot", "size": 10.178571428571429, "title": "tree-style MRF"}, {"color": "#6FA8DC", "id": "hierarchical dependencies", "label": "hierarchical dependencies", "shape": "dot", "size": 10.178571428571429, "title": "hierarchical dependencies"}, {"color": "#6FA8DC", "id": "Tree-Style MRF", "label": "Tree-Style MRF", "shape": "dot", "size": 10.089285714285714, "title": "Tree-Style MRF"}, {"color": "#6FA8DC", "id": "Modifications", "label": "Modifications", "shape": "dot", "size": 10.178571428571429, "title": "Modifications"}, {"color": "#6FA8DC", "id": "Semantic Segmentation", "label": "Semantic Segmentation", "shape": "dot", "size": 10.625, "title": "Semantic Segmentation"}, {"color": "#6FA8DC", "id": "Deep Neural Networks", "label": "Deep Neural Networks", "shape": "dot", "size": 10.535714285714286, "title": "Deep Neural Networks"}, {"color": "#6FA8DC", "id": "Recursive Context Propagation Network (RCPN)", "label": "Recursive Context Propagation Network (RCPN)", "shape": "dot", "size": 10.089285714285714, "title": "Recursive Context Propagation Network (RCPN)"}, {"color": "#6FA8DC", "id": "Contextual Propagation", "label": "Contextual Propagation", "shape": "dot", "size": 10.089285714285714, "title": "Contextual Propagation"}, {"color": "#6FA8DC", "id": "Socher et al. (2011)", "label": "Socher et al. (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Socher et al. (2011)"}, {"color": "#6FA8DC", "id": "Recursive Neural Networks", "label": "Recursive Neural Networks", "shape": "dot", "size": 10.089285714285714, "title": "Recursive Neural Networks"}, {"color": "#6FA8DC", "id": "Farabet et al. (2013)", "label": "Farabet et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Farabet et al. (2013)"}, {"color": "#6FA8DC", "id": "scene labeling", "label": "scene labeling", "shape": "dot", "size": 10.089285714285714, "title": "scene labeling"}, {"color": "#6FA8DC", "id": "Fergus and Eigen (2012)", "label": "Fergus and Eigen (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Fergus and Eigen (2012)"}, {"color": "#6FA8DC", "id": "image parsing", "label": "image parsing", "shape": "dot", "size": 10.089285714285714, "title": "image parsing"}, {"color": "#6FA8DC", "id": "Markov Random Fields (MRF)", "label": "Markov Random Fields (MRF)", "shape": "dot", "size": 10.089285714285714, "title": "Markov Random Fields (MRF)"}, {"color": "#6FA8DC", "id": "Najman", "label": "Najman", "shape": "dot", "size": 10.089285714285714, "title": "Najman"}, {"color": "#6FA8DC", "id": "Learning hierarchical features for scene labeling", "label": "Learning hierarchical features for scene labeling", "shape": "dot", "size": 10.178571428571429, "title": "Learning hierarchical features for scene labeling"}, {"color": "#6FA8DC", "id": "R. Fergus", "label": "R. Fergus", "shape": "dot", "size": 10.089285714285714, "title": "R. Fergus"}, {"color": "#6FA8DC", "id": "Nonparametric image parsing", "label": "Nonparametric image parsing", "shape": "dot", "size": 10.178571428571429, "title": "Nonparametric image parsing"}, {"color": "#6FA8DC", "id": "A. Torralba", "label": "A. Torralba", "shape": "dot", "size": 10.089285714285714, "title": "A. Torralba"}, {"color": "#6FA8DC", "id": "Context-based vision system", "label": "Context-based vision system", "shape": "dot", "size": 10.178571428571429, "title": "Context-based vision system"}, {"color": "#6FA8DC", "id": "P. H. O. Pinheiro", "label": "P. H. O. Pinheiro", "shape": "dot", "size": 10.089285714285714, "title": "P. H. O. Pinheiro"}, {"color": "#6FA8DC", "id": "Recurrent convolutional neural networks", "label": "Recurrent convolutional neural networks", "shape": "dot", "size": 10.178571428571429, "title": "Recurrent convolutional neural networks"}, {"color": "#6FA8DC", "id": "A. Sharma", "label": "A. Sharma", "shape": "dot", "size": 10.089285714285714, "title": "A. Sharma"}, {"color": "#6FA8DC", "id": "Recursive context propagation network", "label": "Recursive context propagation network", "shape": "dot", "size": 10.178571428571429, "title": "Recursive context propagation network"}, {"color": "#6FA8DC", "id": "J. Tighe", "label": "J. Tighe", "shape": "dot", "size": 10.178571428571429, "title": "J. Tighe"}, {"color": "#6FA8DC", "id": "Finding things", "label": "Finding things", "shape": "dot", "size": 10.178571428571429, "title": "Finding things"}, {"color": "#6FA8DC", "id": "R. Mottaghi", "label": "R. Mottaghi", "shape": "dot", "size": 10.089285714285714, "title": "R. Mottaghi"}, {"color": "#6FA8DC", "id": "Analyzing semantic segmentation", "label": "Analyzing semantic segmentation", "shape": "dot", "size": 10.178571428571429, "title": "Analyzing semantic segmentation"}, {"color": "#6FA8DC", "id": "Superparsing", "label": "Superparsing", "shape": "dot", "size": 10.178571428571429, "title": "Superparsing"}, {"color": "#6FA8DC", "id": "Computer Science Department", "label": "Computer Science Department", "shape": "dot", "size": 10.267857142857142, "title": "Computer Science Department"}, {"color": "#6FA8DC", "id": "bhokaal@cs.umd.edu", "label": "bhokaal@cs.umd.edu", "shape": "dot", "size": 10.089285714285714, "title": "bhokaal@cs.umd.edu"}, {"color": "#6FA8DC", "id": "IEEE TPAM", "label": "IEEE TPAM", "shape": "dot", "size": 10.089285714285714, "title": "IEEE TPAM"}, {"color": "#6FA8DC", "id": "IEEE CVPR", "label": "IEEE CVPR", "shape": "dot", "size": 10.625, "title": "IEEE CVPR"}, {"color": "#6FA8DC", "id": "ICML", "label": "ICML", "shape": "dot", "size": 10.267857142857142, "title": "ICML"}, {"color": "#6FA8DC", "id": "Junlin Hu", "label": "Junlin Hu", "shape": "dot", "size": 10.357142857142858, "title": "Junlin Hu"}, {"color": "#6FA8DC", "id": "Deep Transfer Metric Learning", "label": "Deep Transfer Metric Learning", "shape": "dot", "size": 10.267857142857142, "title": "Deep Transfer Metric Learning"}, {"color": "#6FA8DC", "id": "Jiwen Lu", "label": "Jiwen Lu", "shape": "dot", "size": 10.357142857142858, "title": "Jiwen Lu"}, {"color": "#6FA8DC", "id": "MERL", "label": "MERL", "shape": "dot", "size": 10.089285714285714, "title": "MERL"}, {"color": "#6FA8DC", "id": "metric learning methods", "label": "metric learning methods", "shape": "dot", "size": 10.089285714285714, "title": "metric learning methods"}, {"color": "#6FA8DC", "id": "similar scenarios", "label": "similar scenarios", "shape": "dot", "size": 10.178571428571429, "title": "similar scenarios"}, {"color": "#6FA8DC", "id": "real-world visual recognition applications", "label": "real-world visual recognition applications", "shape": "dot", "size": 10.089285714285714, "title": "real-world visual recognition applications"}, {"color": "#6FA8DC", "id": "DTML method", "label": "DTML method", "shape": "dot", "size": 10.446428571428571, "title": "DTML method"}, {"color": "#6FA8DC", "id": "discriminative knowledge", "label": "discriminative knowledge", "shape": "dot", "size": 10.089285714285714, "title": "discriminative knowledge"}, {"color": "#6FA8DC", "id": "inter-class variations", "label": "inter-class variations", "shape": "dot", "size": 10.178571428571429, "title": "inter-class variations"}, {"color": "#6FA8DC", "id": "intra-class variations", "label": "intra-class variations", "shape": "dot", "size": 10.178571428571429, "title": "intra-class variations"}, {"color": "#6FA8DC", "id": "distribution divergence", "label": "distribution divergence", "shape": "dot", "size": 10.089285714285714, "title": "distribution divergence"}, {"color": "#6FA8DC", "id": "DSTML method", "label": "DSTML method", "shape": "dot", "size": 10.357142857142858, "title": "DSTML method"}, {"color": "#6FA8DC", "id": "outputs of hidden and top layers", "label": "outputs of hidden and top layers", "shape": "dot", "size": 10.089285714285714, "title": "outputs of hidden and top layers"}, {"color": "#6FA8DC", "id": "deeply supervised transfer metric learning", "label": "deeply supervised transfer metric learning", "shape": "dot", "size": 10.089285714285714, "title": "deeply supervised transfer metric learning"}, {"color": "#6FA8DC", "id": "vergence", "label": "vergence", "shape": "dot", "size": 10.089285714285714, "title": "vergence"}, {"color": "#6FA8DC", "id": "source and target domains", "label": "source and target domains", "shape": "dot", "size": 10.178571428571429, "title": "source and target domains"}, {"color": "#6FA8DC", "id": "transfer metric learning method", "label": "transfer metric learning method", "shape": "dot", "size": 10.089285714285714, "title": "transfer metric learning method"}, {"color": "#6FA8DC", "id": "effectiveness of proposed methods", "label": "effectiveness of proposed methods", "shape": "dot", "size": 10.089285714285714, "title": "effectiveness of proposed methods"}, {"color": "#6FA8DC", "id": "cross-dataset task", "label": "cross-dataset task", "shape": "dot", "size": 10.178571428571429, "title": "cross-dataset task"}, {"color": "#6FA8DC", "id": "cross-dataset tasks", "label": "cross-dataset tasks", "shape": "dot", "size": 10.089285714285714, "title": "cross-dataset tasks"}, {"color": "#6FA8DC", "id": "hidden layers", "label": "hidden layers", "shape": "dot", "size": 10.089285714285714, "title": "hidden layers"}, {"color": "#6FA8DC", "id": "top layers", "label": "top layers", "shape": "dot", "size": 10.089285714285714, "title": "top layers"}, {"color": "#6FA8DC", "id": "Deep Transfer Metric Learning (DTML)", "label": "Deep Transfer Metric Learning (DTML)", "shape": "dot", "size": 10.267857142857142, "title": "Deep Transfer Metric Learning (DTML)"}, {"color": "#6FA8DC", "id": "Cross-Domain Visual Recognition", "label": "Cross-Domain Visual Recognition", "shape": "dot", "size": 10.178571428571429, "title": "Cross-Domain Visual Recognition"}, {"color": "#6FA8DC", "id": "Distribution Divergence", "label": "Distribution Divergence", "shape": "dot", "size": 10.089285714285714, "title": "Distribution Divergence"}, {"color": "#6FA8DC", "id": "Face Description", "label": "Face Description", "shape": "dot", "size": 10.089285714285714, "title": "Face Description"}, {"color": "#6FA8DC", "id": "Learning Deep Architectures", "label": "Learning Deep Architectures", "shape": "dot", "size": 10.089285714285714, "title": "Learning Deep Architectures"}, {"color": "#6FA8DC", "id": "Predictive Structures", "label": "Predictive Structures", "shape": "dot", "size": 10.089285714285714, "title": "Predictive Structures"}, {"color": "#6FA8DC", "id": "Multiple Tasks", "label": "Multiple Tasks", "shape": "dot", "size": 10.089285714285714, "title": "Multiple Tasks"}, {"color": "#6FA8DC", "id": "Journal of Machine Learning Research", "label": "Journal of Machine Learning Research", "shape": "dot", "size": 10.178571428571429, "title": "Journal of Machine Learning Research"}, {"color": "#6FA8DC", "id": "Learning deep architectures for AI", "label": "Learning deep architectures for AI", "shape": "dot", "size": 10.089285714285714, "title": "Learning deep architectures for AI"}, {"color": "#6FA8DC", "id": "Foundations and Trends in Machine Learning", "label": "Foundations and Trends in Machine Learning", "shape": "dot", "size": 10.089285714285714, "title": "Foundations and Trends in Machine Learning"}, {"color": "#6FA8DC", "id": "ACM Multimedia", "label": "ACM Multimedia", "shape": "dot", "size": 10.178571428571429, "title": "ACM Multimedia"}, {"color": "#6FA8DC", "id": "ACM", "label": "ACM", "shape": "dot", "size": 10.178571428571429, "title": "ACM"}, {"color": "#6FA8DC", "id": "Chen, D.", "label": "Chen, D.", "shape": "dot", "size": 10.089285714285714, "title": "Chen, D."}, {"color": "#6FA8DC", "id": "Bayesian face revisited", "label": "Bayesian face revisited", "shape": "dot", "size": 10.357142857142858, "title": "Bayesian face revisited"}, {"color": "#6FA8DC", "id": "Duan, L.", "label": "Duan, L.", "shape": "dot", "size": 10.089285714285714, "title": "Duan, L."}, {"color": "#6FA8DC", "id": "Domain transfer SVM", "label": "Domain transfer SVM", "shape": "dot", "size": 10.089285714285714, "title": "Domain transfer SVM"}, {"color": "#6FA8DC", "id": "Conference on Computer Vision and Pattern Recognition", "label": "Conference on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.267857142857142, "title": "Conference on Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "Viewpoint invariant pedestrian recognition", "label": "Viewpoint invariant pedestrian recognition", "shape": "dot", "size": 10.089285714285714, "title": "Viewpoint invariant pedestrian recognition"}, {"color": "#6FA8DC", "id": "Gray \u0026 Tao (2008)", "label": "Gray \u0026 Tao (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Gray \u0026 Tao (2008)"}, {"color": "#6FA8DC", "id": "Gretton et al. (2006)", "label": "Gretton et al. (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Gretton et al. (2006)"}, {"color": "#6FA8DC", "id": "Neural Information Processing Systems", "label": "Neural Information Processing Systems", "shape": "dot", "size": 10.178571428571429, "title": "Neural Information Processing Systems"}, {"color": "#6FA8DC", "id": "Hinton et al. (2006)", "label": "Hinton et al. (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Hinton et al. (2006)"}, {"color": "#6FA8DC", "id": "Neural Computation", "label": "Neural Computation", "shape": "dot", "size": 10.089285714285714, "title": "Neural Computation"}, {"color": "#6FA8DC", "id": "Huang et al. (2012)", "label": "Huang et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Huang et al. (2012)"}, {"color": "#6FA8DC", "id": "School of Electrical and Electronic Engineering", "label": "School of Electrical and Electronic Engineering", "shape": "dot", "size": 10.178571428571429, "title": "School of Electrical and Electronic Engineering"}, {"color": "#6FA8DC", "id": "jhu007@e.ntu.edu.sg", "label": "jhu007@e.ntu.edu.sg", "shape": "dot", "size": 10.089285714285714, "title": "jhu007@e.ntu.edu.sg"}, {"color": "#6FA8DC", "id": "Nanyang Technological University", "label": "Nanyang Technological University", "shape": "dot", "size": 10.178571428571429, "title": "Nanyang Technological University"}, {"color": "#6FA8DC", "id": "Singapore", "label": "Singapore", "shape": "dot", "size": 10.178571428571429, "title": "Singapore"}, {"color": "#6FA8DC", "id": "jiwen.lu@adsc.com.sg", "label": "jiwen.lu@adsc.com.sg", "shape": "dot", "size": 10.089285714285714, "title": "jiwen.lu@adsc.com.sg"}, {"color": "#6FA8DC", "id": "Yap-Peng Tan", "label": "Yap-Peng Tan", "shape": "dot", "size": 10.089285714285714, "title": "Yap-Peng Tan"}, {"color": "#6FA8DC", "id": "eyptan@ntu.edu.sg", "label": "eyptan@ntu.edu.sg", "shape": "dot", "size": 10.089285714285714, "title": "eyptan@ntu.edu.sg"}, {"color": "#6FA8DC", "id": "Takuya Narihira", "label": "Takuya Narihira", "shape": "dot", "size": 10.089285714285714, "title": "Takuya Narihira"}, {"color": "#6FA8DC", "id": "Learning Lightness from Human Judgement", "label": "Learning Lightness from Human Judgement", "shape": "dot", "size": 10.446428571428571, "title": "Learning Lightness from Human Judgement"}, {"color": "#6FA8DC", "id": "Michael Maire", "label": "Michael Maire", "shape": "dot", "size": 10.178571428571429, "title": "Michael Maire"}, {"color": "#6FA8DC", "id": "Stella X. Yu", "label": "Stella X. Yu", "shape": "dot", "size": 10.267857142857142, "title": "Stella X. Yu"}, {"color": "#6FA8DC", "id": "Narihira_Learning_Lightness_From_2015_CVPR_paper.pdf", "label": "Narihira_Learning_Lightness_From_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Narihira_Learning_Lightness_From_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Narihira_Learning_Lightness_From_2015_CVPR_paper", "label": "Narihira_Learning_Lightness_From_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Narihira_Learning_Lightness_From_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "inferring lightness", "label": "inferring lightness", "shape": "dot", "size": 10.178571428571429, "title": "inferring lightness"}, {"color": "#6FA8DC", "id": "perceived re\ufb02ectance", "label": "perceived re\ufb02ectance", "shape": "dot", "size": 10.089285714285714, "title": "perceived re\ufb02ectance"}, {"color": "#6FA8DC", "id": "classic methods", "label": "classic methods", "shape": "dot", "size": 10.089285714285714, "title": "classic methods"}, {"color": "#6FA8DC", "id": "intrinsic image decomposition", "label": "intrinsic image decomposition", "shape": "dot", "size": 10.892857142857142, "title": "intrinsic image decomposition"}, {"color": "#6FA8DC", "id": "re\ufb02ectance and shading components", "label": "re\ufb02ectance and shading components", "shape": "dot", "size": 10.089285714285714, "title": "re\ufb02ectance and shading components"}, {"color": "#6FA8DC", "id": "lightness differences between pixels", "label": "lightness differences between pixels", "shape": "dot", "size": 10.089285714285714, "title": "lightness differences between pixels"}, {"color": "#6FA8DC", "id": "patch representations", "label": "patch representations", "shape": "dot", "size": 10.178571428571429, "title": "patch representations"}, {"color": "#6FA8DC", "id": "deep networks", "label": "deep networks", "shape": "dot", "size": 10.178571428571429, "title": "deep networks"}, {"color": "#6FA8DC", "id": "Intrinsic Images in the Wild dataset", "label": "Intrinsic Images in the Wild dataset", "shape": "dot", "size": 10.089285714285714, "title": "Intrinsic Images in the Wild dataset"}, {"color": "#6FA8DC", "id": "local lightness model", "label": "local lightness model", "shape": "dot", "size": 10.357142857142858, "title": "local lightness model"}, {"color": "#6FA8DC", "id": "on-par with global lightness model", "label": "on-par with global lightness model", "shape": "dot", "size": 10.089285714285714, "title": "on-par with global lightness model"}, {"color": "#6FA8DC", "id": "global lightness model", "label": "global lightness model", "shape": "dot", "size": 10.178571428571429, "title": "global lightness model"}, {"color": "#6FA8DC", "id": "shading/re\ufb02ectance priors", "label": "shading/re\ufb02ectance priors", "shape": "dot", "size": 10.089285714285714, "title": "shading/re\ufb02ectance priors"}, {"color": "#6FA8DC", "id": "on-par performance", "label": "on-par performance", "shape": "dot", "size": 10.089285714285714, "title": "on-par performance"}, {"color": "#6FA8DC", "id": "state-of-the-art global lightness model", "label": "state-of-the-art global lightness model", "shape": "dot", "size": 10.357142857142858, "title": "state-of-the-art global lightness model"}, {"color": "#6FA8DC", "id": "shading/reflectance priors", "label": "shading/reflectance priors", "shape": "dot", "size": 10.089285714285714, "title": "shading/reflectance priors"}, {"color": "#6FA8DC", "id": "dense conditional random field formulation", "label": "dense conditional random field formulation", "shape": "dot", "size": 10.267857142857142, "title": "dense conditional random field formulation"}, {"color": "#6FA8DC", "id": "simultaneous reasoning", "label": "simultaneous reasoning", "shape": "dot", "size": 10.178571428571429, "title": "simultaneous reasoning"}, {"color": "#6FA8DC", "id": "pairs of pixels", "label": "pairs of pixels", "shape": "dot", "size": 10.089285714285714, "title": "pairs of pixels"}, {"color": "#6FA8DC", "id": "multiple priors", "label": "multiple priors", "shape": "dot", "size": 10.089285714285714, "title": "multiple priors"}, {"color": "#6FA8DC", "id": "ld dataset", "label": "ld dataset", "shape": "dot", "size": 10.089285714285714, "title": "ld dataset"}, {"color": "#6FA8DC", "id": "lightness perception", "label": "lightness perception", "shape": "dot", "size": 10.357142857142858, "title": "lightness perception"}, {"color": "#6FA8DC", "id": "cognitive neurosciences", "label": "cognitive neurosciences", "shape": "dot", "size": 10.089285714285714, "title": "cognitive neurosciences"}, {"color": "#6FA8DC", "id": "Lightness perception and lightness illusions", "label": "Lightness perception and lightness illusions", "shape": "dot", "size": 10.089285714285714, "title": "Lightness perception and lightness illusions"}, {"color": "#6FA8DC", "id": "foundational work", "label": "foundational work", "shape": "dot", "size": 10.446428571428571, "title": "foundational work"}, {"color": "#6FA8DC", "id": "H. G. Barrow", "label": "H. G. Barrow", "shape": "dot", "size": 10.089285714285714, "title": "H. G. Barrow"}, {"color": "#6FA8DC", "id": "Recovering intrinsic scene characteristics from images", "label": "Recovering intrinsic scene characteristics from images", "shape": "dot", "size": 10.178571428571429, "title": "Recovering intrinsic scene characteristics from images"}, {"color": "#6FA8DC", "id": "intrinsic image algorithms", "label": "intrinsic image algorithms", "shape": "dot", "size": 10.446428571428571, "title": "intrinsic image algorithms"}, {"color": "#6FA8DC", "id": "relative reflectance", "label": "relative reflectance", "shape": "dot", "size": 10.089285714285714, "title": "relative reflectance"}, {"color": "#6FA8DC", "id": "human judgment data", "label": "human judgment data", "shape": "dot", "size": 10.089285714285714, "title": "human judgment data"}, {"color": "#6FA8DC", "id": "Computer Vision Systems", "label": "Computer Vision Systems", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision Systems"}, {"color": "#6FA8DC", "id": "scene characteristics from images", "label": "scene characteristics from images", "shape": "dot", "size": 10.178571428571429, "title": "scene characteristics from images"}, {"color": "#6FA8DC", "id": "Retinex theory", "label": "Retinex theory", "shape": "dot", "size": 10.267857142857142, "title": "Retinex theory"}, {"color": "#6FA8DC", "id": "E. H. Land and J. J. McCann", "label": "E. H. Land and J. J. McCann", "shape": "dot", "size": 10.089285714285714, "title": "E. H. Land and J. J. McCann"}, {"color": "#6FA8DC", "id": "brightness perception", "label": "brightness perception", "shape": "dot", "size": 10.089285714285714, "title": "brightness perception"}, {"color": "#6FA8DC", "id": "determining lightness from an image", "label": "determining lightness from an image", "shape": "dot", "size": 10.089285714285714, "title": "determining lightness from an image"}, {"color": "#6FA8DC", "id": "M. Tappen, W. Freeman, and E. Adelson", "label": "M. Tappen, W. Freeman, and E. Adelson", "shape": "dot", "size": 10.089285714285714, "title": "M. Tappen, W. Freeman, and E. Adelson"}, {"color": "#6FA8DC", "id": "intrinsic image recovery", "label": "intrinsic image recovery", "shape": "dot", "size": 10.357142857142858, "title": "intrinsic image recovery"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2005", "label": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2005", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2005"}, {"color": "#6FA8DC", "id": "R. Grosse", "label": "R. Grosse", "shape": "dot", "size": 10.089285714285714, "title": "R. Grosse"}, {"color": "#6FA8DC", "id": "Ground truth dataset", "label": "Ground truth dataset", "shape": "dot", "size": 10.535714285714286, "title": "Ground truth dataset"}, {"color": "#6FA8DC", "id": "International Conference on Computer Vision, 2009", "label": "International Conference on Computer Vision, 2009", "shape": "dot", "size": 10.089285714285714, "title": "International Conference on Computer Vision, 2009"}, {"color": "#6FA8DC", "id": "Y. Tang", "label": "Y. Tang", "shape": "dot", "size": 10.089285714285714, "title": "Y. Tang"}, {"color": "#6FA8DC", "id": "Deep Lambertian networks", "label": "Deep Lambertian networks", "shape": "dot", "size": 10.446428571428571, "title": "Deep Lambertian networks"}, {"color": "#6FA8DC", "id": "Lambertian reflectance models", "label": "Lambertian reflectance models", "shape": "dot", "size": 10.267857142857142, "title": "Lambertian reflectance models"}, {"color": "#6FA8DC", "id": "International Conference on Machine Learning, 2012", "label": "International Conference on Machine Learning, 2012", "shape": "dot", "size": 10.089285714285714, "title": "International Conference on Machine Learning, 2012"}, {"color": "#6FA8DC", "id": "Lambertian networks", "label": "Lambertian networks", "shape": "dot", "size": 10.089285714285714, "title": "Lambertian networks"}, {"color": "#6FA8DC", "id": "deep learning approaches", "label": "deep learning approaches", "shape": "dot", "size": 10.267857142857142, "title": "deep learning approaches"}, {"color": "#6FA8DC", "id": "large dataset", "label": "large dataset", "shape": "dot", "size": 10.089285714285714, "title": "large dataset"}, {"color": "#6FA8DC", "id": "training computer vision models", "label": "training computer vision models", "shape": "dot", "size": 10.089285714285714, "title": "training computer vision models"}, {"color": "#6FA8DC", "id": "deep convolutional neural network", "label": "deep convolutional neural network", "shape": "dot", "size": 10.089285714285714, "title": "deep convolutional neural network"}, {"color": "#6FA8DC", "id": "breakthrough performance", "label": "breakthrough performance", "shape": "dot", "size": 10.089285714285714, "title": "breakthrough performance"}, {"color": "#6FA8DC", "id": "research in intrinsic image decomposition", "label": "research in intrinsic image decomposition", "shape": "dot", "size": 10.089285714285714, "title": "research in intrinsic image decomposition"}, {"color": "#6FA8DC", "id": "Imaginet classification with deep convolutional neural networks", "label": "Imaginet classification with deep convolutional neural networks", "shape": "dot", "size": 10.178571428571429, "title": "Imaginet classification with deep convolutional neural networks"}, {"color": "#6FA8DC", "id": "subsequent research", "label": "subsequent research", "shape": "dot", "size": 10.089285714285714, "title": "subsequent research"}, {"color": "#6FA8DC", "id": "deep learning framework", "label": "deep learning framework", "shape": "dot", "size": 10.089285714285714, "title": "deep learning framework"}, {"color": "#6FA8DC", "id": "Takaya Narihira", "label": "Takaya Narihira", "shape": "dot", "size": 10.267857142857142, "title": "Takaya Narihira"}, {"color": "#6FA8DC", "id": "UC Berkeley", "label": "UC Berkeley", "shape": "dot", "size": 10.625, "title": "UC Berkeley"}, {"color": "#6FA8DC", "id": "ICSI", "label": "ICSI", "shape": "dot", "size": 10.267857142857142, "title": "ICSI"}, {"color": "#6FA8DC", "id": "Sony Corp.", "label": "Sony Corp.", "shape": "dot", "size": 10.089285714285714, "title": "Sony Corp."}, {"color": "#6FA8DC", "id": "TTI Chicago", "label": "TTI Chicago", "shape": "dot", "size": 10.089285714285714, "title": "TTI Chicago"}, {"color": "#6FA8DC", "id": "Hierarchical-PEP Model", "label": "Hierarchical-PEP Model", "shape": "dot", "size": 10.267857142857142, "title": "Hierarchical-PEP Model"}, {"color": "#6FA8DC", "id": "face recognition", "label": "face recognition", "shape": "dot", "size": 10.625, "title": "face recognition"}, {"color": "#6FA8DC", "id": "Pose variation", "label": "Pose variation", "shape": "dot", "size": 10.178571428571429, "title": "Pose variation"}, {"color": "#6FA8DC", "id": "Hierarchical-PEP model", "label": "Hierarchical-PEP model", "shape": "dot", "size": 10.714285714285714, "title": "Hierarchical-PEP model"}, {"color": "#6FA8DC", "id": "Probabilistic Elastic Part (PEP) model", "label": "Probabilistic Elastic Part (PEP) model", "shape": "dot", "size": 10.089285714285714, "title": "Probabilistic Elastic Part (PEP) model"}, {"color": "#6FA8DC", "id": "Deep Hierarchical Architectures", "label": "Deep Hierarchical Architectures", "shape": "dot", "size": 10.089285714285714, "title": "Deep Hierarchical Architectures"}, {"color": "#6FA8DC", "id": "Face Image", "label": "Face Image", "shape": "dot", "size": 10.089285714285714, "title": "Face Image"}, {"color": "#6FA8DC", "id": "Face Parts", "label": "Face Parts", "shape": "dot", "size": 10.178571428571429, "title": "Face Parts"}, {"color": "#6FA8DC", "id": "Detail Level", "label": "Detail Level", "shape": "dot", "size": 10.089285714285714, "title": "Detail Level"}, {"color": "#6FA8DC", "id": "Face Part Representations", "label": "Face Part Representations", "shape": "dot", "size": 10.089285714285714, "title": "Face Part Representations"}, {"color": "#6FA8DC", "id": "Layer", "label": "Layer", "shape": "dot", "size": 10.178571428571429, "title": "Layer"}, {"color": "#6FA8DC", "id": "Dimensionality", "label": "Dimensionality", "shape": "dot", "size": 10.089285714285714, "title": "Dimensionality"}, {"color": "#6FA8DC", "id": "Face Representation", "label": "Face Representation", "shape": "dot", "size": 10.089285714285714, "title": "Face Representation"}, {"color": "#6FA8DC", "id": "Invariant", "label": "Invariant", "shape": "dot", "size": 10.089285714285714, "title": "Invariant"}, {"color": "#6FA8DC", "id": "Fine-grained Structures", "label": "Fine-grained Structures", "shape": "dot", "size": 10.089285714285714, "title": "Fine-grained Structures"}, {"color": "#6FA8DC", "id": "Supervised Information", "label": "Supervised Information", "shape": "dot", "size": 10.089285714285714, "title": "Supervised Information"}, {"color": "#6FA8DC", "id": "LFW", "label": "LFW", "shape": "dot", "size": 10.535714285714286, "title": "LFW"}, {"color": "#6FA8DC", "id": "YouTube Faces", "label": "YouTube Faces", "shape": "dot", "size": 10.178571428571429, "title": "YouTube Faces"}, {"color": "#6FA8DC", "id": "PaSC", "label": "PaSC", "shape": "dot", "size": 10.267857142857142, "title": "PaSC"}, {"color": "#6FA8DC", "id": "face parts", "label": "face parts", "shape": "dot", "size": 10.089285714285714, "title": "face parts"}, {"color": "#6FA8DC", "id": "supervised information", "label": "supervised information", "shape": "dot", "size": 10.178571428571429, "title": "supervised information"}, {"color": "#6FA8DC", "id": "face recognition challenge", "label": "face recognition challenge", "shape": "dot", "size": 10.089285714285714, "title": "face recognition challenge"}, {"color": "#6FA8DC", "id": "PEP (Probabilistic Elastic Part) Model", "label": "PEP (Probabilistic Elastic Part) Model", "shape": "dot", "size": 10.178571428571429, "title": "PEP (Probabilistic Elastic Part) Model"}, {"color": "#6FA8DC", "id": "Ahonen, T.", "label": "Ahonen, T.", "shape": "dot", "size": 10.089285714285714, "title": "Ahonen, T."}, {"color": "#6FA8DC", "id": "Face recognition with local binary patterns", "label": "Face recognition with local binary patterns", "shape": "dot", "size": 10.178571428571429, "title": "Face recognition with local binary patterns"}, {"color": "#6FA8DC", "id": "Grauman, K.", "label": "Grauman, K.", "shape": "dot", "size": 10.089285714285714, "title": "Grauman, K."}, {"color": "#6FA8DC", "id": "The pyramid match kernel", "label": "The pyramid match kernel", "shape": "dot", "size": 10.178571428571429, "title": "The pyramid match kernel"}, {"color": "#6FA8DC", "id": "Hu, J.", "label": "Hu, J.", "shape": "dot", "size": 10.267857142857142, "title": "Hu, J."}, {"color": "#6FA8DC", "id": "Discriminative deep metric learning", "label": "Discriminative deep metric learning", "shape": "dot", "size": 10.178571428571429, "title": "Discriminative deep metric learning"}, {"color": "#6FA8DC", "id": "Eigenfaces", "label": "Eigenfaces", "shape": "dot", "size": 10.089285714285714, "title": "Eigenfaces"}, {"color": "#6FA8DC", "id": "Fisherfaces", "label": "Fisherfaces", "shape": "dot", "size": 10.178571428571429, "title": "Fisherfaces"}, {"color": "#6FA8DC", "id": "linear projection", "label": "linear projection", "shape": "dot", "size": 10.089285714285714, "title": "linear projection"}, {"color": "#6FA8DC", "id": "Unsupervised joint alignment", "label": "Unsupervised joint alignment", "shape": "dot", "size": 10.089285714285714, "title": "Unsupervised joint alignment"}, {"color": "#6FA8DC", "id": "complex images", "label": "complex images", "shape": "dot", "size": 10.089285714285714, "title": "complex images"}, {"color": "#6FA8DC", "id": "Labeled faces in the wild", "label": "Labeled faces in the wild", "shape": "dot", "size": 10.089285714285714, "title": "Labeled faces in the wild"}, {"color": "#6FA8DC", "id": "reporting procedures", "label": "reporting procedures", "shape": "dot", "size": 10.089285714285714, "title": "reporting procedures"}, {"color": "#6FA8DC", "id": "Large margin multi-metric learning", "label": "Large margin multi-metric learning", "shape": "dot", "size": 10.267857142857142, "title": "Large margin multi-metric learning"}, {"color": "#6FA8DC", "id": "kinship verification", "label": "kinship verification", "shape": "dot", "size": 10.089285714285714, "title": "kinship verification"}, {"color": "#6FA8DC", "id": "Asian Conference on Computer Vision (ACCV)", "label": "Asian Conference on Computer Vision (ACCV)", "shape": "dot", "size": 10.089285714285714, "title": "Asian Conference on Computer Vision (ACCV)"}, {"color": "#6FA8DC", "id": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "label": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "publication", "label": "publication", "shape": "dot", "size": 10.357142857142858, "title": "publication"}, {"color": "#6FA8DC", "id": "practical transfer learning algorithm", "label": "practical transfer learning algorithm", "shape": "dot", "size": 10.089285714285714, "title": "practical transfer learning algorithm"}, {"color": "#6FA8DC", "id": "Lei, Z.", "label": "Lei, Z.", "shape": "dot", "size": 10.089285714285714, "title": "Lei, Z."}, {"color": "#6FA8DC", "id": "discriminant face descriptor", "label": "discriminant face descriptor", "shape": "dot", "size": 10.089285714285714, "title": "discriminant face descriptor"}, {"color": "#6FA8DC", "id": "Simonyan, K.", "label": "Simonyan, K.", "shape": "dot", "size": 10.178571428571429, "title": "Simonyan, K."}, {"color": "#6FA8DC", "id": "Deep fisher networks", "label": "Deep fisher networks", "shape": "dot", "size": 10.089285714285714, "title": "Deep fisher networks"}, {"color": "#6FA8DC", "id": "Yu Kong", "label": "Yu Kong", "shape": "dot", "size": 10.178571428571429, "title": "Yu Kong"}, {"color": "#6FA8DC", "id": "Bilinear Heterogeneous Information Machine", "label": "Bilinear Heterogeneous Information Machine", "shape": "dot", "size": 10.357142857142858, "title": "Bilinear Heterogeneous Information Machine"}, {"color": "#6FA8DC", "id": "Yun Fu", "label": "Yun Fu", "shape": "dot", "size": 10.267857142857142, "title": "Yun Fu"}, {"color": "#6FA8DC", "id": "{ghua}@steverns.edu", "label": "{ghua}@steverns.edu", "shape": "dot", "size": 10.089285714285714, "title": "{ghua}@steverns.edu"}, {"color": "#6FA8DC", "id": "Kong_Bilinear_Heterogeneous_Information_2015_CVPR_paper.pdf", "label": "Kong_Bilinear_Heterogeneous_Information_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.178571428571429, "title": "Kong_Bilinear_Heterogeneous_Information_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "RGB-D Action Recognition", "label": "RGB-D Action Recognition", "shape": "dot", "size": 10.089285714285714, "title": "RGB-D Action Recognition"}, {"color": "#6FA8DC", "id": "depth features", "label": "depth features", "shape": "dot", "size": 10.089285714285714, "title": "depth features"}, {"color": "#6FA8DC", "id": "RGB visual features", "label": "RGB visual features", "shape": "dot", "size": 10.089285714285714, "title": "RGB visual features"}, {"color": "#6FA8DC", "id": "compressed", "label": "compressed", "shape": "dot", "size": 10.089285714285714, "title": "compressed"}, {"color": "#6FA8DC", "id": "projected", "label": "projected", "shape": "dot", "size": 10.089285714285714, "title": "projected"}, {"color": "#6FA8DC", "id": "space", "label": "space", "shape": "dot", "size": 10.089285714285714, "title": "space"}, {"color": "#6FA8DC", "id": "learned", "label": "learned", "shape": "dot", "size": 10.089285714285714, "title": "learned"}, {"color": "#6FA8DC", "id": "knowledge", "label": "knowledge", "shape": "dot", "size": 10.089285714285714, "title": "knowledge"}, {"color": "#6FA8DC", "id": "shared", "label": "shared", "shape": "dot", "size": 10.089285714285714, "title": "shared"}, {"color": "#6FA8DC", "id": "low-rank", "label": "low-rank", "shape": "dot", "size": 10.089285714285714, "title": "low-rank"}, {"color": "#6FA8DC", "id": "generalization power", "label": "generalization power", "shape": "dot", "size": 10.267857142857142, "title": "generalization power"}, {"color": "#6FA8DC", "id": "RGB-D action datasets", "label": "RGB-D action datasets", "shape": "dot", "size": 10.267857142857142, "title": "RGB-D action datasets"}, {"color": "#6FA8DC", "id": "low-rank classifier", "label": "low-rank classifier", "shape": "dot", "size": 10.178571428571429, "title": "low-rank classifier"}, {"color": "#6FA8DC", "id": "promising results", "label": "promising results", "shape": "dot", "size": 10.267857142857142, "title": "promising results"}, {"color": "#6FA8DC", "id": "RGB data are missing", "label": "RGB data are missing", "shape": "dot", "size": 10.089285714285714, "title": "RGB data are missing"}, {"color": "#6FA8DC", "id": "depth data are missing", "label": "depth data are missing", "shape": "dot", "size": 10.089285714285714, "title": "depth data are missing"}, {"color": "#6FA8DC", "id": "eter", "label": "eter", "shape": "dot", "size": 10.089285714285714, "title": "eter"}, {"color": "#6FA8DC", "id": "missing RGB data", "label": "missing RGB data", "shape": "dot", "size": 10.089285714285714, "title": "missing RGB data"}, {"color": "#6FA8DC", "id": "missing depth data", "label": "missing depth data", "shape": "dot", "size": 10.089285714285714, "title": "missing depth data"}, {"color": "#6FA8DC", "id": "Argyriou et al. (2008)", "label": "Argyriou et al. (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Argyriou et al. (2008)"}, {"color": "#6FA8DC", "id": "feature learning", "label": "feature learning", "shape": "dot", "size": 10.178571428571429, "title": "feature learning"}, {"color": "#6FA8DC", "id": "Bo et al. (2011)", "label": "Bo et al. (2011)", "shape": "dot", "size": 10.178571428571429, "title": "Bo et al. (2011)"}, {"color": "#6FA8DC", "id": "kernel descriptors", "label": "kernel descriptors", "shape": "dot", "size": 10.089285714285714, "title": "kernel descriptors"}, {"color": "#6FA8DC", "id": "Do and Artieres (2009)", "label": "Do and Artieres (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Do and Artieres (2009)"}, {"color": "#6FA8DC", "id": "HMMs", "label": "HMMs", "shape": "dot", "size": 10.178571428571429, "title": "HMMs"}, {"color": "#6FA8DC", "id": "Artieres et al.", "label": "Artieres et al.", "shape": "dot", "size": 10.089285714285714, "title": "Artieres et al."}, {"color": "#6FA8DC", "id": "Hidden Markov Models", "label": "Hidden Markov Models", "shape": "dot", "size": 10.178571428571429, "title": "Hidden Markov Models"}, {"color": "#6FA8DC", "id": "Had\ufb01eld and Bowden", "label": "Had\ufb01eld and Bowden", "shape": "dot", "size": 10.089285714285714, "title": "Had\ufb01eld and Bowden"}, {"color": "#6FA8DC", "id": "3D natural scenes", "label": "3D natural scenes", "shape": "dot", "size": 10.089285714285714, "title": "3D natural scenes"}, {"color": "#6FA8DC", "id": "Ji et al.", "label": "Ji et al.", "shape": "dot", "size": 10.089285714285714, "title": "Ji et al."}, {"color": "#6FA8DC", "id": "3D Convolutional Neural Networks", "label": "3D Convolutional Neural Networks", "shape": "dot", "size": 10.178571428571429, "title": "3D Convolutional Neural Networks"}, {"color": "#6FA8DC", "id": "depth cameras", "label": "depth cameras", "shape": "dot", "size": 10.089285714285714, "title": "depth cameras"}, {"color": "#6FA8DC", "id": "Kobayashi", "label": "Kobayashi", "shape": "dot", "size": 10.089285714285714, "title": "Kobayashi"}, {"color": "#6FA8DC", "id": "low-rank bilinear classification", "label": "low-rank bilinear classification", "shape": "dot", "size": 10.267857142857142, "title": "low-rank bilinear classification"}, {"color": "#6FA8DC", "id": "modeling complex interactions", "label": "modeling complex interactions", "shape": "dot", "size": 10.089285714285714, "title": "modeling complex interactions"}, {"color": "#6FA8DC", "id": "spatio-temporal depth cuboid similarity feature", "label": "spatio-temporal depth cuboid similarity feature", "shape": "dot", "size": 10.089285714285714, "title": "spatio-temporal depth cuboid similarity feature"}, {"color": "#6FA8DC", "id": "activity recognition", "label": "activity recognition", "shape": "dot", "size": 10.267857142857142, "title": "activity recognition"}, {"color": "#6FA8DC", "id": "information bottleneck method", "label": "information bottleneck method", "shape": "dot", "size": 10.178571428571429, "title": "information bottleneck method"}, {"color": "#6FA8DC", "id": "feature selection", "label": "feature selection", "shape": "dot", "size": 10.267857142857142, "title": "feature selection"}, {"color": "#6FA8DC", "id": "representation learning", "label": "representation learning", "shape": "dot", "size": 10.178571428571429, "title": "representation learning"}, {"color": "#6FA8DC", "id": "depth camera", "label": "depth camera", "shape": "dot", "size": 10.178571428571429, "title": "depth camera"}, {"color": "#6FA8DC", "id": "depth sequences", "label": "depth sequences", "shape": "dot", "size": 10.089285714285714, "title": "depth sequences"}, {"color": "#6FA8DC", "id": "HON4D", "label": "HON4D", "shape": "dot", "size": 10.089285714285714, "title": "HON4D"}, {"color": "#6FA8DC", "id": "oriented 4D normals", "label": "oriented 4D normals", "shape": "dot", "size": 10.089285714285714, "title": "oriented 4D normals"}, {"color": "#6FA8DC", "id": "depth data", "label": "depth data", "shape": "dot", "size": 10.178571428571429, "title": "depth data"}, {"color": "#6FA8DC", "id": "information bottlenecks", "label": "information bottlenecks", "shape": "dot", "size": 10.178571428571429, "title": "information bottlenecks"}, {"color": "#6FA8DC", "id": "Sebastian Haner", "label": "Sebastian Haner", "shape": "dot", "size": 10.446428571428571, "title": "Sebastian Haner"}, {"color": "#6FA8DC", "id": "Absolute Pose for Cameras", "label": "Absolute Pose for Cameras", "shape": "dot", "size": 10.446428571428571, "title": "Absolute Pose for Cameras"}, {"color": "#6FA8DC", "id": "Kalle \u02daAstr\u00a8om", "label": "Kalle \u02daAstr\u00a8om", "shape": "dot", "size": 10.357142857142858, "title": "Kalle \u02daAstr\u00a8om"}, {"color": "#6FA8DC", "id": "refractive interfaces", "label": "refractive interfaces", "shape": "dot", "size": 10.089285714285714, "title": "refractive interfaces"}, {"color": "#6FA8DC", "id": "Yukong", "label": "Yukong", "shape": "dot", "size": 10.089285714285714, "title": "Yukong"}, {"color": "#6FA8DC", "id": "yukong@ece.neu.edu", "label": "yukong@ece.neu.edu", "shape": "dot", "size": 10.089285714285714, "title": "yukong@ece.neu.edu"}, {"color": "#6FA8DC", "id": "yunfu@ece.neu.edu", "label": "yunfu@ece.neu.edu", "shape": "dot", "size": 10.089285714285714, "title": "yunfu@ece.neu.edu"}, {"color": "#6FA8DC", "id": "absolute pose of a perspective camera", "label": "absolute pose of a perspective camera", "shape": "dot", "size": 10.089285714285714, "title": "absolute pose of a perspective camera"}, {"color": "#6FA8DC", "id": "perspective camera", "label": "perspective camera", "shape": "dot", "size": 10.089285714285714, "title": "perspective camera"}, {"color": "#6FA8DC", "id": "scene", "label": "scene", "shape": "dot", "size": 10.178571428571429, "title": "scene"}, {"color": "#6FA8DC", "id": "refractive plane", "label": "refractive plane", "shape": "dot", "size": 10.178571428571429, "title": "refractive plane"}, {"color": "#6FA8DC", "id": "transparent media", "label": "transparent media", "shape": "dot", "size": 10.089285714285714, "title": "transparent media"}, {"color": "#6FA8DC", "id": "solvers", "label": "solvers", "shape": "dot", "size": 10.357142857142858, "title": "solvers"}, {"color": "#6FA8DC", "id": "2D cases", "label": "2D cases", "shape": "dot", "size": 10.089285714285714, "title": "2D cases"}, {"color": "#6FA8DC", "id": "minimal", "label": "minimal", "shape": "dot", "size": 10.089285714285714, "title": "minimal"}, {"color": "#6FA8DC", "id": "Snell\u2019s law", "label": "Snell\u2019s law", "shape": "dot", "size": 10.089285714285714, "title": "Snell\u2019s law"}, {"color": "#6FA8DC", "id": "false solutions", "label": "false solutions", "shape": "dot", "size": 10.178571428571429, "title": "false solutions"}, {"color": "#6FA8DC", "id": "complexity of problem", "label": "complexity of problem", "shape": "dot", "size": 10.089285714285714, "title": "complexity of problem"}, {"color": "#6FA8DC", "id": "synthetic data", "label": "synthetic data", "shape": "dot", "size": 10.089285714285714, "title": "synthetic data"}, {"color": "#6FA8DC", "id": "real data", "label": "real data", "shape": "dot", "size": 10.089285714285714, "title": "real data"}, {"color": "#6FA8DC", "id": "pose estimates", "label": "pose estimates", "shape": "dot", "size": 10.089285714285714, "title": "pose estimates"}, {"color": "#6FA8DC", "id": "explicitly modelling refraction", "label": "explicitly modelling refraction", "shape": "dot", "size": 10.089285714285714, "title": "explicitly modelling refraction"}, {"color": "#6FA8DC", "id": "Absolute Pose Estimation", "label": "Absolute Pose Estimation", "shape": "dot", "size": 10.178571428571429, "title": "Absolute Pose Estimation"}, {"color": "#6FA8DC", "id": "Refractive Interfaces Modelling", "label": "Refractive Interfaces Modelling", "shape": "dot", "size": 10.089285714285714, "title": "Refractive Interfaces Modelling"}, {"color": "#6FA8DC", "id": "Refractive Interfaces", "label": "Refractive Interfaces", "shape": "dot", "size": 10.089285714285714, "title": "Refractive Interfaces"}, {"color": "#6FA8DC", "id": "Snell\u0027s Law", "label": "Snell\u0027s Law", "shape": "dot", "size": 10.089285714285714, "title": "Snell\u0027s Law"}, {"color": "#6FA8DC", "id": "Structure-and-Motion", "label": "Structure-and-Motion", "shape": "dot", "size": 10.178571428571429, "title": "Structure-and-Motion"}, {"color": "#6FA8DC", "id": "Agrawal et al. (2012)", "label": "Agrawal et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Agrawal et al. (2012)"}, {"color": "#6FA8DC", "id": "Multi-layer Flat Refractive Geometry Theory", "label": "Multi-layer Flat Refractive Geometry Theory", "shape": "dot", "size": 10.089285714285714, "title": "Multi-layer Flat Refractive Geometry Theory"}, {"color": "#6FA8DC", "id": "Byr\u00a8od et al. (2009)", "label": "Byr\u00a8od et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Byr\u00a8od et al. (2009)"}, {"color": "#6FA8DC", "id": "Polynomial Equation Solving", "label": "Polynomial Equation Solving", "shape": "dot", "size": 10.267857142857142, "title": "Polynomial Equation Solving"}, {"color": "#6FA8DC", "id": "Multi-layer Flat Refractive Geometry", "label": "Multi-layer Flat Refractive Geometry", "shape": "dot", "size": 10.089285714285714, "title": "Multi-layer Flat Refractive Geometry"}, {"color": "#6FA8DC", "id": "Pose Estimation Accuracy", "label": "Pose Estimation Accuracy", "shape": "dot", "size": 10.089285714285714, "title": "Pose Estimation Accuracy"}, {"color": "#6FA8DC", "id": "Refraction", "label": "Refraction", "shape": "dot", "size": 10.089285714285714, "title": "Refraction"}, {"color": "#6FA8DC", "id": "polynomial equation solving", "label": "polynomial equation solving", "shape": "dot", "size": 10.178571428571429, "title": "polynomial equation solving"}, {"color": "#6FA8DC", "id": "Ideals, Varieties, and Algorithms", "label": "Ideals, Varieties, and Algorithms", "shape": "dot", "size": 10.178571428571429, "title": "Ideals, Varieties, and Algorithms"}, {"color": "#6FA8DC", "id": "computational algebraic geometry", "label": "computational algebraic geometry", "shape": "dot", "size": 10.089285714285714, "title": "computational algebraic geometry"}, {"color": "#6FA8DC", "id": "commutative algebra", "label": "commutative algebra", "shape": "dot", "size": 10.089285714285714, "title": "commutative algebra"}, {"color": "#6FA8DC", "id": "\u02daAstr\u00a8om, Kuang, \u0026 Ask", "label": "\u02daAstr\u00a8om, Kuang, \u0026 Ask", "shape": "dot", "size": 10.089285714285714, "title": "\u02daAstr\u00a8om, Kuang, \u0026 Ask"}, {"color": "#6FA8DC", "id": "polynomial equation solving optimization", "label": "polynomial equation solving optimization", "shape": "dot", "size": 10.178571428571429, "title": "polynomial equation solving optimization"}, {"color": "#6FA8DC", "id": "p-fold symmetries", "label": "p-fold symmetries", "shape": "dot", "size": 10.089285714285714, "title": "p-fold symmetries"}, {"color": "#6FA8DC", "id": "Chari \u0026 Sturm", "label": "Chari \u0026 Sturm", "shape": "dot", "size": 10.089285714285714, "title": "Chari \u0026 Sturm"}, {"color": "#6FA8DC", "id": "multi-view geometry", "label": "multi-view geometry", "shape": "dot", "size": 10.178571428571429, "title": "multi-view geometry"}, {"color": "#6FA8DC", "id": "Chari, V.", "label": "Chari, V.", "shape": "dot", "size": 10.089285714285714, "title": "Chari, V."}, {"color": "#6FA8DC", "id": "Multi-view geometry of the refractive plane", "label": "Multi-view geometry of the refractive plane", "shape": "dot", "size": 10.267857142857142, "title": "Multi-view geometry of the refractive plane"}, {"color": "#6FA8DC", "id": "Sturm, P. F.", "label": "Sturm, P. F.", "shape": "dot", "size": 10.089285714285714, "title": "Sturm, P. F."}, {"color": "#6FA8DC", "id": "British Machine Vision Conference", "label": "British Machine Vision Conference", "shape": "dot", "size": 10.089285714285714, "title": "British Machine Vision Conference"}, {"color": "#6FA8DC", "id": "Fitzgibbon, A. W.", "label": "Fitzgibbon, A. W.", "shape": "dot", "size": 10.178571428571429, "title": "Fitzgibbon, A. W."}, {"color": "#6FA8DC", "id": "Simultaneous linear estimation", "label": "Simultaneous linear estimation", "shape": "dot", "size": 10.267857142857142, "title": "Simultaneous linear estimation"}, {"color": "#6FA8DC", "id": "geometric estimation", "label": "geometric estimation", "shape": "dot", "size": 10.089285714285714, "title": "geometric estimation"}, {"color": "#6FA8DC", "id": "lens distortion", "label": "lens distortion", "shape": "dot", "size": 10.089285714285714, "title": "lens distortion"}, {"color": "#6FA8DC", "id": "Kuang, Y.", "label": "Kuang, Y.", "shape": "dot", "size": 10.089285714285714, "title": "Kuang, Y."}, {"color": "#6FA8DC", "id": "Numerically stable optimization", "label": "Numerically stable optimization", "shape": "dot", "size": 10.267857142857142, "title": "Numerically stable optimization"}, {"color": "#6FA8DC", "id": "polynomial solvers", "label": "polynomial solvers", "shape": "dot", "size": 10.089285714285714, "title": "polynomial solvers"}, {"color": "#6FA8DC", "id": "chmid", "label": "chmid", "shape": "dot", "size": 10.089285714285714, "title": "chmid"}, {"color": "#6FA8DC", "id": "European Conference on ComputerVision", "label": "European Conference on ComputerVision", "shape": "dot", "size": 10.267857142857142, "title": "European Conference on ComputerVision"}, {"color": "#6FA8DC", "id": "Lecture Notes in Computer Science", "label": "Lecture Notes in Computer Science", "shape": "dot", "size": 10.357142857142858, "title": "Lecture Notes in Computer Science"}, {"color": "#6FA8DC", "id": "polynomial solver optimization", "label": "polynomial solver optimization", "shape": "dot", "size": 10.089285714285714, "title": "polynomial solver optimization"}, {"color": "#6FA8DC", "id": "Nist\u00e9r", "label": "Nist\u00e9r", "shape": "dot", "size": 10.089285714285714, "title": "Nist\u00e9r"}, {"color": "#6FA8DC", "id": "generalized 3-point pose problem", "label": "generalized 3-point pose problem", "shape": "dot", "size": 10.089285714285714, "title": "generalized 3-point pose problem"}, {"color": "#6FA8DC", "id": "Stew\u00e9nius", "label": "Stew\u00e9nius", "shape": "dot", "size": 10.178571428571429, "title": "Stew\u00e9nius"}, {"color": "#6FA8DC", "id": "generalized relative pose problems", "label": "generalized relative pose problems", "shape": "dot", "size": 10.089285714285714, "title": "generalized relative pose problems"}, {"color": "#6FA8DC", "id": "Kukelova", "label": "Kukelova", "shape": "dot", "size": 10.178571428571429, "title": "Kukelova"}, {"color": "#6FA8DC", "id": "polynomial eigenvalue solutions", "label": "polynomial eigenvalue solutions", "shape": "dot", "size": 10.089285714285714, "title": "polynomial eigenvalue solutions"}, {"color": "#6FA8DC", "id": "minimal problems", "label": "minimal problems", "shape": "dot", "size": 10.089285714285714, "title": "minimal problems"}, {"color": "#6FA8DC", "id": "Centre for Mathematical Sciences", "label": "Centre for Mathematical Sciences", "shape": "dot", "size": 10.089285714285714, "title": "Centre for Mathematical Sciences"}, {"color": "#6FA8DC", "id": "Lund University", "label": "Lund University", "shape": "dot", "size": 10.089285714285714, "title": "Lund University"}, {"color": "#6FA8DC", "id": "Workshop on Omnidirectional Vision", "label": "Workshop on Omnidirectional Vision", "shape": "dot", "size": 10.089285714285714, "title": "Workshop on Omnidirectional Vision"}, {"color": "#6FA8DC", "id": "Centre for Mathematical Sciences, Lund University", "label": "Centre for Mathematical Sciences, Lund University", "shape": "dot", "size": 10.178571428571429, "title": "Centre for Mathematical Sciences, Lund University"}, {"color": "#6FA8DC", "id": "haner@maths.lth.se", "label": "haner@maths.lth.se", "shape": "dot", "size": 10.089285714285714, "title": "haner@maths.lth.se"}, {"color": "#6FA8DC", "id": "kalle@maths.lth.se", "label": "kalle@maths.lth.se", "shape": "dot", "size": 10.089285714285714, "title": "kalle@maths.lth.se"}, {"color": "#6FA8DC", "id": "R6P", "label": "R6P", "shape": "dot", "size": 10.089285714285714, "title": "R6P"}, {"color": "#6FA8DC", "id": "Albl_R6P_-_Rolling_2015_CVPR_paper", "label": "Albl_R6P_-_Rolling_2015_CVPR_paper", "shape": "dot", "size": 10.446428571428571, "title": "Albl_R6P_-_Rolling_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Cenek Albl", "label": "Cenek Albl", "shape": "dot", "size": 10.178571428571429, "title": "Cenek Albl"}, {"color": "#6FA8DC", "id": "Zuana Kukelova", "label": "Zuana Kukelova", "shape": "dot", "size": 10.178571428571429, "title": "Zuana Kukelova"}, {"color": "#6FA8DC", "id": "Albi_R6P_-_Rolling_2015_CVPR_paper", "label": "Albi_R6P_-_Rolling_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Albi_R6P_-_Rolling_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Tomas Pajdla", "label": "Tomas Pajdla", "shape": "dot", "size": 10.178571428571429, "title": "Tomas Pajdla"}, {"color": "#6FA8DC", "id": "polynomial solutions", "label": "polynomial solutions", "shape": "dot", "size": 10.089285714285714, "title": "polynomial solutions"}, {"color": "#6FA8DC", "id": "absolute pose problem", "label": "absolute pose problem", "shape": "dot", "size": 10.178571428571429, "title": "absolute pose problem"}, {"color": "#6FA8DC", "id": "rolling shutter", "label": "rolling shutter", "shape": "dot", "size": 10.089285714285714, "title": "rolling shutter"}, {"color": "#6FA8DC", "id": "digital cameras", "label": "digital cameras", "shape": "dot", "size": 10.089285714285714, "title": "digital cameras"}, {"color": "#6FA8DC", "id": "camera model", "label": "camera model", "shape": "dot", "size": 10.178571428571429, "title": "camera model"}, {"color": "#6FA8DC", "id": "polynomial solver", "label": "polynomial solver", "shape": "dot", "size": 10.089285714285714, "title": "polynomial solver"}, {"color": "#6FA8DC", "id": "camera orientation", "label": "camera orientation", "shape": "dot", "size": 10.446428571428571, "title": "camera orientation"}, {"color": "#6FA8DC", "id": "linear approximation", "label": "linear approximation", "shape": "dot", "size": 10.178571428571429, "title": "linear approximation"}, {"color": "#6FA8DC", "id": "identity rotation", "label": "identity rotation", "shape": "dot", "size": 10.089285714285714, "title": "identity rotation"}, {"color": "#6FA8DC", "id": "P3P algorithm", "label": "P3P algorithm", "shape": "dot", "size": 10.267857142857142, "title": "P3P algorithm"}, {"color": "#6FA8DC", "id": "camera rotation velocity", "label": "camera rotation velocity", "shape": "dot", "size": 10.089285714285714, "title": "camera rotation velocity"}, {"color": "#6FA8DC", "id": "30deg/frame", "label": "30deg/frame", "shape": "dot", "size": 10.089285714285714, "title": "30deg/frame"}, {"color": "#6FA8DC", "id": "estimate camera orientation", "label": "estimate camera orientation", "shape": "dot", "size": 10.089285714285714, "title": "estimate camera orientation"}, {"color": "#6FA8DC", "id": "Ithm", "label": "Ithm", "shape": "dot", "size": 10.089285714285714, "title": "Ithm"}, {"color": "#6FA8DC", "id": "6 degrees", "label": "6 degrees", "shape": "dot", "size": 10.089285714285714, "title": "6 degrees"}, {"color": "#6FA8DC", "id": "camera rotation matrix", "label": "camera rotation matrix", "shape": "dot", "size": 10.178571428571429, "title": "camera rotation matrix"}, {"color": "#6FA8DC", "id": "identity", "label": "identity", "shape": "dot", "size": 10.089285714285714, "title": "identity"}, {"color": "#6FA8DC", "id": "camera position", "label": "camera position", "shape": "dot", "size": 10.178571428571429, "title": "camera position"}, {"color": "#6FA8DC", "id": "translational velocity", "label": "translational velocity", "shape": "dot", "size": 10.089285714285714, "title": "translational velocity"}, {"color": "#6FA8DC", "id": "angular velocity", "label": "angular velocity", "shape": "dot", "size": 10.089285714285714, "title": "angular velocity"}, {"color": "#6FA8DC", "id": "2%", "label": "2%", "shape": "dot", "size": 10.178571428571429, "title": "2%"}, {"color": "#6FA8DC", "id": "orientation error", "label": "orientation error", "shape": "dot", "size": 10.178571428571429, "title": "orientation error"}, {"color": "#6FA8DC", "id": "0.5 degrees", "label": "0.5 degrees", "shape": "dot", "size": 10.089285714285714, "title": "0.5 degrees"}, {"color": "#6FA8DC", "id": "number of inliers", "label": "number of inliers", "shape": "dot", "size": 10.178571428571429, "title": "number of inliers"}, {"color": "#6FA8DC", "id": "Rolling Shutter Cameras", "label": "Rolling Shutter Cameras", "shape": "dot", "size": 10.089285714285714, "title": "Rolling Shutter Cameras"}, {"color": "#6FA8DC", "id": "Absolute Pose Problem", "label": "Absolute Pose Problem", "shape": "dot", "size": 10.267857142857142, "title": "Absolute Pose Problem"}, {"color": "#6FA8DC", "id": "Polynomial Solvers", "label": "Polynomial Solvers", "shape": "dot", "size": 10.089285714285714, "title": "Polynomial Solvers"}, {"color": "#6FA8DC", "id": "Linearized Camera Models", "label": "Linearized Camera Models", "shape": "dot", "size": 10.089285714285714, "title": "Linearized Camera Models"}, {"color": "#6FA8DC", "id": "model fitting", "label": "model fitting", "shape": "dot", "size": 10.357142857142858, "title": "model fitting"}, {"color": "#6FA8DC", "id": "computer vision problems", "label": "computer vision problems", "shape": "dot", "size": 10.267857142857142, "title": "computer vision problems"}, {"color": "#6FA8DC", "id": "half a degree", "label": "half a degree", "shape": "dot", "size": 10.089285714285714, "title": "half a degree"}, {"color": "#6FA8DC", "id": "relative position error", "label": "relative position error", "shape": "dot", "size": 10.089285714285714, "title": "relative position error"}, {"color": "#6FA8DC", "id": "RANSAC", "label": "RANSAC", "shape": "dot", "size": 10.267857142857142, "title": "RANSAC"}, {"color": "#6FA8DC", "id": "robust model fitting", "label": "robust model fitting", "shape": "dot", "size": 10.267857142857142, "title": "robust model fitting"}, {"color": "#6FA8DC", "id": "structure and motion estimation", "label": "structure and motion estimation", "shape": "dot", "size": 10.446428571428571, "title": "structure and motion estimation"}, {"color": "#6FA8DC", "id": "Haralick", "label": "Haralick", "shape": "dot", "size": 10.089285714285714, "title": "Haralick"}, {"color": "#6FA8DC", "id": "Hedborg", "label": "Hedborg", "shape": "dot", "size": 10.089285714285714, "title": "Hedborg"}, {"color": "#6FA8DC", "id": "RANAC", "label": "RANAC", "shape": "dot", "size": 10.267857142857142, "title": "RANAC"}, {"color": "#6FA8DC", "id": "rolling shutter video", "label": "rolling shutter video", "shape": "dot", "size": 10.535714285714286, "title": "rolling shutter video"}, {"color": "#6FA8DC", "id": "rolling shutter data", "label": "rolling shutter data", "shape": "dot", "size": 10.178571428571429, "title": "rolling shutter data"}, {"color": "#6FA8DC", "id": "bundle adjustment", "label": "bundle adjustment", "shape": "dot", "size": 10.178571428571429, "title": "bundle adjustment"}, {"color": "#6FA8DC", "id": "C. Jia and B. L. Evans", "label": "C. Jia and B. L. Evans", "shape": "dot", "size": 10.089285714285714, "title": "C. Jia and B. L. Evans"}, {"color": "#6FA8DC", "id": "inertial measurements", "label": "inertial measurements", "shape": "dot", "size": 10.267857142857142, "title": "inertial measurements"}, {"color": "#6FA8DC", "id": "motion estimation", "label": "motion estimation", "shape": "dot", "size": 10.267857142857142, "title": "motion estimation"}, {"color": "#6FA8DC", "id": "ter video recti\ufb01cation", "label": "ter video recti\ufb01cation", "shape": "dot", "size": 10.178571428571429, "title": "ter video recti\ufb01cation"}, {"color": "#6FA8DC", "id": "visual SLAM", "label": "visual SLAM", "shape": "dot", "size": 10.267857142857142, "title": "visual SLAM"}, {"color": "#6FA8DC", "id": "parallel tracking and mapping", "label": "parallel tracking and mapping", "shape": "dot", "size": 10.089285714285714, "title": "parallel tracking and mapping"}, {"color": "#6FA8DC", "id": "ISMAR \u201909", "label": "ISMAR \u201909", "shape": "dot", "size": 10.089285714285714, "title": "ISMAR \u201909"}, {"color": "#6FA8DC", "id": "EEE International Symposium on Mixed and augmented Reality", "label": "EEE International Symposium on Mixed and augmented Reality", "shape": "dot", "size": 10.089285714285714, "title": "EEE International Symposium on Mixed and augmented Reality"}, {"color": "#6FA8DC", "id": "Z. Kukelova", "label": "Z. Kukelova", "shape": "dot", "size": 10.178571428571429, "title": "Z. Kukelova"}, {"color": "#6FA8DC", "id": "Singly-bordered block-diagonal form", "label": "Singly-bordered block-diagonal form", "shape": "dot", "size": 10.178571428571429, "title": "Singly-bordered block-diagonal form"}, {"color": "#6FA8DC", "id": "efficient computation", "label": "efficient computation", "shape": "dot", "size": 10.446428571428571, "title": "efficient computation"}, {"color": "#6FA8DC", "id": "Automatic generator of minimal problem solvers", "label": "Automatic generator of minimal problem solvers", "shape": "dot", "size": 10.267857142857142, "title": "Automatic generator of minimal problem solvers"}, {"color": "#6FA8DC", "id": "efficient solvers", "label": "efficient solvers", "shape": "dot", "size": 10.178571428571429, "title": "efficient solvers"}, {"color": "#6FA8DC", "id": "ECCV 2008", "label": "ECCV 2008", "shape": "dot", "size": 10.089285714285714, "title": "ECCV 2008"}, {"color": "#6FA8DC", "id": "Computer Vision - ECCV 2008", "label": "Computer Vision - ECCV 2008", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision - ECCV 2008"}, {"color": "#6FA8DC", "id": "Proceedings", "label": "Proceedings", "shape": "dot", "size": 10.089285714285714, "title": "Proceedings"}, {"color": "#6FA8DC", "id": "5304", "label": "5304", "shape": "dot", "size": 10.089285714285714, "title": "5304"}, {"color": "#6FA8DC", "id": "Cox", "label": "Cox", "shape": "dot", "size": 10.089285714285714, "title": "Cox"}, {"color": "#6FA8DC", "id": "Using Algebraic Geometry", "label": "Using Algebraic Geometry", "shape": "dot", "size": 10.178571428571429, "title": "Using Algebraic Geometry"}, {"color": "#6FA8DC", "id": "Springer", "label": "Springer", "shape": "dot", "size": 10.267857142857142, "title": "Springer"}, {"color": "#6FA8DC", "id": "Czech Technical University in Prague", "label": "Czech Technical University in Prague", "shape": "dot", "size": 10.178571428571429, "title": "Czech Technical University in Prague"}, {"color": "#6FA8DC", "id": "Microsoft Research Ltd", "label": "Microsoft Research Ltd", "shape": "dot", "size": 10.089285714285714, "title": "Microsoft Research Ltd"}, {"color": "#6FA8DC", "id": "Sridhar", "label": "Sridhar", "shape": "dot", "size": 10.178571428571429, "title": "Sridhar"}, {"color": "#6FA8DC", "id": "Fast and Robust Hand Tracking", "label": "Fast and Robust Hand Tracking", "shape": "dot", "size": 10.178571428571429, "title": "Fast and Robust Hand Tracking"}, {"color": "#6FA8DC", "id": "Detection-Guided Optimization", "label": "Detection-Guided Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Detection-Guided Optimization"}, {"color": "#6FA8DC", "id": "Theobalt", "label": "Theobalt", "shape": "dot", "size": 10.089285714285714, "title": "Theobalt"}, {"color": "#6FA8DC", "id": "tracking inaccuracies", "label": "tracking inaccuracies", "shape": "dot", "size": 10.089285714285714, "title": "tracking inaccuracies"}, {"color": "#6FA8DC", "id": "detection-guided optimization strategy", "label": "detection-guided optimization strategy", "shape": "dot", "size": 10.089285714285714, "title": "detection-guided optimization strategy"}, {"color": "#6FA8DC", "id": "model-based generative tracking", "label": "model-based generative tracking", "shape": "dot", "size": 10.089285714285714, "title": "model-based generative tracking"}, {"color": "#6FA8DC", "id": "discriminative hand pose detection", "label": "discriminative hand pose detection", "shape": "dot", "size": 10.089285714285714, "title": "discriminative hand pose detection"}, {"color": "#6FA8DC", "id": "high efficiency", "label": "high efficiency", "shape": "dot", "size": 10.089285714285714, "title": "high efficiency"}, {"color": "#6FA8DC", "id": "robust performance", "label": "robust performance", "shape": "dot", "size": 10.089285714285714, "title": "robust performance"}, {"color": "#6FA8DC", "id": "varying camera-to-scene arrangements", "label": "varying camera-to-scene arrangements", "shape": "dot", "size": 10.089285714285714, "title": "varying camera-to-scene arrangements"}, {"color": "#6FA8DC", "id": "mutual failures", "label": "mutual failures", "shape": "dot", "size": 10.089285714285714, "title": "mutual failures"}, {"color": "#6FA8DC", "id": "50 fps", "label": "50 fps", "shape": "dot", "size": 10.089285714285714, "title": "50 fps"}, {"color": "#6FA8DC", "id": "Baak et al.", "label": "Baak et al.", "shape": "dot", "size": 10.089285714285714, "title": "Baak et al."}, {"color": "#6FA8DC", "id": "full body pose reconstruction", "label": "full body pose reconstruction", "shape": "dot", "size": 10.178571428571429, "title": "full body pose reconstruction"}, {"color": "#6FA8DC", "id": "Ballan et al.", "label": "Ballan et al.", "shape": "dot", "size": 10.089285714285714, "title": "Ballan et al."}, {"color": "#6FA8DC", "id": "motion capture of hands", "label": "motion capture of hands", "shape": "dot", "size": 10.089285714285714, "title": "motion capture of hands"}, {"color": "#6FA8DC", "id": "Bhattacharyya", "label": "Bhattacharyya", "shape": "dot", "size": 10.089285714285714, "title": "Bhattacharyya"}, {"color": "#6FA8DC", "id": "measure of divergence", "label": "measure of divergence", "shape": "dot", "size": 10.089285714285714, "title": "measure of divergence"}, {"color": "#6FA8DC", "id": "Criminisi and Shotton", "label": "Criminisi and Shotton", "shape": "dot", "size": 10.089285714285714, "title": "Criminisi and Shotton"}, {"color": "#6FA8DC", "id": "Decision forests", "label": "Decision forests", "shape": "dot", "size": 10.089285714285714, "title": "Decision forests"}, {"color": "#6FA8DC", "id": "Srinath Srilhar", "label": "Srinath Srilhar", "shape": "dot", "size": 10.089285714285714, "title": "Srinath Srilhar"}, {"color": "#6FA8DC", "id": "A. Criminisi", "label": "A. Criminisi", "shape": "dot", "size": 10.357142857142858, "title": "A. Criminisi"}, {"color": "#6FA8DC", "id": "Decision forests for computer vision", "label": "Decision forests for computer vision", "shape": "dot", "size": 10.178571428571429, "title": "Decision forests for computer vision"}, {"color": "#6FA8DC", "id": "J. Shotton", "label": "J. Shotton", "shape": "dot", "size": 10.267857142857142, "title": "J. Shotton"}, {"color": "#6FA8DC", "id": "S. R. Fanello", "label": "S. R. Fanello", "shape": "dot", "size": 10.089285714285714, "title": "S. R. Fanello"}, {"color": "#6FA8DC", "id": "Learning to be a depth camera", "label": "Learning to be a depth camera", "shape": "dot", "size": 10.267857142857142, "title": "Learning to be a depth camera"}, {"color": "#6FA8DC", "id": "Efficient regression of general-activity human poses", "label": "Efficient regression of general-activity human poses", "shape": "dot", "size": 10.267857142857142, "title": "Efficient regression of general-activity human poses"}, {"color": "#6FA8DC", "id": "H. Hamer", "label": "H. Hamer", "shape": "dot", "size": 10.089285714285714, "title": "H. Hamer"}, {"color": "#6FA8DC", "id": "Tracking a hand manipulating an object", "label": "Tracking a hand manipulating an object", "shape": "dot", "size": 10.089285714285714, "title": "Tracking a hand manipulating an object"}, {"color": "#6FA8DC", "id": "C. Keskin", "label": "C. Keskin", "shape": "dot", "size": 10.178571428571429, "title": "C. Keskin"}, {"color": "#6FA8DC", "id": "Real time hand pose estimation", "label": "Real time hand pose estimation", "shape": "dot", "size": 10.089285714285714, "title": "Real time hand pose estimation"}, {"color": "#6FA8DC", "id": "ICCV Workshops", "label": "ICCV Workshops", "shape": "dot", "size": 10.267857142857142, "title": "ICCV Workshops"}, {"color": "#6FA8DC", "id": "F. Kirac", "label": "F. Kirac", "shape": "dot", "size": 10.089285714285714, "title": "F. Kirac"}, {"color": "#6FA8DC", "id": "Y. Kara", "label": "Y. Kara", "shape": "dot", "size": 10.089285714285714, "title": "Y. Kara"}, {"color": "#6FA8DC", "id": "L. Akarun", "label": "L. Akarun", "shape": "dot", "size": 10.089285714285714, "title": "L. Akarun"}, {"color": "#6FA8DC", "id": "Srinath Sridhar", "label": "Srinath Sridhar", "shape": "dot", "size": 10.089285714285714, "title": "Srinath Sridhar"}, {"color": "#6FA8DC", "id": "Antti Oulasvirta", "label": "Antti Oulasvirta", "shape": "dot", "size": 10.089285714285714, "title": "Antti Oulasvirta"}, {"color": "#6FA8DC", "id": "Aalto University", "label": "Aalto University", "shape": "dot", "size": 10.089285714285714, "title": "Aalto University"}, {"color": "#6FA8DC", "id": "Fumin Shen", "label": "Fumin Shen", "shape": "dot", "size": 10.178571428571429, "title": "Fumin Shen"}, {"color": "#6FA8DC", "id": "Supervised Discrete Hashing", "label": "Supervised Discrete Hashing", "shape": "dot", "size": 10.446428571428571, "title": "Supervised Discrete Hashing"}, {"color": "#6FA8DC", "id": "Heng Tao Shen", "label": "Heng Tao Shen", "shape": "dot", "size": 10.178571428571429, "title": "Heng Tao Shen"}, {"color": "#6FA8DC", "id": "Supervised Discrete Hanning (SDH)", "label": "Supervised Discrete Hanning (SDH)", "shape": "dot", "size": 10.178571428571429, "title": "Supervised Discrete Hanning (SDH)"}, {"color": "#6FA8DC", "id": "hashing framework", "label": "hashing framework", "shape": "dot", "size": 10.089285714285714, "title": "hashing framework"}, {"color": "#6FA8DC", "id": "linear classification", "label": "linear classification", "shape": "dot", "size": 10.089285714285714, "title": "linear classification"}, {"color": "#6FA8DC", "id": "handling discrete constraints", "label": "handling discrete constraints", "shape": "dot", "size": 10.089285714285714, "title": "handling discrete constraints"}, {"color": "#6FA8DC", "id": "NP-hard optimization problems", "label": "NP-hard optimization problems", "shape": "dot", "size": 10.089285714285714, "title": "NP-hard optimization problems"}, {"color": "#6FA8DC", "id": "objective", "label": "objective", "shape": "dot", "size": 10.178571428571429, "title": "objective"}, {"color": "#6FA8DC", "id": "introducing an auxiliary variable and regularization algorithm", "label": "introducing an auxiliary variable and regularization algorithm", "shape": "dot", "size": 10.089285714285714, "title": "introducing an auxiliary variable and regularization algorithm"}, {"color": "#6FA8DC", "id": "cyclic coordinate descent", "label": "cyclic coordinate descent", "shape": "dot", "size": 10.089285714285714, "title": "cyclic coordinate descent"}, {"color": "#6FA8DC", "id": "regularization sub-problem", "label": "regularization sub-problem", "shape": "dot", "size": 10.089285714285714, "title": "regularization sub-problem"}, {"color": "#6FA8DC", "id": "SDH", "label": "SDH", "shape": "dot", "size": 10.446428571428571, "title": "SDH"}, {"color": "#6FA8DC", "id": "high-quality discrete solutions", "label": "high-quality discrete solutions", "shape": "dot", "size": 10.089285714285714, "title": "high-quality discrete solutions"}, {"color": "#6FA8DC", "id": "handling of massive datasets", "label": "handling of massive datasets", "shape": "dot", "size": 10.178571428571429, "title": "handling of massive datasets"}, {"color": "#6FA8DC", "id": "four large image datasets", "label": "four large image datasets", "shape": "dot", "size": 10.089285714285714, "title": "four large image datasets"}, {"color": "#6FA8DC", "id": "Hashing", "label": "Hashing", "shape": "dot", "size": 10.267857142857142, "title": "Hashing"}, {"color": "#6FA8DC", "id": "p-stable distributions", "label": "p-stable distributions", "shape": "dot", "size": 10.089285714285714, "title": "p-stable distributions"}, {"color": "#6FA8DC", "id": "hashing technique", "label": "hashing technique", "shape": "dot", "size": 10.267857142857142, "title": "hashing technique"}, {"color": "#6FA8DC", "id": "bilinear projections", "label": "bilinear projections", "shape": "dot", "size": 10.446428571428571, "title": "bilinear projections"}, {"color": "#6FA8DC", "id": "learning binary codes", "label": "learning binary codes", "shape": "dot", "size": 10.446428571428571, "title": "learning binary codes"}, {"color": "#6FA8DC", "id": "Belkin, M., \u0026 Niyogi, P.", "label": "Belkin, M., \u0026 Niyogi, P.", "shape": "dot", "size": 10.089285714285714, "title": "Belkin, M., \u0026 Niyogi, P."}, {"color": "#6FA8DC", "id": "foundational paper", "label": "foundational paper", "shape": "dot", "size": 10.089285714285714, "title": "foundational paper"}, {"color": "#6FA8DC", "id": "Datar, N., et al.", "label": "Datar, N., et al.", "shape": "dot", "size": 10.089285714285714, "title": "Datar, N., et al."}, {"color": "#6FA8DC", "id": "Gong, Y., et al.", "label": "Gong, Y., et al.", "shape": "dot", "size": 10.089285714285714, "title": "Gong, Y., et al."}, {"color": "#6FA8DC", "id": "Rowley et al. (2013) paper", "label": "Rowley et al. (2013) paper", "shape": "dot", "size": 10.089285714285714, "title": "Rowley et al. (2013) paper"}, {"color": "#6FA8DC", "id": "Weiss et al. (2008) paper", "label": "Weiss et al. (2008) paper", "shape": "dot", "size": 10.089285714285714, "title": "Weiss et al. (2008) paper"}, {"color": "#6FA8DC", "id": "spectral hashing", "label": "spectral hashing", "shape": "dot", "size": 10.178571428571429, "title": "spectral hashing"}, {"color": "#6FA8DC", "id": "contribution to field", "label": "contribution to field", "shape": "dot", "size": 10.089285714285714, "title": "contribution to field"}, {"color": "#6FA8DC", "id": "Gong et al. (2013) paper", "label": "Gong et al. (2013) paper", "shape": "dot", "size": 10.089285714285714, "title": "Gong et al. (2013) paper"}, {"color": "#6FA8DC", "id": "iterative quantization approach", "label": "iterative quantization approach", "shape": "dot", "size": 10.267857142857142, "title": "iterative quantization approach"}, {"color": "#6FA8DC", "id": "procustean approach", "label": "procustean approach", "shape": "dot", "size": 10.089285714285714, "title": "procustean approach"}, {"color": "#6FA8DC", "id": "Kulis \u0026 Darrell (2009) paper", "label": "Kulis \u0026 Darrell (2009) paper", "shape": "dot", "size": 10.089285714285714, "title": "Kulis \u0026 Darrell (2009) paper"}, {"color": "#6FA8DC", "id": "method for learning to hash", "label": "method for learning to hash", "shape": "dot", "size": 10.178571428571429, "title": "method for learning to hash"}, {"color": "#6FA8DC", "id": "binary reconstructive embeddings", "label": "binary reconstructive embeddings", "shape": "dot", "size": 10.178571428571429, "title": "binary reconstructive embeddings"}, {"color": "#6FA8DC", "id": "Kulis \u0026 Darrell (2009)", "label": "Kulis \u0026 Darrell (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Kulis \u0026 Darrell (2009)"}, {"color": "#6FA8DC", "id": "binary reconstructive embeddings hashing method", "label": "binary reconstructive embeddings hashing method", "shape": "dot", "size": 10.178571428571429, "title": "binary reconstructive embeddings hashing method"}, {"color": "#6FA8DC", "id": "Liu, Wang, Kumar, \u0026 Chang (2011)", "label": "Liu, Wang, Kumar, \u0026 Chang (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Liu, Wang, Kumar, \u0026 Chang (2011)"}, {"color": "#6FA8DC", "id": "hashing techniques", "label": "hashing techniques", "shape": "dot", "size": 10.267857142857142, "title": "hashing techniques"}, {"color": "#6FA8DC", "id": "graph structures", "label": "graph structures", "shape": "dot", "size": 10.089285714285714, "title": "graph structures"}, {"color": "#6FA8DC", "id": "Wang, Kumar, \u0026 Chang (2012)", "label": "Wang, Kumar, \u0026 Chang (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Wang, Kumar, \u0026 Chang (2012)"}, {"color": "#6FA8DC", "id": "hashing", "label": "hashing", "shape": "dot", "size": 10.178571428571429, "title": "hashing"}, {"color": "#6FA8DC", "id": "semi-supervised setting", "label": "semi-supervised setting", "shape": "dot", "size": 10.089285714285714, "title": "semi-supervised setting"}, {"color": "#6FA8DC", "id": "Shen \u0026 Hao (2011)", "label": "Shen \u0026 Hao (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Shen \u0026 Hao (2011)"}, {"color": "#6FA8DC", "id": "learning and classification", "label": "learning and classification", "shape": "dot", "size": 10.089285714285714, "title": "learning and classification"}, {"color": "#6FA8DC", "id": "Norouzi \u0026 Blei (2011)", "label": "Norouzi \u0026 Blei (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Norouzi \u0026 Blei (2011)"}, {"color": "#6FA8DC", "id": "minimal loss hashing", "label": "minimal loss hashing", "shape": "dot", "size": 10.267857142857142, "title": "minimal loss hashing"}, {"color": "#6FA8DC", "id": "Blei", "label": "Blei", "shape": "dot", "size": 10.089285714285714, "title": "Blei"}, {"color": "#6FA8DC", "id": "University of Electronic Science and Technology of China", "label": "University of Electronic Science and Technology of China", "shape": "dot", "size": 10.089285714285714, "title": "University of Electronic Science and Technology of China"}, {"color": "#6FA8DC", "id": "IBM Research", "label": "IBM Research", "shape": "dot", "size": 10.089285714285714, "title": "IBM Research"}, {"color": "#6FA8DC", "id": "The University of Queensland", "label": "The University of Queensland", "shape": "dot", "size": 10.089285714285714, "title": "The University of Queensland"}, {"color": "#6FA8DC", "id": "A Maximum Entropy Feature Descriptor", "label": "A Maximum Entropy Feature Descriptor", "shape": "dot", "size": 10.535714285714286, "title": "A Maximum Entropy Feature Descriptor"}, {"color": "#6FA8DC", "id": "Li, Zhifeng", "label": "Li, Zhifeng", "shape": "dot", "size": 10.178571428571429, "title": "Li, Zhifeng"}, {"color": "#6FA8DC", "id": "Tao, Dacheng", "label": "Tao, Dacheng", "shape": "dot", "size": 10.089285714285714, "title": "Tao, Dacheng"}, {"color": "#6FA8DC", "id": "Liu, Jianzhang", "label": "Liu, Jianzhang", "shape": "dot", "size": 10.089285714285714, "title": "Liu, Jianzhang"}, {"color": "#6FA8DC", "id": "Li, Xuelong", "label": "Li, Xuelong", "shape": "dot", "size": 10.089285714285714, "title": "Li, Xuelong"}, {"color": "#6FA8DC", "id": "Age Invariant Face Recognition", "label": "Age Invariant Face Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Age Invariant Face Recognition"}, {"color": "#6FA8DC", "id": "age invariant face recognition", "label": "age invariant face recognition", "shape": "dot", "size": 10.089285714285714, "title": "age invariant face recognition"}, {"color": "#6FA8DC", "id": "maximum entropy feature descriptor", "label": "maximum entropy feature descriptor", "shape": "dot", "size": 10.267857142857142, "title": "maximum entropy feature descriptor"}, {"color": "#6FA8DC", "id": "microstructure", "label": "microstructure", "shape": "dot", "size": 10.089285714285714, "title": "microstructure"}, {"color": "#6FA8DC", "id": "discrete codes", "label": "discrete codes", "shape": "dot", "size": 10.089285714285714, "title": "discrete codes"}, {"color": "#6FA8DC", "id": "sampling", "label": "sampling", "shape": "dot", "size": 10.089285714285714, "title": "sampling"}, {"color": "#6FA8DC", "id": "discriminatory information", "label": "discriminatory information", "shape": "dot", "size": 10.089285714285714, "title": "discriminatory information"}, {"color": "#6FA8DC", "id": "identity factor analysis", "label": "identity factor analysis", "shape": "dot", "size": 10.089285714285714, "title": "identity factor analysis"}, {"color": "#6FA8DC", "id": "probability of same identity", "label": "probability of same identity", "shape": "dot", "size": 10.089285714285714, "title": "probability of same identity"}, {"color": "#6FA8DC", "id": "experimentation", "label": "experimentation", "shape": "dot", "size": 10.446428571428571, "title": "experimentation"}, {"color": "#6FA8DC", "id": "MORPH dataset", "label": "MORPH dataset", "shape": "dot", "size": 10.089285714285714, "title": "MORPH dataset"}, {"color": "#6FA8DC", "id": "FGNET dataset", "label": "FGNET dataset", "shape": "dot", "size": 10.089285714285714, "title": "FGNET dataset"}, {"color": "#6FA8DC", "id": "feature descriptor", "label": "feature descriptor", "shape": "dot", "size": 10.089285714285714, "title": "feature descriptor"}, {"color": "#6FA8DC", "id": "MORPH", "label": "MORPH", "shape": "dot", "size": 10.267857142857142, "title": "MORPH"}, {"color": "#6FA8DC", "id": "generalizability", "label": "generalizability", "shape": "dot", "size": 10.089285714285714, "title": "generalizability"}, {"color": "#6FA8DC", "id": "face aging dataset", "label": "face aging dataset", "shape": "dot", "size": 10.178571428571429, "title": "face aging dataset"}, {"color": "#6FA8DC", "id": "FGNET", "label": "FGNET", "shape": "dot", "size": 10.178571428571429, "title": "FGNET"}, {"color": "#6FA8DC", "id": "Age Invariant Face Recognition (AIFR)", "label": "Age Invariant Face Recognition (AIFR)", "shape": "dot", "size": 10.357142857142858, "title": "Age Invariant Face Recognition (AIFR)"}, {"color": "#6FA8DC", "id": "Age Incompliant Face Recognition (AIFR)", "label": "Age Incompliant Face Recognition (AIFR)", "shape": "dot", "size": 10.089285714285714, "title": "Age Incompliant Face Recognition (AIFR)"}, {"color": "#6FA8DC", "id": "Maximum Entropy Feature Descriptor (MEFD)", "label": "Maximum Entropy Feature Descriptor (MEFD)", "shape": "dot", "size": 10.089285714285714, "title": "Maximum Entropy Feature Descriptor (MEFD)"}, {"color": "#6FA8DC", "id": "Identity Factor Analysis (IFA)", "label": "Identity Factor Analysis (IFA)", "shape": "dot", "size": 10.089285714285714, "title": "Identity Factor Analysis (IFA)"}, {"color": "#6FA8DC", "id": "Nonparametric Discriminent Analysis for Face Recognition", "label": "Nonparametric Discriminent Analysis for Face Recognition", "shape": "dot", "size": 10.178571428571429, "title": "Nonparametric Discriminent Analysis for Face Recognition"}, {"color": "#6FA8DC", "id": "Wang, Xiaogang", "label": "Wang, Xiaogang", "shape": "dot", "size": 10.089285714285714, "title": "Wang, Xiaogang"}, {"color": "#6FA8DC", "id": "A unified framework for subspace face recognition", "label": "A unified framework for subspace face recognition", "shape": "dot", "size": 10.178571428571429, "title": "A unified framework for subspace face recognition"}, {"color": "#6FA8DC", "id": "Li, Unsang", "label": "Li, Unsang", "shape": "dot", "size": 10.267857142857142, "title": "Li, Unsang"}, {"color": "#6FA8DC", "id": "A discriminative model for age invariant face recognition", "label": "A discriminative model for age invariant face recognition", "shape": "dot", "size": 10.178571428571429, "title": "A discriminative model for age invariant face recognition"}, {"color": "#6FA8DC", "id": "IEEE Trans. Pattern Anal. Mach. Intell.", "label": "IEEE Trans. Pattern Anal. Mach. Intell.", "shape": "dot", "size": 10.357142857142858, "title": "IEEE Trans. Pattern Anal. Mach. Intell."}, {"color": "#6FA8DC", "id": "IEEE Transactions on Information Forensics and Security", "label": "IEEE Transactions on Information Forensics and Security", "shape": "dot", "size": 10.178571428571429, "title": "IEEE Transactions on Information Forensics and Security"}, {"color": "#6FA8DC", "id": "Park, Unsav", "label": "Park, Unsav", "shape": "dot", "size": 10.178571428571429, "title": "Park, Unsav"}, {"color": "#6FA8DC", "id": "Belhumeur, Peter N.", "label": "Belhumeur, Peter N.", "shape": "dot", "size": 10.089285714285714, "title": "Belhumeur, Peter N."}, {"color": "#6FA8DC", "id": "Gong, D.", "label": "Gong, D.", "shape": "dot", "size": 10.089285714285714, "title": "Gong, D."}, {"color": "#6FA8DC", "id": "ICCV 2013", "label": "ICCV 2013", "shape": "dot", "size": 10.089285714285714, "title": "ICCV 2013"}, {"color": "#6FA8DC", "id": "Huang, G.B.", "label": "Huang, G.B.", "shape": "dot", "size": 10.089285714285714, "title": "Huang, G.B."}, {"color": "#6FA8DC", "id": "Labelled faces in the wild", "label": "Labelled faces in the wild", "shape": "dot", "size": 10.357142857142858, "title": "Labelled faces in the wild"}, {"color": "#6FA8DC", "id": "Zhifeng Li", "label": "Zhifeng Li", "shape": "dot", "size": 10.267857142857142, "title": "Zhifeng Li"}, {"color": "#6FA8DC", "id": "Yiying Tong", "label": "Yiying Tong", "shape": "dot", "size": 10.089285714285714, "title": "Yiying Tong"}, {"color": "#6FA8DC", "id": "face recognition in unconstrained environments", "label": "face recognition in unconstrained environments", "shape": "dot", "size": 10.089285714285714, "title": "face recognition in unconstrained environments"}, {"color": "#6FA8DC", "id": "Technical Report 07-49", "label": "Technical Report 07-49", "shape": "dot", "size": 10.089285714285714, "title": "Technical Report 07-49"}, {"color": "#6FA8DC", "id": "Nonparametric Discriminant Analysis for Face Recognition", "label": "Nonparametric Discriminant Analysis for Face Recognition", "shape": "dot", "size": 10.178571428571429, "title": "Nonparametric Discriminant Analysis for Face Recognition"}, {"color": "#6FA8DC", "id": "Random sampling LDA", "label": "Random sampling LDA", "shape": "dot", "size": 10.089285714285714, "title": "Random sampling LDA"}, {"color": "#6FA8DC", "id": "DiHong Gong", "label": "DiHong Gong", "shape": "dot", "size": 10.089285714285714, "title": "DiHong Gong"}, {"color": "#6FA8DC", "id": "Shenzhen Key Lab of Computer Vision and Pattern Recognition", "label": "Shenzhen Key Lab of Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.267857142857142, "title": "Shenzhen Key Lab of Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "Dihong Gong", "label": "Dihong Gong", "shape": "dot", "size": 10.089285714285714, "title": "Dihong Gong"}, {"color": "#6FA8DC", "id": "Shenzhen Key Lab of Computer Vision and Pattern Recogniton", "label": "Shenzhen Key Lab of Computer Vision and Pattern Recogniton", "shape": "dot", "size": 10.089285714285714, "title": "Shenzhen Key Lab of Computer Vision and Pattern Recogniton"}, {"color": "#6FA8DC", "id": "Dacheng Tao", "label": "Dacheng Tao", "shape": "dot", "size": 10.089285714285714, "title": "Dacheng Tao"}, {"color": "#6FA8DC", "id": "University of Technology, Sydney", "label": "University of Technology, Sydney", "shape": "dot", "size": 10.089285714285714, "title": "University of Technology, Sydney"}, {"color": "#6FA8DC", "id": "Jianzhuang Liu", "label": "Jianzhuang Liu", "shape": "dot", "size": 10.178571428571429, "title": "Jianzhuang Liu"}, {"color": "#6FA8DC", "id": "Dept. of Information Engineering", "label": "Dept. of Information Engineering", "shape": "dot", "size": 10.089285714285714, "title": "Dept. of Information Engineering"}, {"color": "#6FA8DC", "id": "Huawei Technologies Co. Ltd.", "label": "Huawei Technologies Co. Ltd.", "shape": "dot", "size": 10.089285714285714, "title": "Huawei Technologies Co. Ltd."}, {"color": "#6FA8DC", "id": "Xuelong Li", "label": "Xuelong Li", "shape": "dot", "size": 10.089285714285714, "title": "Xuelong Li"}, {"color": "#6FA8DC", "id": "Xi\u0027an Institute of Optics and Precision Mechanics", "label": "Xi\u0027an Institute of Optics and Precision Mechanics", "shape": "dot", "size": 10.178571428571429, "title": "Xi\u0027an Institute of Optics and Precision Mechanics"}, {"color": "#6FA8DC", "id": "Sayed Hossein Khatoonabadi", "label": "Sayed Hossein Khatoonabadi", "shape": "dot", "size": 10.178571428571429, "title": "Sayed Hossein Khatoonabadi"}, {"color": "#6FA8DC", "id": "Sayed Hosheen Khatoonabadi", "label": "Sayed Hosheen Khatoonabadi", "shape": "dot", "size": 10.089285714285714, "title": "Sayed Hosheen Khatoonabadi"}, {"color": "#6FA8DC", "id": "How Many Bits Does It Take for a Stimulus to Be Salient?", "label": "How Many Bits Does It Take for a Stimulus to Be Salient?", "shape": "dot", "size": 10.446428571428571, "title": "How Many Bits Does It Take for a Stimulus to Be Salient?"}, {"color": "#6FA8DC", "id": "Nuno Vasconcelos", "label": "Nuno Vasconcelos", "shape": "dot", "size": 10.178571428571429, "title": "Nuno Vasconcelos"}, {"color": "#6FA8DC", "id": "Yuifeng Shan", "label": "Yuifeng Shan", "shape": "dot", "size": 10.089285714285714, "title": "Yuifeng Shan"}, {"color": "#6FA8DC", "id": "Khatoonabadi_How_Many_Bits_2015_CVPR_paper.pdf", "label": "Khatoonabadi_How_Many_Bits_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Khatoonabadi_How_Many_Bits_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "hanics", "label": "hanics", "shape": "dot", "size": 10.178571428571429, "title": "hanics"}, {"color": "#6FA8DC", "id": "xuelong_li@opt.ac.cn", "label": "xuelong_li@opt.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "xuelong_li@opt.ac.cn"}, {"color": "#6FA8DC", "id": "Stimulus", "label": "Stimulus", "shape": "dot", "size": 10.089285714285714, "title": "Stimulus"}, {"color": "#6FA8DC", "id": "computational models", "label": "computational models", "shape": "dot", "size": 10.089285714285714, "title": "computational models"}, {"color": "#6FA8DC", "id": "early approaches", "label": "early approaches", "shape": "dot", "size": 10.089285714285714, "title": "early approaches"}, {"color": "#6FA8DC", "id": "center-surround filters", "label": "center-surround filters", "shape": "dot", "size": 10.089285714285714, "title": "center-surround filters"}, {"color": "#6FA8DC", "id": "recent works", "label": "recent works", "shape": "dot", "size": 10.089285714285714, "title": "recent works"}, {"color": "#6FA8DC", "id": "general computational principles", "label": "general computational principles", "shape": "dot", "size": 10.089285714285714, "title": "general computational principles"}, {"color": "#6FA8DC", "id": "measure of salience", "label": "measure of salience", "shape": "dot", "size": 10.357142857142858, "title": "measure of salience"}, {"color": "#6FA8DC", "id": "bits required by video compressor", "label": "bits required by video compressor", "shape": "dot", "size": 10.089285714285714, "title": "bits required by video compressor"}, {"color": "#6FA8DC", "id": "predictive power", "label": "predictive power", "shape": "dot", "size": 10.089285714285714, "title": "predictive power"}, {"color": "#6FA8DC", "id": "global salience effects", "label": "global salience effects", "shape": "dot", "size": 10.178571428571429, "title": "global salience effects"}, {"color": "#6FA8DC", "id": "state-of-the-art accuracy", "label": "state-of-the-art accuracy", "shape": "dot", "size": 10.267857142857142, "title": "state-of-the-art accuracy"}, {"color": "#6FA8DC", "id": "probabilistic inference", "label": "probabilistic inference", "shape": "dot", "size": 10.178571428571429, "title": "probabilistic inference"}, {"color": "#6FA8DC", "id": "brain", "label": "brain", "shape": "dot", "size": 10.178571428571429, "title": "brain"}, {"color": "#6FA8DC", "id": "universal compression device", "label": "universal compression device", "shape": "dot", "size": 10.267857142857142, "title": "universal compression device"}, {"color": "#6FA8DC", "id": "Fixation Prediction", "label": "Fixation Prediction", "shape": "dot", "size": 10.089285714285714, "title": "Fixation Prediction"}, {"color": "#6FA8DC", "id": "Salience", "label": "Salience", "shape": "dot", "size": 10.089285714285714, "title": "Salience"}, {"color": "#6FA8DC", "id": "view of the brain", "label": "view of the brain", "shape": "dot", "size": 10.089285714285714, "title": "view of the brain"}, {"color": "#6FA8DC", "id": "Agarwal et al. (2003)", "label": "Agarwal et al. (2003)", "shape": "dot", "size": 10.089285714285714, "title": "Agarwal et al. (2003)"}, {"color": "#6FA8DC", "id": "region-of-interest", "label": "region-of-interest", "shape": "dot", "size": 10.178571428571429, "title": "region-of-interest"}, {"color": "#6FA8DC", "id": "compressed MPEG domain", "label": "compressed MPEG domain", "shape": "dot", "size": 10.089285714285714, "title": "compressed MPEG domain"}, {"color": "#6FA8DC", "id": "Hou and Zhang (2007)", "label": "Hou and Zhang (2007)", "shape": "dot", "size": 10.089285714285714, "title": "Hou and Zhang (2007)"}, {"color": "#6FA8DC", "id": "spectral residual approach", "label": "spectral residual approach", "shape": "dot", "size": 10.178571428571429, "title": "spectral residual approach"}, {"color": "#6FA8DC", "id": "salience detection method", "label": "salience detection method", "shape": "dot", "size": 10.089285714285714, "title": "salience detection method"}, {"color": "#6FA8DC", "id": "Helbing and Molnar (1995)", "label": "Helbing and Molnar (1995)", "shape": "dot", "size": 10.089285714285714, "title": "Helbing and Molnar (1995)"}, {"color": "#6FA8DC", "id": "pedestrian dynamics", "label": "pedestrian dynamics", "shape": "dot", "size": 10.089285714285714, "title": "pedestrian dynamics"}, {"color": "#6FA8DC", "id": "EE CVPR\u201907", "label": "EE CVPR\u201907", "shape": "dot", "size": 10.089285714285714, "title": "EE CVPR\u201907"}, {"color": "#6FA8DC", "id": "Agarwal, G.", "label": "Agarwal, G.", "shape": "dot", "size": 10.089285714285714, "title": "Agarwal, G."}, {"color": "#6FA8DC", "id": "Anstis, S. M.", "label": "Anstis, S. M.", "shape": "dot", "size": 10.089285714285714, "title": "Anstis, S. M."}, {"color": "#6FA8DC", "id": "perception of apparent movement", "label": "perception of apparent movement", "shape": "dot", "size": 10.089285714285714, "title": "perception of apparent movement"}, {"color": "#6FA8DC", "id": "Attneave, F.", "label": "Attneave, F.", "shape": "dot", "size": 10.089285714285714, "title": "Attneave, F."}, {"color": "#6FA8DC", "id": "Informational aspects of visual perception", "label": "Informational aspects of visual perception", "shape": "dot", "size": 10.089285714285714, "title": "Informational aspects of visual perception"}, {"color": "#6FA8DC", "id": "Barlow, H.", "label": "Barlow, H.", "shape": "dot", "size": 10.178571428571429, "title": "Barlow, H."}, {"color": "#6FA8DC", "id": "Cerebral cortex as a model builder", "label": "Cerebral cortex as a model builder", "shape": "dot", "size": 10.089285714285714, "title": "Cerebral cortex as a model builder"}, {"color": "#6FA8DC", "id": "Redundancy reduction revisited", "label": "Redundancy reduction revisited", "shape": "dot", "size": 10.089285714285714, "title": "Redundancy reduction revisited"}, {"color": "#6FA8DC", "id": "Besag, J.", "label": "Besag, J.", "shape": "dot", "size": 10.089285714285714, "title": "Besag, J."}, {"color": "#6FA8DC", "id": "Spatial interaction", "label": "Spatial interaction", "shape": "dot", "size": 10.089285714285714, "title": "Spatial interaction"}, {"color": "#6FA8DC", "id": "Simon Fraser University", "label": "Simon Fraser University", "shape": "dot", "size": 10.178571428571429, "title": "Simon Fraser University"}, {"color": "#6FA8DC", "id": "University of California, San Diego", "label": "University of California, San Diego", "shape": "dot", "size": 10.089285714285714, "title": "University of California, San Diego"}, {"color": "#6FA8DC", "id": "Royal Statistical Society", "label": "Royal Statistical Society", "shape": "dot", "size": 10.089285714285714, "title": "Royal Statistical Society"}, {"color": "#6FA8DC", "id": "Series B", "label": "Series B", "shape": "dot", "size": 10.267857142857142, "title": "Series B"}, {"color": "#6FA8DC", "id": "36", "label": "36", "shape": "dot", "size": 10.089285714285714, "title": "36"}, {"color": "#6FA8DC", "id": "192\u2013236", "label": "192\u2013236", "shape": "dot", "size": 10.089285714285714, "title": "192\u2013236"}, {"color": "#6FA8DC", "id": "Ivan V. Bajic", "label": "Ivan V. Bajic", "shape": "dot", "size": 10.089285714285714, "title": "Ivan V. Bajic"}, {"color": "#6FA8DC", "id": "Limin Wang", "label": "Limin Wang", "shape": "dot", "size": 10.267857142857142, "title": "Limin Wang"}, {"color": "#6FA8DC", "id": "Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors", "label": "Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors", "shape": "dot", "size": 10.267857142857142, "title": "Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors"}, {"color": "#6FA8DC", "id": "Yu Qiao", "label": "Yu Qiao", "shape": "dot", "size": 10.357142857142858, "title": "Yu Qiao"}, {"color": "#6FA8DC", "id": "Xiaoou Tang", "label": "Xiaoou Tang", "shape": "dot", "size": 10.178571428571429, "title": "Xiaoou Tang"}, {"color": "#6FA8DC", "id": "Action Recognized with Trajectory-Pooled Deep-Convolutional Descriptors", "label": "Action Recognized with Trajectory-Pooled Deep-Convolutional Descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Action Recognized with Trajectory-Pooled Deep-Convolutional Descriptors"}, {"color": "#6FA8DC", "id": "TDD", "label": "TDD", "shape": "dot", "size": 10.357142857142858, "title": "TDD"}, {"color": "#6FA8DC", "id": "video representation", "label": "video representation", "shape": "dot", "size": 10.089285714285714, "title": "video representation"}, {"color": "#6FA8DC", "id": "trajectory-constrained pooling", "label": "trajectory-constrained pooling", "shape": "dot", "size": 10.178571428571429, "title": "trajectory-constrained pooling"}, {"color": "#6FA8DC", "id": "feature maps", "label": "feature maps", "shape": "dot", "size": 10.178571428571429, "title": "feature maps"}, {"color": "#6FA8DC", "id": "normalization methods", "label": "normalization methods", "shape": "dot", "size": 10.089285714285714, "title": "normalization methods"}, {"color": "#6FA8DC", "id": "TDDs", "label": "TDDs", "shape": "dot", "size": 10.178571428571429, "title": "TDDs"}, {"color": "#6FA8DC", "id": "deep-learned features", "label": "deep-learned features", "shape": "dot", "size": 10.089285714285714, "title": "deep-learned features"}, {"color": "#6FA8DC", "id": "HMD-B51", "label": "HMD-B51", "shape": "dot", "size": 10.089285714285714, "title": "HMD-B51"}, {"color": "#6FA8DC", "id": "UCF101", "label": "UCF101", "shape": "dot", "size": 10.089285714285714, "title": "UCF101"}, {"color": "#6FA8DC", "id": "Human Action Recognition", "label": "Human Action Recognition", "shape": "dot", "size": 10.267857142857142, "title": "Human Action Recognition"}, {"color": "#6FA8DC", "id": "Deep Convolutional Descriptors", "label": "Deep Convolutional Descriptors", "shape": "dot", "size": 10.089285714285714, "title": "Deep Convolutional Descriptors"}, {"color": "#6FA8DC", "id": "Trajectory-Constrained Pooling", "label": "Trajectory-Constrained Pooling", "shape": "dot", "size": 10.089285714285714, "title": "Trajectory-Constrained Pooling"}, {"color": "#6FA8DC", "id": "Multi-view super vector", "label": "Multi-view super vector", "shape": "dot", "size": 10.089285714285714, "title": "Multi-view super vector"}, {"color": "#6FA8DC", "id": "Convolutional Nets", "label": "Convolutional Nets", "shape": "dot", "size": 10.089285714285714, "title": "Convolutional Nets"}, {"color": "#6FA8DC", "id": "Aggarwal, J. K., \u0026 Ryoo, M. S.", "label": "Aggarwal, J. K., \u0026 Ryoo, M. S.", "shape": "dot", "size": 10.089285714285714, "title": "Aggarwal, J. K., \u0026 Ryoo, M. S."}, {"color": "#6FA8DC", "id": "Human activity analysis review", "label": "Human activity analysis review", "shape": "dot", "size": 10.089285714285714, "title": "Human activity analysis review"}, {"color": "#6FA8DC", "id": "Bay, H., Tuytelaars, T., \u0026 Van Gool, L. J.", "label": "Bay, H., Tuytelaars, T., \u0026 Van Gool, L. J.", "shape": "dot", "size": 10.089285714285714, "title": "Bay, H., Tuytelaars, T., \u0026 Van Gool, L. J."}, {"color": "#6FA8DC", "id": "SURF description", "label": "SURF description", "shape": "dot", "size": 10.089285714285714, "title": "SURF description"}, {"color": "#6FA8DC", "id": "Karpathy et al.", "label": "Karpathy et al.", "shape": "dot", "size": 10.089285714285714, "title": "Karpathy et al."}, {"color": "#6FA8DC", "id": "HMDB", "label": "HMDB", "shape": "dot", "size": 10.267857142857142, "title": "HMDB"}, {"color": "#6FA8DC", "id": "video database", "label": "video database", "shape": "dot", "size": 10.089285714285714, "title": "video database"}, {"color": "#6FA8DC", "id": "human motion recognition", "label": "human motion recognition", "shape": "dot", "size": 10.089285714285714, "title": "human motion recognition"}, {"color": "#6FA8DC", "id": "Department of Information Engineering", "label": "Department of Information Engineering", "shape": "dot", "size": 10.178571428571429, "title": "Department of Information Engineering"}, {"color": "#6FA8DC", "id": "07wanglimin@gmail.com", "label": "07wanglimin@gmail.com", "shape": "dot", "size": 10.089285714285714, "title": "07wanglimin@gmail.com"}, {"color": "#6FA8DC", "id": "researcher", "label": "researcher", "shape": "dot", "size": 10.089285714285714, "title": "researcher"}, {"color": "#6FA8DC", "id": "T", "label": "T", "shape": "dot", "size": 10.178571428571429, "title": "T"}, {"color": "#6FA8DC", "id": "CAS", "label": "CAS", "shape": "dot", "size": 10.089285714285714, "title": "CAS"}, {"color": "#6FA8DC", "id": "Jing Shao", "label": "Jing Shao", "shape": "dot", "size": 10.178571428571429, "title": "Jing Shao"}, {"color": "#6FA8DC", "id": "Deeply Learned Attributes", "label": "Deeply Learned Attributes", "shape": "dot", "size": 10.446428571428571, "title": "Deeply Learned Attributes"}, {"color": "#6FA8DC", "id": "Kai Kang", "label": "Kai Kang", "shape": "dot", "size": 10.178571428571429, "title": "Kai Kang"}, {"color": "#6FA8DC", "id": "Chen Change Loy", "label": "Chen Change Loy", "shape": "dot", "size": 10.089285714285714, "title": "Chen Change Loy"}, {"color": "#6FA8DC", "id": "Crowded scene understanding", "label": "Crowded scene understanding", "shape": "dot", "size": 10.089285714285714, "title": "Crowded scene understanding"}, {"color": "#6FA8DC", "id": "Deep model", "label": "Deep model", "shape": "dot", "size": 10.178571428571429, "title": "Deep model"}, {"color": "#6FA8DC", "id": "appearance features", "label": "appearance features", "shape": "dot", "size": 10.089285714285714, "title": "appearance features"}, {"color": "#6FA8DC", "id": "motion features", "label": "motion features", "shape": "dot", "size": 10.089285714285714, "title": "motion features"}, {"color": "#6FA8DC", "id": "Crowd motion channels", "label": "Crowd motion channels", "shape": "dot", "size": 10.178571428571429, "title": "Crowd motion channels"}, {"color": "#6FA8DC", "id": "deep model", "label": "deep model", "shape": "dot", "size": 10.089285714285714, "title": "deep model"}, {"color": "#6FA8DC", "id": "generic properties of crowd systems", "label": "generic properties of crowd systems", "shape": "dot", "size": 10.089285714285714, "title": "generic properties of crowd systems"}, {"color": "#6FA8DC", "id": "WWW Crowd dataset", "label": "WWW Crowd dataset", "shape": "dot", "size": 10.267857142857142, "title": "WWW Crowd dataset"}, {"color": "#6FA8DC", "id": "10,000 videos", "label": "10,000 videos", "shape": "dot", "size": 10.089285714285714, "title": "10,000 videos"}, {"color": "#6FA8DC", "id": "8,257 crowded scenes", "label": "8,257 crowded scenes", "shape": "dot", "size": 10.089285714285714, "title": "8,257 crowded scenes"}, {"color": "#6FA8DC", "id": "Attribute set", "label": "Attribute set", "shape": "dot", "size": 10.089285714285714, "title": "Attribute set"}, {"color": "#6FA8DC", "id": "94 attributes", "label": "94 attributes", "shape": "dot", "size": 10.089285714285714, "title": "94 attributes"}, {"color": "#6FA8DC", "id": "Deep models", "label": "Deep models", "shape": "dot", "size": 10.089285714285714, "title": "Deep models"}, {"color": "#6FA8DC", "id": "significant performance improvements", "label": "significant performance improvements", "shape": "dot", "size": 10.267857142857142, "title": "significant performance improvements"}, {"color": "#6FA8DC", "id": "cross-scene attribute recognition", "label": "cross-scene attribute recognition", "shape": "dot", "size": 10.267857142857142, "title": "cross-scene attribute recognition"}, {"color": "#6FA8DC", "id": "deep models", "label": "deep models", "shape": "dot", "size": 10.357142857142858, "title": "deep models"}, {"color": "#6FA8DC", "id": "feature-based baselines", "label": "feature-based baselines", "shape": "dot", "size": 10.089285714285714, "title": "feature-based baselines"}, {"color": "#6FA8DC", "id": "deeply learned features", "label": "deeply learned features", "shape": "dot", "size": 10.267857142857142, "title": "deeply learned features"}, {"color": "#6FA8DC", "id": "multi-task learning", "label": "multi-task learning", "shape": "dot", "size": 10.089285714285714, "title": "multi-task learning"}, {"color": "#6FA8DC", "id": "attribute recognition", "label": "attribute recognition", "shape": "dot", "size": 10.178571428571429, "title": "attribute recognition"}, {"color": "#6FA8DC", "id": "cross-scene", "label": "cross-scene", "shape": "dot", "size": 10.089285714285714, "title": "cross-scene"}, {"color": "#6FA8DC", "id": "baselines", "label": "baselines", "shape": "dot", "size": 10.089285714285714, "title": "baselines"}, {"color": "#6FA8DC", "id": "feature-based", "label": "feature-based", "shape": "dot", "size": 10.089285714285714, "title": "feature-based"}, {"color": "#6FA8DC", "id": "Deep learning models", "label": "Deep learning models", "shape": "dot", "size": 10.178571428571429, "title": "Deep learning models"}, {"color": "#6FA8DC", "id": "crowd motion channels", "label": "crowd motion channels", "shape": "dot", "size": 10.089285714285714, "title": "crowd motion channels"}, {"color": "#6FA8DC", "id": "Ali and Shah (2007)", "label": "Ali and Shah (2007)", "shape": "dot", "size": 10.089285714285714, "title": "Ali and Shah (2007)"}, {"color": "#6FA8DC", "id": "crowd flow segmentation", "label": "crowd flow segmentation", "shape": "dot", "size": 10.089285714285714, "title": "crowd flow segmentation"}, {"color": "#6FA8DC", "id": "Ali and Shah (2008)", "label": "Ali and Shah (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Ali and Shah (2008)"}, {"color": "#6FA8DC", "id": "tracking in high density crowd scenes", "label": "tracking in high density crowd scenes", "shape": "dot", "size": 10.089285714285714, "title": "tracking in high density crowd scenes"}, {"color": "#6FA8DC", "id": "Andrade, Blunsden, and Fisher (2006)", "label": "Andrade, Blunsden, and Fisher (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Andrade, Blunsden, and Fisher (2006)"}, {"color": "#6FA8DC", "id": "event detection in crowd scenes", "label": "event detection in crowd scenes", "shape": "dot", "size": 10.089285714285714, "title": "event detection in crowd scenes"}, {"color": "#6FA8DC", "id": "Chan and Vasconcelos (2008)", "label": "Chan and Vasconcelos (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Chan and Vasconcelos (2008)"}, {"color": "#6FA8DC", "id": "video segmentation", "label": "video segmentation", "shape": "dot", "size": 10.714285714285714, "title": "video segmentation"}, {"color": "#6FA8DC", "id": "crowd-related features", "label": "crowd-related features", "shape": "dot", "size": 10.089285714285714, "title": "crowd-related features"}, {"color": "#6FA8DC", "id": "oring", "label": "oring", "shape": "dot", "size": 10.089285714285714, "title": "oring"}, {"color": "#6FA8DC", "id": "CVPR 2008", "label": "CVPR 2008", "shape": "dot", "size": 10.089285714285714, "title": "CVPR 2008"}, {"color": "#6FA8DC", "id": "Modeling, clustering, and segmenting video", "label": "Modeling, clustering, and segmenting video", "shape": "dot", "size": 10.178571428571429, "title": "Modeling, clustering, and segmenting video"}, {"color": "#6FA8DC", "id": "Vasconcelos, N.", "label": "Vasconcelos, N.", "shape": "dot", "size": 10.089285714285714, "title": "Vasconcelos, N."}, {"color": "#6FA8DC", "id": "Dalal, N.", "label": "Dalal, N.", "shape": "dot", "size": 10.089285714285714, "title": "Dalal, N."}, {"color": "#6FA8DC", "id": "Triggers, B.", "label": "Triggers, B.", "shape": "dot", "size": 10.089285714285714, "title": "Triggers, B."}, {"color": "#6FA8DC", "id": "Farhad, A.", "label": "Farhad, A.", "shape": "dot", "size": 10.089285714285714, "title": "Farhad, A."}, {"color": "#6FA8DC", "id": "Describing objects by their attributes", "label": "Describing objects by their attributes", "shape": "dot", "size": 10.089285714285714, "title": "Describing objects by their attributes"}, {"color": "#6FA8DC", "id": "Hospedales, T.", "label": "Hospedales, T.", "shape": "dot", "size": 10.089285714285714, "title": "Hospedales, T."}, {"color": "#6FA8DC", "id": "A markov clustering topic model", "label": "A markov clustering topic model", "shape": "dot", "size": 10.089285714285714, "title": "A markov clustering topic model"}, {"color": "#6FA8DC", "id": "Kang, K.", "label": "Kang, K.", "shape": "dot", "size": 10.089285714285714, "title": "Kang, K."}, {"color": "#6FA8DC", "id": "Fully convolutional neural networks", "label": "Fully convolutional neural networks", "shape": "dot", "size": 10.178571428571429, "title": "Fully convolutional neural networks"}, {"color": "#6FA8DC", "id": "Wang, X.", "label": "Wang, X.", "shape": "dot", "size": 10.089285714285714, "title": "Wang, X."}, {"color": "#6FA8DC", "id": "eye tracking data", "label": "eye tracking data", "shape": "dot", "size": 10.357142857142858, "title": "eye tracking data"}, {"color": "#6FA8DC", "id": "dominant visual tracks", "label": "dominant visual tracks", "shape": "dot", "size": 10.178571428571429, "title": "dominant visual tracks"}, {"color": "#6FA8DC", "id": "object search algorithm", "label": "object search algorithm", "shape": "dot", "size": 10.089285714285714, "title": "object search algorithm"}, {"color": "#6FA8DC", "id": "spatio-temporal mixed graph", "label": "spatio-temporal mixed graph", "shape": "dot", "size": 10.089285714285714, "title": "spatio-temporal mixed graph"}, {"color": "#6FA8DC", "id": "binary linear integer programming", "label": "binary linear integer programming", "shape": "dot", "size": 10.089285714285714, "title": "binary linear integer programming"}, {"color": "#6FA8DC", "id": "object boundaries", "label": "object boundaries", "shape": "dot", "size": 10.089285714285714, "title": "object boundaries"}, {"color": "#6FA8DC", "id": "grabcut segmentation", "label": "grabcut segmentation", "shape": "dot", "size": 10.089285714285714, "title": "grabcut segmentation"}, {"color": "#6FA8DC", "id": "eye tracking prior", "label": "eye tracking prior", "shape": "dot", "size": 10.089285714285714, "title": "eye tracking prior"}, {"color": "#6FA8DC", "id": "Intriligator \u0026 Cavanagh", "label": "Intriligator \u0026 Cavanagh", "shape": "dot", "size": 10.089285714285714, "title": "Intriligator \u0026 Cavanagh"}, {"color": "#6FA8DC", "id": "Cognitive psychology article", "label": "Cognitive psychology article", "shape": "dot", "size": 10.178571428571429, "title": "Cognitive psychology article"}, {"color": "#6FA8DC", "id": "Itti, Koch, \u0026 Niebur", "label": "Itti, Koch, \u0026 Niebur", "shape": "dot", "size": 10.089285714285714, "title": "Itti, Koch, \u0026 Niebur"}, {"color": "#6FA8DC", "id": "salience-based visual attention model", "label": "salience-based visual attention model", "shape": "dot", "size": 10.267857142857142, "title": "salience-based visual attention model"}, {"color": "#6FA8DC", "id": "rapid scene analysis", "label": "rapid scene analysis", "shape": "dot", "size": 10.089285714285714, "title": "rapid scene analysis"}, {"color": "#6FA8DC", "id": "Judd, Ehinger, Durand, \u0026 Torralba", "label": "Judd, Ehinger, Durand, \u0026 Torralba", "shape": "dot", "size": 10.089285714285714, "title": "Judd, Ehinger, Durand, \u0026 Torralba"}, {"color": "#6FA8DC", "id": "human gaze prediction", "label": "human gaze prediction", "shape": "dot", "size": 10.089285714285714, "title": "human gaze prediction"}, {"color": "#6FA8DC", "id": "Object Extraction", "label": "Object Extraction", "shape": "dot", "size": 10.178571428571429, "title": "Object Extraction"}, {"color": "#6FA8DC", "id": "Binary Linear Integer Programming", "label": "Binary Linear Integer Programming", "shape": "dot", "size": 10.089285714285714, "title": "Binary Linear Integer Programming"}, {"color": "#6FA8DC", "id": "Video Segmentation", "label": "Video Segmentation", "shape": "dot", "size": 10.178571428571429, "title": "Video Segmentation"}, {"color": "#6FA8DC", "id": "scene analysis", "label": "scene analysis", "shape": "dot", "size": 10.089285714285714, "title": "scene analysis"}, {"color": "#6FA8DC", "id": "Judd et al.", "label": "Judd et al.", "shape": "dot", "size": 10.178571428571429, "title": "Judd et al."}, {"color": "#6FA8DC", "id": "Learning to predict where humans look", "label": "Learning to predict where humans look", "shape": "dot", "size": 10.089285714285714, "title": "Learning to predict where humans look"}, {"color": "#6FA8DC", "id": "Computer Vision, 2009 IEEE 12th international conference on", "label": "Computer Vision, 2009 IEEE 12th international conference on", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision, 2009 IEEE 12th international conference on"}, {"color": "#6FA8DC", "id": "Karthikeyan et al. (2012)", "label": "Karthikeyan et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Karthikeyan et al. (2012)"}, {"color": "#6FA8DC", "id": "Uni\ufb01ed probabilistic framework", "label": "Uni\ufb01ed probabilistic framework", "shape": "dot", "size": 10.089285714285714, "title": "Uni\ufb01ed probabilistic framework"}, {"color": "#6FA8DC", "id": "Borji \u0026 Itti", "label": "Borji \u0026 Itti", "shape": "dot", "size": 10.178571428571429, "title": "Borji \u0026 Itti"}, {"color": "#6FA8DC", "id": "Borji, Sihite, \u0026 Itti", "label": "Borji, Sihite, \u0026 Itti", "shape": "dot", "size": 10.178571428571429, "title": "Borji, Sihite, \u0026 Itti"}, {"color": "#6FA8DC", "id": "Salient object detection: A benchmark", "label": "Salient object detection: A benchmark", "shape": "dot", "size": 10.089285714285714, "title": "Salient object detection: A benchmark"}, {"color": "#6FA8DC", "id": "Computer Vision\u2013ECCV 2012", "label": "Computer Vision\u2013ECCV 2012", "shape": "dot", "size": 10.267857142857142, "title": "Computer Vision\u2013ECCV 2012"}, {"color": "#6FA8DC", "id": "Karthikeyan et al. (2013)", "label": "Karthikeyan et al. (2013)", "shape": "dot", "size": 10.178571428571429, "title": "Karthikeyan et al. (2013)"}, {"color": "#6FA8DC", "id": "Learning top-down scene context", "label": "Learning top-down scene context", "shape": "dot", "size": 10.089285714285714, "title": "Learning top-down scene context"}, {"color": "#6FA8DC", "id": "ICIP, IEEE", "label": "ICIP, IEEE", "shape": "dot", "size": 10.089285714285714, "title": "ICIP, IEEE"}, {"color": "#6FA8DC", "id": "pages 414\u2013429", "label": "pages 414\u2013429", "shape": "dot", "size": 10.089285714285714, "title": "pages 414\u2013429"}, {"color": "#6FA8DC", "id": "Karthikeyan, S.", "label": "Karthikeyan, S.", "shape": "dot", "size": 10.178571428571429, "title": "Karthikeyan, S."}, {"color": "#6FA8DC", "id": "University of California Santa Barbara", "label": "University of California Santa Barbara", "shape": "dot", "size": 10.357142857142858, "title": "University of California Santa Barbara"}, {"color": "#6FA8DC", "id": "{karthikeyan, thuyen, manj}@ece.ucsb.edu", "label": "{karthikeyan, thuyen, manj}@ece.ucsb.edu", "shape": "dot", "size": 10.267857142857142, "title": "{karthikeyan, thuyen, manj}@ece.ucsb.edu"}, {"color": "#6FA8DC", "id": "Thuyen Ngo", "label": "Thuyen Ngo", "shape": "dot", "size": 10.178571428571429, "title": "Thuyen Ngo"}, {"color": "#6FA8DC", "id": "Miguel Eckstein", "label": "Miguel Eckstein", "shape": "dot", "size": 10.267857142857142, "title": "Miguel Eckstein"}, {"color": "#6FA8DC", "id": "eckstein@psych.ucsb.edu", "label": "eckstein@psych.ucsb.edu", "shape": "dot", "size": 10.178571428571429, "title": "eckstein@psych.ucsb.edu"}, {"color": "#6FA8DC", "id": "B.S. Manjunath", "label": "B.S. Manjunath", "shape": "dot", "size": 10.178571428571429, "title": "B.S. Manjunath"}, {"color": "#6FA8DC", "id": "Felzenszwalb, P.", "label": "Felzenszwalb, P.", "shape": "dot", "size": 10.089285714285714, "title": "Felzenszwalb, P."}, {"color": "#6FA8DC", "id": "Eckstein, M. P.", "label": "Eckstein, M. P.", "shape": "dot", "size": 10.089285714285714, "title": "Eckstein, M. P."}, {"color": "#6FA8DC", "id": "Visual search: A retrospective", "label": "Visual search: A retrospective", "shape": "dot", "size": 10.089285714285714, "title": "Visual search: A retrospective"}, {"color": "#6FA8DC", "id": "Shervin Ardeshir", "label": "Shervin Ardeshir", "shape": "dot", "size": 10.089285714285714, "title": "Shervin Ardeshir"}, {"color": "#6FA8DC", "id": "Geo-Semantic Segmentation", "label": "Geo-Semantic Segmentation", "shape": "dot", "size": 10.357142857142858, "title": "Geo-Semantic Segmentation"}, {"color": "#6FA8DC", "id": "Ko\ufb01 Malcolm Collins-Sibley", "label": "Ko\ufb01 Malcolm Collins-Sibley", "shape": "dot", "size": 10.089285714285714, "title": "Ko\ufb01 Malcolm Collins-Sibley"}, {"color": "#6FA8DC", "id": "Mubarak Shah", "label": "Mubarak Shah", "shape": "dot", "size": 10.267857142857142, "title": "Mubarak Shah"}, {"color": "#6FA8DC", "id": "geo-semantic segmentation method", "label": "geo-semantic segmentation method", "shape": "dot", "size": 10.267857142857142, "title": "geo-semantic segmentation method"}, {"color": "#6FA8DC", "id": "GIS databases", "label": "GIS databases", "shape": "dot", "size": 10.089285714285714, "title": "GIS databases"}, {"color": "#6FA8DC", "id": "GIS projections alignment", "label": "GIS projections alignment", "shape": "dot", "size": 10.089285714285714, "title": "GIS projections alignment"}, {"color": "#6FA8DC", "id": "GIS data", "label": "GIS data", "shape": "dot", "size": 10.267857142857142, "title": "GIS data"}, {"color": "#6FA8DC", "id": "building locations", "label": "building locations", "shape": "dot", "size": 10.089285714285714, "title": "building locations"}, {"color": "#6FA8DC", "id": "street locations", "label": "street locations", "shape": "dot", "size": 10.089285714285714, "title": "street locations"}, {"color": "#6FA8DC", "id": "projections", "label": "projections", "shape": "dot", "size": 10.535714285714286, "title": "projections"}, {"color": "#6FA8DC", "id": "GPS errors", "label": "GPS errors", "shape": "dot", "size": 10.089285714285714, "title": "GPS errors"}, {"color": "#6FA8DC", "id": "camera parameter inaccuracies", "label": "camera parameter inaccuracies", "shape": "dot", "size": 10.089285714285714, "title": "camera parameter inaccuracies"}, {"color": "#6FA8DC", "id": "data fusion approach", "label": "data fusion approach", "shape": "dot", "size": 10.089285714285714, "title": "data fusion approach"}, {"color": "#6FA8DC", "id": "projections reliability", "label": "projections reliability", "shape": "dot", "size": 10.089285714285714, "title": "projections reliability"}, {"color": "#6FA8DC", "id": "super-pixel segmentations", "label": "super-pixel segmentations", "shape": "dot", "size": 10.089285714285714, "title": "super-pixel segmentations"}, {"color": "#6FA8DC", "id": "alignment of projections", "label": "alignment of projections", "shape": "dot", "size": 10.178571428571429, "title": "alignment of projections"}, {"color": "#6FA8DC", "id": "alignment", "label": "alignment", "shape": "dot", "size": 10.267857142857142, "title": "alignment"}, {"color": "#6FA8DC", "id": "random walks", "label": "random walks", "shape": "dot", "size": 10.267857142857142, "title": "random walks"}, {"color": "#6FA8DC", "id": "global transformations", "label": "global transformations", "shape": "dot", "size": 10.267857142857142, "title": "global transformations"}, {"color": "#6FA8DC", "id": "segmentations", "label": "segmentations", "shape": "dot", "size": 10.089285714285714, "title": "segmentations"}, {"color": "#6FA8DC", "id": "semantically segmented images", "label": "semantically segmented images", "shape": "dot", "size": 10.089285714285714, "title": "semantically segmented images"}, {"color": "#6FA8DC", "id": "geo-references", "label": "geo-references", "shape": "dot", "size": 10.178571428571429, "title": "geo-references"}, {"color": "#6FA8DC", "id": "addresses", "label": "addresses", "shape": "dot", "size": 10.089285714285714, "title": "addresses"}, {"color": "#6FA8DC", "id": "geo-locations", "label": "geo-locations", "shape": "dot", "size": 10.089285714285714, "title": "geo-locations"}, {"color": "#6FA8DC", "id": "geo-referenced images", "label": "geo-referenced images", "shape": "dot", "size": 10.089285714285714, "title": "geo-referenced images"}, {"color": "#6FA8DC", "id": "image processing technique", "label": "image processing technique", "shape": "dot", "size": 10.178571428571429, "title": "image processing technique"}, {"color": "#6FA8DC", "id": "Geo-semantic Segmentation", "label": "Geo-semantic Segmentation", "shape": "dot", "size": 10.446428571428571, "title": "Geo-semantic Segmentation"}, {"color": "#6FA8DC", "id": "Random Walks", "label": "Random Walks", "shape": "dot", "size": 10.089285714285714, "title": "Random Walks"}, {"color": "#6FA8DC", "id": "Global Transformations", "label": "Global Transformations", "shape": "dot", "size": 10.089285714285714, "title": "Global Transformations"}, {"color": "#6FA8DC", "id": "Semantically Segmented Images", "label": "Semantically Segmented Images", "shape": "dot", "size": 10.178571428571429, "title": "Semantically Segmented Images"}, {"color": "#6FA8DC", "id": "Geo-references", "label": "Geo-references", "shape": "dot", "size": 10.178571428571429, "title": "Geo-references"}, {"color": "#6FA8DC", "id": "Addresses", "label": "Addresses", "shape": "dot", "size": 10.089285714285714, "title": "Addresses"}, {"color": "#6FA8DC", "id": "GIS Data Integration", "label": "GIS Data Integration", "shape": "dot", "size": 10.089285714285714, "title": "GIS Data Integration"}, {"color": "#6FA8DC", "id": "Iterative Data Fusion", "label": "Iterative Data Fusion", "shape": "dot", "size": 10.089285714285714, "title": "Iterative Data Fusion"}, {"color": "#6FA8DC", "id": "Image Alignment", "label": "Image Alignment", "shape": "dot", "size": 10.089285714285714, "title": "Image Alignment"}, {"color": "#6FA8DC", "id": "P. Zhao et al. [17]", "label": "P. Zhao et al. [17]", "shape": "dot", "size": 10.089285714285714, "title": "P. Zhao et al. [17]"}, {"color": "#6FA8DC", "id": "Rectilinear parsing", "label": "Rectilinear parsing", "shape": "dot", "size": 10.089285714285714, "title": "Rectilinear parsing"}, {"color": "#6FA8DC", "id": "O. Teboul et al. [10]", "label": "O. Teboul et al. [10]", "shape": "dot", "size": 10.089285714285714, "title": "O. Teboul et al. [10]"}, {"color": "#6FA8DC", "id": "Segmentation of building facades", "label": "Segmentation of building facades", "shape": "dot", "size": 10.089285714285714, "title": "Segmentation of building facades"}, {"color": "#6FA8DC", "id": "G. J. Brostow et al. [2]", "label": "G. J. Brostow et al. [2]", "shape": "dot", "size": 10.089285714285714, "title": "G. J. Brostow et al. [2]"}, {"color": "#6FA8DC", "id": "Segmentation and recognition", "label": "Segmentation and recognition", "shape": "dot", "size": 10.089285714285714, "title": "Segmentation and recognition"}, {"color": "#6FA8DC", "id": "EE", "label": "EE", "shape": "dot", "size": 10.089285714285714, "title": "EE"}, {"color": "#6FA8DC", "id": "2010", "label": "2010", "shape": "dot", "size": 10.089285714285714, "title": "2010"}, {"color": "#6FA8DC", "id": "Brostow", "label": "Brostow", "shape": "dot", "size": 10.089285714285714, "title": "Brostow"}, {"color": "#6FA8DC", "id": "Segmentation and recognition using structure from motion point clouds", "label": "Segmentation and recognition using structure from motion point clouds", "shape": "dot", "size": 10.089285714285714, "title": "Segmentation and recognition using structure from motion point clouds"}, {"color": "#6FA8DC", "id": "He", "label": "He", "shape": "dot", "size": 10.089285714285714, "title": "He"}, {"color": "#6FA8DC", "id": "Multiscale conditional random fields for image labeling", "label": "Multiscale conditional random fields for image labeling", "shape": "dot", "size": 10.178571428571429, "title": "Multiscale conditional random fields for image labeling"}, {"color": "#6FA8DC", "id": "CVPR 2004", "label": "CVPR 2004", "shape": "dot", "size": 10.089285714285714, "title": "CVPR 2004"}, {"color": "#6FA8DC", "id": "Liu", "label": "Liu", "shape": "dot", "size": 10.178571428571429, "title": "Liu"}, {"color": "#6FA8DC", "id": "Entropy rate superpixel segmentation", "label": "Entropy rate superpixel segmentation", "shape": "dot", "size": 10.178571428571429, "title": "Entropy rate superpixel segmentation"}, {"color": "#6FA8DC", "id": "M\u00fcller", "label": "M\u00fcller", "shape": "dot", "size": 10.089285714285714, "title": "M\u00fcller"}, {"color": "#6FA8DC", "id": "Procedural modeling of buildings", "label": "Procedural modeling of buildings", "shape": "dot", "size": 10.089285714285714, "title": "Procedural modeling of buildings"}, {"color": "#6FA8DC", "id": "Musialski", "label": "Musialski", "shape": "dot", "size": 10.089285714285714, "title": "Musialski"}, {"color": "#6FA8DC", "id": "Interactive coherence-based fac\u00b8ade modeling", "label": "Interactive coherence-based fac\u00b8ade modeling", "shape": "dot", "size": 10.178571428571429, "title": "Interactive coherence-based fac\u00b8ade modeling"}, {"color": "#6FA8DC", "id": "Computer Graphics Forum", "label": "Computer Graphics Forum", "shape": "dot", "size": 10.089285714285714, "title": "Computer Graphics Forum"}, {"color": "#6FA8DC", "id": "dings", "label": "dings", "shape": "dot", "size": 10.089285714285714, "title": "dings"}, {"color": "#6FA8DC", "id": "Ardeshir", "label": "Ardeshir", "shape": "dot", "size": 10.178571428571429, "title": "Ardeshir"}, {"color": "#6FA8DC", "id": "University of Central Florida", "label": "University of Central Florida", "shape": "dot", "size": 10.267857142857142, "title": "University of Central Florida"}, {"color": "#6FA8DC", "id": "Gis-assisted object detection", "label": "Gis-assisted object detection", "shape": "dot", "size": 10.089285714285714, "title": "Gis-assisted object detection"}, {"color": "#6FA8DC", "id": "Lerma", "label": "Lerma", "shape": "dot", "size": 10.089285714285714, "title": "Lerma"}, {"color": "#6FA8DC", "id": "Hoiem", "label": "Hoiem", "shape": "dot", "size": 10.089285714285714, "title": "Hoiem"}, {"color": "#6FA8DC", "id": "Automatic photo popup", "label": "Automatic photo popup", "shape": "dot", "size": 10.089285714285714, "title": "Automatic photo popup"}, {"color": "#6FA8DC", "id": "Collins-Sibley", "label": "Collins-Sibley", "shape": "dot", "size": 10.089285714285714, "title": "Collins-Sibley"}, {"color": "#6FA8DC", "id": "Northeaster University", "label": "Northeaster University", "shape": "dot", "size": 10.089285714285714, "title": "Northeaster University"}, {"color": "#6FA8DC", "id": "Shah", "label": "Shah", "shape": "dot", "size": 10.089285714285714, "title": "Shah"}, {"color": "#6FA8DC", "id": "Huang", "label": "Huang", "shape": "dot", "size": 10.089285714285714, "title": "Huang"}, {"color": "#6FA8DC", "id": "Bayesian Inference", "label": "Bayesian Inference", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian Inference"}, {"color": "#6FA8DC", "id": "University of  Central Florida", "label": "University of  Central Florida", "shape": "dot", "size": 10.089285714285714, "title": "University of  Central Florida"}, {"color": "#6FA8DC", "id": "shah@crcv.ucf.edu", "label": "shah@crcv.ucf.edu", "shape": "dot", "size": 10.089285714285714, "title": "shah@crcv.ucf.edu"}, {"color": "#6FA8DC", "id": "Chao-Tsung Huang", "label": "Chao-Tsung Huang", "shape": "dot", "size": 10.178571428571429, "title": "Chao-Tsung Huang"}, {"color": "#6FA8DC", "id": "Bayesian Inference for Neighborhood Filters", "label": "Bayesian Inference for Neighborhood Filters", "shape": "dot", "size": 10.267857142857142, "title": "Bayesian Inference for Neighborhood Filters"}, {"color": "#6FA8DC", "id": "Denoising", "label": "Denoising", "shape": "dot", "size": 10.178571428571429, "title": "Denoising"}, {"color": "#6FA8DC", "id": "collins-sibley.k@husky.neu.edu", "label": "collins-sibley.k@husky.neu.edu", "shape": "dot", "size": 10.089285714285714, "title": "collins-sibley.k@husky.neu.edu"}, {"color": "#6FA8DC", "id": "Huang_Bayesian_Infrenence_for_2015_CVPR_paper.pdf", "label": "Huang_Bayesian_Infrenence_for_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.178571428571429, "title": "Huang_Bayesian_Infrenence_for_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Range-weighted neighborhood filters", "label": "Range-weighted neighborhood filters", "shape": "dot", "size": 10.178571428571429, "title": "Range-weighted neighborhood filters"}, {"color": "#6FA8DC", "id": "edge-preserving denoising", "label": "edge-preserving denoising", "shape": "dot", "size": 10.089285714285714, "title": "edge-preserving denoising"}, {"color": "#6FA8DC", "id": "limited theoretical understanding", "label": "limited theoretical understanding", "shape": "dot", "size": 10.089285714285714, "title": "limited theoretical understanding"}, {"color": "#6FA8DC", "id": "unified empirical Bayesian framework", "label": "unified empirical Bayesian framework", "shape": "dot", "size": 10.178571428571429, "title": "unified empirical Bayesian framework"}, {"color": "#6FA8DC", "id": "filters", "label": "filters", "shape": "dot", "size": 10.089285714285714, "title": "filters"}, {"color": "#6FA8DC", "id": "range variance", "label": "range variance", "shape": "dot", "size": 10.267857142857142, "title": "range variance"}, {"color": "#6FA8DC", "id": "neighborhood noise model", "label": "neighborhood noise model", "shape": "dot", "size": 10.089285714285714, "title": "neighborhood noise model"}, {"color": "#6FA8DC", "id": "Yaroslavsky, bilateral, and modified non-local means filters", "label": "Yaroslavsky, bilateral, and modified non-local means filters", "shape": "dot", "size": 10.089285714285714, "title": "Yaroslavsky, bilateral, and modified non-local means filters"}, {"color": "#6FA8DC", "id": "EM+ algorithm", "label": "EM+ algorithm", "shape": "dot", "size": 10.178571428571429, "title": "EM+ algorithm"}, {"color": "#6FA8DC", "id": "noisy images", "label": "noisy images", "shape": "dot", "size": 10.446428571428571, "title": "noisy images"}, {"color": "#6FA8DC", "id": "extensible to other range-weighted filters", "label": "extensible to other range-weighted filters", "shape": "dot", "size": 10.089285714285714, "title": "extensible to other range-weighted filters"}, {"color": "#6FA8DC", "id": "color-image denoising", "label": "color-image denoising", "shape": "dot", "size": 10.089285714285714, "title": "color-image denoising"}, {"color": "#6FA8DC", "id": "model\u0027s effectiveness", "label": "model\u0027s effectiveness", "shape": "dot", "size": 10.089285714285714, "title": "model\u0027s effectiveness"}, {"color": "#6FA8DC", "id": "range-weighted algorithms", "label": "range-weighted algorithms", "shape": "dot", "size": 10.089285714285714, "title": "range-weighted algorithms"}, {"color": "#6FA8DC", "id": "recursive fitting", "label": "recursive fitting", "shape": "dot", "size": 10.089285714285714, "title": "recursive fitting"}, {"color": "#6FA8DC", "id": "accurate estimation", "label": "accurate estimation", "shape": "dot", "size": 10.089285714285714, "title": "accurate estimation"}, {"color": "#6FA8DC", "id": "Image Quality", "label": "Image Quality", "shape": "dot", "size": 10.089285714285714, "title": "Image Quality"}, {"color": "#6FA8DC", "id": "Paris, S.", "label": "Paris, S.", "shape": "dot", "size": 10.089285714285714, "title": "Paris, S."}, {"color": "#6FA8DC", "id": "Bilateral filtering", "label": "Bilateral filtering", "shape": "dot", "size": 10.267857142857142, "title": "Bilateral filtering"}, {"color": "#6FA8DC", "id": "Buades, A.", "label": "Buades, A.", "shape": "dot", "size": 10.089285714285714, "title": "Buades, A."}, {"color": "#6FA8DC", "id": "image denoising algorithms review", "label": "image denoising algorithms review", "shape": "dot", "size": 10.178571428571429, "title": "image denoising algorithms review"}, {"color": "#6FA8DC", "id": "SIAM Journal on Multi-scale Modeling and Simulation", "label": "SIAM Journal on Multi-scale Modeling and Simulation", "shape": "dot", "size": 10.089285714285714, "title": "SIAM Journal on Multi-scale Modeling and Simulation"}, {"color": "#6FA8DC", "id": "Chatterjee, P.", "label": "Chatterjee, P.", "shape": "dot", "size": 10.089285714285714, "title": "Chatterjee, P."}, {"color": "#6FA8DC", "id": "Patch-based near-optimal image denoising", "label": "Patch-based near-optimal image denoising", "shape": "dot", "size": 10.178571428571429, "title": "Patch-based near-optimal image denoising"}, {"color": "#6FA8DC", "id": "Peng, H.", "label": "Peng, H.", "shape": "dot", "size": 10.178571428571429, "title": "Peng, H."}, {"color": "#6FA8DC", "id": "Bilateral kernel parameter optimization", "label": "Bilateral kernel parameter optimization", "shape": "dot", "size": 10.178571428571429, "title": "Bilateral kernel parameter optimization"}, {"color": "#6FA8DC", "id": "International Conference on Image Processing", "label": "International Conference on Image Processing", "shape": "dot", "size": 10.089285714285714, "title": "International Conference on Image Processing"}, {"color": "#6FA8DC", "id": "Multispectral image denoising", "label": "Multispectral image denoising", "shape": "dot", "size": 10.357142857142858, "title": "Multispectral image denoising"}, {"color": "#6FA8DC", "id": "vector bilateral filter", "label": "vector bilateral filter", "shape": "dot", "size": 10.178571428571429, "title": "vector bilateral filter"}, {"color": "#6FA8DC", "id": "image filtering technique", "label": "image filtering technique", "shape": "dot", "size": 10.089285714285714, "title": "image filtering technique"}, {"color": "#6FA8DC", "id": "Vector bilateral filter", "label": "Vector bilateral filter", "shape": "dot", "size": 10.089285714285714, "title": "Vector bilateral filter"}, {"color": "#6FA8DC", "id": "Image denoising", "label": "Image denoising", "shape": "dot", "size": 10.089285714285714, "title": "Image denoising"}, {"color": "#6FA8DC", "id": "scale mixtures of gausians", "label": "scale mixtures of gausians", "shape": "dot", "size": 10.089285714285714, "title": "scale mixtures of gausians"}, {"color": "#6FA8DC", "id": "Bilateral filter", "label": "Bilateral filter", "shape": "dot", "size": 10.089285714285714, "title": "Bilateral filter"}, {"color": "#6FA8DC", "id": "Local Estimation", "label": "Local Estimation", "shape": "dot", "size": 10.267857142857142, "title": "Local Estimation"}, {"color": "#6FA8DC", "id": "Deep Networks for Saliency Detection", "label": "Deep Networks for Saliency Detection", "shape": "dot", "size": 10.535714285714286, "title": "Deep Networks for Saliency Detection"}, {"color": "#6FA8DC", "id": "Global Search", "label": "Global Search", "shape": "dot", "size": 10.267857142857142, "title": "Global Search"}, {"color": "#6FA8DC", "id": "Chao-Tsun Huang", "label": "Chao-Tsun Huang", "shape": "dot", "size": 10.089285714285714, "title": "Chao-Tsun Huang"}, {"color": "#6FA8DC", "id": "National Tsing Hua University", "label": "National Tsing Hua University", "shape": "dot", "size": 10.089285714285714, "title": "National Tsing Hua University"}, {"color": "#6FA8DC", "id": "Lijun Wang", "label": "Lijun Wang", "shape": "dot", "size": 10.178571428571429, "title": "Lijun Wang"}, {"color": "#6FA8DC", "id": "Deep Networks for Salience Detection", "label": "Deep Networks for Salience Detection", "shape": "dot", "size": 10.446428571428571, "title": "Deep Networks for Salience Detection"}, {"color": "#6FA8DC", "id": "Deep Networks for Salience Detected", "label": "Deep Networks for Salience Detected", "shape": "dot", "size": 10.089285714285714, "title": "Deep Networks for Salience Detected"}, {"color": "#6FA8DC", "id": "Wang_Deep_Networks_for_2015_CVPR_paper", "label": "Wang_Deep_Networks_for_2015_CVPR_paper", "shape": "dot", "size": 10.178571428571429, "title": "Wang_Deep_Networks_for_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Wang_Deep_Networks_for_2015_CVPR_paper.pdf", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Wang_Deep_Networks_for_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Wang_Deep_Networks_for_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Salience Detection", "label": "Salience Detection", "shape": "dot", "size": 10.357142857142858, "title": "Salience Detection"}, {"color": "#6FA8DC", "id": "local estimation", "label": "local estimation", "shape": "dot", "size": 10.267857142857142, "title": "local estimation"}, {"color": "#6FA8DC", "id": "global search", "label": "global search", "shape": "dot", "size": 10.267857142857142, "title": "global search"}, {"color": "#6FA8DC", "id": "DNN-L", "label": "DNN-L", "shape": "dot", "size": 10.267857142857142, "title": "DNN-L"}, {"color": "#6FA8DC", "id": "local patch features", "label": "local patch features", "shape": "dot", "size": 10.089285714285714, "title": "local patch features"}, {"color": "#6FA8DC", "id": "salience value", "label": "salience value", "shape": "dot", "size": 10.089285714285714, "title": "salience value"}, {"color": "#6FA8DC", "id": "object concepts", "label": "object concepts", "shape": "dot", "size": 10.089285714285714, "title": "object concepts"}, {"color": "#6FA8DC", "id": "global contrast", "label": "global contrast", "shape": "dot", "size": 10.089285714285714, "title": "global contrast"}, {"color": "#6FA8DC", "id": "DNN-G", "label": "DNN-G", "shape": "dot", "size": 10.089285714285714, "title": "DNN-G"}, {"color": "#6FA8DC", "id": "salient score", "label": "salient score", "shape": "dot", "size": 10.089285714285714, "title": "salient score"}, {"color": "#6FA8DC", "id": "salient object regions", "label": "salient object regions", "shape": "dot", "size": 10.089285714285714, "title": "salient object regions"}, {"color": "#6FA8DC", "id": "weighted sum", "label": "weighted sum", "shape": "dot", "size": 10.178571428571429, "title": "weighted sum"}, {"color": "#6FA8DC", "id": "saliency map", "label": "saliency map", "shape": "dot", "size": 10.089285714285714, "title": "saliency map"}, {"color": "#6FA8DC", "id": "local contrast", "label": "local contrast", "shape": "dot", "size": 10.089285714285714, "title": "local contrast"}, {"color": "#6FA8DC", "id": "shape information", "label": "shape information", "shape": "dot", "size": 10.089285714285714, "title": "shape information"}, {"color": "#6FA8DC", "id": "global saliency cues", "label": "global saliency cues", "shape": "dot", "size": 10.089285714285714, "title": "global saliency cues"}, {"color": "#6FA8DC", "id": "insight", "label": "insight", "shape": "dot", "size": 10.089285714285714, "title": "insight"}, {"color": "#6FA8DC", "id": "object region", "label": "object region", "shape": "dot", "size": 10.089285714285714, "title": "object region"}, {"color": "#6FA8DC", "id": "saliency score", "label": "saliency score", "shape": "dot", "size": 10.178571428571429, "title": "saliency score"}, {"color": "#6FA8DC", "id": "global features", "label": "global features", "shape": "dot", "size": 10.089285714285714, "title": "global features"}, {"color": "#6FA8DC", "id": "Algorithm", "label": "Algorithm", "shape": "dot", "size": 10.178571428571429, "title": "Algorithm"}, {"color": "#6FA8DC", "id": "Salient Region Detection", "label": "Salient Region Detection", "shape": "dot", "size": 10.267857142857142, "title": "Salient Region Detection"}, {"color": "#6FA8DC", "id": "field", "label": "field", "shape": "dot", "size": 10.089285714285714, "title": "field"}, {"color": "#6FA8DC", "id": "R. Achanta et al.", "label": "R. Achanta et al.", "shape": "dot", "size": 10.089285714285714, "title": "R. Achanta et al."}, {"color": "#6FA8DC", "id": "J. Carreira and C. Sminchisescu", "label": "J. Carreira and C. Sminchisescu", "shape": "dot", "size": 10.178571428571429, "title": "J. Carreira and C. Sminchisescu"}, {"color": "#6FA8DC", "id": "min-cuts", "label": "min-cuts", "shape": "dot", "size": 10.089285714285714, "title": "min-cuts"}, {"color": "#6FA8DC", "id": "Constrained parametric min-cuts", "label": "Constrained parametric min-cuts", "shape": "dot", "size": 10.446428571428571, "title": "Constrained parametric min-cuts"}, {"color": "#6FA8DC", "id": "Object Candidate Regions", "label": "Object Candidate Regions", "shape": "dot", "size": 10.089285714285714, "title": "Object Candidate Regions"}, {"color": "#6FA8DC", "id": "tric min-cuts", "label": "tric min-cuts", "shape": "dot", "size": 10.089285714285714, "title": "tric min-cuts"}, {"color": "#6FA8DC", "id": "visual salience", "label": "visual salience", "shape": "dot", "size": 10.089285714285714, "title": "visual salience"}, {"color": "#6FA8DC", "id": "Itti, Koch, and Niebur (1998)", "label": "Itti, Koch, and Niebur (1998)", "shape": "dot", "size": 10.267857142857142, "title": "Itti, Koch, and Niebur (1998)"}, {"color": "#6FA8DC", "id": "computational model", "label": "computational model", "shape": "dot", "size": 10.089285714285714, "title": "computational model"}, {"color": "#6FA8DC", "id": "saliency detection", "label": "saliency detection", "shape": "dot", "size": 10.267857142857142, "title": "saliency detection"}, {"color": "#6FA8DC", "id": "absorbing Markov chain", "label": "absorbing Markov chain", "shape": "dot", "size": 10.178571428571429, "title": "absorbing Markov chain"}, {"color": "#6FA8DC", "id": "tric min-cuts paper", "label": "tric min-cuts paper", "shape": "dot", "size": 10.089285714285714, "title": "tric min-cuts paper"}, {"color": "#6FA8DC", "id": "Markov Chain approach", "label": "Markov Chain approach", "shape": "dot", "size": 10.178571428571429, "title": "Markov Chain approach"}, {"color": "#6FA8DC", "id": "Hierarchical approaches", "label": "Hierarchical approaches", "shape": "dot", "size": 10.178571428571429, "title": "Hierarchical approaches"}, {"color": "#6FA8DC", "id": "Selective search", "label": "Selective search", "shape": "dot", "size": 10.267857142857142, "title": "Selective search"}, {"color": "#6FA8DC", "id": "generating object proposals", "label": "generating object proposals", "shape": "dot", "size": 10.089285714285714, "title": "generating object proposals"}, {"color": "#6FA8DC", "id": "preprocessing step", "label": "preprocessing step", "shape": "dot", "size": 10.089285714285714, "title": "preprocessing step"}, {"color": "#6FA8DC", "id": "salient object detection pipelines", "label": "salient object detection pipelines", "shape": "dot", "size": 10.089285714285714, "title": "salient object detection pipelines"}, {"color": "#6FA8DC", "id": "salient regions", "label": "salient regions", "shape": "dot", "size": 10.089285714285714, "title": "salient regions"}, {"color": "#6FA8DC", "id": "simultaneous detection and segmentation", "label": "simultaneous detection and segmentation", "shape": "dot", "size": 10.267857142857142, "title": "simultaneous detection and segmentation"}, {"color": "#6FA8DC", "id": "related task", "label": "related task", "shape": "dot", "size": 10.089285714285714, "title": "related task"}, {"color": "#6FA8DC", "id": "Bayesian models", "label": "Bayesian models", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian models"}, {"color": "#6FA8DC", "id": "visual salience detection", "label": "visual salience detection", "shape": "dot", "size": 10.089285714285714, "title": "visual salience detection"}, {"color": "#6FA8DC", "id": "ICC paper", "label": "ICC paper", "shape": "dot", "size": 10.089285714285714, "title": "ICC paper"}, {"color": "#6FA8DC", "id": "ECCV paper", "label": "ECCV paper", "shape": "dot", "size": 10.089285714285714, "title": "ECCV paper"}, {"color": "#6FA8DC", "id": "ICIP paper", "label": "ICIP paper", "shape": "dot", "size": 10.089285714285714, "title": "ICIP paper"}, {"color": "#6FA8DC", "id": "Bayesian model", "label": "Bayesian model", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian model"}, {"color": "#6FA8DC", "id": "Abhishek Kar", "label": "Abhishek Kar", "shape": "dot", "size": 10.267857142857142, "title": "Abhishek Kar"}, {"color": "#6FA8DC", "id": "Jo\u02dcao Carreira", "label": "Jo\u02dcao Carreira", "shape": "dot", "size": 10.267857142857142, "title": "Jo\u02dcao Carreira"}, {"color": "#6FA8DC", "id": "akar@eecs.berkeley.edu", "label": "akar@eecs.berkeley.edu", "shape": "dot", "size": 10.089285714285714, "title": "akar@eecs.berkeley.edu"}, {"color": "#6FA8DC", "id": "shubhtuls@eecs.berkeley.edu", "label": "shubhtuls@eecs.berkeley.edu", "shape": "dot", "size": 10.089285714285714, "title": "shubhtuls@eecs.berkeley.edu"}, {"color": "#6FA8DC", "id": "carreira@eecs.berkeley.edu", "label": "carreira@eecs.berkeley.edu", "shape": "dot", "size": 10.089285714285714, "title": "carreira@eecs.berkeley.edu"}, {"color": "#6FA8DC", "id": "malik@eecs.berkeley.edu", "label": "malik@eecs.berkeley.edu", "shape": "dot", "size": 10.089285714285714, "title": "malik@eecs.berkeley.edu"}, {"color": "#6FA8DC", "id": "Category-Speci\ufb01c Object Reconstruction from a Single Image", "label": "Category-Speci\ufb01c Object Reconstruction from a Single Image", "shape": "dot", "size": 10.357142857142858, "title": "Category-Speci\ufb01c Object Reconstruction from a Single Image"}, {"color": "#6FA8DC", "id": "Shubham Tulisiani", "label": "Shubham Tulisiani", "shape": "dot", "size": 10.089285714285714, "title": "Shubham Tulisiani"}, {"color": "#6FA8DC", "id": "Thorsten Beier", "label": "Thorsten Beier", "shape": "dot", "size": 10.535714285714286, "title": "Thorsten Beier"}, {"color": "#6FA8DC", "id": "Fusion Moves for Correlation Clustering", "label": "Fusion Moves for Correlation Clustering", "shape": "dot", "size": 10.535714285714286, "title": "Fusion Moves for Correlation Clustering"}, {"color": "#6FA8DC", "id": "Fred A. Hamprecht", "label": "Fred A. Hamprecht", "shape": "dot", "size": 10.446428571428571, "title": "Fred A. Hamprecht"}, {"color": "#6FA8DC", "id": "University of Heidelberg", "label": "University of Heidelberg", "shape": "dot", "size": 10.267857142857142, "title": "University of Heidelberg"}, {"color": "#6FA8DC", "id": "J\u00f6rg H. Kappes", "label": "J\u00f6rg H. Kappes", "shape": "dot", "size": 10.446428571428571, "title": "J\u00f6rg H. Kappes"}, {"color": "#6FA8DC", "id": "Math", "label": "Math", "shape": "dot", "size": 10.089285714285714, "title": "Math"}, {"color": "#6FA8DC", "id": "thorsten.beier@iwr.uni-heidelberg.de", "label": "thorsten.beier@iwr.uni-heidelberg.de", "shape": "dot", "size": 10.089285714285714, "title": "thorsten.beier@iwr.uni-heidelberg.de"}, {"color": "#6FA8DC", "id": "fred.hamprecht@iwr.uni-heidelberg.de", "label": "fred.hamprecht@iwr.uni-heidelberg.de", "shape": "dot", "size": 10.089285714285714, "title": "fred.hamprecht@iwr.uni-heidelberg.de"}, {"color": "#6FA8DC", "id": "kappes@math.uni-heidelberg.de", "label": "kappes@math.uni-heidelberg.de", "shape": "dot", "size": 10.089285714285714, "title": "kappes@math.uni-heidelberg.de"}, {"color": "#6FA8DC", "id": "Hossein Rahmani", "label": "Hossein Rahmani", "shape": "dot", "size": 10.267857142857142, "title": "Hossein Rahmani"}, {"color": "#6FA8DC", "id": "The University of Western Australia", "label": "The University of Western Australia", "shape": "dot", "size": 10.089285714285714, "title": "The University of Western Australia"}, {"color": "#6FA8DC", "id": "Hossein Rahman\u0131", "label": "Hossein Rahman\u0131", "shape": "dot", "size": 10.089285714285714, "title": "Hossein Rahman\u0131"}, {"color": "#6FA8DC", "id": "hossein@csse.uwa.edu.au", "label": "hossein@csse.uwa.edu.au", "shape": "dot", "size": 10.089285714285714, "title": "hossein@csse.uwa.edu.au"}, {"color": "#6FA8DC", "id": "Ajmal Mian", "label": "Ajmal Mian", "shape": "dot", "size": 10.357142857142858, "title": "Ajmal Mian"}, {"color": "#6FA8DC", "id": "The University of Western Canada", "label": "The University of Western Canada", "shape": "dot", "size": 10.089285714285714, "title": "The University of Western Canada"}, {"color": "#6FA8DC", "id": "ajmal.mian@uwa.edu.au", "label": "ajmal.mian@uwa.edu.au", "shape": "dot", "size": 10.089285714285714, "title": "ajmal.mian@uwa.edu.au"}, {"color": "#6FA8DC", "id": "Learning a Non-linear Knowledge Transfer Model for Cross-View Action Recognition", "label": "Learning a Non-linear Knowledge Transfer Model for Cross-View Action Recognition", "shape": "dot", "size": 10.267857142857142, "title": "Learning a Non-linear Knowledge Transfer Model for Cross-View Action Recognition"}, {"color": "#6FA8DC", "id": "Rahmani_Learning_a_Non-Linear_2015_CVPR_paper.pdf", "label": "Rahmani_Learning_a_Non-Linear_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.178571428571429, "title": "Rahmani_Learning_a_Non-Linear_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Sparse Kernel Multi-task Learning (SKMTL) models", "label": "Sparse Kernel Multi-task Learning (SKMTL) models", "shape": "dot", "size": 10.267857142857142, "title": "Sparse Kernel Multi-task Learning (SKMTL) models"}, {"color": "#6FA8DC", "id": "Convex Multi-task Cluster Learning", "label": "Convex Multi-task Cluster Learning", "shape": "dot", "size": 10.089285714285714, "title": "Convex Multi-task Cluster Learning"}, {"color": "#6FA8DC", "id": "SKMTL problem", "label": "SKMTL problem", "shape": "dot", "size": 10.089285714285714, "title": "SKMTL problem"}, {"color": "#6FA8DC", "id": "jointly convex", "label": "jointly convex", "shape": "dot", "size": 10.089285714285714, "title": "jointly convex"}, {"color": "#6FA8DC", "id": "clustered structures", "label": "clustered structures", "shape": "dot", "size": 10.178571428571429, "title": "clustered structures"}, {"color": "#6FA8DC", "id": "tasks", "label": "tasks", "shape": "dot", "size": 10.267857142857142, "title": "tasks"}, {"color": "#6FA8DC", "id": "Robotics (Sarcos) dataset", "label": "Robotics (Sarcos) dataset", "shape": "dot", "size": 10.178571428571429, "title": "Robotics (Sarcos) dataset"}, {"color": "#6FA8DC", "id": "sparse structure", "label": "sparse structure", "shape": "dot", "size": 10.089285714285714, "title": "sparse structure"}, {"color": "#6FA8DC", "id": "settings beyond computer vision", "label": "settings beyond computer vision", "shape": "dot", "size": 10.089285714285714, "title": "settings beyond computer vision"}, {"color": "#6FA8DC", "id": "Laplacian Eigenmaps", "label": "Laplacian Eigenmaps", "shape": "dot", "size": 10.267857142857142, "title": "Laplacian Eigenmaps"}, {"color": "#6FA8DC", "id": "Sparse Kernel Multi-task Learning", "label": "Sparse Kernel Multi-task Learning", "shape": "dot", "size": 10.357142857142858, "title": "Sparse Kernel Multi-task Learning"}, {"color": "#6FA8DC", "id": "Joint Convexity", "label": "Joint Convexity", "shape": "dot", "size": 10.089285714285714, "title": "Joint Convexity"}, {"color": "#6FA8DC", "id": "Cluster Multi-task Learning", "label": "Cluster Multi-task Learning", "shape": "dot", "size": 10.089285714285714, "title": "Cluster Multi-task Learning"}, {"color": "#6FA8DC", "id": "Robotics", "label": "Robotics", "shape": "dot", "size": 10.089285714285714, "title": "Robotics"}, {"color": "#6FA8DC", "id": "Sarcos dataset", "label": "Sarcos dataset", "shape": "dot", "size": 10.089285714285714, "title": "Sarcos dataset"}, {"color": "#6FA8DC", "id": "Robust Multiple Homography Estimation", "label": "Robust Multiple Homography Estimation", "shape": "dot", "size": 10.446428571428571, "title": "Robust Multiple Homography Estimation"}, {"color": "#6FA8DC", "id": "ill-solved problem", "label": "ill-solved problem", "shape": "dot", "size": 10.178571428571429, "title": "ill-solved problem"}, {"color": "#6FA8DC", "id": "Zygmunt L. Szpak", "label": "Zygmunt L. Szpak", "shape": "dot", "size": 10.089285714285714, "title": "Zygmunt L. Szpak"}, {"color": "#6FA8DC", "id": "Wojciech Chojnacki", "label": "Wojciech Chojnacki", "shape": "dot", "size": 10.089285714285714, "title": "Wojciech Chojnacki"}, {"color": "#6FA8DC", "id": "Szpak_Robust_Multiple_Homography_2015_CVPR_paper.pdf", "label": "Szpak_Robust_Multiple_Homography_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Szpak_Robust_Multiple_Homography_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "multiple homographies estimation", "label": "multiple homographies estimation", "shape": "dot", "size": 10.178571428571429, "title": "multiple homographies estimation"}, {"color": "#6FA8DC", "id": "failure to enforce consistency constraints", "label": "failure to enforce consistency constraints", "shape": "dot", "size": 10.089285714285714, "title": "failure to enforce consistency constraints"}, {"color": "#6FA8DC", "id": "rigidity", "label": "rigidity", "shape": "dot", "size": 10.178571428571429, "title": "rigidity"}, {"color": "#6FA8DC", "id": "consistency constraints", "label": "consistency constraints", "shape": "dot", "size": 10.178571428571429, "title": "consistency constraints"}, {"color": "#6FA8DC", "id": "homographies", "label": "homographies", "shape": "dot", "size": 10.267857142857142, "title": "homographies"}, {"color": "#6FA8DC", "id": "new constraints", "label": "new constraints", "shape": "dot", "size": 10.089285714285714, "title": "new constraints"}, {"color": "#6FA8DC", "id": "epipolar geometries", "label": "epipolar geometries", "shape": "dot", "size": 10.089285714285714, "title": "epipolar geometries"}, {"color": "#6FA8DC", "id": "inconsistent", "label": "inconsistent", "shape": "dot", "size": 10.089285714285714, "title": "inconsistent"}, {"color": "#6FA8DC", "id": "robust multi-structure estimation methods", "label": "robust multi-structure estimation methods", "shape": "dot", "size": 10.178571428571429, "title": "robust multi-structure estimation methods"}, {"color": "#6FA8DC", "id": "enforcing constraints on homography matrices", "label": "enforcing constraints on homography matrices", "shape": "dot", "size": 10.089285714285714, "title": "enforcing constraints on homography matrices"}, {"color": "#6FA8DC", "id": "incomplete constraint satisfaction", "label": "incomplete constraint satisfaction", "shape": "dot", "size": 10.089285714285714, "title": "incomplete constraint satisfaction"}, {"color": "#6FA8DC", "id": "views", "label": "views", "shape": "dot", "size": 10.089285714285714, "title": "views"}, {"color": "#6FA8DC", "id": "multi-structure estimation methods", "label": "multi-structure estimation methods", "shape": "dot", "size": 10.178571428571429, "title": "multi-structure estimation methods"}, {"color": "#6FA8DC", "id": "enforcing constraints", "label": "enforcing constraints", "shape": "dot", "size": 10.089285714285714, "title": "enforcing constraints"}, {"color": "#6FA8DC", "id": "homography matrices", "label": "homography matrices", "shape": "dot", "size": 10.178571428571429, "title": "homography matrices"}, {"color": "#6FA8DC", "id": "new generation", "label": "new generation", "shape": "dot", "size": 10.089285714285714, "title": "new generation"}, {"color": "#6FA8DC", "id": "critiques", "label": "critiques", "shape": "dot", "size": 10.089285714285714, "title": "critiques"}, {"color": "#6FA8DC", "id": "Robust Multi-Structure Estimation", "label": "Robust Multi-Structure Estimation", "shape": "dot", "size": 10.178571428571429, "title": "Robust Multi-Structure Estimation"}, {"color": "#6FA8DC", "id": "constraints on homography matrices", "label": "constraints on homography matrices", "shape": "dot", "size": 10.089285714285714, "title": "constraints on homography matrices"}, {"color": "#6FA8DC", "id": "Homography Matrices", "label": "Homography Matrices", "shape": "dot", "size": 10.178571428571429, "title": "Homography Matrices"}, {"color": "#6FA8DC", "id": "Projective Geometry", "label": "Projective Geometry", "shape": "dot", "size": 10.089285714285714, "title": "Projective Geometry"}, {"color": "#6FA8DC", "id": "Epiopolar Geometry", "label": "Epiopolar Geometry", "shape": "dot", "size": 10.089285714285714, "title": "Epiopolar Geometry"}, {"color": "#6FA8DC", "id": "Baker, S., Datta, A., and Kanade, T.", "label": "Baker, S., Datta, A., and Kanade, T.", "shape": "dot", "size": 10.089285714285714, "title": "Baker, S., Datta, A., and Kanade, T."}, {"color": "#6FA8DC", "id": "Parameterizing homographies", "label": "Parameterizing homographies", "shape": "dot", "size": 10.178571428571429, "title": "Parameterizing homographies"}, {"color": "#6FA8DC", "id": "Bernstein, D. S.", "label": "Bernstein, D. S.", "shape": "dot", "size": 10.089285714285714, "title": "Bernstein, D. S."}, {"color": "#6FA8DC", "id": "Matrix Mathematics", "label": "Matrix Mathematics", "shape": "dot", "size": 10.089285714285714, "title": "Matrix Mathematics"}, {"color": "#6FA8DC", "id": "Chen, P., and Suter, D.", "label": "Chen, P., and Suter, D.", "shape": "dot", "size": 10.089285714285714, "title": "Chen, P., and Suter, D."}, {"color": "#6FA8DC", "id": "Rank constraints for homographies", "label": "Rank constraints for homographies", "shape": "dot", "size": 10.089285714285714, "title": "Rank constraints for homographies"}, {"color": "#6FA8DC", "id": "tech. rep. CMU-RI-TR-06-11", "label": "tech. rep. CMU-RI-TR-06-11", "shape": "dot", "size": 10.089285714285714, "title": "tech. rep. CMU-RI-TR-06-11"}, {"color": "#6FA8DC", "id": "Chen, P.", "label": "Chen, P.", "shape": "dot", "size": 10.089285714285714, "title": "Chen, P."}, {"color": "#6FA8DC", "id": "Rank constraints", "label": "Rank constraints", "shape": "dot", "size": 10.267857142857142, "title": "Rank constraints"}, {"color": "#6FA8DC", "id": "Suter, D.", "label": "Suter, D.", "shape": "dot", "size": 10.089285714285714, "title": "Suter, D."}, {"color": "#6FA8DC", "id": "Chojnacki, W.", "label": "Chojnacki, W.", "shape": "dot", "size": 10.178571428571429, "title": "Chojnacki, W."}, {"color": "#6FA8DC", "id": "Multiple homography estimation", "label": "Multiple homography estimation", "shape": "dot", "size": 10.357142857142858, "title": "Multiple homography estimation"}, {"color": "#6FA8DC", "id": "Szpak, Z.", "label": "Szpak, Z.", "shape": "dot", "size": 10.089285714285714, "title": "Szpak, Z."}, {"color": "#6FA8DC", "id": "van den Hengel, A.", "label": "van den Hengel, A.", "shape": "dot", "size": 10.178571428571429, "title": "van den Hengel, A."}, {"color": "#6FA8DC", "id": "Dimensionality result", "label": "Dimensionality result", "shape": "dot", "size": 10.267857142857142, "title": "Dimensionality result"}, {"color": "#6FA8DC", "id": "Fouhey, D. F.", "label": "Fouhey, D. F.", "shape": "dot", "size": 10.089285714285714, "title": "Fouhey, D. F."}, {"color": "#6FA8DC", "id": "Multiple plane detection", "label": "Multiple plane detection", "shape": "dot", "size": 10.357142857142858, "title": "Multiple plane detection"}, {"color": "#6FA8DC", "id": "Scharstein, D.", "label": "Scharstein, D.", "shape": "dot", "size": 10.089285714285714, "title": "Scharstein, D."}, {"color": "#6FA8DC", "id": "Briggs, A. J.", "label": "Briggs, A. J.", "shape": "dot", "size": 10.089285714285714, "title": "Briggs, A. J."}, {"color": "#6FA8DC", "id": "J-linkage", "label": "J-linkage", "shape": "dot", "size": 10.089285714285714, "title": "J-linkage"}, {"color": "#6FA8DC", "id": "Goldberger, J.", "label": "Goldberger, J.", "shape": "dot", "size": 10.089285714285714, "title": "Goldberger, J."}, {"color": "#6FA8DC", "id": "Camera projection matrices", "label": "Camera projection matrices", "shape": "dot", "size": 10.089285714285714, "title": "Camera projection matrices"}, {"color": "#6FA8DC", "id": "Goldberger", "label": "Goldberger", "shape": "dot", "size": 10.089285714285714, "title": "Goldberger"}, {"color": "#6FA8DC", "id": "Reconstructing camera projection matrices", "label": "Reconstructing camera projection matrices", "shape": "dot", "size": 10.089285714285714, "title": "Reconstructing camera projection matrices"}, {"color": "#6FA8DC", "id": "Irving", "label": "Irving", "shape": "dot", "size": 10.089285714285714, "title": "Irving"}, {"color": "#6FA8DC", "id": "Integers, Polynomials, and Rings", "label": "Integers, Polynomials, and Rings", "shape": "dot", "size": 10.089285714285714, "title": "Integers, Polynomials, and Rings"}, {"color": "#6FA8DC", "id": "Szpak", "label": "Szpak", "shape": "dot", "size": 10.089285714285714, "title": "Szpak"}, {"color": "#6FA8DC", "id": "Chojnicki", "label": "Chojnicki", "shape": "dot", "size": 10.089285714285714, "title": "Chojnicki"}, {"color": "#6FA8DC", "id": "van den Hengel", "label": "van den Hengel", "shape": "dot", "size": 10.089285714285714, "title": "van den Hengel"}, {"color": "#6FA8DC", "id": "Saturation-Preerving Specular Reflection Separation", "label": "Saturation-Preerving Specular Reflection Separation", "shape": "dot", "size": 10.446428571428571, "title": "Saturation-Preerving Specular Reflection Separation"}, {"color": "#6FA8DC", "id": "Yuan", "label": "Yuan", "shape": "dot", "size": 10.089285714285714, "title": "Yuan"}, {"color": "#6FA8DC", "id": "Zheng", "label": "Zheng", "shape": "dot", "size": 10.089285714285714, "title": "Zheng"}, {"color": "#6FA8DC", "id": "Wu", "label": "Wu", "shape": "dot", "size": 10.357142857142858, "title": "Wu"}, {"color": "#6FA8DC", "id": "Yuanliu Liu", "label": "Yuanliu Liu", "shape": "dot", "size": 10.357142857142858, "title": "Yuanliu Liu"}, {"color": "#6FA8DC", "id": "Saturation-Preerving Specular Reflection Paper", "label": "Saturation-Preerving Specular Reflection Paper", "shape": "dot", "size": 10.625, "title": "Saturation-Preerving Specular Reflection Paper"}, {"color": "#6FA8DC", "id": "Zejian Yuan", "label": "Zejian Yuan", "shape": "dot", "size": 10.267857142857142, "title": "Zejian Yuan"}, {"color": "#6FA8DC", "id": "Nanning Zheng", "label": "Nanning Zheng", "shape": "dot", "size": 10.178571428571429, "title": "Nanning Zheng"}, {"color": "#6FA8DC", "id": "Yang Wu", "label": "Yang Wu", "shape": "dot", "size": 10.178571428571429, "title": "Yang Wu"}, {"color": "#6FA8DC", "id": "Reflection", "label": "Reflection", "shape": "dot", "size": 10.089285714285714, "title": "Reflection"}, {"color": "#6FA8DC", "id": "Specular Reflection", "label": "Specular Reflection", "shape": "dot", "size": 10.267857142857142, "title": "Specular Reflection"}, {"color": "#6FA8DC", "id": "Saturation-Preserving Specular Reflection Paper", "label": "Saturation-Preserving Specular Reflection Paper", "shape": "dot", "size": 10.089285714285714, "title": "Saturation-Preserving Specular Reflection Paper"}, {"color": "#6FA8DC", "id": "Liu_Saturation-Preerving Specular Reflection Paper", "label": "Liu_Saturation-Preerving Specular Reflection Paper", "shape": "dot", "size": 10.089285714285714, "title": "Liu_Saturation-Preerving Specular Reflection Paper"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Liu_Saturation-Preerving_Specular_Reflection_2015_CVPR_paper.pdf", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Liu_Saturation-Preerving_Specular_Reflection_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Liu_Saturation-Preerving_Specular_Reflection_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Specular reflection", "label": "Specular reflection", "shape": "dot", "size": 10.089285714285714, "title": "Specular reflection"}, {"color": "#6FA8DC", "id": "saturation of surface colors", "label": "saturation of surface colors", "shape": "dot", "size": 10.089285714285714, "title": "saturation of surface colors"}, {"color": "#6FA8DC", "id": "decreased saturation", "label": "decreased saturation", "shape": "dot", "size": 10.089285714285714, "title": "decreased saturation"}, {"color": "#6FA8DC", "id": "confusion with other colors", "label": "confusion with other colors", "shape": "dot", "size": 10.089285714285714, "title": "confusion with other colors"}, {"color": "#6FA8DC", "id": "Traditional methods", "label": "Traditional methods", "shape": "dot", "size": 10.089285714285714, "title": "Traditional methods"}, {"color": "#6FA8DC", "id": "hue-saturation ambiguity", "label": "hue-saturation ambiguity", "shape": "dot", "size": 10.089285714285714, "title": "hue-saturation ambiguity"}, {"color": "#6FA8DC", "id": "Specular-free images", "label": "Specular-free images", "shape": "dot", "size": 10.089285714285714, "title": "Specular-free images"}, {"color": "#6FA8DC", "id": "oversaturated", "label": "oversaturated", "shape": "dot", "size": 10.089285714285714, "title": "oversaturated"}, {"color": "#6FA8DC", "id": "This paper", "label": "This paper", "shape": "dot", "size": 10.089285714285714, "title": "This paper"}, {"color": "#6FA8DC", "id": "two-step approach", "label": "two-step approach", "shape": "dot", "size": 10.178571428571429, "title": "two-step approach"}, {"color": "#6FA8DC", "id": "over-saturated specular-free image", "label": "over-saturated specular-free image", "shape": "dot", "size": 10.178571428571429, "title": "over-saturated specular-free image"}, {"color": "#6FA8DC", "id": "global chromaticity propagation", "label": "global chromaticity propagation", "shape": "dot", "size": 10.089285714285714, "title": "global chromaticity propagation"}, {"color": "#6FA8DC", "id": "Saturation", "label": "Saturation", "shape": "dot", "size": 10.178571428571429, "title": "Saturation"}, {"color": "#6FA8DC", "id": "piecewise constancy of diffuse chromaticity", "label": "piecewise constancy of diffuse chromaticity", "shape": "dot", "size": 10.089285714285714, "title": "piecewise constancy of diffuse chromaticity"}, {"color": "#6FA8DC", "id": "spatial sparsity/smoothness of specular reflection", "label": "spatial sparsity/smoothness of specular reflection", "shape": "dot", "size": 10.089285714285714, "title": "spatial sparsity/smoothness of specular reflection"}, {"color": "#6FA8DC", "id": "achieved by increasing", "label": "achieved by increasing", "shape": "dot", "size": 10.089285714285714, "title": "achieved by increasing"}, {"color": "#6FA8DC", "id": "linear programming", "label": "linear programming", "shape": "dot", "size": 10.267857142857142, "title": "linear programming"}, {"color": "#6FA8DC", "id": "diffuse chromaticity", "label": "diffuse chromaticity", "shape": "dot", "size": 10.089285714285714, "title": "diffuse chromaticity"}, {"color": "#6FA8DC", "id": "chromaticity", "label": "chromaticity", "shape": "dot", "size": 10.089285714285714, "title": "chromaticity"}, {"color": "#6FA8DC", "id": "specular reflection", "label": "specular reflection", "shape": "dot", "size": 10.446428571428571, "title": "specular reflection"}, {"color": "#6FA8DC", "id": "spatial sparsity", "label": "spatial sparsity", "shape": "dot", "size": 10.178571428571429, "title": "spatial sparsity"}, {"color": "#6FA8DC", "id": "achromatic component", "label": "achromatic component", "shape": "dot", "size": 10.089285714285714, "title": "achromatic component"}, {"color": "#6FA8DC", "id": "ability to separate specular reflection", "label": "ability to separate specular reflection", "shape": "dot", "size": 10.089285714285714, "title": "ability to separate specular reflection"}, {"color": "#6FA8DC", "id": "saturation of underlying surface colors", "label": "saturation of underlying surface colors", "shape": "dot", "size": 10.089285714285714, "title": "saturation of underlying surface colors"}, {"color": "#6FA8DC", "id": "surface colors", "label": "surface colors", "shape": "dot", "size": 10.178571428571429, "title": "surface colors"}, {"color": "#6FA8DC", "id": "saturation", "label": "saturation", "shape": "dot", "size": 10.089285714285714, "title": "saturation"}, {"color": "#6FA8DC", "id": "increase achromatic component", "label": "increase achromatic component", "shape": "dot", "size": 10.089285714285714, "title": "increase achromatic component"}, {"color": "#6FA8DC", "id": "Diffuse Chromaticity", "label": "Diffuse Chromaticity", "shape": "dot", "size": 10.178571428571429, "title": "Diffuse Chromaticity"}, {"color": "#6FA8DC", "id": "Linear Programming", "label": "Linear Programming", "shape": "dot", "size": 10.446428571428571, "title": "Linear Programming"}, {"color": "#6FA8DC", "id": "surface color saturation", "label": "surface color saturation", "shape": "dot", "size": 10.089285714285714, "title": "surface color saturation"}, {"color": "#6FA8DC", "id": "Shafer, S.", "label": "Shafer, S.", "shape": "dot", "size": 10.089285714285714, "title": "Shafer, S."}, {"color": "#6FA8DC", "id": "Artusi, A. et al.", "label": "Artusi, A. et al.", "shape": "dot", "size": 10.089285714285714, "title": "Artusi, A. et al."}, {"color": "#6FA8DC", "id": "survey of specular removal methods", "label": "survey of specular removal methods", "shape": "dot", "size": 10.089285714285714, "title": "survey of specular removal methods"}, {"color": "#6FA8DC", "id": "Diffuse Reflection", "label": "Diffuse Reflection", "shape": "dot", "size": 10.089285714285714, "title": "Diffuse Reflection"}, {"color": "#6FA8DC", "id": "Hue-Saturation Ambiguity", "label": "Hue-Saturation Ambiguity", "shape": "dot", "size": 10.089285714285714, "title": "Hue-Saturation Ambiguity"}, {"color": "#6FA8DC", "id": "Chromaticity Propagation", "label": "Chromaticity Propagation", "shape": "dot", "size": 10.089285714285714, "title": "Chromaticity Propagation"}, {"color": "#6FA8DC", "id": "reflection component separation", "label": "reflection component separation", "shape": "dot", "size": 10.089285714285714, "title": "reflection component separation"}, {"color": "#6FA8DC", "id": "Diffuse and specular interface reflections", "label": "Diffuse and specular interface reflections", "shape": "dot", "size": 10.089285714285714, "title": "Diffuse and specular interface reflections"}, {"color": "#6FA8DC", "id": "Gonzalez \u0026 Woods", "label": "Gonzalez \u0026 Woods", "shape": "dot", "size": 10.089285714285714, "title": "Gonzalez \u0026 Woods"}, {"color": "#6FA8DC", "id": "Digital Image Processing", "label": "Digital Image Processing", "shape": "dot", "size": 10.089285714285714, "title": "Digital Image Processing"}, {"color": "#6FA8DC", "id": "Land \u0026 McCann", "label": "Land \u0026 McCann", "shape": "dot", "size": 10.089285714285714, "title": "Land \u0026 McCann"}, {"color": "#6FA8DC", "id": "retinex theory", "label": "retinex theory", "shape": "dot", "size": 10.178571428571429, "title": "retinex theory"}, {"color": "#6FA8DC", "id": "Kim et al.", "label": "Kim et al.", "shape": "dot", "size": 10.089285714285714, "title": "Kim et al."}, {"color": "#6FA8DC", "id": "dark channel prior", "label": "dark channel prior", "shape": "dot", "size": 10.178571428571429, "title": "dark channel prior"}, {"color": "#6FA8DC", "id": "Mallick et al.", "label": "Mallick et al.", "shape": "dot", "size": 10.178571428571429, "title": "Mallick et al."}, {"color": "#6FA8DC", "id": "specular surfaces", "label": "specular surfaces", "shape": "dot", "size": 10.267857142857142, "title": "specular surfaces"}, {"color": "#6FA8DC", "id": "color information", "label": "color information", "shape": "dot", "size": 10.178571428571429, "title": "color information"}, {"color": "#6FA8DC", "id": "specular reflection separation", "label": "specular reflection separation", "shape": "dot", "size": 10.089285714285714, "title": "specular reflection separation"}, {"color": "#6FA8DC", "id": "S. P.", "label": "S. P.", "shape": "dot", "size": 10.089285714285714, "title": "S. P."}, {"color": "#6FA8DC", "id": "Beyond lambert", "label": "Beyond lambert", "shape": "dot", "size": 10.625, "title": "Beyond lambert"}, {"color": "#6FA8DC", "id": "Zickler", "label": "Zickler", "shape": "dot", "size": 10.089285714285714, "title": "Zickler"}, {"color": "#6FA8DC", "id": "T.", "label": "T.", "shape": "dot", "size": 10.089285714285714, "title": "T."}, {"color": "#6FA8DC", "id": "P. N. Belhumeur", "label": "P. N. Belhumeur", "shape": "dot", "size": 10.089285714285714, "title": "P. N. Belhumeur"}, {"color": "#6FA8DC", "id": "D. J. Kriegman", "label": "D. J. Kriegman", "shape": "dot", "size": 10.089285714285714, "title": "D. J. Kriegman"}, {"color": "#6FA8DC", "id": "reconstructing specular surfaces", "label": "reconstructing specular surfaces", "shape": "dot", "size": 10.089285714285714, "title": "reconstructing specular surfaces"}, {"color": "#6FA8DC", "id": "P., Zickler, T., Belhumeur, P. N., \u0026 Kriegman, D. J.", "label": "P., Zickler, T., Belhumeur, P. N., \u0026 Kriegman, D. J.", "shape": "dot", "size": 10.089285714285714, "title": "P., Zickler, T., Belhumeur, P. N., \u0026 Kriegman, D. J."}, {"color": "#6FA8DC", "id": "Lin, S., \u0026 Shum, H.-Y.", "label": "Lin, S., \u0026 Shum, H.-Y.", "shape": "dot", "size": 10.089285714285714, "title": "Lin, S., \u0026 Shum, H.-Y."}, {"color": "#6FA8DC", "id": "separation of diffuse and specular reflection", "label": "separation of diffuse and specular reflection", "shape": "dot", "size": 10.089285714285714, "title": "separation of diffuse and specular reflection"}, {"color": "#6FA8DC", "id": "Tan, R. T., Nishino, K., \u0026 Ikeuchi, K.", "label": "Tan, R. T., Nishino, K., \u0026 Ikeuchi, K.", "shape": "dot", "size": 10.089285714285714, "title": "Tan, R. T., Nishino, K., \u0026 Ikeuchi, K."}, {"color": "#6FA8DC", "id": "Mallick, S. P., Zickler, T., Kriegman, D. J., \u0026 Belhumeur, P. N.", "label": "Mallick, S. P., Zickler, T., Kriegman, D. J., \u0026 Belhumeur, P. N.", "shape": "dot", "size": 10.089285714285714, "title": "Mallick, S. P., Zickler, T., Kriegman, D. J., \u0026 Belhumeur, P. N."}, {"color": "#6FA8DC", "id": "PDE approach", "label": "PDE approach", "shape": "dot", "size": 10.267857142857142, "title": "PDE approach"}, {"color": "#6FA8DC", "id": "diffuse reflection", "label": "diffuse reflection", "shape": "dot", "size": 10.089285714285714, "title": "diffuse reflection"}, {"color": "#6FA8DC", "id": "specular removal", "label": "specular removal", "shape": "dot", "size": 10.089285714285714, "title": "specular removal"}, {"color": "#6FA8DC", "id": "Institute of Artificial AI and Robotics", "label": "Institute of Artificial AI and Robotics", "shape": "dot", "size": 10.267857142857142, "title": "Institute of Artificial AI and Robotics"}, {"color": "#6FA8DC", "id": "Institute of Artificial Intelligence and Robotics", "label": "Institute of Artificial Intelligence and Robotics", "shape": "dot", "size": 10.089285714285714, "title": "Institute of Artificial Intelligence and Robotics"}, {"color": "#6FA8DC", "id": "Nara Institute of Science and Technology", "label": "Nara Institute of Science and Technology", "shape": "dot", "size": 10.089285714285714, "title": "Nara Institute of Science and Technology"}, {"color": "#6FA8DC", "id": "Wuyuan Xie", "label": "Wuyuan Xie", "shape": "dot", "size": 10.089285714285714, "title": "Wuyuan Xie"}, {"color": "#6FA8DC", "id": "Photometric Stereo with Near Point Lighting", "label": "Photometric Stereo with Near Point Lighting", "shape": "dot", "size": 10.446428571428571, "title": "Photometric Stereo with Near Point Lighting"}, {"color": "#6FA8DC", "id": "Chengkai Dai", "label": "Chengkai Dai", "shape": "dot", "size": 10.089285714285714, "title": "Chengkai Dai"}, {"color": "#6FA8DC", "id": "Charlie C. L. Wang", "label": "Charlie C. L. Wang", "shape": "dot", "size": 10.089285714285714, "title": "Charlie C. L. Wang"}, {"color": "#6FA8DC", "id": "Xie_Photometric_Stereo_With_2015_CVPR_paper.pdf", "label": "Xie_Photometric_Stereo_With_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Xie_Photometric_Stereo_With_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "photometric stereo", "label": "photometric stereo", "shape": "dot", "size": 10.267857142857142, "title": "photometric stereo"}, {"color": "#6FA8DC", "id": "near point lighting", "label": "near point lighting", "shape": "dot", "size": 10.178571428571429, "title": "near point lighting"}, {"color": "#6FA8DC", "id": "nonlinear relationship", "label": "nonlinear relationship", "shape": "dot", "size": 10.267857142857142, "title": "nonlinear relationship"}, {"color": "#6FA8DC", "id": "local surface normals", "label": "local surface normals", "shape": "dot", "size": 10.089285714285714, "title": "local surface normals"}, {"color": "#6FA8DC", "id": "light source positions", "label": "light source positions", "shape": "dot", "size": 10.089285714285714, "title": "light source positions"}, {"color": "#6FA8DC", "id": "mesh deformation approach", "label": "mesh deformation approach", "shape": "dot", "size": 10.446428571428571, "title": "mesh deformation approach"}, {"color": "#6FA8DC", "id": "facet position", "label": "facet position", "shape": "dot", "size": 10.089285714285714, "title": "facet position"}, {"color": "#6FA8DC", "id": "facet orientation", "label": "facet orientation", "shape": "dot", "size": 10.089285714285714, "title": "facet orientation"}, {"color": "#6FA8DC", "id": "local projection", "label": "local projection", "shape": "dot", "size": 10.089285714285714, "title": "local projection"}, {"color": "#6FA8DC", "id": "global blending", "label": "global blending", "shape": "dot", "size": 10.089285714285714, "title": "global blending"}, {"color": "#6FA8DC", "id": "accurate surface shape estimation", "label": "accurate surface shape estimation", "shape": "dot", "size": 10.089285714285714, "title": "accurate surface shape estimation"}, {"color": "#6FA8DC", "id": "robustness to light source position errors", "label": "robustness to light source position errors", "shape": "dot", "size": 10.089285714285714, "title": "robustness to light source position errors"}, {"color": "#6FA8DC", "id": "Photometric Stereo", "label": "Photometric Stereo", "shape": "dot", "size": 10.178571428571429, "title": "Photometric Stereo"}, {"color": "#6FA8DC", "id": "Nonlinear Optimization", "label": "Nonlinear Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Nonlinear Optimization"}, {"color": "#6FA8DC", "id": "S. Barsky", "label": "S. Barsky", "shape": "dot", "size": 10.089285714285714, "title": "S. Barsky"}, {"color": "#6FA8DC", "id": "4-source photometric stereo technique", "label": "4-source photometric stereo technique", "shape": "dot", "size": 10.178571428571429, "title": "4-source photometric stereo technique"}, {"color": "#6FA8DC", "id": "highlights and shadows", "label": "highlights and shadows", "shape": "dot", "size": 10.089285714285714, "title": "highlights and shadows"}, {"color": "#6FA8DC", "id": "D. Nehab", "label": "D. Nehab", "shape": "dot", "size": 10.089285714285714, "title": "D. Nehab"}, {"color": "#6FA8DC", "id": "Efficiently combining positions and normals", "label": "Efficiently combining positions and normals", "shape": "dot", "size": 10.178571428571429, "title": "Efficiently combining positions and normals"}, {"color": "#6FA8DC", "id": "precise 3d geometry", "label": "precise 3d geometry", "shape": "dot", "size": 10.089285714285714, "title": "precise 3d geometry"}, {"color": "#6FA8DC", "id": "A. Hertzmann", "label": "A. Hertzmann", "shape": "dot", "size": 10.089285714285714, "title": "A. Hertzmann"}, {"color": "#6FA8DC", "id": "Example-based photometric stereo", "label": "Example-based photometric stereo", "shape": "dot", "size": 10.178571428571429, "title": "Example-based photometric stereo"}, {"color": "#6FA8DC", "id": "shape", "label": "shape", "shape": "dot", "size": 10.178571428571429, "title": "shape"}, {"color": "#6FA8DC", "id": "Shape and spatially-ranging brdfs", "label": "Shape and spatially-ranging brdfs", "shape": "dot", "size": 10.089285714285714, "title": "Shape and spatially-ranging brdfs"}, {"color": "#6FA8DC", "id": "Mesh Deformation", "label": "Mesh Deformation", "shape": "dot", "size": 10.089285714285714, "title": "Mesh Deformation"}, {"color": "#6FA8DC", "id": "Near Point Lighting", "label": "Near Point Lighting", "shape": "dot", "size": 10.089285714285714, "title": "Near Point Lighting"}, {"color": "#6FA8DC", "id": "Photometric stereo", "label": "Photometric stereo", "shape": "dot", "size": 10.357142857142858, "title": "Photometric stereo"}, {"color": "#6FA8DC", "id": "Shape", "label": "Shape", "shape": "dot", "size": 10.089285714285714, "title": "Shape"}, {"color": "#6FA8DC", "id": "Proceedings of the Fifth Eurographics Symposium on Geometry Processing", "label": "Proceedings of the Fifth Eurographics Symposium on Geometry Processing", "shape": "dot", "size": 10.089285714285714, "title": "Proceedings of the Fifth Eurographics Symposium on Geometry Processing"}, {"color": "#6FA8DC", "id": "Computer Vision Workshops (ICCV Workshops)", "label": "Computer Vision Workshops (ICCV Workshops)", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision Workshops (ICCV Workshops)"}, {"color": "#6FA8DC", "id": "Surface orientation", "label": "Surface orientation", "shape": "dot", "size": 10.089285714285714, "title": "Surface orientation"}, {"color": "#6FA8DC", "id": "photometric method", "label": "photometric method", "shape": "dot", "size": 10.089285714285714, "title": "photometric method"}, {"color": "#6FA8DC", "id": "Surface modeling", "label": "Surface modeling", "shape": "dot", "size": 10.089285714285714, "title": "Surface modeling"}, {"color": "#6FA8DC", "id": "as-rigid-as-possible surface modeling", "label": "as-rigid-as-possible surface modeling", "shape": "dot", "size": 10.089285714285714, "title": "as-rigid-as-possible surface modeling"}, {"color": "#6FA8DC", "id": "point light sources", "label": "point light sources", "shape": "dot", "size": 10.089285714285714, "title": "point light sources"}, {"color": "#6FA8DC", "id": "Discrete geometry", "label": "Discrete geometry", "shape": "dot", "size": 10.089285714285714, "title": "Discrete geometry"}, {"color": "#6FA8DC", "id": "BRDF", "label": "BRDF", "shape": "dot", "size": 10.089285714285714, "title": "BRDF"}, {"color": "#6FA8DC", "id": "urographics Symposium on Geometry Processing", "label": "urographics Symposium on Geometry Processing", "shape": "dot", "size": 10.178571428571429, "title": "urographics Symposium on Geometry Processing"}, {"color": "#6FA8DC", "id": "2007", "label": "2007", "shape": "dot", "size": 10.089285714285714, "title": "2007"}, {"color": "#6FA8DC", "id": "S. Bouaziz", "label": "S. Bouaziz", "shape": "dot", "size": 10.089285714285714, "title": "S. Bouaziz"}, {"color": "#6FA8DC", "id": "deep hashing (DH) approach", "label": "deep hashing (DH) approach", "shape": "dot", "size": 10.178571428571429, "title": "deep hashing (DH) approach"}, {"color": "#6FA8DC", "id": "existing binary codes learning methods", "label": "existing binary codes learning methods", "shape": "dot", "size": 10.089285714285714, "title": "existing binary codes learning methods"}, {"color": "#6FA8DC", "id": "single linear projection", "label": "single linear projection", "shape": "dot", "size": 10.089285714285714, "title": "single linear projection"}, {"color": "#6FA8DC", "id": "deep neural network", "label": "deep neural network", "shape": "dot", "size": 10.267857142857142, "title": "deep neural network"}, {"color": "#6FA8DC", "id": "hierarchical non-linear transformations", "label": "hierarchical non-linear transformations", "shape": "dot", "size": 10.089285714285714, "title": "hierarchical non-linear transformations"}, {"color": "#6FA8DC", "id": "nonlinear relationship of samples", "label": "nonlinear relationship of samples", "shape": "dot", "size": 10.089285714285714, "title": "nonlinear relationship of samples"}, {"color": "#6FA8DC", "id": "loss minimization", "label": "loss minimization", "shape": "dot", "size": 10.178571428571429, "title": "loss minimization"}, {"color": "#6FA8DC", "id": "real-valued feature descriptor", "label": "real-valued feature descriptor", "shape": "dot", "size": 10.089285714285714, "title": "real-valued feature descriptor"}, {"color": "#6FA8DC", "id": "each bit", "label": "each bit", "shape": "dot", "size": 10.089285714285714, "title": "each bit"}, {"color": "#6FA8DC", "id": "different bits", "label": "different bits", "shape": "dot", "size": 10.178571428571429, "title": "different bits"}, {"color": "#6FA8DC", "id": "independent", "label": "independent", "shape": "dot", "size": 10.089285714285714, "title": "independent"}, {"color": "#6FA8DC", "id": "nary vector", "label": "nary vector", "shape": "dot", "size": 10.089285714285714, "title": "nary vector"}, {"color": "#6FA8DC", "id": "each other", "label": "each other", "shape": "dot", "size": 10.089285714285714, "title": "each other"}, {"color": "#6FA8DC", "id": "DH", "label": "DH", "shape": "dot", "size": 10.089285714285714, "title": "DH"}, {"color": "#6FA8DC", "id": "discriminative term", "label": "discriminative term", "shape": "dot", "size": 10.357142857142858, "title": "discriminative term"}, {"color": "#6FA8DC", "id": "learned binary codes", "label": "learned binary codes", "shape": "dot", "size": 10.089285714285714, "title": "learned binary codes"}, {"color": "#6FA8DC", "id": "discriminative power", "label": "discriminative power", "shape": "dot", "size": 10.089285714285714, "title": "discriminative power"}, {"color": "#6FA8DC", "id": "state-of-the-arts", "label": "state-of-the-arts", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-arts"}, {"color": "#6FA8DC", "id": "Deep Hashing", "label": "Deep Hashing", "shape": "dot", "size": 10.178571428571429, "title": "Deep Hashing"}, {"color": "#6FA8DC", "id": "Binary Codes Learning", "label": "Binary Codes Learning", "shape": "dot", "size": 10.267857142857142, "title": "Binary Codes Learning"}, {"color": "#6FA8DC", "id": "maximize inter-class variations", "label": "maximize inter-class variations", "shape": "dot", "size": 10.089285714285714, "title": "maximize inter-class variations"}, {"color": "#6FA8DC", "id": "minimize intra-class variations", "label": "minimize intra-class variations", "shape": "dot", "size": 10.089285714285714, "title": "minimize intra-class variations"}, {"color": "#6FA8DC", "id": "Large-Scale Visual Search", "label": "Large-Scale Visual Search", "shape": "dot", "size": 10.089285714285714, "title": "Large-Scale Visual Search"}, {"color": "#6FA8DC", "id": "Hashing Functions", "label": "Hashing Functions", "shape": "dot", "size": 10.089285714285714, "title": "Hashing Functions"}, {"color": "#6FA8DC", "id": "Deep HHashing", "label": "Deep HHashing", "shape": "dot", "size": 10.089285714285714, "title": "Deep HHashing"}, {"color": "#6FA8DC", "id": "Andoni \u0026 Indyk (2006)", "label": "Andoni \u0026 Indyk (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Andoni \u0026 Indyk (2006)"}, {"color": "#6FA8DC", "id": "Near-optimal Hashing Algorithms", "label": "Near-optimal Hashing Algorithms", "shape": "dot", "size": 10.178571428571429, "title": "Near-optimal Hashing Algorithms"}, {"color": "#6FA8DC", "id": "Gong et al. (2012)", "label": "Gong et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Gong et al. (2012)"}, {"color": "#6FA8DC", "id": "Angular Quantization-based Binary Codes", "label": "Angular Quantization-based Binary Codes", "shape": "dot", "size": 10.178571428571429, "title": "Angular Quantization-based Binary Codes"}, {"color": "#6FA8DC", "id": "Hinton \u0026 Salakhutdinov (2006)", "label": "Hinton \u0026 Salakhutdinov (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Hinton \u0026 Salakhutdinov (2006)"}, {"color": "#6FA8DC", "id": "Reducing Data Dimensionality", "label": "Reducing Data Dimensionality", "shape": "dot", "size": 10.089285714285714, "title": "Reducing Data Dimensionality"}, {"color": "#6FA8DC", "id": "Approximate Nearest Neighbor Search", "label": "Approximate Nearest Neighbor Search", "shape": "dot", "size": 10.089285714285714, "title": "Approximate Nearest Neighbor Search"}, {"color": "#6FA8DC", "id": "Fast Similarity Search", "label": "Fast Similarity Search", "shape": "dot", "size": 10.089285714285714, "title": "Fast Similarity Search"}, {"color": "#6FA8DC", "id": "Neural Networks", "label": "Neural Networks", "shape": "dot", "size": 10.357142857142858, "title": "Neural Networks"}, {"color": "#6FA8DC", "id": "data dimensionality", "label": "data dimensionality", "shape": "dot", "size": 10.089285714285714, "title": "data dimensionality"}, {"color": "#6FA8DC", "id": "Tiny Images", "label": "Tiny Images", "shape": "dot", "size": 10.089285714285714, "title": "Tiny Images"}, {"color": "#6FA8DC", "id": "nonparametric object recognition", "label": "nonparametric object recognition", "shape": "dot", "size": 10.089285714285714, "title": "nonparametric object recognition"}, {"color": "#6FA8DC", "id": "Hash Bit Selection", "label": "Hash Bit Selection", "shape": "dot", "size": 10.089285714285714, "title": "Hash Bit Selection"}, {"color": "#6FA8DC", "id": "unified solution", "label": "unified solution", "shape": "dot", "size": 10.089285714285714, "title": "unified solution"}, {"color": "#6FA8DC", "id": "Shift-invariant kernels", "label": "Shift-invariant kernels", "shape": "dot", "size": 10.089285714285714, "title": "Shift-invariant kernels"}, {"color": "#6FA8DC", "id": "locality-sensitive binary codes", "label": "locality-sensitive binary codes", "shape": "dot", "size": 10.089285714285714, "title": "locality-sensitive binary codes"}, {"color": "#6FA8DC", "id": "Minimal Loss Hashing", "label": "Minimal Loss Hashing", "shape": "dot", "size": 10.089285714285714, "title": "Minimal Loss Hashing"}, {"color": "#6FA8DC", "id": "Science", "label": "Science", "shape": "dot", "size": 10.089285714285714, "title": "Science"}, {"color": "#6FA8DC", "id": "Torralba, A.", "label": "Torralba, A.", "shape": "dot", "size": 10.089285714285714, "title": "Torralba, A."}, {"color": "#6FA8DC", "id": "80 million tiny images", "label": "80 million tiny images", "shape": "dot", "size": 10.178571428571429, "title": "80 million tiny images"}, {"color": "#6FA8DC", "id": "*PAM*I", "label": "*PAM*I", "shape": "dot", "size": 10.089285714285714, "title": "*PAM*I"}, {"color": "#6FA8DC", "id": "Wang, J.", "label": "Wang, J.", "shape": "dot", "size": 10.089285714285714, "title": "Wang, J."}, {"color": "#6FA8DC", "id": "Venice Erin Liong", "label": "Venice Erin Liong", "shape": "dot", "size": 10.089285714285714, "title": "Venice Erin Liong"}, {"color": "#6FA8DC", "id": "Gang Wang", "label": "Gang Wang", "shape": "dot", "size": 10.089285714285714, "title": "Gang Wang"}, {"color": "#6FA8DC", "id": "Department of ECE", "label": "Department of ECE", "shape": "dot", "size": 10.089285714285714, "title": "Department of ECE"}, {"color": "#6FA8DC", "id": "Jie Zhou", "label": "Jie Zhou", "shape": "dot", "size": 10.089285714285714, "title": "Jie Zhou"}, {"color": "#6FA8DC", "id": "Department of Automation", "label": "Department of Automation", "shape": "dot", "size": 10.357142857142858, "title": "Department of Automation"}, {"color": "#6FA8DC", "id": "Dongyoon Han", "label": "Dongyoon Han", "shape": "dot", "size": 10.267857142857142, "title": "Dongyoon Han"}, {"color": "#6FA8DC", "id": "Unsupervised Simultaneous Orthogonal Basis Clustering Feature Selection", "label": "Unsupervised Simultaneous Orthogonal Basis Clustering Feature Selection", "shape": "dot", "size": 10.267857142857142, "title": "Unsupervised Simultaneous Orthogonal Basis Clustering Feature Selection"}, {"color": "#6FA8DC", "id": "jzhou@tsinghua.edu.cn", "label": "jzhou@tsinghua.edu.cn", "shape": "dot", "size": 10.089285714285714, "title": "jzhou@tsinghua.edu.cn"}, {"color": "#6FA8DC", "id": "Han_Unsupervised_Simultaneous_Orthogonal_2015_CVPR_paper", "label": "Han_Unsupervised_Simultaneous_Orthogonal_2015_CVPR_paper", "shape": "dot", "size": 10.178571428571429, "title": "Han_Unsupervised_Simultaneous_Orthogonal_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Han_Unpublished_Simultaneous_Orthogonal_2015_CVPR_paper", "label": "Han_Unpublished_Simultaneous_Orthogonal_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Han_Unpublished_Simultaneous_Orthogonal_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "feature selection methods", "label": "feature selection methods", "shape": "dot", "size": 10.089285714285714, "title": "feature selection methods"}, {"color": "#6FA8DC", "id": "supervised and unsupervised feature selection methods", "label": "supervised and unsupervised feature selection methods", "shape": "dot", "size": 10.089285714285714, "title": "supervised and unsupervised feature selection methods"}, {"color": "#6FA8DC", "id": "SOCFS", "label": "SOCFS", "shape": "dot", "size": 10.446428571428571, "title": "SOCFS"}, {"color": "#6FA8DC", "id": "unsupervised feature selection method", "label": "unsupervised feature selection method", "shape": "dot", "size": 10.089285714285714, "title": "unsupervised feature selection method"}, {"color": "#6FA8DC", "id": "feature selection on unlabeled data", "label": "feature selection on unlabeled data", "shape": "dot", "size": 10.089285714285714, "title": "feature selection on unlabeled data"}, {"color": "#6FA8DC", "id": "regularized regression-based formulation", "label": "regularized regression-based formulation", "shape": "dot", "size": 10.178571428571429, "title": "regularized regression-based formulation"}, {"color": "#6FA8DC", "id": "target matrix", "label": "target matrix", "shape": "dot", "size": 10.267857142857142, "title": "target matrix"}, {"color": "#6FA8DC", "id": "latent cluster centers", "label": "latent cluster centers", "shape": "dot", "size": 10.089285714285714, "title": "latent cluster centers"}, {"color": "#6FA8DC", "id": "projection matrix", "label": "projection matrix", "shape": "dot", "size": 10.267857142857142, "title": "projection matrix"}, {"color": "#6FA8DC", "id": "discriminative features", "label": "discriminative features", "shape": "dot", "size": 10.089285714285714, "title": "discriminative features"}, {"color": "#6FA8DC", "id": "real world datasets", "label": "real world datasets", "shape": "dot", "size": 10.089285714285714, "title": "real world datasets"}, {"color": "#6FA8DC", "id": "Nie et al.", "label": "Nie et al.", "shape": "dot", "size": 10.089285714285714, "title": "Nie et al."}, {"color": "#6FA8DC", "id": "feature selection via joint l2,1-norms minimization", "label": "feature selection via joint l2,1-norms minimization", "shape": "dot", "size": 10.178571428571429, "title": "feature selection via joint l2,1-norms minimization"}, {"color": "#6FA8DC", "id": "Nene et al.", "label": "Nene et al.", "shape": "dot", "size": 10.089285714285714, "title": "Nene et al."}, {"color": "#6FA8DC", "id": "Columbia object image library (coil-20)", "label": "Columbia object image library (coil-20)", "shape": "dot", "size": 10.178571428571429, "title": "Columbia object image library (coil-20)"}, {"color": "#6FA8DC", "id": "CCUCS-005-96", "label": "CCUCS-005-96", "shape": "dot", "size": 10.089285714285714, "title": "CCUCS-005-96"}, {"color": "#6FA8DC", "id": "Yang et al.", "label": "Yang et al.", "shape": "dot", "size": 10.089285714285714, "title": "Yang et al."}, {"color": "#6FA8DC", "id": "l2,1-norm regularized discriminative feature selection", "label": "l2,1-norm regularized discriminative feature selection", "shape": "dot", "size": 10.089285714285714, "title": "l2,1-norm regularized discriminative feature selection"}, {"color": "#6FA8DC", "id": "Qian and Zhai", "label": "Qian and Zhai", "shape": "dot", "size": 10.089285714285714, "title": "Qian and Zhai"}, {"color": "#6FA8DC", "id": "Robust unsupervised feature selection", "label": "Robust unsupervised feature selection", "shape": "dot", "size": 10.178571428571429, "title": "Robust unsupervised feature selection"}, {"color": "#6FA8DC", "id": "IJCAI", "label": "IJCAI", "shape": "dot", "size": 10.089285714285714, "title": "IJCAI"}, {"color": "#6FA8DC", "id": "Sch\u00a8onemann", "label": "Sch\u00a8onemann", "shape": "dot", "size": 10.089285714285714, "title": "Sch\u00a8onemann"}, {"color": "#6FA8DC", "id": "generalized solution of the orthogonal Procustes problem", "label": "generalized solution of the orthogonal Procustes problem", "shape": "dot", "size": 10.089285714285714, "title": "generalized solution of the orthogonal Procustes problem"}, {"color": "#6FA8DC", "id": "Zhao and Liu", "label": "Zhao and Liu", "shape": "dot", "size": 10.089285714285714, "title": "Zhao and Liu"}, {"color": "#6FA8DC", "id": "Spectral feature selection", "label": "Spectral feature selection", "shape": "dot", "size": 10.267857142857142, "title": "Spectral feature selection"}, {"color": "#6FA8DC", "id": "Procrustes problem", "label": "Procrustes problem", "shape": "dot", "size": 10.089285714285714, "title": "Procrustes problem"}, {"color": "#6FA8DC", "id": "Psychometrika", "label": "Psychometrika", "shape": "dot", "size": 10.089285714285714, "title": "Psychometrika"}, {"color": "#6FA8DC", "id": "Zhao, Z.", "label": "Zhao, Z.", "shape": "dot", "size": 10.089285714285714, "title": "Zhao, Z."}, {"color": "#6FA8DC", "id": "Samaria, F. S.", "label": "Samaria, F. S.", "shape": "dot", "size": 10.089285714285714, "title": "Samaria, F. S."}, {"color": "#6FA8DC", "id": "stochastic model", "label": "stochastic model", "shape": "dot", "size": 10.089285714285714, "title": "stochastic model"}, {"color": "#6FA8DC", "id": "Jianming Zhang", "label": "Jianming Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Jianming Zhang"}, {"color": "#6FA8DC", "id": "Salient Object Subitizing", "label": "Salient Object Subitizing", "shape": "dot", "size": 10.803571428571429, "title": "Salient Object Subitizing"}, {"color": "#6FA8DC", "id": "Shugao Ma", "label": "Shugao Ma", "shape": "dot", "size": 10.178571428571429, "title": "Shugao Ma"}, {"color": "#6FA8DC", "id": "Mehrnooush Sameki", "label": "Mehrnooush Sameki", "shape": "dot", "size": 10.089285714285714, "title": "Mehrnooush Sameki"}, {"color": "#6FA8DC", "id": "Stan Sclaroff", "label": "Stan Sclaroff", "shape": "dot", "size": 10.178571428571429, "title": "Stan Sclaroff"}, {"color": "#6FA8DC", "id": "Margrit Betke", "label": "Margrit Betke", "shape": "dot", "size": 10.178571428571429, "title": "Margrit Betke"}, {"color": "#6FA8DC", "id": "Radom\u00edr M\u011bch", "label": "Radom\u00edr M\u011bch", "shape": "dot", "size": 10.089285714285714, "title": "Radom\u00edr M\u011bch"}, {"color": "#6FA8DC", "id": "People", "label": "People", "shape": "dot", "size": 10.089285714285714, "title": "People"}, {"color": "#6FA8DC", "id": "subitizing", "label": "subitizing", "shape": "dot", "size": 10.089285714285714, "title": "subitizing"}, {"color": "#6FA8DC", "id": "Salient Object Subitizing (SOS)", "label": "Salient Object Subitizing (SOS)", "shape": "dot", "size": 10.357142857142858, "title": "Salient Object Subitizing (SOS)"}, {"color": "#6FA8DC", "id": "predict existence and number", "label": "predict existence and number", "shape": "dot", "size": 10.089285714285714, "title": "predict existence and number"}, {"color": "#6FA8DC", "id": "annotated through crowdsourcing", "label": "annotated through crowdsourcing", "shape": "dot", "size": 10.089285714285714, "title": "annotated through crowdsourcing"}, {"color": "#6FA8DC", "id": "high accuracy", "label": "high accuracy", "shape": "dot", "size": 10.089285714285714, "title": "high accuracy"}, {"color": "#6FA8DC", "id": "salient objects", "label": "salient objects", "shape": "dot", "size": 10.089285714285714, "title": "salient objects"}, {"color": "#6FA8DC", "id": "number of objects", "label": "number of objects", "shape": "dot", "size": 10.089285714285714, "title": "number of objects"}, {"color": "#6FA8DC", "id": "object proposal applications", "label": "object proposal applications", "shape": "dot", "size": 10.089285714285714, "title": "object proposal applications"}, {"color": "#6FA8DC", "id": "Crowd Sourcing", "label": "Crowd Sourcing", "shape": "dot", "size": 10.089285714285714, "title": "Crowd Sourcing"}, {"color": "#6FA8DC", "id": "Holistic Image Analysis", "label": "Holistic Image Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Holistic Image Analysis"}, {"color": "#6FA8DC", "id": "Computer Vision Applications", "label": "Computer Vision Applications", "shape": "dot", "size": 10.178571428571429, "title": "Computer Vision Applications"}, {"color": "#6FA8DC", "id": "robot vision", "label": "robot vision", "shape": "dot", "size": 10.089285714285714, "title": "robot vision"}, {"color": "#6FA8DC", "id": "Boston University", "label": "Boston University", "shape": "dot", "size": 10.446428571428571, "title": "Boston University"}, {"color": "#6FA8DC", "id": "Mehrnoosh Sameki", "label": "Mehrnoosh Sameki", "shape": "dot", "size": 10.089285714285714, "title": "Mehrnoosh Sameki"}, {"color": "#6FA8DC", "id": "Radom\u00b4\u0131r M\u02d8ech", "label": "Radom\u00b4\u0131r M\u02d8ech", "shape": "dot", "size": 10.089285714285714, "title": "Radom\u00b4\u0131r M\u02d8ech"}, {"color": "#6FA8DC", "id": "Discriminaitve Shape from Shading", "label": "Discriminaitve Shape from Shading", "shape": "dot", "size": 10.357142857142858, "title": "Discriminaitve Shape from Shading"}, {"color": "#6FA8DC", "id": "Richter_Discriminaitve_Shape_From_2015_CVPR_paper.pdf", "label": "Richter_Discriminaitve_Shape_From_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.178571428571429, "title": "Richter_Discriminaitve_Shape_From_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Estimating surface normals", "label": "Estimating surface normals", "shape": "dot", "size": 10.178571428571429, "title": "Estimating surface normals"}, {"color": "#6FA8DC", "id": "challenging problem", "label": "challenging problem", "shape": "dot", "size": 10.089285714285714, "title": "challenging problem"}, {"color": "#6FA8DC", "id": "under-constrained problem", "label": "under-constrained problem", "shape": "dot", "size": 10.089285714285714, "title": "under-constrained problem"}, {"color": "#6FA8DC", "id": "Simplifying assumptions", "label": "Simplifying assumptions", "shape": "dot", "size": 10.178571428571429, "title": "Simplifying assumptions"}, {"color": "#6FA8DC", "id": "directional lighting", "label": "directional lighting", "shape": "dot", "size": 10.089285714285714, "title": "directional lighting"}, {"color": "#6FA8DC", "id": "known reflectance maps", "label": "known reflectance maps", "shape": "dot", "size": 10.089285714285714, "title": "known reflectance maps"}, {"color": "#6FA8DC", "id": "regression forests", "label": "regression forests", "shape": "dot", "size": 10.089285714285714, "title": "regression forests"}, {"color": "#6FA8DC", "id": "Von Mises-Fisher distributions", "label": "Von Mises-Fisher distributions", "shape": "dot", "size": 10.089285714285714, "title": "Von Mises-Fisher distributions"}, {"color": "#6FA8DC", "id": "spatial features", "label": "spatial features", "shape": "dot", "size": 10.267857142857142, "title": "spatial features"}, {"color": "#6FA8DC", "id": "textons", "label": "textons", "shape": "dot", "size": 10.089285714285714, "title": "textons"}, {"color": "#6FA8DC", "id": "novel silhouette features", "label": "novel silhouette features", "shape": "dot", "size": 10.089285714285714, "title": "novel silhouette features"}, {"color": "#6FA8DC", "id": "generalization", "label": "generalization", "shape": "dot", "size": 10.178571428571429, "title": "generalization"}, {"color": "#6FA8DC", "id": "uncalibrated illumination", "label": "uncalibrated illumination", "shape": "dot", "size": 10.089285714285714, "title": "uncalibrated illumination"}, {"color": "#6FA8DC", "id": "pixel-independent prediction", "label": "pixel-independent prediction", "shape": "dot", "size": 10.089285714285714, "title": "pixel-independent prediction"}, {"color": "#6FA8DC", "id": "efficient estimation", "label": "efficient estimation", "shape": "dot", "size": 10.089285714285714, "title": "efficient estimation"}, {"color": "#6FA8DC", "id": "research area", "label": "research area", "shape": "dot", "size": 10.178571428571429, "title": "research area"}, {"color": "#6FA8DC", "id": "Discrimiative Learning", "label": "Discrimiative Learning", "shape": "dot", "size": 10.089285714285714, "title": "Discrimiative Learning"}, {"color": "#6FA8DC", "id": "J. T. Barron", "label": "J. T. Barron", "shape": "dot", "size": 10.178571428571429, "title": "J. T. Barron"}, {"color": "#6FA8DC", "id": "Color constancy, intrinsic images, and shape estimation", "label": "Color constancy, intrinsic images, and shape estimation", "shape": "dot", "size": 10.089285714285714, "title": "Color constancy, intrinsic images, and shape estimation"}, {"color": "#6FA8DC", "id": "Shape, albedo, and illumination from a single image", "label": "Shape, albedo, and illumination from a single image", "shape": "dot", "size": 10.089285714285714, "title": "Shape, albedo, and illumination from a single image"}, {"color": "#6FA8DC", "id": "J. Ben-Arie", "label": "J. Ben-Arie", "shape": "dot", "size": 10.089285714285714, "title": "J. Ben-Arie"}, {"color": "#6FA8DC", "id": "A neural network approach", "label": "A neural network approach", "shape": "dot", "size": 10.089285714285714, "title": "A neural network approach"}, {"color": "#6FA8DC", "id": "L. Breiman", "label": "L. Breiman", "shape": "dot", "size": 10.089285714285714, "title": "L. Breiman"}, {"color": "#6FA8DC", "id": "ShapeCollage", "label": "ShapeCollage", "shape": "dot", "size": 10.357142857142858, "title": "ShapeCollage"}, {"color": "#6FA8DC", "id": "example-based methods", "label": "example-based methods", "shape": "dot", "size": 10.089285714285714, "title": "example-based methods"}, {"color": "#6FA8DC", "id": "Image-to-geometry registration", "label": "Image-to-geometry registration", "shape": "dot", "size": 10.178571428571429, "title": "Image-to-geometry registration"}, {"color": "#6FA8DC", "id": "Modeling data", "label": "Modeling data", "shape": "dot", "size": 10.089285714285714, "title": "Modeling data"}, {"color": "#6FA8DC", "id": "directional distributions", "label": "directional distributions", "shape": "dot", "size": 10.089285714285714, "title": "directional distributions"}, {"color": "#6FA8DC", "id": "Dispersion", "label": "Dispersion", "shape": "dot", "size": 10.089285714285714, "title": "Dispersion"}, {"color": "#6FA8DC", "id": "P. Roy. Soc. Lond. B", "label": "P. Roy. Soc. Lond. B", "shape": "dot", "size": 10.089285714285714, "title": "P. Roy. Soc. Lond. B"}, {"color": "#6FA8DC", "id": "Floating scale reconstruction", "label": "Floating scale reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "Floating scale reconstruction"}, {"color": "#6FA8DC", "id": "SIGGRAPH", "label": "SIGGRAPH", "shape": "dot", "size": 10.178571428571429, "title": "SIGGRAPH"}, {"color": "#6FA8DC", "id": "baseline evaluations", "label": "baseline evaluations", "shape": "dot", "size": 10.089285714285714, "title": "baseline evaluations"}, {"color": "#6FA8DC", "id": "occlusion-aware shape interpretation", "label": "occlusion-aware shape interpretation", "shape": "dot", "size": 10.089285714285714, "title": "occlusion-aware shape interpretation"}, {"color": "#6FA8DC", "id": "Adelson", "label": "Adelson", "shape": "dot", "size": 10.089285714285714, "title": "Adelson"}, {"color": "#6FA8DC", "id": "W. T. Freeman", "label": "W. T. Freeman", "shape": "dot", "size": 10.089285714285714, "title": "W. T. Freeman"}, {"color": "#6FA8DC", "id": "Jean-Dominique FAVREAU", "label": "Jean-Dominique FAVREAU", "shape": "dot", "size": 10.178571428571429, "title": "Jean-Dominique FAVREAU"}, {"color": "#6FA8DC", "id": "Line Drawing Interpretation", "label": "Line Drawing Interpretation", "shape": "dot", "size": 10.535714285714286, "title": "Line Drawing Interpretation"}, {"color": "#6FA8DC", "id": "Adrien Bousseau", "label": "Adrien Bousseau", "shape": "dot", "size": 10.357142857142858, "title": "Adrien Bousseau"}, {"color": "#6FA8DC", "id": "interpreting line drawings", "label": "interpreting line drawings", "shape": "dot", "size": 10.089285714285714, "title": "interpreting line drawings"}, {"color": "#6FA8DC", "id": "line drawings", "label": "line drawings", "shape": "dot", "size": 10.178571428571429, "title": "line drawings"}, {"color": "#6FA8DC", "id": "imaginary objects", "label": "imaginary objects", "shape": "dot", "size": 10.089285714285714, "title": "imaginary objects"}, {"color": "#6FA8DC", "id": "photographs", "label": "photographs", "shape": "dot", "size": 10.267857142857142, "title": "photographs"}, {"color": "#6FA8DC", "id": "computer vision algorithms", "label": "computer vision algorithms", "shape": "dot", "size": 10.089285714285714, "title": "computer vision algorithms"}, {"color": "#6FA8DC", "id": "limited support", "label": "limited support", "shape": "dot", "size": 10.089285714285714, "title": "limited support"}, {"color": "#6FA8DC", "id": "multi-view stereo algorithms", "label": "multi-view stereo algorithms", "shape": "dot", "size": 10.089285714285714, "title": "multi-view stereo algorithms"}, {"color": "#6FA8DC", "id": "real-world scenes", "label": "real-world scenes", "shape": "dot", "size": 10.089285714285714, "title": "real-world scenes"}, {"color": "#6FA8DC", "id": "line-drawing interpretation algorithms", "label": "line-drawing interpretation algorithms", "shape": "dot", "size": 10.089285714285714, "title": "line-drawing interpretation algorithms"}, {"color": "#6FA8DC", "id": "contextual awareness", "label": "contextual awareness", "shape": "dot", "size": 10.089285714285714, "title": "contextual awareness"}, {"color": "#6FA8DC", "id": "strengths", "label": "strengths", "shape": "dot", "size": 10.089285714285714, "title": "strengths"}, {"color": "#6FA8DC", "id": "dominant orientations", "label": "dominant orientations", "shape": "dot", "size": 10.089285714285714, "title": "dominant orientations"}, {"color": "#6FA8DC", "id": "interpretation", "label": "interpretation", "shape": "dot", "size": 10.089285714285714, "title": "interpretation"}, {"color": "#6FA8DC", "id": "polygon", "label": "polygon", "shape": "dot", "size": 10.178571428571429, "title": "polygon"}, {"color": "#6FA8DC", "id": "orientation", "label": "orientation", "shape": "dot", "size": 10.089285714285714, "title": "orientation"}, {"color": "#6FA8DC", "id": "creation", "label": "creation", "shape": "dot", "size": 10.089285714285714, "title": "creation"}, {"color": "#6FA8DC", "id": "new structures", "label": "new structures", "shape": "dot", "size": 10.178571428571429, "title": "new structures"}, {"color": "#6FA8DC", "id": "real world", "label": "real world", "shape": "dot", "size": 10.089285714285714, "title": "real world"}, {"color": "#6FA8DC", "id": "furniture design", "label": "furniture design", "shape": "dot", "size": 10.178571428571429, "title": "furniture design"}, {"color": "#6FA8DC", "id": "archaeology", "label": "archaeology", "shape": "dot", "size": 10.178571428571429, "title": "archaeology"}, {"color": "#6FA8DC", "id": "new orientation", "label": "new orientation", "shape": "dot", "size": 10.178571428571429, "title": "new orientation"}, {"color": "#6FA8DC", "id": "creation of new structures", "label": "creation of new structures", "shape": "dot", "size": 10.178571428571429, "title": "creation of new structures"}, {"color": "#6FA8DC", "id": "unknown orientation", "label": "unknown orientation", "shape": "dot", "size": 10.089285714285714, "title": "unknown orientation"}, {"color": "#6FA8DC", "id": "application domain", "label": "application domain", "shape": "dot", "size": 10.267857142857142, "title": "application domain"}, {"color": "#6FA8DC", "id": "Computer-Aided Design", "label": "Computer-Aided Design", "shape": "dot", "size": 10.089285714285714, "title": "Computer-Aided Design"}, {"color": "#6FA8DC", "id": "Computer-Aided Design application", "label": "Computer-Aided Design application", "shape": "dot", "size": 10.178571428571429, "title": "Computer-Aided Design application"}, {"color": "#6FA8DC", "id": "Furniture Design", "label": "Furniture Design", "shape": "dot", "size": 10.089285714285714, "title": "Furniture Design"}, {"color": "#6FA8DC", "id": "O-snap", "label": "O-snap", "shape": "dot", "size": 10.178571428571429, "title": "O-snap"}, {"color": "#6FA8DC", "id": "optimization-based snapping method", "label": "optimization-based snapping method", "shape": "dot", "size": 10.089285714285714, "title": "optimization-based snapping method"}, {"color": "#6FA8DC", "id": "M. Arikan", "label": "M. Arikan", "shape": "dot", "size": 10.089285714285714, "title": "M. Arikan"}, {"color": "#6FA8DC", "id": "3D Scene Understanding", "label": "3D Scene Understanding", "shape": "dot", "size": 10.089285714285714, "title": "3D Scene Understanding"}, {"color": "#6FA8DC", "id": "H. Barrow", "label": "H. Barrow", "shape": "dot", "size": 10.089285714285714, "title": "H. Barrow"}, {"color": "#6FA8DC", "id": "Y. Boykov", "label": "Y. Boykov", "shape": "dot", "size": 10.089285714285714, "title": "Y. Boykov"}, {"color": "#6FA8DC", "id": "energy minimization algorithms", "label": "energy minimization algorithms", "shape": "dot", "size": 10.178571428571429, "title": "energy minimization algorithms"}, {"color": "#6FA8DC", "id": "A.-L. Chauve", "label": "A.-L. Chauve", "shape": "dot", "size": 10.089285714285714, "title": "A.-L. Chauve"}, {"color": "#6FA8DC", "id": "3D reconstruction methods", "label": "3D reconstruction methods", "shape": "dot", "size": 10.089285714285714, "title": "3D reconstruction methods"}, {"color": "#6FA8DC", "id": "Multi-View Stereo Reconstruction", "label": "Multi-View Stereo Reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "Multi-View Stereo Reconstruction"}, {"color": "#6FA8DC", "id": "minimization in vision", "label": "minimization in vision", "shape": "dot", "size": 10.089285714285714, "title": "minimization in vision"}, {"color": "#6FA8DC", "id": "Furukawa et al.", "label": "Furukawa et al.", "shape": "dot", "size": 10.178571428571429, "title": "Furukawa et al."}, {"color": "#6FA8DC", "id": "Manhattan-world stereo", "label": "Manhattan-world stereo", "shape": "dot", "size": 10.089285714285714, "title": "Manhattan-world stereo"}, {"color": "#6FA8DC", "id": "Architectural modeling", "label": "Architectural modeling", "shape": "dot", "size": 10.089285714285714, "title": "Architectural modeling"}, {"color": "#6FA8DC", "id": "Debevec et al.", "label": "Debevec et al.", "shape": "dot", "size": 10.089285714285714, "title": "Debevec et al."}, {"color": "#6FA8DC", "id": "Wiley-ISTE", "label": "Wiley-ISTE", "shape": "dot", "size": 10.089285714285714, "title": "Wiley-ISTE"}, {"color": "#6FA8DC", "id": "Stochastic geometry for image analysis", "label": "Stochastic geometry for image analysis", "shape": "dot", "size": 10.089285714285714, "title": "Stochastic geometry for image analysis"}, {"color": "#6FA8DC", "id": "INRIA Sophia-Antippolis", "label": "INRIA Sophia-Antippolis", "shape": "dot", "size": 10.089285714285714, "title": "INRIA Sophia-Antippolis"}, {"color": "#6FA8DC", "id": "Florent LAFARGE", "label": "Florent LAFARGE", "shape": "dot", "size": 10.267857142857142, "title": "Florent LAFARGE"}, {"color": "#6FA8DC", "id": "INRIA Sophia-Antipollis", "label": "INRIA Sophia-Antipollis", "shape": "dot", "size": 10.178571428571429, "title": "INRIA Sophia-Antipollis"}, {"color": "#6FA8DC", "id": "Bis Publishers", "label": "Bis Publishers", "shape": "dot", "size": 10.089285714285714, "title": "Bis Publishers"}, {"color": "#6FA8DC", "id": " Sketching: The Basics", "label": " Sketching: The Basics", "shape": "dot", "size": 10.089285714285714, "title": " Sketching: The Basics"}, {"color": "#6FA8DC", "id": "jean-dominuque.favreau@inria.fr", "label": "jean-dominuque.favreau@inria.fr", "shape": "dot", "size": 10.089285714285714, "title": "jean-dominuque.favreau@inria.fr"}, {"color": "#6FA8DC", "id": "INRIA Sophia-Antipolis", "label": "INRIA Sophia-Antipolis", "shape": "dot", "size": 10.178571428571429, "title": "INRIA Sophia-Antipolis"}, {"color": "#6FA8DC", "id": "INRIAL Sophia-Antipolis", "label": "INRIAL Sophia-Antipolis", "shape": "dot", "size": 10.089285714285714, "title": "INRIAL Sophia-Antipolis"}, {"color": "#6FA8DC", "id": "Olga Russakovsky", "label": "Olga Russakovsky", "shape": "dot", "size": 10.178571428571429, "title": "Olga Russakovsky"}, {"color": "#6FA8DC", "id": "Best of both worlds", "label": "Best of both worlds", "shape": "dot", "size": 10.357142857142858, "title": "Best of both worlds"}, {"color": "#6FA8DC", "id": "Li-Jia Li", "label": "Li-Jia Li", "shape": "dot", "size": 10.178571428571429, "title": "Li-Jia Li"}, {"color": "#6FA8DC", "id": "Li Fei-Fei", "label": "Li Fei-Fei", "shape": "dot", "size": 10.178571428571429, "title": "Li Fei-Fei"}, {"color": "#6FA8DC", "id": "Russakovsky_Best_of_Both_2015_CVPR_paper.pdf", "label": "Russakovsky_Best_of_Both_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Russakovsky_Best_of_Both_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "jean-dominique.favreau@inria.fr", "label": "jean-dominique.favreau@inria.fr", "shape": "dot", "size": 10.089285714285714, "title": "jean-dominique.favreau@inria.fr"}, {"color": "#6FA8DC", "id": "jean-dominique.favreau", "label": "jean-dominique.favreau", "shape": "dot", "size": 10.089285714285714, "title": "jean-dominique.favreau"}, {"color": "#6FA8DC", "id": "florent.lafarge@inria.fr", "label": "florent.lafarge@inria.fr", "shape": "dot", "size": 10.089285714285714, "title": "florent.lafarge@inria.fr"}, {"color": "#6FA8DC", "id": "adrien.bousseau@inria.fr", "label": "adrien.bousseau@inria.fr", "shape": "dot", "size": 10.089285714285714, "title": "adrien.bousseau@inria.fr"}, {"color": "#6FA8DC", "id": "localizing every object in an image", "label": "localizing every object in an image", "shape": "dot", "size": 10.089285714285714, "title": "localizing every object in an image"}, {"color": "#6FA8DC", "id": "manual annotation", "label": "manual annotation", "shape": "dot", "size": 10.178571428571429, "title": "manual annotation"}, {"color": "#6FA8DC", "id": "quite expensive", "label": "quite expensive", "shape": "dot", "size": 10.089285714285714, "title": "quite expensive"}, {"color": "#6FA8DC", "id": "crowd engineering innovations", "label": "crowd engineering innovations", "shape": "dot", "size": 10.089285714285714, "title": "crowd engineering innovations"}, {"color": "#6FA8DC", "id": "automatic object detectors", "label": "automatic object detectors", "shape": "dot", "size": 10.089285714285714, "title": "automatic object detectors"}, {"color": "#6FA8DC", "id": "at most a few objects per image", "label": "at most a few objects per image", "shape": "dot", "size": 10.089285714285714, "title": "at most a few objects per image"}, {"color": "#6FA8DC", "id": "object detection advancements", "label": "object detection advancements", "shape": "dot", "size": 10.089285714285714, "title": "object detection advancements"}, {"color": "#6FA8DC", "id": "crowd engineering", "label": "crowd engineering", "shape": "dot", "size": 10.089285714285714, "title": "crowd engineering"}, {"color": "#6FA8DC", "id": "image to annotate", "label": "image to annotate", "shape": "dot", "size": 10.089285714285714, "title": "image to annotate"}, {"color": "#6FA8DC", "id": "annotation constraints", "label": "annotation constraints", "shape": "dot", "size": 10.089285714285714, "title": "annotation constraints"}, {"color": "#6FA8DC", "id": "object annotations", "label": "object annotations", "shape": "dot", "size": 10.357142857142858, "title": "object annotations"}, {"color": "#6FA8DC", "id": "human feedback", "label": "human feedback", "shape": "dot", "size": 10.089285714285714, "title": "human feedback"}, {"color": "#6FA8DC", "id": "computer vision models", "label": "computer vision models", "shape": "dot", "size": 10.178571428571429, "title": "computer vision models"}, {"color": "#6FA8DC", "id": "human input", "label": "human input", "shape": "dot", "size": 10.267857142857142, "title": "human input"}, {"color": "#6FA8DC", "id": "Markov Decision Process", "label": "Markov Decision Process", "shape": "dot", "size": 10.178571428571429, "title": "Markov Decision Process"}, {"color": "#6FA8DC", "id": "ILSVRC2014 dataset", "label": "ILSVRC2014 dataset", "shape": "dot", "size": 10.089285714285714, "title": "ILSVRC2014 dataset"}, {"color": "#6FA8DC", "id": "feedback", "label": "feedback", "shape": "dot", "size": 10.089285714285714, "title": "feedback"}, {"color": "#6FA8DC", "id": "human-in-the-loop labeling approach", "label": "human-in-the-loop labeling approach", "shape": "dot", "size": 10.089285714285714, "title": "human-in-the-loop labeling approach"}, {"color": "#6FA8DC", "id": "ILSVRC2014 object detection dataset", "label": "ILSVRC2014 object detection dataset", "shape": "dot", "size": 10.089285714285714, "title": "ILSVRC2014 object detection dataset"}, {"color": "#6FA8DC", "id": "Stanford University", "label": "Stanford University", "shape": "dot", "size": 10.178571428571429, "title": "Stanford University"}, {"color": "#6FA8DC", "id": "Snapchat", "label": "Snapchat", "shape": "dot", "size": 10.089285714285714, "title": "Snapchat"}, {"color": "#6FA8DC", "id": "Visesh Chari", "label": "Visesh Chari", "shape": "dot", "size": 10.267857142857142, "title": "Visesh Chari"}, {"color": "#6FA8DC", "id": "On Pairwise Costs for Network Flow Multi-Object Tracking", "label": "On Pairwise Costs for Network Flow Multi-Object Tracking", "shape": "dot", "size": 10.357142857142858, "title": "On Pairwise Costs for Network Flow Multi-Object Tracking"}, {"color": "#6FA8DC", "id": "Ivan Laptev", "label": "Ivan Laptev", "shape": "dot", "size": 10.178571428571429, "title": "Ivan Laptev"}, {"color": "#6FA8DC", "id": "Josef Sivic", "label": "Josef Sivic", "shape": "dot", "size": 10.178571428571429, "title": "Josef Sivic"}, {"color": "#6FA8DC", "id": "Chari_On_Pairwise_Costs_2015_CVPR_supplemental", "label": "Chari_On_Pairwise_Costs_2015_CVPR_supplemental", "shape": "dot", "size": 10.089285714285714, "title": "Chari_On_Pairwise_Costs_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "Multi-object Tracking", "label": "Multi-object Tracking", "shape": "dot", "size": 10.267857142857142, "title": "Multi-object Tracking"}, {"color": "#6FA8DC", "id": "Network Flow Optimization", "label": "Network Flow Optimization", "shape": "dot", "size": 10.178571428571429, "title": "Network Flow Optimization"}, {"color": "#6FA8DC", "id": "dependencies among tracks", "label": "dependencies among tracks", "shape": "dot", "size": 10.089285714285714, "title": "dependencies among tracks"}, {"color": "#6FA8DC", "id": "Pairwise Costs", "label": "Pairwise Costs", "shape": "dot", "size": 10.178571428571429, "title": "Pairwise Costs"}, {"color": "#6FA8DC", "id": "object detector failures", "label": "object detector failures", "shape": "dot", "size": 10.089285714285714, "title": "object detector failures"}, {"color": "#6FA8DC", "id": "min-cost network flow framework", "label": "min-cost network flow framework", "shape": "dot", "size": 10.089285714285714, "title": "min-cost network flow framework"}, {"color": "#6FA8DC", "id": "Convex Relaxation", "label": "Convex Relaxation", "shape": "dot", "size": 10.089285714285714, "title": "Convex Relaxation"}, {"color": "#6FA8DC", "id": "efficient rounding heuristic", "label": "efficient rounding heuristic", "shape": "dot", "size": 10.089285714285714, "title": "efficient rounding heuristic"}, {"color": "#6FA8DC", "id": "pairwise costs", "label": "pairwise costs", "shape": "dot", "size": 10.267857142857142, "title": "pairwise costs"}, {"color": "#6FA8DC", "id": "real-world video sequences", "label": "real-world video sequences", "shape": "dot", "size": 10.089285714285714, "title": "real-world video sequences"}, {"color": "#6FA8DC", "id": "recent tracking methods", "label": "recent tracking methods", "shape": "dot", "size": 10.089285714285714, "title": "recent tracking methods"}, {"color": "#6FA8DC", "id": "INRIA", "label": "INRIA", "shape": "dot", "size": 10.267857142857142, "title": "INRIA"}, {"color": "#6FA8DC", "id": "Ecole Normale Sup\u00b4erieure", "label": "Ecole Normale Sup\u00b4erieure", "shape": "dot", "size": 10.089285714285714, "title": "Ecole Normale Sup\u00b4erieure"}, {"color": "#6FA8DC", "id": "Tracking-by-Detection", "label": "Tracking-by-Detection", "shape": "dot", "size": 10.178571428571429, "title": "Tracking-by-Detection"}, {"color": "#6FA8DC", "id": "TILDE", "label": "TILDE", "shape": "dot", "size": 10.446428571428571, "title": "TILDE"}, {"color": "#6FA8DC", "id": "Temporally Invariant Learned Detector", "label": "Temporally Invariant Learned Detector", "shape": "dot", "size": 10.089285714285714, "title": "Temporally Invariant Learned Detector"}, {"color": "#6FA8DC", "id": "Yannick Verdie", "label": "Yannick Verdie", "shape": "dot", "size": 10.178571428571429, "title": "Yannick Verdie"}, {"color": "#6FA8DC", "id": "Kwang Moo Yi", "label": "Kwang Moo Yi", "shape": "dot", "size": 10.178571428571429, "title": "Kwang Moo Yi"}, {"color": "#6FA8DC", "id": "Pascal Fua", "label": "Pascal Fua", "shape": "dot", "size": 10.089285714285714, "title": "Pascal Fua"}, {"color": "#6FA8DC", "id": "Vincent Lepetit", "label": "Vincent Lepetit", "shape": "dot", "size": 10.089285714285714, "title": "Vincent Lepetit"}, {"color": "#6FA8DC", "id": "Simon Lacoste-Julien", "label": "Simon Lacoste-Julien", "shape": "dot", "size": 10.089285714285714, "title": "Simon Lacoste-Julien"}, {"color": "#6FA8DC", "id": "INRIO", "label": "INRIO", "shape": "dot", "size": 10.089285714285714, "title": "INRIO"}, {"color": "#6FA8DC", "id": "Cortes, C.", "label": "Cortes, C.", "shape": "dot", "size": 10.178571428571429, "title": "Cortes, C."}, {"color": "#6FA8DC", "id": "Support-Vector Networks", "label": "Support-Vector Networks", "shape": "dot", "size": 10.357142857142858, "title": "Support-Vector Networks"}, {"color": "#6FA8DC", "id": "Vapnik, V.", "label": "Vapnik, V.", "shape": "dot", "size": 10.178571428571429, "title": "Vapnik, V."}, {"color": "#6FA8DC", "id": "Harris, C.", "label": "Harris, C.", "shape": "dot", "size": 10.178571428571429, "title": "Harris, C."}, {"color": "#6FA8DC", "id": "Combined Corner and Edge Detector", "label": "Combined Corner and Edge Detector", "shape": "dot", "size": 10.178571428571429, "title": "Combined Corner and Edge Detector"}, {"color": "#6FA8DC", "id": "Stephens, M.", "label": "Stephens, M.", "shape": "dot", "size": 10.178571428571429, "title": "Stephens, M."}, {"color": "#6FA8DC", "id": "C.", "label": "C.", "shape": "dot", "size": 10.089285714285714, "title": "C."}, {"color": "#6FA8DC", "id": "Corner Detector", "label": "Corner Detector", "shape": "dot", "size": 10.178571428571429, "title": "Corner Detector"}, {"color": "#6FA8DC", "id": "Bay, H.", "label": "Bay, H.", "shape": "dot", "size": 10.089285714285714, "title": "Bay, H."}, {"color": "#6FA8DC", "id": "Hinging Hyperplanes", "label": "Hinging Hyperplanes", "shape": "dot", "size": 10.178571428571429, "title": "Hinging Hyperplanes"}, {"color": "#6FA8DC", "id": "IEEE Transactions on Information Theory", "label": "IEEE Transactions on Information Theory", "shape": "dot", "size": 10.178571428571429, "title": "IEEE Transactions on Information Theory"}, {"color": "#6FA8DC", "id": "Gradient-Based Learning", "label": "Gradient-Based Learning", "shape": "dot", "size": 10.089285714285714, "title": "Gradient-Based Learning"}, {"color": "#6FA8DC", "id": "Document Recognition", "label": "Document Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Document Recognition"}, {"color": "#6FA8DC", "id": "Af\ufb01ne Region Detectors", "label": "Af\ufb01ne Region Detectors", "shape": "dot", "size": 10.089285714285714, "title": "Af\ufb01ne Region Detectors"}, {"color": "#6FA8DC", "id": "Mikolajczyk, K.", "label": "Mikolajczyk, K.", "shape": "dot", "size": 10.089285714285714, "title": "Mikolajczyk, K."}, {"color": "#6FA8DC", "id": "A Comparison of Af\ufb01ne Region Detectors", "label": "A Comparison of Af\ufb01ne Region Detectors", "shape": "dot", "size": 10.535714285714286, "title": "A Comparison of Af\ufb01ne Region Detectors"}, {"color": "#6FA8DC", "id": "rs", "label": "rs", "shape": "dot", "size": 10.089285714285714, "title": "rs"}, {"color": "#6FA8DC", "id": "Zisserma", "label": "Zisserma", "shape": "dot", "size": 10.089285714285714, "title": "Zisserma"}, {"color": "#6FA8DC", "id": "Mata", "label": "Mata", "shape": "dot", "size": 10.089285714285714, "title": "Mata"}, {"color": "#6FA8DC", "id": "Schaffalitzky", "label": "Schaffalitzky", "shape": "dot", "size": 10.089285714285714, "title": "Schaffalitzky"}, {"color": "#6FA8DC", "id": "Kadir", "label": "Kadir", "shape": "dot", "size": 10.089285714285714, "title": "Kadir"}, {"color": "#6FA8DC", "id": "Van Gool", "label": "Van Gool", "shape": "dot", "size": 10.089285714285714, "title": "Van Gool"}, {"color": "#6FA8DC", "id": "A Review of Af\ufb01ne Region Detectors", "label": "A Review of Af\ufb01ne Region Detectors", "shape": "dot", "size": 10.089285714285714, "title": "A Review of Af\ufb01ne Region Detectors"}, {"color": "#6FA8DC", "id": "Dollar", "label": "Dollar", "shape": "dot", "size": 10.089285714285714, "title": "Dollar"}, {"color": "#6FA8DC", "id": "Supervised Learning of Edges and Object Boundaries", "label": "Supervised Learning of Edges and Object Boundaries", "shape": "dot", "size": 10.267857142857142, "title": "Supervised Learning of Edges and Object Boundaries"}, {"color": "#6FA8DC", "id": "Tu", "label": "Tu", "shape": "dot", "size": 10.089285714285714, "title": "Tu"}, {"color": "#6FA8DC", "id": "Belongie", "label": "Belongie", "shape": "dot", "size": 10.089285714285714, "title": "Belongie"}, {"color": "#6FA8DC", "id": "Rosten", "label": "Rosten", "shape": "dot", "size": 10.089285714285714, "title": "Rosten"}, {"color": "#6FA8DC", "id": "Machine Learning for High-Speed Corner Detection", "label": "Machine Learning for High-Speed Corner Detection", "shape": "dot", "size": 10.178571428571429, "title": "Machine Learning for High-Speed Corner Detection"}, {"color": "#6FA8DC", "id": "Drummond", "label": "Drummond", "shape": "dot", "size": 10.089285714285714, "title": "Drummond"}, {"color": "#6FA8DC", "id": "Lowe", "label": "Lowe", "shape": "dot", "size": 10.089285714285714, "title": "Lowe"}, {"color": "#6FA8DC", "id": "Distinctive Image Features from Scale-Invariant Keypoints", "label": "Distinctive Image Features from Scale-Invariant Keypoints", "shape": "dot", "size": 10.089285714285714, "title": "Distinctive Image Features from Scale-Invariant Keypoints"}, {"color": "#6FA8DC", "id": "Fan", "label": "Fan", "shape": "dot", "size": 10.178571428571429, "title": "Fan"}, {"color": "#6FA8DC", "id": "LIBLINEAR", "label": "LIBLINEAR", "shape": "dot", "size": 10.446428571428571, "title": "LIBLINEAR"}, {"color": "#6FA8DC", "id": "Chang", "label": "Chang", "shape": "dot", "size": 10.178571428571429, "title": "Chang"}, {"color": "#6FA8DC", "id": "Hsieh", "label": "Hsieh", "shape": "dot", "size": 10.089285714285714, "title": "Hsieh"}, {"color": "#6FA8DC", "id": "Lin", "label": "Lin", "shape": "dot", "size": 10.089285714285714, "title": "Lin"}, {"color": "#6FA8DC", "id": "Verdie", "label": "Verdie", "shape": "dot", "size": 10.089285714285714, "title": "Verdie"}, {"color": "#6FA8DC", "id": "EPFL", "label": "EPFL", "shape": "dot", "size": 10.178571428571429, "title": "EPFL"}, {"color": "#6FA8DC", "id": "Yi", "label": "Yi", "shape": "dot", "size": 10.089285714285714, "title": "Yi"}, {"color": "#6FA8DC", "id": "Computer Vision Laboratory, EPFL", "label": "Computer Vision Laboratory, EPFL", "shape": "dot", "size": 10.178571428571429, "title": "Computer Vision Laboratory, EPFL"}, {"color": "#6FA8DC", "id": "Vincent Le Petit", "label": "Vincent Le Petit", "shape": "dot", "size": 10.089285714285714, "title": "Vincent Le Petit"}, {"color": "#6FA8DC", "id": "JOTS", "label": "JOTS", "shape": "dot", "size": 10.446428571428571, "title": "JOTS"}, {"color": "#6FA8DC", "id": "Joint Online Tracking and Segmentation", "label": "Joint Online Tracking and Segmentation", "shape": "dot", "size": 10.625, "title": "Joint Online Tracking and Segmentation"}, {"color": "#6FA8DC", "id": "Longyin Wen", "label": "Longyin Wen", "shape": "dot", "size": 10.178571428571429, "title": "Longyin Wen"}, {"color": "#6FA8DC", "id": "Dawei Du", "label": "Dawei Du", "shape": "dot", "size": 10.178571428571429, "title": "Dawei Du"}, {"color": "#6FA8DC", "id": "JETS", "label": "JETS", "shape": "dot", "size": 10.089285714285714, "title": "JETS"}, {"color": "#6FA8DC", "id": "Zhen Lei", "label": "Zhen Lei", "shape": "dot", "size": 10.535714285714286, "title": "Zhen Lei"}, {"color": "#6FA8DC", "id": "Stan Z. Li", "label": "Stan Z. Li", "shape": "dot", "size": 10.535714285714286, "title": "Stan Z. Li"}, {"color": "#6FA8DC", "id": "Wen_JOTS_Joint_Online_2015_CVPR_paper.pdf", "label": "Wen_JOTS_Joint_Online_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Wen_JOTS_Joint_Online_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Video Segmentation task", "label": "Video Segmentation task", "shape": "dot", "size": 10.089285714285714, "title": "Video Segmentation task"}, {"color": "#6FA8DC", "id": "Multi-part tracking", "label": "Multi-part tracking", "shape": "dot", "size": 10.089285714285714, "title": "Multi-part tracking"}, {"color": "#6FA8DC", "id": "Energy Function Optimization", "label": "Energy Function Optimization", "shape": "dot", "size": 10.178571428571429, "title": "Energy Function Optimization"}, {"color": "#6FA8DC", "id": "Tracking and Segmentation stages", "label": "Tracking and Segmentation stages", "shape": "dot", "size": 10.089285714285714, "title": "Tracking and Segmentation stages"}, {"color": "#6FA8DC", "id": "RANSA-style approach", "label": "RANSA-style approach", "shape": "dot", "size": 10.089285714285714, "title": "RANSA-style approach"}, {"color": "#6FA8DC", "id": "SegTrack database", "label": "SegTrack database", "shape": "dot", "size": 10.089285714285714, "title": "SegTrack database"}, {"color": "#6FA8DC", "id": "SegTrack v2 database", "label": "SegTrack v2 database", "shape": "dot", "size": 10.089285714285714, "title": "SegTrack v2 database"}, {"color": "#6FA8DC", "id": "Multi-part Models", "label": "Multi-part Models", "shape": "dot", "size": 10.089285714285714, "title": "Multi-part Models"}, {"color": "#6FA8DC", "id": "Tracking and Segmentation", "label": "Tracking and Segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Tracking and Segmentation"}, {"color": "#6FA8DC", "id": "video analysis", "label": "video analysis", "shape": "dot", "size": 10.178571428571429, "title": "video analysis"}, {"color": "#6FA8DC", "id": "multi-target tracking", "label": "multi-target tracking", "shape": "dot", "size": 10.089285714285714, "title": "multi-target tracking"}, {"color": "#6FA8DC", "id": "topological constraints", "label": "topological constraints", "shape": "dot", "size": 10.178571428571429, "title": "topological constraints"}, {"color": "#6FA8DC", "id": "deformable objects", "label": "deformable objects", "shape": "dot", "size": 10.089285714285714, "title": "deformable objects"}, {"color": "#6FA8DC", "id": "occluded objects", "label": "occluded objects", "shape": "dot", "size": 10.089285714285714, "title": "occluded objects"}, {"color": "#6FA8DC", "id": "dynamic graph", "label": "dynamic graph", "shape": "dot", "size": 10.089285714285714, "title": "dynamic graph"}, {"color": "#6FA8DC", "id": "Vasconcelos", "label": "Vasconcelos", "shape": "dot", "size": 10.178571428571429, "title": "Vasconcelos"}, {"color": "#6FA8DC", "id": "NLPR, Institute of Automation, Chinese Academy of Sciences", "label": "NLPR, Institute of Automation, Chinese Academy of Sciences", "shape": "dot", "size": 10.357142857142858, "title": "NLPR, Institute of Automation, Chinese Academy of Sciences"}, {"color": "#6FA8DC", "id": "S. Z. Li", "label": "S. Z. Li", "shape": "dot", "size": 10.089285714285714, "title": "S. Z. Li"}, {"color": "#6FA8DC", "id": "SCCE, University of Chinese Academy of Sciences", "label": "SCCE, University of Chinese Academy of Sciences", "shape": "dot", "size": 10.089285714285714, "title": "SCCE, University of Chinese Academy of Sciences"}, {"color": "#6FA8DC", "id": "tracking deformable and occluded objects", "label": "tracking deformable and occluded objects", "shape": "dot", "size": 10.089285714285714, "title": "tracking deformable and occluded objects"}, {"color": "#6FA8DC", "id": "Delong", "label": "Delong", "shape": "dot", "size": 10.089285714285714, "title": "Delong"}, {"color": "#6FA8DC", "id": "optimization method", "label": "optimization method", "shape": "dot", "size": 10.089285714285714, "title": "optimization method"}, {"color": "#6FA8DC", "id": "NLPR", "label": "NLPR", "shape": "dot", "size": 10.267857142857142, "title": "NLPR"}, {"color": "#6FA8DC", "id": "Philipp Kr\u00e4henbuhl", "label": "Philipp Kr\u00e4henbuhl", "shape": "dot", "size": 10.089285714285714, "title": "Philipp Kr\u00e4henbuhl"}, {"color": "#6FA8DC", "id": "Learning to Propose Objects", "label": "Learning to Propose Objects", "shape": "dot", "size": 10.357142857142858, "title": "Learning to Propose Objects"}, {"color": "#6FA8DC", "id": "Vladlen Koltun", "label": "Vladlen Koltun", "shape": "dot", "size": 10.089285714285714, "title": "Vladlen Koltun"}, {"color": "#6FA8DC", "id": "Krahenbuhl_Learning_to_Propos_2015_CVPR_paper.pdf", "label": "Krahenbuhl_Learning_to_Propos_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Krahenbuhl_Learning_to_Propos_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "zlei", "label": "zlei", "shape": "dot", "size": 10.089285714285714, "title": "zlei"}, {"color": "#6FA8DC", "id": "highly accurate bottom-up object segmentation", "label": "highly accurate bottom-up object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "highly accurate bottom-up object segmentation"}, {"color": "#6FA8DC", "id": "set of regions", "label": "set of regions", "shape": "dot", "size": 10.089285714285714, "title": "set of regions"}, {"color": "#6FA8DC", "id": "candidate objects", "label": "candidate objects", "shape": "dot", "size": 10.089285714285714, "title": "candidate objects"}, {"color": "#6FA8DC", "id": "ensemble of figure-ground segmentation models", "label": "ensemble of figure-ground segmentation models", "shape": "dot", "size": 10.089285714285714, "title": "ensemble of figure-ground segmentation models"}, {"color": "#6FA8DC", "id": "ensemble", "label": "ensemble", "shape": "dot", "size": 10.446428571428571, "title": "ensemble"}, {"color": "#6FA8DC", "id": "jointly", "label": "jointly", "shape": "dot", "size": 10.089285714285714, "title": "jointly"}, {"color": "#6FA8DC", "id": "ensemble training", "label": "ensemble training", "shape": "dot", "size": 10.089285714285714, "title": "ensemble training"}, {"color": "#6FA8DC", "id": "sequence of uncapacitated facility location problems", "label": "sequence of uncapacitated facility location problems", "shape": "dot", "size": 10.089285714285714, "title": "sequence of uncapacitated facility location problems"}, {"color": "#6FA8DC", "id": "procedure", "label": "procedure", "shape": "dot", "size": 10.357142857142858, "title": "procedure"}, {"color": "#6FA8DC", "id": "size of the ensemble", "label": "size of the ensemble", "shape": "dot", "size": 10.089285714285714, "title": "size of the ensemble"}, {"color": "#6FA8DC", "id": "composition", "label": "composition", "shape": "dot", "size": 10.178571428571429, "title": "composition"}, {"color": "#6FA8DC", "id": "ensembles", "label": "ensembles", "shape": "dot", "size": 10.089285714285714, "title": "ensembles"}, {"color": "#6FA8DC", "id": "elementary image features", "label": "elementary image features", "shape": "dot", "size": 10.178571428571429, "title": "elementary image features"}, {"color": "#6FA8DC", "id": "rapid image analysis", "label": "rapid image analysis", "shape": "dot", "size": 10.089285714285714, "title": "rapid image analysis"}, {"color": "#6FA8DC", "id": "presented approach", "label": "presented approach", "shape": "dot", "size": 10.357142857142858, "title": "presented approach"}, {"color": "#6FA8DC", "id": "prior object proposal algorithms", "label": "prior object proposal algorithms", "shape": "dot", "size": 10.089285714285714, "title": "prior object proposal algorithms"}, {"color": "#6FA8DC", "id": "lowest running time", "label": "lowest running time", "shape": "dot", "size": 10.089285714285714, "title": "lowest running time"}, {"color": "#6FA8DC", "id": "trained ensembles", "label": "trained ensembles", "shape": "dot", "size": 10.089285714285714, "title": "trained ensembles"}, {"color": "#6FA8DC", "id": "bottom-up segmentation model", "label": "bottom-up segmentation model", "shape": "dot", "size": 10.089285714285714, "title": "bottom-up segmentation model"}, {"color": "#6FA8DC", "id": "bottom-up segmentation", "label": "bottom-up segmentation", "shape": "dot", "size": 10.178571428571429, "title": "bottom-up segmentation"}, {"color": "#6FA8DC", "id": "parameters", "label": "parameters", "shape": "dot", "size": 10.089285714285714, "title": "parameters"}, {"color": "#6FA8DC", "id": "generally applicable model", "label": "generally applicable model", "shape": "dot", "size": 10.089285714285714, "title": "generally applicable model"}, {"color": "#6FA8DC", "id": "Ensemble Methods", "label": "Ensemble Methods", "shape": "dot", "size": 10.089285714285714, "title": "Ensemble Methods"}, {"color": "#6FA8DC", "id": "running time", "label": "running time", "shape": "dot", "size": 10.089285714285714, "title": "running time"}, {"color": "#6FA8DC", "id": "Arbel\u00e1ez et al. (2012)", "label": "Arbel\u00e1ez et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Arbel\u00e1ez et al. (2012)"}, {"color": "#6FA8DC", "id": "Semantic segmentation using regions and parts", "label": "Semantic segmentation using regions and parts", "shape": "dot", "size": 10.089285714285714, "title": "Semantic segmentation using regions and parts"}, {"color": "#6FA8DC", "id": "Microsoft COCO: Common objects in context", "label": "Microsoft COCO: Common objects in context", "shape": "dot", "size": 10.089285714285714, "title": "Microsoft COCO: Common objects in context"}, {"color": "#6FA8DC", "id": "Carreira et al.", "label": "Carreira et al.", "shape": "dot", "size": 10.089285714285714, "title": "Carreira et al."}, {"color": "#6FA8DC", "id": "Free-form region description with second-order pooling", "label": "Free-form region description with second-order pooling", "shape": "dot", "size": 10.178571428571429, "title": "Free-form region description with second-order pooling"}, {"color": "#6FA8DC", "id": "Microsoft COCO", "label": "Microsoft COCO", "shape": "dot", "size": 10.089285714285714, "title": "Microsoft COCO"}, {"color": "#6FA8DC", "id": "common objects", "label": "common objects", "shape": "dot", "size": 10.089285714285714, "title": "common objects"}, {"color": "#6FA8DC", "id": "Objectness", "label": "Objectness", "shape": "dot", "size": 10.089285714285714, "title": "Objectness"}, {"color": "#6FA8DC", "id": "Structured forests", "label": "Structured forests", "shape": "dot", "size": 10.089285714285714, "title": "Structured forests"}, {"color": "#6FA8DC", "id": "BING", "label": "BING", "shape": "dot", "size": 10.089285714285714, "title": "BING"}, {"color": "#6FA8DC", "id": "Geometry of cuts and metrics", "label": "Geometry of cuts and metrics", "shape": "dot", "size": 10.089285714285714, "title": "Geometry of cuts and metrics"}, {"color": "#6FA8DC", "id": "Aravindh Mahendran", "label": "Aravindh Mahendran", "shape": "dot", "size": 10.267857142857142, "title": "Aravindh Mahendran"}, {"color": "#6FA8DC", "id": "Understanding Deep Image Representations", "label": "Understanding Deep Image Representations", "shape": "dot", "size": 10.178571428571429, "title": "Understanding Deep Image Representations"}, {"color": "#6FA8DC", "id": "Andrea Vedaldi", "label": "Andrea Vedaldi", "shape": "dot", "size": 10.178571428571429, "title": "Andrea Vedaldi"}, {"color": "#6FA8DC", "id": "graph cuts", "label": "graph cuts", "shape": "dot", "size": 10.089285714285714, "title": "graph cuts"}, {"color": "#6FA8DC", "id": "Understanding Deep Image Representations by Inverting Them", "label": "Understanding Deep Image Representations by Inverting Them", "shape": "dot", "size": 10.357142857142858, "title": "Understanding Deep Image Representations by Inverting Them"}, {"color": "#6FA8DC", "id": "Understanding Deep Image Presentations by Inverting Them", "label": "Understanding Deep Image Presentations by Inverting Them", "shape": "dot", "size": 10.089285714285714, "title": "Understanding Deep Image Presentations by Inverting Them"}, {"color": "#6FA8DC", "id": "Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf", "label": "Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle"}, {"color": "#6FA8DC", "id": "Intel Labs", "label": "Intel Labs", "shape": "dot", "size": 10.089285714285714, "title": "Intel Labs"}, {"color": "#6FA8DC", "id": "Deep Image Representations", "label": "Deep Image Representations", "shape": "dot", "size": 10.089285714285714, "title": "Deep Image Representations"}, {"color": "#6FA8DC", "id": "Image Representations", "label": "Image Representations", "shape": "dot", "size": 10.089285714285714, "title": "Image Representations"}, {"color": "#6FA8DC", "id": "geometric and photometric invariance", "label": "geometric and photometric invariance", "shape": "dot", "size": 10.089285714285714, "title": "geometric and photometric invariance"}, {"color": "#6FA8DC", "id": "image representation", "label": "image representation", "shape": "dot", "size": 10.089285714285714, "title": "image representation"}, {"color": "#6FA8DC", "id": "image processing tasks", "label": "image processing tasks", "shape": "dot", "size": 10.178571428571429, "title": "image processing tasks"}, {"color": "#6FA8DC", "id": "Bishop", "label": "Bishop", "shape": "dot", "size": 10.089285714285714, "title": "Bishop"}, {"color": "#6FA8DC", "id": "Neural Networks for Pattern Recognition", "label": "Neural Networks for Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Neural Networks for Pattern Recognition"}, {"color": "#6FA8DC", "id": "key component", "label": "key component", "shape": "dot", "size": 10.089285714285714, "title": "key component"}, {"color": "#6FA8DC", "id": "deformable part models", "label": "deformable part models", "shape": "dot", "size": 10.178571428571429, "title": "deformable part models"}, {"color": "#6FA8DC", "id": "3D textons", "label": "3D textons", "shape": "dot", "size": 10.089285714285714, "title": "3D textons"}, {"color": "#6FA8DC", "id": "SIFT detector", "label": "SIFT detector", "shape": "dot", "size": 10.178571428571429, "title": "SIFT detector"}, {"color": "#6FA8DC", "id": "open-source implementation", "label": "open-source implementation", "shape": "dot", "size": 10.089285714285714, "title": "open-source implementation"}, {"color": "#6FA8DC", "id": "distinctive image features", "label": "distinctive image features", "shape": "dot", "size": 10.089285714285714, "title": "distinctive image features"}, {"color": "#6FA8DC", "id": "Zeiler \u0026 Fergus", "label": "Zeiler \u0026 Fergus", "shape": "dot", "size": 10.089285714285714, "title": "Zeiler \u0026 Fergus"}, {"color": "#6FA8DC", "id": "visualizing convolutional networks", "label": "visualizing convolutional networks", "shape": "dot", "size": 10.089285714285714, "title": "visualizing convolutional networks"}, {"color": "#6FA8DC", "id": "Hinton \u0026 Salakhutdinov", "label": "Hinton \u0026 Salakhutdinov", "shape": "dot", "size": 10.089285714285714, "title": "Hinton \u0026 Salakhutdinov"}, {"color": "#6FA8DC", "id": "Wang et al.", "label": "Wang et al.", "shape": "dot", "size": 10.089285714285714, "title": "Wang et al."}, {"color": "#6FA8DC", "id": "locality-constrained linear coding", "label": "locality-constrained linear coding", "shape": "dot", "size": 10.089285714285714, "title": "locality-constrained linear coding"}, {"color": "#6FA8DC", "id": "Arvindh Mahendran", "label": "Arvindh Mahendran", "shape": "dot", "size": 10.089285714285714, "title": "Arvindh Mahendran"}, {"color": "#6FA8DC", "id": "University of Oxford", "label": "University of Oxford", "shape": "dot", "size": 10.089285714285714, "title": "University of Oxford"}, {"color": "#6FA8DC", "id": "Yan Xia", "label": "Yan Xia", "shape": "dot", "size": 10.267857142857142, "title": "Yan Xia"}, {"color": "#6FA8DC", "id": "Sparse Projections for High-Dimensional Binary Codes", "label": "Sparse Projections for High-Dimensional Binary Codes", "shape": "dot", "size": 10.357142857142858, "title": "Sparse Projections for High-Dimensional Binary Codes"}, {"color": "#6FA8DC", "id": "Pushmeet Kohli", "label": "Pushmeet Kohli", "shape": "dot", "size": 10.357142857142858, "title": "Pushmeet Kohli"}, {"color": "#6FA8DC", "id": "Sparse Projections", "label": "Sparse Projections", "shape": "dot", "size": 10.178571428571429, "title": "Sparse Projections"}, {"color": "#6FA8DC", "id": "problem of learning long binary codes", "label": "problem of learning long binary codes", "shape": "dot", "size": 10.178571428571429, "title": "problem of learning long binary codes"}, {"color": "#6FA8DC", "id": "lack of effective regularizer", "label": "lack of effective regularizer", "shape": "dot", "size": 10.178571428571429, "title": "lack of effective regularizer"}, {"color": "#6FA8DC", "id": "high computational cost", "label": "high computational cost", "shape": "dot", "size": 10.089285714285714, "title": "high computational cost"}, {"color": "#6FA8DC", "id": "sparsity encouraging regularizer", "label": "sparsity encouraging regularizer", "shape": "dot", "size": 10.267857142857142, "title": "sparsity encouraging regularizer"}, {"color": "#6FA8DC", "id": "number of parameters", "label": "number of parameters", "shape": "dot", "size": 10.089285714285714, "title": "number of parameters"}, {"color": "#6FA8DC", "id": "overfitting", "label": "overfitting", "shape": "dot", "size": 10.089285714285714, "title": "overfitting"}, {"color": "#6FA8DC", "id": "sparse nature", "label": "sparse nature", "shape": "dot", "size": 10.089285714285714, "title": "sparse nature"}, {"color": "#6FA8DC", "id": "sparse projection matrix", "label": "sparse projection matrix", "shape": "dot", "size": 10.089285714285714, "title": "sparse projection matrix"}, {"color": "#6FA8DC", "id": "reduction in computational cost", "label": "reduction in computational cost", "shape": "dot", "size": 10.178571428571429, "title": "reduction in computational cost"}, {"color": "#6FA8DC", "id": "better accuracy", "label": "better accuracy", "shape": "dot", "size": 10.089285714285714, "title": "better accuracy"}, {"color": "#6FA8DC", "id": "dense projections", "label": "dense projections", "shape": "dot", "size": 10.178571428571429, "title": "dense projections"}, {"color": "#6FA8DC", "id": "rix", "label": "rix", "shape": "dot", "size": 10.089285714285714, "title": "rix"}, {"color": "#6FA8DC", "id": "ITQ", "label": "ITQ", "shape": "dot", "size": 10.089285714285714, "title": "ITQ"}, {"color": "#6FA8DC", "id": "other methods", "label": "other methods", "shape": "dot", "size": 10.178571428571429, "title": "other methods"}, {"color": "#6FA8DC", "id": "high-dimensional binary encoding", "label": "high-dimensional binary encoding", "shape": "dot", "size": 10.089285714285714, "title": "high-dimensional binary encoding"}, {"color": "#6FA8DC", "id": "Other methods", "label": "Other methods", "shape": "dot", "size": 10.089285714285714, "title": "Other methods"}, {"color": "#6FA8DC", "id": "High-Dimensional Binary Encoding", "label": "High-Dimensional Binary Encoding", "shape": "dot", "size": 10.089285714285714, "title": "High-Dimensional Binary Encoding"}, {"color": "#6FA8DC", "id": "Agrawal et al. (2014)", "label": "Agrawal et al. (2014)", "shape": "dot", "size": 10.178571428571429, "title": "Agrawal et al. (2014)"}, {"color": "#6FA8DC", "id": "Foundational context", "label": "Foundational context", "shape": "dot", "size": 10.089285714285714, "title": "Foundational context"}, {"color": "#6FA8DC", "id": "Object Recognition", "label": "Object Recognition", "shape": "dot", "size": 10.178571428571429, "title": "Object Recognition"}, {"color": "#6FA8DC", "id": "Fan et al. (2008)", "label": "Fan et al. (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Fan et al. (2008)"}, {"color": "#6FA8DC", "id": "Liblinear", "label": "Liblinear", "shape": "dot", "size": 10.178571428571429, "title": "Liblinear"}, {"color": "#6FA8DC", "id": "binary code learning", "label": "binary code learning", "shape": "dot", "size": 10.178571428571429, "title": "binary code learning"}, {"color": "#6FA8DC", "id": "efficient similarity search", "label": "efficient similarity search", "shape": "dot", "size": 10.178571428571429, "title": "efficient similarity search"}, {"color": "#6FA8DC", "id": "approximate nearest neighbor search", "label": "approximate nearest neighbor search", "shape": "dot", "size": 10.625, "title": "approximate nearest neighbor search"}, {"color": "#6FA8DC", "id": "many applications", "label": "many applications", "shape": "dot", "size": 10.089285714285714, "title": "many applications"}, {"color": "#6FA8DC", "id": "sparse approximation techniques", "label": "sparse approximation techniques", "shape": "dot", "size": 10.178571428571429, "title": "sparse approximation techniques"}, {"color": "#6FA8DC", "id": "product quantization", "label": "product quantization", "shape": "dot", "size": 10.267857142857142, "title": "product quantization"}, {"color": "#6FA8DC", "id": "atomic decomposition", "label": "atomic decomposition", "shape": "dot", "size": 10.178571428571429, "title": "atomic decomposition"}, {"color": "#6FA8DC", "id": "basis pursuit", "label": "basis pursuit", "shape": "dot", "size": 10.178571428571429, "title": "basis pursuit"}, {"color": "#6FA8DC", "id": "hashing algorithms", "label": "hashing algorithms", "shape": "dot", "size": 10.089285714285714, "title": "hashing algorithms"}, {"color": "#6FA8DC", "id": "ear-optimal hashing algorithms", "label": "ear-optimal hashing algorithms", "shape": "dot", "size": 10.178571428571429, "title": "ear-optimal hashing algorithms"}, {"color": "#6FA8DC", "id": "locality-sensitive hashing", "label": "locality-sensitive hashing", "shape": "dot", "size": 10.178571428571429, "title": "locality-sensitive hashing"}, {"color": "#6FA8DC", "id": "Procrustes analysis", "label": "Procrustes analysis", "shape": "dot", "size": 10.089285714285714, "title": "Procrustes analysis"}, {"color": "#6FA8DC", "id": "finding optimal transformation", "label": "finding optimal transformation", "shape": "dot", "size": 10.089285714285714, "title": "finding optimal transformation"}, {"color": "#6FA8DC", "id": "FOCS", "label": "FOCS", "shape": "dot", "size": 10.089285714285714, "title": "FOCS"}, {"color": "#6FA8DC", "id": "Symposium on Computational Geometry", "label": "Symposium on Computational Geometry", "shape": "dot", "size": 10.089285714285714, "title": "Symposium on Computational Geometry"}, {"color": "#6FA8DC", "id": "Procrustes problems", "label": "Procrustes problems", "shape": "dot", "size": 10.089285714285714, "title": "Procrustes problems"}, {"color": "#6FA8DC", "id": "Oxford University Press", "label": "Oxford University Press", "shape": "dot", "size": 10.089285714285714, "title": "Oxford University Press"}, {"color": "#6FA8DC", "id": "University of Science and Technology of China", "label": "University of Science and Technology of China", "shape": "dot", "size": 10.178571428571429, "title": "University of Science and Technology of China"}, {"color": "#6FA8DC", "id": "Huazhu Fu", "label": "Huazhu Fu", "shape": "dot", "size": 10.178571428571429, "title": "Huazhu Fu"}, {"color": "#6FA8DC", "id": "Dong Xu", "label": "Dong Xu", "shape": "dot", "size": 10.178571428571429, "title": "Dong Xu"}, {"color": "#6FA8DC", "id": "Stephen Lin", "label": "Stephen Lin", "shape": "dot", "size": 10.178571428571429, "title": "Stephen Lin"}, {"color": "#6FA8DC", "id": "Jiang Liu", "label": "Jiang Liu", "shape": "dot", "size": 10.089285714285714, "title": "Jiang Liu"}, {"color": "#6FA8DC", "id": "Object-based RGBD Image Co-segmentation with Mutex Constraint", "label": "Object-based RGBD Image Co-segmentation with Mutex Constraint", "shape": "dot", "size": 10.178571428571429, "title": "Object-based RGBD Image Co-segmentation with Mutex Constraint"}, {"color": "#6FA8DC", "id": "Object-based RGBD Image Co-segmentation with Mutux Constraint", "label": "Object-based RGBD Image Co-segmentation with Mutux Constraint", "shape": "dot", "size": 10.178571428571429, "title": "Object-based RGBD Image Co-segmentation with Mutux Constraint"}, {"color": "#6FA8DC", "id": "depth channel", "label": "depth channel", "shape": "dot", "size": 10.178571428571429, "title": "depth channel"}, {"color": "#6FA8DC", "id": "identification of similar foreground objects", "label": "identification of similar foreground objects", "shape": "dot", "size": 10.089285714285714, "title": "identification of similar foreground objects"}, {"color": "#6FA8DC", "id": "detection of object-like regions", "label": "detection of object-like regions", "shape": "dot", "size": 10.089285714285714, "title": "detection of object-like regions"}, {"color": "#6FA8DC", "id": "depth-based local features", "label": "depth-based local features", "shape": "dot", "size": 10.089285714285714, "title": "depth-based local features"}, {"color": "#6FA8DC", "id": "co-segmentation", "label": "co-segmentation", "shape": "dot", "size": 10.089285714285714, "title": "co-segmentation"}, {"color": "#6FA8DC", "id": "fully-connected graph structure", "label": "fully-connected graph structure", "shape": "dot", "size": 10.089285714285714, "title": "fully-connected graph structure"}, {"color": "#6FA8DC", "id": "graph structure", "label": "graph structure", "shape": "dot", "size": 10.089285714285714, "title": "graph structure"}, {"color": "#6FA8DC", "id": "mutex constraints", "label": "mutex constraints", "shape": "dot", "size": 10.267857142857142, "title": "mutex constraints"}, {"color": "#6FA8DC", "id": "improper solutions", "label": "improper solutions", "shape": "dot", "size": 10.089285714285714, "title": "improper solutions"}, {"color": "#6FA8DC", "id": "object-based RGBD co-segmentation", "label": "object-based RGBD co-segmentation", "shape": "dot", "size": 10.267857142857142, "title": "object-based RGBD co-segmentation"}, {"color": "#6FA8DC", "id": "related methods", "label": "related methods", "shape": "dot", "size": 10.089285714285714, "title": "related methods"}, {"color": "#6FA8DC", "id": "RGBD co-segmentation", "label": "RGBD co-segmentation", "shape": "dot", "size": 10.089285714285714, "title": "RGBD co-segmentation"}, {"color": "#6FA8DC", "id": "related techniques", "label": "related techniques", "shape": "dot", "size": 10.089285714285714, "title": "related techniques"}, {"color": "#6FA8DC", "id": "comparable performance", "label": "comparable performance", "shape": "dot", "size": 10.178571428571429, "title": "comparable performance"}, {"color": "#6FA8DC", "id": "RGB co-segmentation techniques", "label": "RGB co-segmentation techniques", "shape": "dot", "size": 10.178571428571429, "title": "RGB co-segmentation techniques"}, {"color": "#6FA8DC", "id": "depth maps", "label": "depth maps", "shape": "dot", "size": 10.267857142857142, "title": "depth maps"}, {"color": "#6FA8DC", "id": "RGB images", "label": "RGB images", "shape": "dot", "size": 10.178571428571429, "title": "RGB images"}, {"color": "#6FA8DC", "id": "segmentation accuracy", "label": "segmentation accuracy", "shape": "dot", "size": 10.089285714285714, "title": "segmentation accuracy"}, {"color": "#6FA8DC", "id": "Depth maps", "label": "Depth maps", "shape": "dot", "size": 10.089285714285714, "title": "Depth maps"}, {"color": "#6FA8DC", "id": "Object-Based Methods", "label": "Object-Based Methods", "shape": "dot", "size": 10.089285714285714, "title": "Object-Based Methods"}, {"color": "#6FA8DC", "id": "Mutual Exclusion Constraints", "label": "Mutual Exclusion Constraints", "shape": "dot", "size": 10.089285714285714, "title": "Mutual Exclusion Constraints"}, {"color": "#6FA8DC", "id": "Co-Saliency Maps", "label": "Co-Saliency Maps", "shape": "dot", "size": 10.089285714285714, "title": "Co-Saliency Maps"}, {"color": "#6FA8DC", "id": "Graph Formulation", "label": "Graph Formulation", "shape": "dot", "size": 10.089285714285714, "title": "Graph Formulation"}, {"color": "#6FA8DC", "id": "Multi-Plane Block-Coordinate Frank-Wilfe Algorithm", "label": "Multi-Plane Block-Coordinate Frank-Wilfe Algorithm", "shape": "dot", "size": 10.178571428571429, "title": "Multi-Plane Block-Coordinate Frank-Wilfe Algorithm"}, {"color": "#6FA8DC", "id": "Structural SVMs", "label": "Structural SVMs", "shape": "dot", "size": 10.089285714285714, "title": "Structural SVMs"}, {"color": "#6FA8DC", "id": "max-Oracle", "label": "max-Oracle", "shape": "dot", "size": 10.089285714285714, "title": "max-Oracle"}, {"color": "#6FA8DC", "id": "Neel Shah", "label": "Neel Shah", "shape": "dot", "size": 10.178571428571429, "title": "Neel Shah"}, {"color": "#6FA8DC", "id": "Vladimir Kolmogorov", "label": "Vladimir Kolmogorov", "shape": "dot", "size": 10.178571428571429, "title": "Vladimir Kolmogorov"}, {"color": "#6FA8DC", "id": "Chris H. Lampert", "label": "Chris H. Lampert", "shape": "dot", "size": 10.178571428571429, "title": "Chris H. Lampert"}, {"color": "#6FA8DC", "id": "Structural Support Vector Machines", "label": "Structural Support Vector Machines", "shape": "dot", "size": 10.357142857142858, "title": "Structural Support Vector Machines"}, {"color": "#6FA8DC", "id": "structured computer vision tasks", "label": "structured computer vision tasks", "shape": "dot", "size": 10.089285714285714, "title": "structured computer vision tasks"}, {"color": "#6FA8DC", "id": "structured prediction subroutine", "label": "structured prediction subroutine", "shape": "dot", "size": 10.089285714285714, "title": "structured prediction subroutine"}, {"color": "#6FA8DC", "id": "Frank-Wolfe algorithm", "label": "Frank-Wolfe algorithm", "shape": "dot", "size": 10.178571428571429, "title": "Frank-Wolfe algorithm"}, {"color": "#6FA8DC", "id": "training SSVMs", "label": "training SSVMs", "shape": "dot", "size": 10.089285714285714, "title": "training SSVMs"}, {"color": "#6FA8DC", "id": "caching mechanism", "label": "caching mechanism", "shape": "dot", "size": 10.089285714285714, "title": "caching mechanism"}, {"color": "#6FA8DC", "id": "geometrically motivated criterion", "label": "geometrically motivated criterion", "shape": "dot", "size": 10.089285714285714, "title": "geometrically motivated criterion"}, {"color": "#6FA8DC", "id": "criterion", "label": "criterion", "shape": "dot", "size": 10.089285714285714, "title": "criterion"}, {"color": "#6FA8DC", "id": "call max-oracle", "label": "call max-oracle", "shape": "dot", "size": 10.089285714285714, "title": "call max-oracle"}, {"color": "#6FA8DC", "id": "faster convergence", "label": "faster convergence", "shape": "dot", "size": 10.178571428571429, "title": "faster convergence"}, {"color": "#6FA8DC", "id": "total runtime", "label": "total runtime", "shape": "dot", "size": 10.089285714285714, "title": "total runtime"}, {"color": "#6FA8DC", "id": "max-oracle", "label": "max-oracle", "shape": "dot", "size": 10.089285714285714, "title": "max-oracle"}, {"color": "#6FA8DC", "id": "bottleneck", "label": "bottleneck", "shape": "dot", "size": 10.089285714285714, "title": "bottleneck"}, {"color": "#6FA8DC", "id": "block-coordinate Frank-Wolfe (BCFW) algorithm", "label": "block-coordinate Frank-Wolfe (BCFW) algorithm", "shape": "dot", "size": 10.089285714285714, "title": "block-coordinate Frank-Wolfe (BCFW) algorithm"}, {"color": "#6FA8DC", "id": "Max-Oracle", "label": "Max-Oracle", "shape": "dot", "size": 10.178571428571429, "title": "Max-Oracle"}, {"color": "#6FA8DC", "id": "Frank-Wolfe Algorithm", "label": "Frank-Wolfe Algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Frank-Wolfe Algorithm"}, {"color": "#6FA8DC", "id": "Block-Coordinate Methods", "label": "Block-Coordinate Methods", "shape": "dot", "size": 10.089285714285714, "title": "Block-Coordinate Methods"}, {"color": "#6FA8DC", "id": "IST Austria", "label": "IST Austria", "shape": "dot", "size": 10.178571428571429, "title": "IST Austria"}, {"color": "#6FA8DC", "id": "IST Australia", "label": "IST Australia", "shape": "dot", "size": 10.089285714285714, "title": "IST Australia"}, {"color": "#6FA8DC", "id": "Beier_Fusion_Moves_for_2015_CVPR_supplemental.pdf", "label": "Beier_Fusion_Moves_for_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Beier_Fusion_Moves_for_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Beier_Fusion_Moves_for_2015_CVPR_supplemental", "label": "Beier_Fusion_Moves_for_2015_CVPR_supplemental", "shape": "dot", "size": 10.178571428571429, "title": "Beier_Fusion_Moves_for_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "PIVOT-BOEM", "label": "PIVOT-BOEM", "shape": "dot", "size": 10.089285714285714, "title": "PIVOT-BOEM"}, {"color": "#6FA8DC", "id": "Correlation Clustering", "label": "Correlation Clustering", "shape": "dot", "size": 10.357142857142858, "title": "Correlation Clustering"}, {"color": "#6FA8DC", "id": "HC", "label": "HC", "shape": "dot", "size": 10.089285714285714, "title": "HC"}, {"color": "#6FA8DC", "id": "CGC", "label": "CGC", "shape": "dot", "size": 10.089285714285714, "title": "CGC"}, {"color": "#6FA8DC", "id": "Fusion Moves", "label": "Fusion Moves", "shape": "dot", "size": 10.089285714285714, "title": "Fusion Moves"}, {"color": "#6FA8DC", "id": "Experimental Analysis", "label": "Experimental Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Experimental Analysis"}, {"color": "#6FA8DC", "id": "Runtime", "label": "Runtime", "shape": "dot", "size": 10.089285714285714, "title": "Runtime"}, {"color": "#6FA8DC", "id": "Solution Quality", "label": "Solution Quality", "shape": "dot", "size": 10.089285714285714, "title": "Solution Quality"}, {"color": "#6FA8DC", "id": "Anytime Algorithms", "label": "Anytime Algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Anytime Algorithms"}, {"color": "#6FA8DC", "id": "Anytime Behavior", "label": "Anytime Behavior", "shape": "dot", "size": 10.178571428571429, "title": "Anytime Behavior"}, {"color": "#6FA8DC", "id": "Progressive Improvement", "label": "Progressive Improvement", "shape": "dot", "size": 10.089285714285714, "title": "Progressive Improvement"}, {"color": "#6FA8DC", "id": "Dataset Performance", "label": "Dataset Performance", "shape": "dot", "size": 10.089285714285714, "title": "Dataset Performance"}, {"color": "#6FA8DC", "id": "Instances", "label": "Instances", "shape": "dot", "size": 10.089285714285714, "title": "Instances"}, {"color": "#6FA8DC", "id": "University of Heidelberg (Iwr)", "label": "University of Heidelberg (Iwr)", "shape": "dot", "size": 10.357142857142858, "title": "University of Heidelberg (Iwr)"}, {"color": "#6FA8DC", "id": "Mohammadreza Mostajabi", "label": "Mohammadreza Mostajabi", "shape": "dot", "size": 10.178571428571429, "title": "Mohammadreza Mostajabi"}, {"color": "#6FA8DC", "id": "Feedforward Semantic Segmentation", "label": "Feedforward Semantic Segmentation", "shape": "dot", "size": 10.357142857142858, "title": "Feedforward Semantic Segmentation"}, {"color": "#6FA8DC", "id": "Payman Yadollahpour", "label": "Payman Yadollahpour", "shape": "dot", "size": 10.178571428571429, "title": "Payman Yadollahpour"}, {"color": "#6FA8DC", "id": "Gregory Shakhnarovich", "label": "Gregory Shakhnarovich", "shape": "dot", "size": 10.267857142857142, "title": "Gregory Shakhnarovich"}, {"color": "#6FA8DC", "id": "University of Heidelberg (Department of Mathematics)", "label": "University of Heidelberg (Department of Mathematics)", "shape": "dot", "size": 10.089285714285714, "title": "University of Heidelberg (Department of Mathematics)"}, {"color": "#6FA8DC", "id": "Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper", "label": "Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Mostajabi_Feedforwad_Semantic_Segmentation_2015_CVPR_paper", "label": "Mostajabi_Feedforwad_Semantic_Segmentation_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Mostajabi_Feedforwad_Semantic_Segmentation_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "feed-forward architecture", "label": "feed-forward architecture", "shape": "dot", "size": 10.178571428571429, "title": "feed-forward architecture"}, {"color": "#6FA8DC", "id": "image elements", "label": "image elements", "shape": "dot", "size": 10.089285714285714, "title": "image elements"}, {"color": "#6FA8DC", "id": "rich feature representations", "label": "rich feature representations", "shape": "dot", "size": 10.089285714285714, "title": "rich feature representations"}, {"color": "#6FA8DC", "id": "nested regions", "label": "nested regions", "shape": "dot", "size": 10.089285714285714, "title": "nested regions"}, {"color": "#6FA8DC", "id": "zoom-out", "label": "zoom-out", "shape": "dot", "size": 10.178571428571429, "title": "zoom-out"}, {"color": "#6FA8DC", "id": "superpixel", "label": "superpixel", "shape": "dot", "size": 10.089285714285714, "title": "superpixel"}, {"color": "#6FA8DC", "id": "statistical structure", "label": "statistical structure", "shape": "dot", "size": 10.089285714285714, "title": "statistical structure"}, {"color": "#6FA8DC", "id": "feedforward multilayer network", "label": "feedforward multilayer network", "shape": "dot", "size": 10.089285714285714, "title": "feedforward multilayer network"}, {"color": "#6FA8DC", "id": "69.6% average accuracy", "label": "69.6% average accuracy", "shape": "dot", "size": 10.089285714285714, "title": "69.6% average accuracy"}, {"color": "#6FA8DC", "id": "PAS-CAL VOC 2012 test set", "label": "PAS-CAL VOC 2012 test set", "shape": "dot", "size": 10.178571428571429, "title": "PAS-CAL VOC 2012 test set"}, {"color": "#6FA8DC", "id": "Regions", "label": "Regions", "shape": "dot", "size": 10.089285714285714, "title": "Regions"}, {"color": "#6FA8DC", "id": "Parts", "label": "Parts", "shape": "dot", "size": 10.089285714285714, "title": "Parts"}, {"color": "#6FA8DC", "id": "Hypercolumns for object segmentation and fine-grained localization", "label": "Hypercolumns for object segmentation and fine-grained localization", "shape": "dot", "size": 10.267857142857142, "title": "Hypercolumns for object segmentation and fine-grained localization"}, {"color": "#6FA8DC", "id": "Chen et al.", "label": "Chen et al.", "shape": "dot", "size": 10.089285714285714, "title": "Chen et al."}, {"color": "#6FA8DC", "id": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "label": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "shape": "dot", "size": 10.178571428571429, "title": "Semantic image segmentation with deep convolutional nets and fully connected crfs"}, {"color": "#6FA8DC", "id": "Long et al.", "label": "Long et al.", "shape": "dot", "size": 10.089285714285714, "title": "Long et al."}, {"color": "#6FA8DC", "id": "Fully convolutional networks for semantic segmentation", "label": "Fully convolutional networks for semantic segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Fully convolutional networks for semantic segmentation"}, {"color": "#6FA8DC", "id": "Associative hierarchical CRFs for object class image segmentation", "label": "Associative hierarchical CRFs for object class image segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Associative hierarchical CRFs for object class image segmentation"}, {"color": "#6FA8DC", "id": "Carreira and Sminchisescu", "label": "Carreira and Sminchisescu", "shape": "dot", "size": 10.089285714285714, "title": "Carreira and Sminchisescu"}, {"color": "#6FA8DC", "id": "CPMC: Automatic object segmentation using constrained parametric min-cuts", "label": "CPMC: Automatic object segmentation using constrained parametric min-cuts", "shape": "dot", "size": 10.178571428571429, "title": "CPMC: Automatic object segmentation using constrained parametric min-cuts"}, {"color": "#6FA8DC", "id": "CPMC", "label": "CPMC", "shape": "dot", "size": 10.267857142857142, "title": "CPMC"}, {"color": "#6FA8DC", "id": "Carreira, J.", "label": "Carreira, J.", "shape": "dot", "size": 10.089285714285714, "title": "Carreira, J."}, {"color": "#6FA8DC", "id": "Sminchisescu, C.", "label": "Sminchisescu, C.", "shape": "dot", "size": 10.089285714285714, "title": "Sminchisescu, C."}, {"color": "#6FA8DC", "id": "Very deep convolutional networks", "label": "Very deep convolutional networks", "shape": "dot", "size": 10.178571428571429, "title": "Very deep convolutional networks"}, {"color": "#6FA8DC", "id": "Zisserma, A.", "label": "Zisserma, A.", "shape": "dot", "size": 10.089285714285714, "title": "Zisserma, A."}, {"color": "#6FA8DC", "id": "Toyota Technological Institute at Chicago", "label": "Toyota Technological Institute at Chicago", "shape": "dot", "size": 10.267857142857142, "title": "Toyota Technological Institute at Chicago"}, {"color": "#6FA8DC", "id": "Fr\u00b4edo Durand", "label": "Fr\u00b4edo Durand", "shape": "dot", "size": 10.267857142857142, "title": "Fr\u00b4edo Durand"}, {"color": "#6FA8DC", "id": "Reflection Removal using Ghosting Cues", "label": "Reflection Removal using Ghosting Cues", "shape": "dot", "size": 10.357142857142858, "title": "Reflection Removal using Ghosting Cues"}, {"color": "#6FA8DC", "id": "YiChang Shih", "label": "YiChang Shih", "shape": "dot", "size": 10.357142857142858, "title": "YiChang Shih"}, {"color": "#6FA8DC", "id": "Dilip Krishnan", "label": "Dilip Krishnan", "shape": "dot", "size": 10.267857142857142, "title": "Dilip Krishnan"}, {"color": "#6FA8DC", "id": "William T. Freeman", "label": "William T. Freeman", "shape": "dot", "size": 10.446428571428571, "title": "William T. Freeman"}, {"color": "#6FA8DC", "id": "Ghosting Cues", "label": "Ghosting Cues", "shape": "dot", "size": 10.357142857142858, "title": "Ghosting Cues"}, {"color": "#6FA8DC", "id": "Ghosting Cunes", "label": "Ghosting Cunes", "shape": "dot", "size": 10.089285714285714, "title": "Ghosting Cunes"}, {"color": "#6FA8DC", "id": "Shih_Reflection_Removal_Using_2015_CVPR_paper", "label": "Shih_Reflection_Removal_Using_2015_CVPR_paper", "shape": "dot", "size": 10.357142857142858, "title": "Shih_Reflection_Removal_Using_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "reflection removal", "label": "reflection removal", "shape": "dot", "size": 10.357142857142858, "title": "reflection removal"}, {"color": "#6FA8DC", "id": "desired scene", "label": "desired scene", "shape": "dot", "size": 10.089285714285714, "title": "desired scene"}, {"color": "#6FA8DC", "id": "undesired reflections", "label": "undesired reflections", "shape": "dot", "size": 10.089285714285714, "title": "undesired reflections"}, {"color": "#6FA8DC", "id": "layer separation", "label": "layer separation", "shape": "dot", "size": 10.089285714285714, "title": "layer separation"}, {"color": "#6FA8DC", "id": "ill-posed problem", "label": "ill-posed problem", "shape": "dot", "size": 10.089285714285714, "title": "ill-posed problem"}, {"color": "#6FA8DC", "id": "ghosting cues", "label": "ghosting cues", "shape": "dot", "size": 10.267857142857142, "title": "ghosting cues"}, {"color": "#6FA8DC", "id": "asymmetry", "label": "asymmetry", "shape": "dot", "size": 10.089285714285714, "title": "asymmetry"}, {"color": "#6FA8DC", "id": "barely perceptible", "label": "barely perceptible", "shape": "dot", "size": 10.089285714285714, "title": "barely perceptible"}, {"color": "#6FA8DC", "id": "ghosted reflection", "label": "ghosted reflection", "shape": "dot", "size": 10.089285714285714, "title": "ghosted reflection"}, {"color": "#6FA8DC", "id": "double-impulse convolution kernel", "label": "double-impulse convolution kernel", "shape": "dot", "size": 10.089285714285714, "title": "double-impulse convolution kernel"}, {"color": "#6FA8DC", "id": "Gaussian Mixture Model", "label": "Gaussian Mixture Model", "shape": "dot", "size": 10.267857142857142, "title": "Gaussian Mixture Model"}, {"color": "#6FA8DC", "id": "single input image", "label": "single input image", "shape": "dot", "size": 10.178571428571429, "title": "single input image"}, {"color": "#6FA8DC", "id": "shifted double reflections", "label": "shifted double reflections", "shape": "dot", "size": 10.089285714285714, "title": "shifted double reflections"}, {"color": "#6FA8DC", "id": "synthetic inputs", "label": "synthetic inputs", "shape": "dot", "size": 10.178571428571429, "title": "synthetic inputs"}, {"color": "#6FA8DC", "id": "real-world inputs", "label": "real-world inputs", "shape": "dot", "size": 10.178571428571429, "title": "real-world inputs"}, {"color": "#6FA8DC", "id": "ghosted reflection components", "label": "ghosted reflection components", "shape": "dot", "size": 10.089285714285714, "title": "ghosted reflection components"}, {"color": "#6FA8DC", "id": "relative attenuation", "label": "relative attenuation", "shape": "dot", "size": 10.089285714285714, "title": "relative attenuation"}, {"color": "#6FA8DC", "id": "Reflection Removal", "label": "Reflection Removal", "shape": "dot", "size": 10.178571428571429, "title": "Reflection Removal"}, {"color": "#6FA8DC", "id": "MIT CSAIL", "label": "MIT CSAIL", "shape": "dot", "size": 10.357142857142858, "title": "MIT CSAIL"}, {"color": "#6FA8DC", "id": "Google Research", "label": "Google Research", "shape": "dot", "size": 10.178571428571429, "title": "Google Research"}, {"color": "#6FA8DC", "id": "Soonmin Hwang", "label": "Soonmin Hwang", "shape": "dot", "size": 10.178571428571429, "title": "Soonmin Hwang"}, {"color": "#6FA8DC", "id": "Multispectral Pedestrian Detection", "label": "Multispectral Pedestrian Detection", "shape": "dot", "size": 10.178571428571429, "title": "Multispectral Pedestrian Detection"}, {"color": "#6FA8DC", "id": "Benchmark Dataset", "label": "Benchmark Dataset", "shape": "dot", "size": 10.089285714285714, "title": "Benchmark Dataset"}, {"color": "#6FA8DC", "id": "pedestrian datasets", "label": "pedestrian datasets", "shape": "dot", "size": 10.089285714285714, "title": "pedestrian datasets"}, {"color": "#6FA8DC", "id": "color channel", "label": "color channel", "shape": "dot", "size": 10.089285714285714, "title": "color channel"}, {"color": "#6FA8DC", "id": "thermal channel", "label": "thermal channel", "shape": "dot", "size": 10.089285714285714, "title": "thermal channel"}, {"color": "#6FA8DC", "id": "multispectral pedestrian dataset", "label": "multispectral pedestrian dataset", "shape": "dot", "size": 10.357142857142858, "title": "multispectral pedestrian dataset"}, {"color": "#6FA8DC", "id": "color-thermal image pairs", "label": "color-thermal image pairs", "shape": "dot", "size": 10.446428571428571, "title": "color-thermal image pairs"}, {"color": "#6FA8DC", "id": "previous color-based datasets", "label": "previous color-based datasets", "shape": "dot", "size": 10.089285714285714, "title": "previous color-based datasets"}, {"color": "#6FA8DC", "id": "dense annotations", "label": "dense annotations", "shape": "dot", "size": 10.089285714285714, "title": "dense annotations"}, {"color": "#6FA8DC", "id": "multispectral ACF", "label": "multispectral ACF", "shape": "dot", "size": 10.267857142857142, "title": "multispectral ACF"}, {"color": "#6FA8DC", "id": "aggregated channel features (ACF)", "label": "aggregated channel features (ACF)", "shape": "dot", "size": 10.089285714285714, "title": "aggregated channel features (ACF)"}, {"color": "#6FA8DC", "id": "average miss rate of ACF", "label": "average miss rate of ACF", "shape": "dot", "size": 10.089285714285714, "title": "average miss rate of ACF"}, {"color": "#6FA8DC", "id": "spectral ACF", "label": "spectral ACF", "shape": "dot", "size": 10.178571428571429, "title": "spectral ACF"}, {"color": "#6FA8DC", "id": "aggregated channel features", "label": "aggregated channel features", "shape": "dot", "size": 10.178571428571429, "title": "aggregated channel features"}, {"color": "#6FA8DC", "id": "Multispectral ACF", "label": "Multispectral ACF", "shape": "dot", "size": 10.535714285714286, "title": "Multispectral ACF"}, {"color": "#6FA8DC", "id": "average miss rate", "label": "average miss rate", "shape": "dot", "size": 10.089285714285714, "title": "average miss rate"}, {"color": "#6FA8DC", "id": "15%", "label": "15%", "shape": "dot", "size": 10.089285714285714, "title": "15%"}, {"color": "#6FA8DC", "id": "image feature", "label": "image feature", "shape": "dot", "size": 10.089285714285714, "title": "image feature"}, {"color": "#6FA8DC", "id": "image type", "label": "image type", "shape": "dot", "size": 10.089285714285714, "title": "image type"}, {"color": "#6FA8DC", "id": "image analysis task", "label": "image analysis task", "shape": "dot", "size": 10.089285714285714, "title": "image analysis task"}, {"color": "#6FA8DC", "id": "miss rate", "label": "miss rate", "shape": "dot", "size": 10.089285714285714, "title": "miss rate"}, {"color": "#6FA8DC", "id": "breakthrough in pedestrian detection", "label": "breakthrough in pedestrian detection", "shape": "dot", "size": 10.089285714285714, "title": "breakthrough in pedestrian detection"}, {"color": "#6FA8DC", "id": "RGBD-Fusion", "label": "RGBD-Fusion", "shape": "dot", "size": 10.178571428571429, "title": "RGBD-Fusion"}, {"color": "#6FA8DC", "id": "real-time", "label": "real-time", "shape": "dot", "size": 10.089285714285714, "title": "real-time"}, {"color": "#6FA8DC", "id": "high precision", "label": "high precision", "shape": "dot", "size": 10.089285714285714, "title": "high precision"}, {"color": "#6FA8DC", "id": "Jaesik Park", "label": "Jaesik Park", "shape": "dot", "size": 10.089285714285714, "title": "Jaesik Park"}, {"color": "#6FA8DC", "id": "Namil Kim", "label": "Namil Kim", "shape": "dot", "size": 10.089285714285714, "title": "Namil Kim"}, {"color": "#6FA8DC", "id": "Roy Or", "label": "Roy Or", "shape": "dot", "size": 10.178571428571429, "title": "Roy Or"}, {"color": "#6FA8DC", "id": "RGB-D scanners", "label": "RGB-D scanners", "shape": "dot", "size": 10.178571428571429, "title": "RGB-D scanners"}, {"color": "#6FA8DC", "id": "subtle details", "label": "subtle details", "shape": "dot", "size": 10.089285714285714, "title": "subtle details"}, {"color": "#6FA8DC", "id": "lighting model", "label": "lighting model", "shape": "dot", "size": 10.178571428571429, "title": "lighting model"}, {"color": "#6FA8DC", "id": "natural scene illumination", "label": "natural scene illumination", "shape": "dot", "size": 10.089285714285714, "title": "natural scene illumination"}, {"color": "#6FA8DC", "id": "shape from shading-like technique", "label": "shape from shading-like technique", "shape": "dot", "size": 10.089285714285714, "title": "shape from shading-like technique"}, {"color": "#6FA8DC", "id": "visual fidelity", "label": "visual fidelity", "shape": "dot", "size": 10.089285714285714, "title": "visual fidelity"}, {"color": "#6FA8DC", "id": "detailed geometry", "label": "detailed geometry", "shape": "dot", "size": 10.089285714285714, "title": "detailed geometry"}, {"color": "#6FA8DC", "id": "four orders of magnitude faster", "label": "four orders of magnitude faster", "shape": "dot", "size": 10.089285714285714, "title": "four orders of magnitude faster"}, {"color": "#6FA8DC", "id": "evidence", "label": "evidence", "shape": "dot", "size": 10.089285714285714, "title": "evidence"}, {"color": "#6FA8DC", "id": "improvement in depth", "label": "improvement in depth", "shape": "dot", "size": 10.089285714285714, "title": "improvement in depth"}, {"color": "#6FA8DC", "id": "Depth map enhancement", "label": "Depth map enhancement", "shape": "dot", "size": 10.357142857142858, "title": "Depth map enhancement"}, {"color": "#6FA8DC", "id": "Shape from shading", "label": "Shape from shading", "shape": "dot", "size": 10.357142857142858, "title": "Shape from shading"}, {"color": "#6FA8DC", "id": "Lighting models", "label": "Lighting models", "shape": "dot", "size": 10.089285714285714, "title": "Lighting models"}, {"color": "#6FA8DC", "id": "Real-time processing", "label": "Real-time processing", "shape": "dot", "size": 10.089285714285714, "title": "Real-time processing"}, {"color": "#6FA8DC", "id": "Lambertian reflectance", "label": "Lambertian reflectance", "shape": "dot", "size": 10.089285714285714, "title": "Lambertian reflectance"}, {"color": "#6FA8DC", "id": "Computer Vision, Graphics, and Image Processing", "label": "Computer Vision, Graphics, and Image Processing", "shape": "dot", "size": 10.178571428571429, "title": "Computer Vision, Graphics, and Image Processing"}, {"color": "#6FA8DC", "id": "Bayesian nonparametric intrinsic image decomposition", "label": "Bayesian nonparametric intrinsic image decomposition", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian nonparametric intrinsic image decomposition"}, {"color": "#6FA8DC", "id": "Variable-source shading analysis", "label": "Variable-source shading analysis", "shape": "dot", "size": 10.267857142857142, "title": "Variable-source shading analysis"}, {"color": "#6FA8DC", "id": "Grosse, R.", "label": "Grosse, R.", "shape": "dot", "size": 10.089285714285714, "title": "Grosse, R."}, {"color": "#6FA8DC", "id": "Ground-truth dataset", "label": "Ground-truth dataset", "shape": "dot", "size": 10.178571428571429, "title": "Ground-truth dataset"}, {"color": "#6FA8DC", "id": "Han, Y.", "label": "Han, Y.", "shape": "dot", "size": 10.089285714285714, "title": "Han, Y."}, {"color": "#6FA8DC", "id": "High quality shape", "label": "High quality shape", "shape": "dot", "size": 10.178571428571429, "title": "High quality shape"}, {"color": "#6FA8DC", "id": "Horn, B. K.", "label": "Horn, B. K.", "shape": "dot", "size": 10.178571428571429, "title": "Horn, B. K."}, {"color": "#6FA8DC", "id": "PhD thesis", "label": "PhD thesis", "shape": "dot", "size": 10.089285714285714, "title": "PhD thesis"}, {"color": "#6FA8DC", "id": "The variational approach", "label": "The variational approach", "shape": "dot", "size": 10.089285714285714, "title": "The variational approach"}, {"color": "#6FA8DC", "id": "RGB-D image", "label": "RGB-D image", "shape": "dot", "size": 10.089285714285714, "title": "RGB-D image"}, {"color": "#6FA8DC", "id": "Horn \u0026 Brooks", "label": "Horn \u0026 Brooks", "shape": "dot", "size": 10.178571428571429, "title": "Horn \u0026 Brooks"}, {"color": "#6FA8DC", "id": "The variational approach to shape from shading", "label": "The variational approach to shape from shading", "shape": "dot", "size": 10.089285714285714, "title": "The variational approach to shape from shading"}, {"color": "#6FA8DC", "id": "Johnson \u0026 Adelison", "label": "Johnson \u0026 Adelison", "shape": "dot", "size": 10.089285714285714, "title": "Johnson \u0026 Adelison"}, {"color": "#6FA8DC", "id": "Technion, Israel Institute of Technology", "label": "Technion, Israel Institute of Technology", "shape": "dot", "size": 10.357142857142858, "title": "Technion, Israel Institute of Technology"}, {"color": "#6FA8DC", "id": "Guy Rosman", "label": "Guy Rosman", "shape": "dot", "size": 10.089285714285714, "title": "Guy Rosman"}, {"color": "#6FA8DC", "id": "Computer Science and Artificial Intelligence Lab, MIT", "label": "Computer Science and Artificial Intelligence Lab, MIT", "shape": "dot", "size": 10.089285714285714, "title": "Computer Science and Artificial Intelligence Lab, MIT"}, {"color": "#6FA8DC", "id": "Aaron Wetzler", "label": "Aaron Wetzler", "shape": "dot", "size": 10.089285714285714, "title": "Aaron Wetzler"}, {"color": "#6FA8DC", "id": "Ron Kimmel", "label": "Ron Kimmel", "shape": "dot", "size": 10.089285714285714, "title": "Ron Kimmel"}, {"color": "#6FA8DC", "id": "Alfred M. Bruckstein", "label": "Alfred M. Bruckstein", "shape": "dot", "size": 10.089285714285714, "title": "Alfred M. Bruckstein"}, {"color": "#6FA8DC", "id": "Xiangyu Zhu", "label": "Xiangyu Zhu", "shape": "dot", "size": 10.267857142857142, "title": "Xiangyu Zhu"}, {"color": "#6FA8DC", "id": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "label": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "shape": "dot", "size": 10.625, "title": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild"}, {"color": "#6FA8DC", "id": "Junnie Yan", "label": "Junnie Yan", "shape": "dot", "size": 10.089285714285714, "title": "Junnie Yan"}, {"color": "#6FA8DC", "id": "High-Fidelity Pose and Expression Normalization for FaceRecognition in the Wild", "label": "High-Fidelity Pose and Expression Normalization for FaceRecognition in the Wild", "shape": "dot", "size": 10.089285714285714, "title": "High-Fidelity Pose and Expression Normalization for FaceRecognition in the Wild"}, {"color": "#6FA8DC", "id": "Junjie Yan", "label": "Junjie Yan", "shape": "dot", "size": 10.446428571428571, "title": "Junjie Yan"}, {"color": "#6FA8DC", "id": "Dong Yi", "label": "Dong Yi", "shape": "dot", "size": 10.267857142857142, "title": "Dong Yi"}, {"color": "#6FA8DC", "id": "freddy@cs.technion.ac.il", "label": "freddy@cs.technion.ac.il", "shape": "dot", "size": 10.089285714285714, "title": "freddy@cs.technion.ac.il"}, {"color": "#6FA8DC", "id": "Technion - Israel Institute of Technology", "label": "Technion - Israel Institute of Technology", "shape": "dot", "size": 10.089285714285714, "title": "Technion - Israel Institute of Technology"}, {"color": "#6FA8DC", "id": "Zhu_High-Fidelity_Pose_and_2015_CVPR_paper.pdf", "label": "Zhu_High-Fidelity_Pose_and_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Zhu_High-Fidelity_Pose_and_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/"}, {"color": "#6FA8DC", "id": "face recognition performance", "label": "face recognition performance", "shape": "dot", "size": 10.089285714285714, "title": "face recognition performance"}, {"color": "#6FA8DC", "id": "pose variations", "label": "pose variations", "shape": "dot", "size": 10.089285714285714, "title": "pose variations"}, {"color": "#6FA8DC", "id": "HPEN method", "label": "HPEN method", "shape": "dot", "size": 10.625, "title": "HPEN method"}, {"color": "#6FA8DC", "id": "3D Morphable Model", "label": "3D Morphable Model", "shape": "dot", "size": 10.089285714285714, "title": "3D Morphable Model"}, {"color": "#6FA8DC", "id": "face images", "label": "face images", "shape": "dot", "size": 10.267857142857142, "title": "face images"}, {"color": "#6FA8DC", "id": "frontal pose", "label": "frontal pose", "shape": "dot", "size": 10.089285714285714, "title": "frontal pose"}, {"color": "#6FA8DC", "id": "neutral expression", "label": "neutral expression", "shape": "dot", "size": 10.089285714285714, "title": "neutral expression"}, {"color": "#6FA8DC", "id": "landmark marching", "label": "landmark marching", "shape": "dot", "size": 10.089285714285714, "title": "landmark marching"}, {"color": "#6FA8DC", "id": "3DMM fitting", "label": "3DMM fitting", "shape": "dot", "size": 10.089285714285714, "title": "3DMM fitting"}, {"color": "#6FA8DC", "id": "3D meshing", "label": "3D meshing", "shape": "dot", "size": 10.089285714285714, "title": "3D meshing"}, {"color": "#6FA8DC", "id": "Poisson Editing", "label": "Poisson Editing", "shape": "dot", "size": 10.267857142857142, "title": "Poisson Editing"}, {"color": "#6FA8DC", "id": "inpainting", "label": "inpainting", "shape": "dot", "size": 10.089285714285714, "title": "inpainting"}, {"color": "#6FA8DC", "id": "Multi-PIE", "label": "Multi-PIE", "shape": "dot", "size": 10.178571428571429, "title": "Multi-PIE"}, {"color": "#6FA8DC", "id": "3D Morphable Models", "label": "3D Morphable Models", "shape": "dot", "size": 10.089285714285714, "title": "3D Morphable Models"}, {"color": "#6FA8DC", "id": "Amberg, B.", "label": "Amberg, B.", "shape": "dot", "size": 10.089285714285714, "title": "Amberg, B."}, {"color": "#6FA8DC", "id": "Optimal step non-rigid icp algorithms for surface registration", "label": "Optimal step non-rigid icp algorithms for surface registration", "shape": "dot", "size": 10.267857142857142, "title": "Optimal step non-rigid icp algorithms for surface registration"}, {"color": "#6FA8DC", "id": "Romdhani, S.", "label": "Romdhani, S.", "shape": "dot", "size": 10.089285714285714, "title": "Romdhani, S."}, {"color": "#6FA8DC", "id": "Vetter, T.", "label": "Vetter, T.", "shape": "dot", "size": 10.089285714285714, "title": "Vetter, T."}, {"color": "#6FA8DC", "id": "Chai, X.", "label": "Chai, X.", "shape": "dot", "size": 10.089285714285714, "title": "Chai, X."}, {"color": "#6FA8DC", "id": "Locally linear regression for pose-invariant face recognition", "label": "Locally linear regression for pose-invariant face recognition", "shape": "dot", "size": 10.357142857142858, "title": "Locally linear regression for pose-invariant face recognition"}, {"color": "#6FA8DC", "id": "Shan, S.", "label": "Shan, S.", "shape": "dot", "size": 10.089285714285714, "title": "Shan, S."}, {"color": "#6FA8DC", "id": "Gao, W.", "label": "Gao, W.", "shape": "dot", "size": 10.089285714285714, "title": "Gao, W."}, {"color": "#6FA8DC", "id": "Locably linear regression for pose-invariant face recognition", "label": "Locably linear regression for pose-invariant face recognition", "shape": "dot", "size": 10.089285714285714, "title": "Locably linear regression for pose-invariant face recognition"}, {"color": "#6FA8DC", "id": "Arashloo, S. R.", "label": "Arashloo, S. R.", "shape": "dot", "size": 10.089285714285714, "title": "Arashloo, S. R."}, {"color": "#6FA8DC", "id": "Pose-invariant face matching using MRF energy minimization framework", "label": "Pose-invariant face matching using MRF energy minimization framework", "shape": "dot", "size": 10.178571428571429, "title": "Pose-invariant face matching using MRF energy minimization framework"}, {"color": "#6FA8DC", "id": "Kittler, J.", "label": "Kittler, J.", "shape": "dot", "size": 10.089285714285714, "title": "Kittler, J."}, {"color": "#6FA8DC", "id": "Chan, C. H.", "label": "Chan, C. H.", "shape": "dot", "size": 10.089285714285714, "title": "Chan, C. H."}, {"color": "#6FA8DC", "id": "Multisculse local phase quantization for robust component-based face recognition", "label": "Multisculse local phase quantization for robust component-based face recognition", "shape": "dot", "size": 10.267857142857142, "title": "Multisculse local phase quantization for robust component-based face recognition"}, {"color": "#6FA8DC", "id": "Tahir, M. A.", "label": "Tahir, M. A.", "shape": "dot", "size": 10.089285714285714, "title": "Tahir, M. A."}, {"color": "#6FA8DC", "id": "local phase quantization", "label": "local phase quantization", "shape": "dot", "size": 10.178571428571429, "title": "local phase quantization"}, {"color": "#6FA8DC", "id": "robust component-based face recognition", "label": "robust component-based face recognition", "shape": "dot", "size": 10.089285714285714, "title": "robust component-based face recognition"}, {"color": "#6FA8DC", "id": "component-based face recognition", "label": "component-based face recognition", "shape": "dot", "size": 10.089285714285714, "title": "component-based face recognition"}, {"color": "#6FA8DC", "id": "kernel fusion", "label": "kernel fusion", "shape": "dot", "size": 10.178571428571429, "title": "kernel fusion"}, {"color": "#6FA8DC", "id": "multiple descriptors", "label": "multiple descriptors", "shape": "dot", "size": 10.089285714285714, "title": "multiple descriptors"}, {"color": "#6FA8DC", "id": "Chen, D. (2012)", "label": "Chen, D. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Chen, D. (2012)"}, {"color": "#6FA8DC", "id": "joint formulation", "label": "joint formulation", "shape": "dot", "size": 10.089285714285714, "title": "joint formulation"}, {"color": "#6FA8DC", "id": "high-dimensional feature", "label": "high-dimensional feature", "shape": "dot", "size": 10.089285714285714, "title": "high-dimensional feature"}, {"color": "#6FA8DC", "id": "efficient compression", "label": "efficient compression", "shape": "dot", "size": 10.089285714285714, "title": "efficient compression"}, {"color": "#6FA8DC", "id": "Asthana, A. (2013)", "label": "Asthana, A. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Asthana, A. (2013)"}, {"color": "#6FA8DC", "id": "discriminative response map fitting", "label": "discriminative response map fitting", "shape": "dot", "size": 10.178571428571429, "title": "discriminative response map fitting"}, {"color": "#6FA8DC", "id": "constrained local models", "label": "constrained local models", "shape": "dot", "size": 10.178571428571429, "title": "constrained local models"}, {"color": "#6FA8DC", "id": "2013 IEEE Conference on Computer Vision and Pattern Recognition", "label": "2013 IEEE Conference on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "2013 IEEE Conference on Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "high-dimensional feature compression", "label": "high-dimensional feature compression", "shape": "dot", "size": 10.089285714285714, "title": "high-dimensional feature compression"}, {"color": "#6FA8DC", "id": "Cheng, S.", "label": "Cheng, S.", "shape": "dot", "size": 10.089285714285714, "title": "Cheng, S."}, {"color": "#6FA8DC", "id": "Robust discriminative response map fitting", "label": "Robust discriminative response map fitting", "shape": "dot", "size": 10.267857142857142, "title": "Robust discriminative response map fitting"}, {"color": "#6FA8DC", "id": "Barkan, O.", "label": "Barkan, O.", "shape": "dot", "size": 10.089285714285714, "title": "Barkan, O."}, {"color": "#6FA8DC", "id": "Fast high dimensional vector multiplication face recognition", "label": "Fast high dimensional vector multiplication face recognition", "shape": "dot", "size": 10.357142857142858, "title": "Fast high dimensional vector multiplication face recognition"}, {"color": "#6FA8DC", "id": "Weill, J.", "label": "Weill, J.", "shape": "dot", "size": 10.089285714285714, "title": "Weill, J."}, {"color": "#6FA8DC", "id": "Wolf, L.", "label": "Wolf, L.", "shape": "dot", "size": 10.089285714285714, "title": "Wolf, L."}, {"color": "#6FA8DC", "id": "Aronowitz, H.", "label": "Aronowitz, H.", "shape": "dot", "size": 10.089285714285714, "title": "Aronowitz, H."}, {"color": "#6FA8DC", "id": "Center for Biometrics and Security Research", "label": "Center for Biometrics and Security Research", "shape": "dot", "size": 10.535714285714286, "title": "Center for Biometrics and Security Research"}, {"color": "#6FA8DC", "id": "National Laboratory of Pattern Recognition", "label": "National Laboratory of Pattern Recognition", "shape": "dot", "size": 10.535714285714286, "title": "National Laboratory of Pattern Recognition"}, {"color": "#6FA8DC", "id": "Center for Biomatrics and Security Research", "label": "Center for Biomatrics and Security Research", "shape": "dot", "size": 10.089285714285714, "title": "Center for Biomatrics and Security Research"}, {"color": "#6FA8DC", "id": "jjyan@nlpr.ia.ac.cn", "label": "jjyan@nlpr.ia.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "jjyan@nlpr.ia.ac.cn"}, {"color": "#6FA8DC", "id": "szli@nlpr.ia.ac.cn", "label": "szli@nlpr.ia.ac.cn", "shape": "dot", "size": 10.089285714285714, "title": "szli@nlpr.ia.ac.cn"}, {"color": "#6FA8DC", "id": "Parsing Occluded People", "label": "Parsing Occluded People", "shape": "dot", "size": 10.357142857142858, "title": "Parsing Occluded People"}, {"color": "#6FA8DC", "id": "Xianjie Chen", "label": "Xianjie Chen", "shape": "dot", "size": 10.089285714285714, "title": "Xianjie Chen"}, {"color": "#6FA8DC", "id": "Alan Yuille", "label": "Alan Yuille", "shape": "dot", "size": 10.089285714285714, "title": "Alan Yuille"}, {"color": "#6FA8DC", "id": "Chen Xianjie", "label": "Chen Xianjie", "shape": "dot", "size": 10.089285714285714, "title": "Chen Xianjie"}, {"color": "#6FA8DC", "id": "Alan Yuilie", "label": "Alan Yuilie", "shape": "dot", "size": 10.089285714285714, "title": "Alan Yuilie"}, {"color": "#6FA8DC", "id": "parsing humans", "label": "parsing humans", "shape": "dot", "size": 10.089285714285714, "title": "parsing humans"}, {"color": "#6FA8DC", "id": "graphical model", "label": "graphical model", "shape": "dot", "size": 10.178571428571429, "title": "graphical model"}, {"color": "#6FA8DC", "id": "tree structure", "label": "tree structure", "shape": "dot", "size": 10.089285714285714, "title": "tree structure"}, {"color": "#6FA8DC", "id": "connected subtree", "label": "connected subtree", "shape": "dot", "size": 10.089285714285714, "title": "connected subtree"}, {"color": "#6FA8DC", "id": "flexible composition", "label": "flexible composition", "shape": "dot", "size": 10.089285714285714, "title": "flexible composition"}, {"color": "#6FA8DC", "id": "inference", "label": "inference", "shape": "dot", "size": 10.178571428571429, "title": "inference"}, {"color": "#6FA8DC", "id": "search over models", "label": "search over models", "shape": "dot", "size": 10.089285714285714, "title": "search over models"}, {"color": "#6FA8DC", "id": "part sharing", "label": "part sharing", "shape": "dot", "size": 10.089285714285714, "title": "part sharing"}, {"color": "#6FA8DC", "id": "computations", "label": "computations", "shape": "dot", "size": 10.178571428571429, "title": "computations"}, {"color": "#6FA8DC", "id": "twice as many", "label": "twice as many", "shape": "dot", "size": 10.089285714285714, "title": "twice as many"}, {"color": "#6FA8DC", "id": "We Are Family", "label": "We Are Family", "shape": "dot", "size": 10.089285714285714, "title": "We Are Family"}, {"color": "#6FA8DC", "id": "searching", "label": "searching", "shape": "dot", "size": 10.089285714285714, "title": "searching"}, {"color": "#6FA8DC", "id": "entire object", "label": "entire object", "shape": "dot", "size": 10.089285714285714, "title": "entire object"}, {"color": "#6FA8DC", "id": "Stickmen dataset", "label": "Stickmen dataset", "shape": "dot", "size": 10.178571428571429, "title": "Stickmen dataset"}, {"color": "#6FA8DC", "id": "standard benchmarked dataset", "label": "standard benchmarked dataset", "shape": "dot", "size": 10.089285714285714, "title": "standard benchmarked dataset"}, {"color": "#6FA8DC", "id": "alternative algorithms", "label": "alternative algorithms", "shape": "dot", "size": 10.178571428571429, "title": "alternative algorithms"}, {"color": "#6FA8DC", "id": "best", "label": "best", "shape": "dot", "size": 10.089285714285714, "title": "best"}, {"color": "#6FA8DC", "id": "modeling", "label": "modeling", "shape": "dot", "size": 10.089285714285714, "title": "modeling"}, {"color": "#6FA8DC", "id": "occlusion", "label": "occlusion", "shape": "dot", "size": 10.178571428571429, "title": "occlusion"}, {"color": "#6FA8DC", "id": "Graphical models", "label": "Graphical models", "shape": "dot", "size": 10.089285714285714, "title": "Graphical models"}, {"color": "#6FA8DC", "id": "Sutskever, I.", "label": "Sutskever, I.", "shape": "dot", "size": 10.089285714285714, "title": "Sutskever, I."}, {"color": "#6FA8DC", "id": "Hinton, G. E.", "label": "Hinton, G. E.", "shape": "dot", "size": 10.089285714285714, "title": "Hinton, G. E."}, {"color": "#6FA8DC", "id": "Yuilie, A.", "label": "Yuilie, A.", "shape": "dot", "size": 10.089285714285714, "title": "Yuilie, A."}, {"color": "#6FA8DC", "id": "Huttenlocher, D. P.", "label": "Huttenlocher, D. P.", "shape": "dot", "size": 10.089285714285714, "title": "Huttenlocher, D. P."}, {"color": "#6FA8DC", "id": "pictorial structures", "label": "pictorial structures", "shape": "dot", "size": 10.089285714285714, "title": "pictorial structures"}, {"color": "#6FA8DC", "id": "grammar models", "label": "grammar models", "shape": "dot", "size": 10.089285714285714, "title": "grammar models"}, {"color": "#6FA8DC", "id": "Ferrari, V.", "label": "Ferrari, V.", "shape": "dot", "size": 10.089285714285714, "title": "Ferrari, V."}, {"color": "#6FA8DC", "id": "Marin-Jimenez, M.", "label": "Marin-Jimenez, M.", "shape": "dot", "size": 10.089285714285714, "title": "Marin-Jimenez, M."}, {"color": "#6FA8DC", "id": "human pose estimation", "label": "human pose estimation", "shape": "dot", "size": 10.089285714285714, "title": "human pose estimation"}, {"color": "#6FA8DC", "id": "progressive search space reduction", "label": "progressive search space reduction", "shape": "dot", "size": 10.089285714285714, "title": "progressive search space reduction"}, {"color": "#6FA8DC", "id": "support-vector networks", "label": "support-vector networks", "shape": "dot", "size": 10.089285714285714, "title": "support-vector networks"}, {"color": "#6FA8DC", "id": "Cortes", "label": "Cortes", "shape": "dot", "size": 10.089285714285714, "title": "Cortes"}, {"color": "#6FA8DC", "id": "Support-vector networks", "label": "Support-vector networks", "shape": "dot", "size": 10.178571428571429, "title": "Support-vector networks"}, {"color": "#6FA8DC", "id": "Dalal", "label": "Dalal", "shape": "dot", "size": 10.089285714285714, "title": "Dalal"}, {"color": "#6FA8DC", "id": "Triggs", "label": "Triggs", "shape": "dot", "size": 10.089285714285714, "title": "Triggs"}, {"color": "#6FA8DC", "id": "Sapp", "label": "Sapp", "shape": "dot", "size": 10.089285714285714, "title": "Sapp"}, {"color": "#6FA8DC", "id": "Adaptive pose priors", "label": "Adaptive pose priors", "shape": "dot", "size": 10.267857142857142, "title": "Adaptive pose priors"}, {"color": "#6FA8DC", "id": "Jordan", "label": "Jordan", "shape": "dot", "size": 10.089285714285714, "title": "Jordan"}, {"color": "#6FA8DC", "id": "Taskar", "label": "Taskar", "shape": "dot", "size": 10.089285714285714, "title": "Taskar"}, {"color": "#6FA8DC", "id": "University of California, Los Angeles", "label": "University of California, Los Angeles", "shape": "dot", "size": 10.178571428571429, "title": "University of California, Los Angeles"}, {"color": "#6FA8DC", "id": "Yuille", "label": "Yuille", "shape": "dot", "size": 10.089285714285714, "title": "Yuille"}, {"color": "#6FA8DC", "id": "Alabort-i-Medina", "label": "Alabort-i-Medina", "shape": "dot", "size": 10.089285714285714, "title": "Alabort-i-Medina"}, {"color": "#6FA8DC", "id": "Unifying Holistic and Parts-Based Deformable Model Fitting", "label": "Unifying Holistic and Parts-Based Deformable Model Fitting", "shape": "dot", "size": 10.178571428571429, "title": "Unifying Holistic and Parts-Based Deformable Model Fitting"}, {"color": "#6FA8DC", "id": "deformable models", "label": "deformable models", "shape": "dot", "size": 10.089285714285714, "title": "deformable models"}, {"color": "#6FA8DC", "id": "degrees of freedom", "label": "degrees of freedom", "shape": "dot", "size": 10.089285714285714, "title": "degrees of freedom"}, {"color": "#6FA8DC", "id": "unified approach", "label": "unified approach", "shape": "dot", "size": 10.089285714285714, "title": "unified approach"}, {"color": "#6FA8DC", "id": "Face Alignment", "label": "Face Alignment", "shape": "dot", "size": 10.446428571428571, "title": "Face Alignment"}, {"color": "#6FA8DC", "id": "Holistic Deformable Models", "label": "Holistic Deformable Models", "shape": "dot", "size": 10.178571428571429, "title": "Holistic Deformable Models"}, {"color": "#6FA8DC", "id": "Parts-Based Deformable Models", "label": "Parts-Based Deformable Models", "shape": "dot", "size": 10.178571428571429, "title": "Parts-Based Deformable Models"}, {"color": "#6FA8DC", "id": "Deformable Models", "label": "Deformable Models", "shape": "dot", "size": 10.178571428571429, "title": "Deformable Models"}, {"color": "#6FA8DC", "id": "Active Appearance Models", "label": "Active Appearance Models", "shape": "dot", "size": 10.178571428571429, "title": "Active Appearance Models"}, {"color": "#6FA8DC", "id": "Active Shape Models", "label": "Active Shape Models", "shape": "dot", "size": 10.178571428571429, "title": "Active Shape Models"}, {"color": "#6FA8DC", "id": "Lucas-Kanade Method", "label": "Lucas-Kanade Method", "shape": "dot", "size": 10.089285714285714, "title": "Lucas-Kanade Method"}, {"color": "#6FA8DC", "id": "T. F. Cootes, G. J. Edwards, and C. J. Taylor (2001)", "label": "T. F. Cootes, G. J. Edwards, and C. J. Taylor (2001)", "shape": "dot", "size": 10.089285714285714, "title": "T. F. Cootes, G. J. Edwards, and C. J. Taylor (2001)"}, {"color": "#6FA8DC", "id": "Local Scale-Invariant Features", "label": "Local Scale-Invariant Features", "shape": "dot", "size": 10.089285714285714, "title": "Local Scale-Invariant Features"}, {"color": "#6FA8DC", "id": "T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham (1995)", "label": "T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham (1995)", "shape": "dot", "size": 10.089285714285714, "title": "T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham (1995)"}, {"color": "#6FA8DC", "id": "Bayesian Active Appearance Models", "label": "Bayesian Active Appearance Models", "shape": "dot", "size": 10.089285714285714, "title": "Bayesian Active Appearance Models"}, {"color": "#6FA8DC", "id": "J. Alabort-i-Medina and S. Zafeiriou (2014)", "label": "J. Alabort-i-Medina and S. Zafeiriou (2014)", "shape": "dot", "size": 10.089285714285714, "title": "J. Alabort-i-Medina and S. Zafeiriou (2014)"}, {"color": "#6FA8DC", "id": "Conference on Computer Vision and Pattern Recognition (CVPR)", "label": "Conference on Computer Vision and Pattern Recognition (CVPR)", "shape": "dot", "size": 10.357142857142858, "title": "Conference on Computer Vision and Pattern Recognition (CVPR)"}, {"color": "#6FA8DC", "id": "2014", "label": "2014", "shape": "dot", "size": 10.089285714285714, "title": "2014"}, {"color": "#6FA8DC", "id": "Lucas-Kanade", "label": "Lucas-Kanade", "shape": "dot", "size": 10.178571428571429, "title": "Lucas-Kanade"}, {"color": "#6FA8DC", "id": "International Journal of Computer Vision (IJCR)", "label": "International Journal of Computer Vision (IJCR)", "shape": "dot", "size": 10.089285714285714, "title": "International Journal of Computer Vision (IJCR)"}, {"color": "#6FA8DC", "id": "X. Cao", "label": "X. Cao", "shape": "dot", "size": 10.089285714285714, "title": "X. Cao"}, {"color": "#6FA8DC", "id": "Face alignment by explicit shape regression", "label": "Face alignment by explicit shape regression", "shape": "dot", "size": 10.178571428571429, "title": "Face alignment by explicit shape regression"}, {"color": "#6FA8DC", "id": "G. Papandreou", "label": "G. Papandreou", "shape": "dot", "size": 10.089285714285714, "title": "G. Papandreou"}, {"color": "#6FA8DC", "id": "Adaptive and constrained algorithms", "label": "Adaptive and constrained algorithms", "shape": "dot", "size": 10.178571428571429, "title": "Adaptive and constrained algorithms"}, {"color": "#6FA8DC", "id": "A. Asthana", "label": "A. Asthana", "shape": "dot", "size": 10.178571428571429, "title": "A. Asthana"}, {"color": "#6FA8DC", "id": "unifying framework", "label": "unifying framework", "shape": "dot", "size": 10.089285714285714, "title": "unifying framework"}, {"color": "#6FA8DC", "id": "inverse compositional active appearance model fitting", "label": "inverse compositional active appearance model fitting", "shape": "dot", "size": 10.089285714285714, "title": "inverse compositional active appearance model fitting"}, {"color": "#6FA8DC", "id": "S. Zafeiriou", "label": "S. Zafeiriou", "shape": "dot", "size": 10.089285714285714, "title": "S. Zafeiriou"}, {"color": "#6FA8DC", "id": "Conference on Computer Vision and Pattern Reduction (CVPR)", "label": "Conference on Computer Vision and Pattern Reduction (CVPR)", "shape": "dot", "size": 10.089285714285714, "title": "Conference on Computer Vision and Pattern Reduction (CVPR)"}, {"color": "#6FA8DC", "id": "J. Sragih", "label": "J. Sragih", "shape": "dot", "size": 10.089285714285714, "title": "J. Sragih"}, {"color": "#6FA8DC", "id": "Joan Alabort-i-Medina", "label": "Joan Alabort-i-Medina", "shape": "dot", "size": 10.178571428571429, "title": "Joan Alabort-i-Medina"}, {"color": "#6FA8DC", "id": "Imperial College London", "label": "Imperial College London", "shape": "dot", "size": 10.178571428571429, "title": "Imperial College London"}, {"color": "#6FA8DC", "id": "ja310@imperial.ac.uk", "label": "ja310@imperial.ac.uk", "shape": "dot", "size": 10.089285714285714, "title": "ja310@imperial.ac.uk"}, {"color": "#6FA8DC", "id": "Stefanos Zafeiriou", "label": "Stefanos Zafeiriou", "shape": "dot", "size": 10.267857142857142, "title": "Stefanos Zafeiriou"}, {"color": "#6FA8DC", "id": "Department of Computing", "label": "Department of Computing", "shape": "dot", "size": 10.089285714285714, "title": "Department of Computing"}, {"color": "#6FA8DC", "id": "s.zafeiriou@imperial.ac.uk", "label": "s.zafeiriou@imperial.ac.uk", "shape": "dot", "size": 10.089285714285714, "title": "s.zafeiriou@imperial.ac.uk"}, {"color": "#6FA8DC", "id": "Jia Xu", "label": "Jia Xu", "shape": "dot", "size": 10.178571428571429, "title": "Jia Xu"}, {"color": "#6FA8DC", "id": "Gaze-Enabled Egocentric Video Summarization", "label": "Gaze-Enabled Egocentric Video Summarization", "shape": "dot", "size": 10.535714285714286, "title": "Gaze-Enabled Egocentric Video Summarization"}, {"color": "#6FA8DC", "id": "Lopamudra Mukherjee", "label": "Lopamudra Mukherjee", "shape": "dot", "size": 10.178571428571429, "title": "Lopamudra Mukherjee"}, {"color": "#6FA8DC", "id": "Yin Li", "label": "Yin Li", "shape": "dot", "size": 10.178571428571429, "title": "Yin Li"}, {"color": "#6FA8DC", "id": "Jamieson Warner", "label": "Jamieson Warner", "shape": "dot", "size": 10.089285714285714, "title": "Jamieson Warner"}, {"color": "#6FA8DC", "id": "James M. Rehg", "label": "James M. Rehg", "shape": "dot", "size": 10.178571428571429, "title": "James M. Rehg"}, {"color": "#6FA8DC", "id": "Vikas Singh", "label": "Vikas Singh", "shape": "dot", "size": 10.089285714285714, "title": "Vikas Singh"}, {"color": "#6FA8DC", "id": "increase in egocentric videos", "label": "increase in egocentric videos", "shape": "dot", "size": 10.089285714285714, "title": "increase in egocentric videos"}, {"color": "#6FA8DC", "id": "egocentric videos", "label": "egocentric videos", "shape": "dot", "size": 10.089285714285714, "title": "egocentric videos"}, {"color": "#6FA8DC", "id": "compact representation", "label": "compact representation", "shape": "dot", "size": 10.089285714285714, "title": "compact representation"}, {"color": "#6FA8DC", "id": "egocentric video summarization", "label": "egocentric video summarization", "shape": "dot", "size": 10.178571428571429, "title": "egocentric video summarization"}, {"color": "#6FA8DC", "id": "unique challenges", "label": "unique challenges", "shape": "dot", "size": 10.089285714285714, "title": "unique challenges"}, {"color": "#6FA8DC", "id": "gaze tracking information", "label": "gaze tracking information", "shape": "dot", "size": 10.178571428571429, "title": "gaze tracking information"}, {"color": "#6FA8DC", "id": "summarization", "label": "summarization", "shape": "dot", "size": 10.178571428571429, "title": "summarization"}, {"color": "#6FA8DC", "id": "frame comparison", "label": "frame comparison", "shape": "dot", "size": 10.089285714285714, "title": "frame comparison"}, {"color": "#6FA8DC", "id": "summarization model", "label": "summarization model", "shape": "dot", "size": 10.089285714285714, "title": "summarization model"}, {"color": "#6FA8DC", "id": "submodular function maximization", "label": "submodular function maximization", "shape": "dot", "size": 10.089285714285714, "title": "submodular function maximization"}, {"color": "#6FA8DC", "id": "gaze-enabled egocentric video dataset", "label": "gaze-enabled egocentric video dataset", "shape": "dot", "size": 10.089285714285714, "title": "gaze-enabled egocentric video dataset"}, {"color": "#6FA8DC", "id": "personalized summaries", "label": "personalized summaries", "shape": "dot", "size": 10.089285714285714, "title": "personalized summaries"}, {"color": "#6FA8DC", "id": "Egocentric Video Summarization", "label": "Egocentric Video Summarization", "shape": "dot", "size": 10.267857142857142, "title": "Egocentric Video Summarization"}, {"color": "#6FA8DC", "id": "Submodular Function Maximization", "label": "Submodular Function Maximization", "shape": "dot", "size": 10.178571428571429, "title": "Submodular Function Maximization"}, {"color": "#6FA8DC", "id": "Multilinear Relaxation", "label": "Multilinear Relaxation", "shape": "dot", "size": 10.089285714285714, "title": "Multilinear Relaxation"}, {"color": "#6FA8DC", "id": "Personalized Summarization", "label": "Personalized Summarization", "shape": "dot", "size": 10.178571428571429, "title": "Personalized Summarization"}, {"color": "#6FA8DC", "id": "Almeida et al.", "label": "Almeida et al.", "shape": "dot", "size": 10.089285714285714, "title": "Almeida et al."}, {"color": "#6FA8DC", "id": "VISON", "label": "VISON", "shape": "dot", "size": 10.178571428571429, "title": "VISON"}, {"color": "#6FA8DC", "id": "Online Applications", "label": "Online Applications", "shape": "dot", "size": 10.089285714285714, "title": "Online Applications"}, {"color": "#6FA8DC", "id": "Submodular Maximization", "label": "Submodular Maximization", "shape": "dot", "size": 10.089285714285714, "title": "Submodular Maximization"}, {"color": "#6FA8DC", "id": "Partition Matroid", "label": "Partition Matroid", "shape": "dot", "size": 10.089285714285714, "title": "Partition Matroid"}, {"color": "#6FA8DC", "id": "Filmus \u0026 Ward", "label": "Filmus \u0026 Ward", "shape": "dot", "size": 10.089285714285714, "title": "Filmus \u0026 Ward"}, {"color": "#6FA8DC", "id": "Combinatorial Algorithm", "label": "Combinatorial Algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Combinatorial Algorithm"}, {"color": "#6FA8DC", "id": "Fujishige", "label": "Fujishige", "shape": "dot", "size": 10.178571428571429, "title": "Fujishige"}, {"color": "#6FA8DC", "id": "Submodular Functions and Optimization", "label": "Submodular Functions and Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Submodular Functions and Optimization"}, {"color": "#6FA8DC", "id": "Gaze Tracking", "label": "Gaze Tracking", "shape": "dot", "size": 10.089285714285714, "title": "Gaze Tracking"}, {"color": "#6FA8DC", "id": "Wearable Cameras", "label": "Wearable Cameras", "shape": "dot", "size": 10.089285714285714, "title": "Wearable Cameras"}, {"color": "#6FA8DC", "id": "Ward", "label": "Ward", "shape": "dot", "size": 10.089285714285714, "title": "Ward"}, {"color": "#6FA8DC", "id": "Submodular functions and optimization", "label": "Submodular functions and optimization", "shape": "dot", "size": 10.178571428571429, "title": "Submodular functions and optimization"}, {"color": "#6FA8DC", "id": "feature hierarchies", "label": "feature hierarchies", "shape": "dot", "size": 10.089285714285714, "title": "feature hierarchies"}, {"color": "#6FA8DC", "id": "sequential subset selection", "label": "sequential subset selection", "shape": "dot", "size": 10.089285714285714, "title": "sequential subset selection"}, {"color": "#6FA8DC", "id": "Iyer", "label": "Iyer", "shape": "dot", "size": 10.089285714285714, "title": "Iyer"}, {"color": "#6FA8DC", "id": "Krause", "label": "Krause", "shape": "dot", "size": 10.089285714285714, "title": "Krause"}, {"color": "#6FA8DC", "id": "information gathering", "label": "information gathering", "shape": "dot", "size": 10.089285714285714, "title": "information gathering"}, {"color": "#6FA8DC", "id": "Xu", "label": "Xu", "shape": "dot", "size": 10.089285714285714, "title": "Xu"}, {"color": "#6FA8DC", "id": "University of Wisconsin-Madison", "label": "University of Wisconsin-Madison", "shape": "dot", "size": 10.178571428571429, "title": "University of Wisconsin-Madison"}, {"color": "#6FA8DC", "id": "submodular maximization", "label": "submodular maximization", "shape": "dot", "size": 10.178571428571429, "title": "submodular maximization"}, {"color": "#6FA8DC", "id": "University of Wisconsin-Whitewater", "label": "University of Wisconsin-Whitewater", "shape": "dot", "size": 10.089285714285714, "title": "University of Wisconsin-Whitewater"}, {"color": "#6FA8DC", "id": "Andreas Geiger", "label": "Andreas Geiger", "shape": "dot", "size": 10.178571428571429, "title": "Andreas Geiger"}, {"color": "#6FA8DC", "id": "Object Scene Flow for Autonomous Vehicles", "label": "Object Scene Flow for Autonomous Vehicles", "shape": "dot", "size": 10.446428571428571, "title": "Object Scene Flow for Autonomous Vehicles"}, {"color": "#6FA8DC", "id": "Moritz Menze", "label": "Moritz Menze", "shape": "dot", "size": 10.089285714285714, "title": "Moritz Menze"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Menze_Object_Scene_Flow_2015_CVPR_supplemental.pdf", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Menze_Object_Scene_Flow_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Menze_Object_Scene_Flow_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Menze_Object_Scene_Flow_2015_CVPR_supplemental", "label": "Menze_Object_Scene_Flow_2015_CVPR_supplemental", "shape": "dot", "size": 10.089285714285714, "title": "Menze_Object_Scene_Flow_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "supplementary document", "label": "supplementary document", "shape": "dot", "size": 10.267857142857142, "title": "supplementary document"}, {"color": "#6FA8DC", "id": "additional descriptions", "label": "additional descriptions", "shape": "dot", "size": 10.089285714285714, "title": "additional descriptions"}, {"color": "#6FA8DC", "id": "visualizations", "label": "visualizations", "shape": "dot", "size": 10.089285714285714, "title": "visualizations"}, {"color": "#6FA8DC", "id": "scene flow ground truth", "label": "scene flow ground truth", "shape": "dot", "size": 10.089285714285714, "title": "scene flow ground truth"}, {"color": "#6FA8DC", "id": "model parameters", "label": "model parameters", "shape": "dot", "size": 10.089285714285714, "title": "model parameters"}, {"color": "#6FA8DC", "id": "model sensitivity", "label": "model sensitivity", "shape": "dot", "size": 10.089285714285714, "title": "model sensitivity"}, {"color": "#6FA8DC", "id": "small loss in performance", "label": "small loss in performance", "shape": "dot", "size": 10.089285714285714, "title": "small loss in performance"}, {"color": "#6FA8DC", "id": "runtime", "label": "runtime", "shape": "dot", "size": 10.089285714285714, "title": "runtime"}, {"color": "#6FA8DC", "id": "stereo approaches", "label": "stereo approaches", "shape": "dot", "size": 10.089285714285714, "title": "stereo approaches"}, {"color": "#6FA8DC", "id": "optical flow approaches", "label": "optical flow approaches", "shape": "dot", "size": 10.089285714285714, "title": "optical flow approaches"}, {"color": "#6FA8DC", "id": "scene flow approaches", "label": "scene flow approaches", "shape": "dot", "size": 10.089285714285714, "title": "scene flow approaches"}, {"color": "#6FA8DC", "id": "qualitative results", "label": "qualitative results", "shape": "dot", "size": 10.178571428571429, "title": "qualitative results"}, {"color": "#6FA8DC", "id": "state-of-the-art stereo", "label": "state-of-the-art stereo", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art stereo"}, {"color": "#6FA8DC", "id": "optical flow", "label": "optical flow", "shape": "dot", "size": 10.178571428571429, "title": "optical flow"}, {"color": "#6FA8DC", "id": "scene flow", "label": "scene flow", "shape": "dot", "size": 10.178571428571429, "title": "scene flow"}, {"color": "#6FA8DC", "id": "KITTI stereo", "label": "KITTI stereo", "shape": "dot", "size": 10.178571428571429, "title": "KITTI stereo"}, {"color": "#6FA8DC", "id": "stereo", "label": "stereo", "shape": "dot", "size": 10.089285714285714, "title": "stereo"}, {"color": "#6FA8DC", "id": "scene flow dataset", "label": "scene flow dataset", "shape": "dot", "size": 10.178571428571429, "title": "scene flow dataset"}, {"color": "#6FA8DC", "id": "novel", "label": "novel", "shape": "dot", "size": 10.089285714285714, "title": "novel"}, {"color": "#6FA8DC", "id": "sphere sequence", "label": "sphere sequence", "shape": "dot", "size": 10.089285714285714, "title": "sphere sequence"}, {"color": "#6FA8DC", "id": "Optical Flow", "label": "Optical Flow", "shape": "dot", "size": 10.178571428571429, "title": "Optical Flow"}, {"color": "#6FA8DC", "id": "Scene Flow", "label": "Scene Flow", "shape": "dot", "size": 10.178571428571429, "title": "Scene Flow"}, {"color": "#6FA8DC", "id": "Brox, T. \u0026 Malik, J.", "label": "Brox, T. \u0026 Malik, J.", "shape": "dot", "size": 10.089285714285714, "title": "Brox, T. \u0026 Malik, J."}, {"color": "#6FA8DC", "id": "Large Displacement Optical Flow", "label": "Large Displacement Optical Flow", "shape": "dot", "size": 10.267857142857142, "title": "Large Displacement Optical Flow"}, {"color": "#6FA8DC", "id": "Variational Motion Estimation", "label": "Variational Motion Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Variational Motion Estimation"}, {"color": "#6FA8DC", "id": "Hirschmueller, H.", "label": "Hirschmueller, H.", "shape": "dot", "size": 10.089285714285714, "title": "Hirschmueller, H."}, {"color": "#6FA8DC", "id": "Stereo Processing", "label": "Stereo Processing", "shape": "dot", "size": 10.089285714285714, "title": "Stereo Processing"}, {"color": "#6FA8DC", "id": "Scene Flow Datasets", "label": "Scene Flow Datasets", "shape": "dot", "size": 10.178571428571429, "title": "Scene Flow Datasets"}, {"color": "#6FA8DC", "id": "Quantitative Results", "label": "Quantitative Results", "shape": "dot", "size": 10.089285714285714, "title": "Quantitative Results"}, {"color": "#6FA8DC", "id": "Qualitative Results", "label": "Qualitative Results", "shape": "dot", "size": 10.089285714285714, "title": "Qualitative Results"}, {"color": "#6FA8DC", "id": "Stereo processing", "label": "Stereo processing", "shape": "dot", "size": 10.357142857142858, "title": "Stereo processing"}, {"color": "#6FA8DC", "id": "Scene flow estimation", "label": "Scene flow estimation", "shape": "dot", "size": 10.535714285714286, "title": "Scene flow estimation"}, {"color": "#6FA8DC", "id": "growing correspondence seeds", "label": "growing correspondence seeds", "shape": "dot", "size": 10.089285714285714, "title": "growing correspondence seeds"}, {"color": "#6FA8DC", "id": "piecewise rigid scene flow", "label": "piecewise rigid scene flow", "shape": "dot", "size": 10.089285714285714, "title": "piecewise rigid scene flow"}, {"color": "#6FA8DC", "id": "variational method", "label": "variational method", "shape": "dot", "size": 10.089285714285714, "title": "variational method"}, {"color": "#6FA8DC", "id": "Cech et al. (2011)", "label": "Cech et al. (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Cech et al. (2011)"}, {"color": "#6FA8DC", "id": "Vogel et al. (2013)", "label": "Vogel et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Vogel et al. (2013)"}, {"color": "#6FA8DC", "id": "Huguet \u0026 Devernay (2007)", "label": "Huguet \u0026 Devernay (2007)", "shape": "dot", "size": 10.267857142857142, "title": "Huguet \u0026 Devernay (2007)"}, {"color": "#6FA8DC", "id": "Semiglobal matching", "label": "Semiglobal matching", "shape": "dot", "size": 10.089285714285714, "title": "Semiglobal matching"}, {"color": "#6FA8DC", "id": "Mutual information", "label": "Mutual information", "shape": "dot", "size": 10.089285714285714, "title": "Mutual information"}, {"color": "#6FA8DC", "id": "scene flow estimation", "label": "scene flow estimation", "shape": "dot", "size": 10.267857142857142, "title": "scene flow estimation"}, {"color": "#6FA8DC", "id": "Sun, Roth, \u0026 Black (2013)", "label": "Sun, Roth, \u0026 Black (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Sun, Roth, \u0026 Black (2013)"}, {"color": "#6FA8DC", "id": "optical flow estimation", "label": "optical flow estimation", "shape": "dot", "size": 10.178571428571429, "title": "optical flow estimation"}, {"color": "#6FA8DC", "id": "Hornacek, Fitzgibbon, \u0026 Rother (2014)", "label": "Hornacek, Fitzgibbon, \u0026 Rother (2014)", "shape": "dot", "size": 10.178571428571429, "title": "Hornacek, Fitzgibbon, \u0026 Rother (2014)"}, {"color": "#6FA8DC", "id": "SphereFlow", "label": "SphereFlow", "shape": "dot", "size": 10.178571428571429, "title": "SphereFlow"}, {"color": "#6FA8DC", "id": "Valgaerts et al. (2010)", "label": "Valgaerts et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Valgaerts et al. (2010)"}, {"color": "#6FA8DC", "id": "motion and geometry estimation", "label": "motion and geometry estimation", "shape": "dot", "size": 10.178571428571429, "title": "motion and geometry estimation"}, {"color": "#6FA8DC", "id": "stereo sequences", "label": "stereo sequences", "shape": "dot", "size": 10.178571428571429, "title": "stereo sequences"}, {"color": "#6FA8DC", "id": "ICVV", "label": "ICVV", "shape": "dot", "size": 10.089285714285714, "title": "ICVV"}, {"color": "#6FA8DC", "id": "Kert et al. (2010)", "label": "Kert et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Kert et al. (2010)"}, {"color": "#6FA8DC", "id": "Wedel et al. (2008)", "label": "Wedel et al. (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Wedel et al. (2008)"}, {"color": "#6FA8DC", "id": "scene flow computation", "label": "scene flow computation", "shape": "dot", "size": 10.089285714285714, "title": "scene flow computation"}, {"color": "#6FA8DC", "id": "Geiger et al. (2011)", "label": "Geiger et al. (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Geiger et al. (2011)"}, {"color": "#6FA8DC", "id": "3D reconstruction techniques", "label": "3D reconstruction techniques", "shape": "dot", "size": 10.089285714285714, "title": "3D reconstruction techniques"}, {"color": "#6FA8DC", "id": "MPI Tubingen", "label": "MPI Tubingen", "shape": "dot", "size": 10.089285714285714, "title": "MPI Tubingen"}, {"color": "#6FA8DC", "id": "Menz", "label": "Menz", "shape": "dot", "size": 10.089285714285714, "title": "Menz"}, {"color": "#6FA8DC", "id": "Leibniz Universit\u00a8at Hannover", "label": "Leibniz Universit\u00a8at Hannover", "shape": "dot", "size": 10.089285714285714, "title": "Leibniz Universit\u00a8at Hannover"}, {"color": "#6FA8DC", "id": "Tal Hassner", "label": "Tal Hassner", "shape": "dot", "size": 10.089285714285714, "title": "Tal Hassner"}, {"color": "#6FA8DC", "id": "Effective Face Frontalization", "label": "Effective Face Frontalization", "shape": "dot", "size": 10.446428571428571, "title": "Effective Face Frontalization"}, {"color": "#6FA8DC", "id": "Shai Harel", "label": "Shai Harel", "shape": "dot", "size": 10.089285714285714, "title": "Shai Harel"}, {"color": "#6FA8DC", "id": "Eran Paz", "label": "Eran Paz", "shape": "dot", "size": 10.089285714285714, "title": "Eran Paz"}, {"color": "#6FA8DC", "id": "Roee Enbar", "label": "Roee Enbar", "shape": "dot", "size": 10.089285714285714, "title": "Roee Enbar"}, {"color": "#6FA8DC", "id": "Hassner_Effective_Face_Frontalization_2015_CVPR_paper.pdf", "label": "Hassner_Effective_Face_Frontalization_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Hassner_Effective_Face_Frontalization_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "face recognition systems", "label": "face recognition systems", "shape": "dot", "size": 10.089285714285714, "title": "face recognition systems"}, {"color": "#6FA8DC", "id": "unconstrained images", "label": "unconstrained images", "shape": "dot", "size": 10.357142857142858, "title": "unconstrained images"}, {"color": "#6FA8DC", "id": "varying poses", "label": "varying poses", "shape": "dot", "size": 10.089285714285714, "title": "varying poses"}, {"color": "#6FA8DC", "id": "varying expressions", "label": "varying expressions", "shape": "dot", "size": 10.089285714285714, "title": "varying expressions"}, {"color": "#6FA8DC", "id": "varying lighting", "label": "varying lighting", "shape": "dot", "size": 10.178571428571429, "title": "varying lighting"}, {"color": "#6FA8DC", "id": "Fronalization", "label": "Fronalization", "shape": "dot", "size": 10.178571428571429, "title": "Fronalization"}, {"color": "#6FA8DC", "id": "problem of varying poses", "label": "problem of varying poses", "shape": "dot", "size": 10.089285714285714, "title": "problem of varying poses"}, {"color": "#6FA8DC", "id": "problem of varying lighting", "label": "problem of varying lighting", "shape": "dot", "size": 10.089285714285714, "title": "problem of varying lighting"}, {"color": "#6FA8DC", "id": "previous methods", "label": "previous methods", "shape": "dot", "size": 10.089285714285714, "title": "previous methods"}, {"color": "#6FA8DC", "id": "estimating 3D facial shapes", "label": "estimating 3D facial shapes", "shape": "dot", "size": 10.089285714285714, "title": "estimating 3D facial shapes"}, {"color": "#6FA8DC", "id": "this paper", "label": "this paper", "shape": "dot", "size": 10.267857142857142, "title": "this paper"}, {"color": "#6FA8DC", "id": "simpler approach", "label": "simpler approach", "shape": "dot", "size": 10.178571428571429, "title": "simpler approach"}, {"color": "#6FA8DC", "id": "single 3D surface", "label": "single 3D surface", "shape": "dot", "size": 10.089285714285714, "title": "single 3D surface"}, {"color": "#6FA8DC", "id": "frontal views", "label": "frontal views", "shape": "dot", "size": 10.267857142857142, "title": "frontal views"}, {"color": "#6FA8DC", "id": "aesthetically pleasing", "label": "aesthetically pleasing", "shape": "dot", "size": 10.089285714285714, "title": "aesthetically pleasing"}, {"color": "#6FA8DC", "id": "gender estimation", "label": "gender estimation", "shape": "dot", "size": 10.089285714285714, "title": "gender estimation"}, {"color": "#6FA8DC", "id": "Face frontalization", "label": "Face frontalization", "shape": "dot", "size": 10.089285714285714, "title": "Face frontalization"}, {"color": "#6FA8DC", "id": "aesthetically pleasing frontal views", "label": "aesthetically pleasing frontal views", "shape": "dot", "size": 10.089285714285714, "title": "aesthetically pleasing frontal views"}, {"color": "#6FA8DC", "id": "AI systems", "label": "AI systems", "shape": "dot", "size": 10.178571428571429, "title": "AI systems"}, {"color": "#6FA8DC", "id": "factual question answering", "label": "factual question answering", "shape": "dot", "size": 10.089285714285714, "title": "factual question answering"}, {"color": "#6FA8DC", "id": "common sense reasoning", "label": "common sense reasoning", "shape": "dot", "size": 10.089285714285714, "title": "common sense reasoning"}, {"color": "#6FA8DC", "id": "visual common sense", "label": "visual common sense", "shape": "dot", "size": 10.178571428571429, "title": "visual common sense"}, {"color": "#6FA8DC", "id": "semantic knowledge", "label": "semantic knowledge", "shape": "dot", "size": 10.089285714285714, "title": "semantic knowledge"}, {"color": "#6FA8DC", "id": "visual cues", "label": "visual cues", "shape": "dot", "size": 10.089285714285714, "title": "visual cues"}, {"color": "#6FA8DC", "id": "textual cues", "label": "textual cues", "shape": "dot", "size": 10.089285714285714, "title": "textual cues"}, {"color": "#6FA8DC", "id": "benchmarks", "label": "benchmarks", "shape": "dot", "size": 10.089285714285714, "title": "benchmarks"}, {"color": "#6FA8DC", "id": "progress", "label": "progress", "shape": "dot", "size": 10.089285714285714, "title": "progress"}, {"color": "#6FA8DC", "id": "Xiao Lin", "label": "Xiao Lin", "shape": "dot", "size": 10.178571428571429, "title": "Xiao Lin"}, {"color": "#6FA8DC", "id": "Visual Common Sense", "label": "Visual Common Sense", "shape": "dot", "size": 10.089285714285714, "title": "Visual Common Sense"}, {"color": "#6FA8DC", "id": "AI Reasoning", "label": "AI Reasoning", "shape": "dot", "size": 10.178571428571429, "title": "AI Reasoning"}, {"color": "#6FA8DC", "id": "Visual Paraphasing", "label": "Visual Paraphasing", "shape": "dot", "size": 10.089285714285714, "title": "Visual Paraphasing"}, {"color": "#6FA8DC", "id": "linxiao@vt.edu", "label": "linxiao@vt.edu", "shape": "dot", "size": 10.089285714285714, "title": "linxiao@vt.edu"}, {"color": "#6FA8DC", "id": "Hsu_Robust_Image_Alignment_2015_CVPR_paper.pdf", "label": "Hsu_Robust_Image_Alignment_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.178571428571429, "title": "Hsu_Robust_Image_Alignment_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "image alignment", "label": "image alignment", "shape": "dot", "size": 10.178571428571429, "title": "image alignment"}, {"color": "#6FA8DC", "id": "complex system", "label": "complex system", "shape": "dot", "size": 10.089285714285714, "title": "complex system"}, {"color": "#6FA8DC", "id": "process", "label": "process", "shape": "dot", "size": 10.267857142857142, "title": "process"}, {"color": "#6FA8DC", "id": "data analysis", "label": "data analysis", "shape": "dot", "size": 10.089285714285714, "title": "data analysis"}, {"color": "#6FA8DC", "id": "solutions", "label": "solutions", "shape": "dot", "size": 10.089285714285714, "title": "solutions"}, {"color": "#6FA8DC", "id": "quantitative", "label": "quantitative", "shape": "dot", "size": 10.089285714285714, "title": "quantitative"}, {"color": "#6FA8DC", "id": "relationships", "label": "relationships", "shape": "dot", "size": 10.089285714285714, "title": "relationships"}, {"color": "#6FA8DC", "id": "dependencies", "label": "dependencies", "shape": "dot", "size": 10.089285714285714, "title": "dependencies"}, {"color": "#6FA8DC", "id": "Data Analysis", "label": "Data Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Data Analysis"}, {"color": "#6FA8DC", "id": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "label": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.892857142857142, "title": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Optimization", "label": "Optimization", "shape": "dot", "size": 10.089285714285714, "title": "Optimization"}, {"color": "#6FA8DC", "id": "System Dynamics", "label": "System Dynamics", "shape": "dot", "size": 10.089285714285714, "title": "System Dynamics"}, {"color": "#6FA8DC", "id": "Parameter Estimation", "label": "Parameter Estimation", "shape": "dot", "size": 10.178571428571429, "title": "Parameter Estimation"}, {"color": "#6FA8DC", "id": "Relationship Modeling", "label": "Relationship Modeling", "shape": "dot", "size": 10.089285714285714, "title": "Relationship Modeling"}, {"color": "#6FA8DC", "id": "Rock_Compleeting_3D_Object_2015_CVPR_paper.pdf", "label": "Rock_Compleeting_3D_Object_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Rock_Compleeting_3D_Object_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Jason Rock", "label": "Jason Rock", "shape": "dot", "size": 10.178571428571429, "title": "Jason Rock"}, {"color": "#6FA8DC", "id": "Justin Thorsten", "label": "Justin Thorsten", "shape": "dot", "size": 10.089285714285714, "title": "Justin Thorsten"}, {"color": "#6FA8DC", "id": "JunYoung Gwak", "label": "JunYoung Gwak", "shape": "dot", "size": 10.178571428571429, "title": "JunYoung Gwak"}, {"color": "#6FA8DC", "id": "Daeyun Shin", "label": "Daeyun Shin", "shape": "dot", "size": 10.178571428571429, "title": "Daeyun Shin"}, {"color": "#6FA8DC", "id": "problem of recovering a complete 3D model", "label": "problem of recovering a complete 3D model", "shape": "dot", "size": 10.089285714285714, "title": "problem of recovering a complete 3D model"}, {"color": "#6FA8DC", "id": "user interaction", "label": "user interaction", "shape": "dot", "size": 10.089285714285714, "title": "user interaction"}, {"color": "#6FA8DC", "id": "similar 3D models", "label": "similar 3D models", "shape": "dot", "size": 10.089285714285714, "title": "similar 3D models"}, {"color": "#6FA8DC", "id": "symmetries", "label": "symmetries", "shape": "dot", "size": 10.089285714285714, "title": "symmetries"}, {"color": "#6FA8DC", "id": "reconstruct a 3D model automatically", "label": "reconstruct a 3D model automatically", "shape": "dot", "size": 10.089285714285714, "title": "reconstruct a 3D model automatically"}, {"color": "#6FA8DC", "id": "viewpoint-based shape matching", "label": "viewpoint-based shape matching", "shape": "dot", "size": 10.089285714285714, "title": "viewpoint-based shape matching"}, {"color": "#6FA8DC", "id": "3D deformation", "label": "3D deformation", "shape": "dot", "size": 10.089285714285714, "title": "3D deformation"}, {"color": "#6FA8DC", "id": "3D mesh analysis", "label": "3D mesh analysis", "shape": "dot", "size": 10.089285714285714, "title": "3D mesh analysis"}, {"color": "#6FA8DC", "id": "3D model synthesis", "label": "3D model synthesis", "shape": "dot", "size": 10.089285714285714, "title": "3D model synthesis"}, {"color": "#6FA8DC", "id": "3D Shape Reconstruction", "label": "3D Shape Reconstruction", "shape": "dot", "size": 10.446428571428571, "title": "3D Shape Reconstruction"}, {"color": "#6FA8DC", "id": "Tanmay Gupta", "label": "Tanmay Gupta", "shape": "dot", "size": 10.089285714285714, "title": "Tanmay Gupta"}, {"color": "#6FA8DC", "id": "View-Based Matching", "label": "View-Based Matching", "shape": "dot", "size": 10.089285714285714, "title": "View-Based Matching"}, {"color": "#6FA8DC", "id": "Shape Completion", "label": "Shape Completion", "shape": "dot", "size": 10.089285714285714, "title": "Shape Completion"}, {"color": "#6FA8DC", "id": "3D Model Synthesis", "label": "3D Model Synthesis", "shape": "dot", "size": 10.089285714285714, "title": "3D Model Synthesis"}, {"color": "#6FA8DC", "id": "Symmetry Transfer", "label": "Symmetry Transfer", "shape": "dot", "size": 10.089285714285714, "title": "Symmetry Transfer"}, {"color": "#6FA8DC", "id": "Liu_Data-Driven_Sparsity-Based_Restoration_2015_CVPR_paper.pdf", "label": "Liu_Data-Driven_Sparsity-Based_Restoration_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Liu_Data-Driven_Sparsity-Based_Restoration_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Rui Caseiro", "label": "Rui Caseiro", "shape": "dot", "size": 10.178571428571429, "title": "Rui Caseiro"}, {"color": "#6FA8DC", "id": "Beyond the Shortest Path", "label": "Beyond the Shortest Path", "shape": "dot", "size": 10.535714285714286, "title": "Beyond the Shortest Path"}, {"color": "#6FA8DC", "id": "Pedro Martins", "label": "Pedro Martins", "shape": "dot", "size": 10.178571428571429, "title": "Pedro Martins"}, {"color": "#6FA8DC", "id": "Jorge Batista", "label": "Jorge Batista", "shape": "dot", "size": 10.267857142857142, "title": "Jorge Batista"}, {"color": "#6FA8DC", "id": "domain adaptation", "label": "domain adaptation", "shape": "dot", "size": 10.178571428571429, "title": "domain adaptation"}, {"color": "#6FA8DC", "id": "spline flow", "label": "spline flow", "shape": "dot", "size": 10.178571428571429, "title": "spline flow"}, {"color": "#6FA8DC", "id": "improve_performance", "label": "improve_performance", "shape": "dot", "size": 10.089285714285714, "title": "improve_performance"}, {"color": "#6FA8DC", "id": "domain adaptation paradigm", "label": "domain adaptation paradigm", "shape": "dot", "size": 10.089285714285714, "title": "domain adaptation paradigm"}, {"color": "#6FA8DC", "id": "shortest path", "label": "shortest path", "shape": "dot", "size": 10.267857142857142, "title": "shortest path"}, {"color": "#6FA8DC", "id": "geodesic curve", "label": "geodesic curve", "shape": "dot", "size": 10.089285714285714, "title": "geodesic curve"}, {"color": "#6FA8DC", "id": "modeling complex domain shifts", "label": "modeling complex domain shifts", "shape": "dot", "size": 10.089285714285714, "title": "modeling complex domain shifts"}, {"color": "#6FA8DC", "id": "use of multiple datasets", "label": "use of multiple datasets", "shape": "dot", "size": 10.089285714285714, "title": "use of multiple datasets"}, {"color": "#6FA8DC", "id": "novel approach", "label": "novel approach", "shape": "dot", "size": 10.446428571428571, "title": "novel approach"}, {"color": "#6FA8DC", "id": "spline curves", "label": "spline curves", "shape": "dot", "size": 10.178571428571429, "title": "spline curves"}, {"color": "#6FA8DC", "id": "rolling maps", "label": "rolling maps", "shape": "dot", "size": 10.089285714285714, "title": "rolling maps"}, {"color": "#6FA8DC", "id": "integration of multiple source domains", "label": "integration of multiple source domains", "shape": "dot", "size": 10.089285714285714, "title": "integration of multiple source domains"}, {"color": "#6FA8DC", "id": "domain shifts", "label": "domain shifts", "shape": "dot", "size": 10.178571428571429, "title": "domain shifts"}, {"color": "#6FA8DC", "id": "improved performance", "label": "improved performance", "shape": "dot", "size": 10.089285714285714, "title": "improved performance"}, {"color": "#6FA8DC", "id": "Domain Adaptation", "label": "Domain Adaptation", "shape": "dot", "size": 10.535714285714286, "title": "Domain Adaptation"}, {"color": "#6FA8DC", "id": "Subspace Representation", "label": "Subspace Representation", "shape": "dot", "size": 10.089285714285714, "title": "Subspace Representation"}, {"color": "#6FA8DC", "id": "Baktas et al. (2013)", "label": "Baktas et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Baktas et al. (2013)"}, {"color": "#6FA8DC", "id": "Domain Invariant Projection", "label": "Domain Invariant Projection", "shape": "dot", "size": 10.089285714285714, "title": "Domain Invariant Projection"}, {"color": "#6FA8DC", "id": "Gopalan et al. (2013)", "label": "Gopalan et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Gopalan et al. (2013)"}, {"color": "#6FA8DC", "id": "location recognition", "label": "location recognition", "shape": "dot", "size": 10.089285714285714, "title": "location recognition"}, {"color": "#6FA8DC", "id": "Gopalan et al. (2011)", "label": "Gopalan et al. (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Gopalan et al. (2011)"}, {"color": "#6FA8DC", "id": "Unsupervised approach", "label": "Unsupervised approach", "shape": "dot", "size": 10.089285714285714, "title": "Unsupervised approach"}, {"color": "#6FA8DC", "id": "Carreira et al. (2012)", "label": "Carreira et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Carreira et al. (2012)"}, {"color": "#6FA8DC", "id": "Caseiro et al. (2010)", "label": "Caseiro et al. (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Caseiro et al. (2010)"}, {"color": "#6FA8DC", "id": "cast shadows", "label": "cast shadows", "shape": "dot", "size": 10.089285714285714, "title": "cast shadows"}, {"color": "#6FA8DC", "id": "Gopalan et al. (2014)", "label": "Gopalan et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Gopalan et al. (2014)"}, {"color": "#6FA8DC", "id": "intermediate data representations", "label": "intermediate data representations", "shape": "dot", "size": 10.089285714285714, "title": "intermediate data representations"}, {"color": "#6FA8DC", "id": "Spline Flow", "label": "Spline Flow", "shape": "dot", "size": 10.089285714285714, "title": "Spline Flow"}, {"color": "#6FA8DC", "id": "Grasmannn Manifold", "label": "Grasmannn Manifold", "shape": "dot", "size": 10.089285714285714, "title": "Grasmannn Manifold"}, {"color": "#6FA8DC", "id": "Rolling Maps", "label": "Rolling Maps", "shape": "dot", "size": 10.089285714285714, "title": "Rolling Maps"}, {"color": "#6FA8DC", "id": "Gopalan", "label": "Gopalan", "shape": "dot", "size": 10.089285714285714, "title": "Gopalan"}, {"color": "#6FA8DC", "id": "Unsupervised adaptation across domain shifts by generating intermediate data representations", "label": "Unsupervised adaptation across domain shifts by generating intermediate data representations", "shape": "dot", "size": 10.178571428571429, "title": "Unsupervised adaptation across domain shifts by generating intermediate data representations"}, {"color": "#6FA8DC", "id": "Li", "label": "Li", "shape": "dot", "size": 10.089285714285714, "title": "Li"}, {"color": "#6FA8DC", "id": "Griffin", "label": "Griffin", "shape": "dot", "size": 10.089285714285714, "title": "Griffin"}, {"color": "#6FA8DC", "id": "Caltech-256 object category dataset", "label": "Caltech-256 object category dataset", "shape": "dot", "size": 10.178571428571429, "title": "Caltech-256 object category dataset"}, {"color": "#6FA8DC", "id": "Holub", "label": "Holub", "shape": "dot", "size": 10.089285714285714, "title": "Holub"}, {"color": "#6FA8DC", "id": "Cal tech-256 object category dataset", "label": "Cal tech-256 object category dataset", "shape": "dot", "size": 10.089285714285714, "title": "Cal tech-256 object category dataset"}, {"color": "#6FA8DC", "id": "Caseiro", "label": "Caseiro", "shape": "dot", "size": 10.089285714285714, "title": "Caseiro"}, {"color": "#6FA8DC", "id": "non-parametric riemannian framework", "label": "non-parametric riemannian framework", "shape": "dot", "size": 10.357142857142858, "title": "non-parametric riemannian framework"}, {"color": "#6FA8DC", "id": "Henriques", "label": "Henriques", "shape": "dot", "size": 10.089285714285714, "title": "Henriques"}, {"color": "#6FA8DC", "id": "Martins", "label": "Martins", "shape": "dot", "size": 10.089285714285714, "title": "Martins"}, {"color": "#6FA8DC", "id": "Batista", "label": "Batista", "shape": "dot", "size": 10.089285714285714, "title": "Batista"}, {"color": "#6FA8DC", "id": "Hays", "label": "Hays", "shape": "dot", "size": 10.089285714285714, "title": "Hays"}, {"color": "#6FA8DC", "id": "Im2gps", "label": "Im2gps", "shape": "dot", "size": 10.178571428571429, "title": "Im2gps"}, {"color": "#6FA8DC", "id": "Efroos", "label": "Efroos", "shape": "dot", "size": 10.089285714285714, "title": "Efroos"}, {"color": "#6FA8DC", "id": "Pan", "label": "Pan", "shape": "dot", "size": 10.089285714285714, "title": "Pan"}, {"color": "#6FA8DC", "id": "A survey on transfer learning", "label": "A survey on transfer learning", "shape": "dot", "size": 10.178571428571429, "title": "A survey on transfer learning"}, {"color": "#6FA8DC", "id": "Institute of Systems and Robotics - University of Coimbra", "label": "Institute of Systems and Robotics - University of Coimbra", "shape": "dot", "size": 10.357142857142858, "title": "Institute of Systems and Robotics - University of Coimbra"}, {"color": "#6FA8DC", "id": "Jo\u00e3o F. Henriques", "label": "Jo\u00e3o F. Henriques", "shape": "dot", "size": 10.089285714285714, "title": "Jo\u00e3o F. Henriques"}, {"color": "#6FA8DC", "id": "Institute of Sistemas and Robotics - University of Coimbra", "label": "Institute of Sistemas and Robotics - University of Coimbra", "shape": "dot", "size": 10.089285714285714, "title": "Institute of Sistemas and Robotics - University of Coimbra"}, {"color": "#6FA8DC", "id": "Sparse Composite Quantization", "label": "Sparse Composite Quantization", "shape": "dot", "size": 10.267857142857142, "title": "Sparse Composite Quantization"}, {"color": "#6FA8DC", "id": "Zhang_Sparse_Composite_Quantization_2015_CVPR_paper", "label": "Zhang_Sparse_Composite_Quantization_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Zhang_Sparse_Composite_Quantization_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "quantization techniques", "label": "quantization techniques", "shape": "dot", "size": 10.089285714285714, "title": "quantization techniques"}, {"color": "#6FA8DC", "id": "sparse composite quantization", "label": "sparse composite quantization", "shape": "dot", "size": 10.625, "title": "sparse composite quantization"}, {"color": "#6FA8DC", "id": "competitive search accuracy", "label": "competitive search accuracy", "shape": "dot", "size": 10.089285714285714, "title": "competitive search accuracy"}, {"color": "#6FA8DC", "id": "Cartesian k-means", "label": "Cartesian k-means", "shape": "dot", "size": 10.267857142857142, "title": "Cartesian k-means"}, {"color": "#6FA8DC", "id": "composite quantization", "label": "composite quantization", "shape": "dot", "size": 10.178571428571429, "title": "composite quantization"}, {"color": "#6FA8DC", "id": "distance table computation", "label": "distance table computation", "shape": "dot", "size": 10.178571428571429, "title": "distance table computation"}, {"color": "#6FA8DC", "id": "sparse dictionaries", "label": "sparse dictionaries", "shape": "dot", "size": 10.178571428571429, "title": "sparse dictionaries"}, {"color": "#6FA8DC", "id": "distance evaluation", "label": "distance evaluation", "shape": "dot", "size": 10.089285714285714, "title": "distance evaluation"}, {"color": "#6FA8DC", "id": "distance table computation time", "label": "distance table computation time", "shape": "dot", "size": 10.089285714285714, "title": "distance table computation time"}, {"color": "#6FA8DC", "id": "large-scale datasets", "label": "large-scale datasets", "shape": "dot", "size": 10.267857142857142, "title": "large-scale datasets"}, {"color": "#6FA8DC", "id": "SIFTs", "label": "SIFTs", "shape": "dot", "size": 10.357142857142858, "title": "SIFTs"}, {"color": "#6FA8DC", "id": "time", "label": "time", "shape": "dot", "size": 10.089285714285714, "title": "time"}, {"color": "#6FA8DC", "id": "1M", "label": "1M", "shape": "dot", "size": 10.089285714285714, "title": "1M"}, {"color": "#6FA8DC", "id": "1B", "label": "1B", "shape": "dot", "size": 10.178571428571429, "title": "1B"}, {"color": "#6FA8DC", "id": "comparable", "label": "comparable", "shape": "dot", "size": 10.089285714285714, "title": "comparable"}, {"color": "#6FA8DC", "id": "search times", "label": "search times", "shape": "dot", "size": 10.089285714285714, "title": "search times"}, {"color": "#6FA8DC", "id": "faster", "label": "faster", "shape": "dot", "size": 10.089285714285714, "title": "faster"}, {"color": "#6FA8DC", "id": "SIFTS", "label": "SIFTS", "shape": "dot", "size": 10.089285714285714, "title": "SIFTS"}, {"color": "#6FA8DC", "id": "ANN", "label": "ANN", "shape": "dot", "size": 10.089285714285714, "title": "ANN"}, {"color": "#6FA8DC", "id": "nearest neighbor search", "label": "nearest neighbor search", "shape": "dot", "size": 10.089285714285714, "title": "nearest neighbor search"}, {"color": "#6FA8DC", "id": "Product Quantization", "label": "Product Quantization", "shape": "dot", "size": 10.089285714285714, "title": "Product Quantization"}, {"color": "#6FA8DC", "id": "for nearest neighbor search", "label": "for nearest neighbor search", "shape": "dot", "size": 10.089285714285714, "title": "for nearest neighbor search"}, {"color": "#6FA8DC", "id": "Babenko and Lempitsky (2012)", "label": "Babenko and Lempitsky (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Babenko and Lempitsky (2012)"}, {"color": "#6FA8DC", "id": "inverted multi-index", "label": "inverted multi-index", "shape": "dot", "size": 10.089285714285714, "title": "inverted multi-index"}, {"color": "#6FA8DC", "id": "Babenko and Lempitsky (2014)", "label": "Babenko and Lempitsky (2014)", "shape": "dot", "size": 10.178571428571429, "title": "Babenko and Lempitsky (2014)"}, {"color": "#6FA8DC", "id": "bilayer product quantization", "label": "bilayer product quantization", "shape": "dot", "size": 10.267857142857142, "title": "bilayer product quantization"}, {"color": "#6FA8DC", "id": "billion-scale approximate nearest neighbors", "label": "billion-scale approximate nearest neighbors", "shape": "dot", "size": 10.089285714285714, "title": "billion-scale approximate nearest neighbors"}, {"color": "#6FA8DC", "id": "High-Dimensional Data", "label": "High-Dimensional Data", "shape": "dot", "size": 10.089285714285714, "title": "High-Dimensional Data"}, {"color": "#6FA8DC", "id": "approximate nearest neighbors", "label": "approximate nearest neighbors", "shape": "dot", "size": 10.089285714285714, "title": "approximate nearest neighbors"}, {"color": "#6FA8DC", "id": "variation", "label": "variation", "shape": "dot", "size": 10.089285714285714, "title": "variation"}, {"color": "#6FA8DC", "id": "vocabulary trees", "label": "vocabulary trees", "shape": "dot", "size": 10.089285714285714, "title": "vocabulary trees"}, {"color": "#6FA8DC", "id": "Hamming embedding", "label": "Hamming embedding", "shape": "dot", "size": 10.089285714285714, "title": "Hamming embedding"}, {"color": "#6FA8DC", "id": "large scale image search", "label": "large scale image search", "shape": "dot", "size": 10.089285714285714, "title": "large scale image search"}, {"color": "#6FA8DC", "id": "semi-supervised hashing", "label": "semi-supervised hashing", "shape": "dot", "size": 10.089285714285714, "title": "semi-supervised hashing"}, {"color": "#6FA8DC", "id": "large-scale search", "label": "large-scale search", "shape": "dot", "size": 10.178571428571429, "title": "large-scale search"}, {"color": "#6FA8DC", "id": "large-scale applications", "label": "large-scale applications", "shape": "dot", "size": 10.089285714285714, "title": "large-scale applications"}, {"color": "#6FA8DC", "id": "CVPR (2013)", "label": "CVPR (2013)", "shape": "dot", "size": 10.089285714285714, "title": "CVPR (2013)"}, {"color": "#6FA8DC", "id": "Re-ranking strategies", "label": "Re-ranking strategies", "shape": "dot", "size": 10.089285714285714, "title": "Re-ranking strategies"}, {"color": "#6FA8DC", "id": "Graph-based search methods", "label": "Graph-based search methods", "shape": "dot", "size": 10.178571428571429, "title": "Graph-based search methods"}, {"color": "#6FA8DC", "id": "search", "label": "search", "shape": "dot", "size": 10.089285714285714, "title": "search"}, {"color": "#6FA8DC", "id": "Angular quantization", "label": "Angular quantization", "shape": "dot", "size": 10.178571428571429, "title": "Angular quantization"}, {"color": "#6FA8DC", "id": "Guo-Jun Qi", "label": "Guo-Jun Qi", "shape": "dot", "size": 10.089285714285714, "title": "Guo-Jun Qi"}, {"color": "#6FA8DC", "id": "Jinhui Tang", "label": "Jinhui Tang", "shape": "dot", "size": 10.178571428571429, "title": "Jinhui Tang"}, {"color": "#6FA8DC", "id": "Unknown", "label": "Unknown", "shape": "dot", "size": 10.089285714285714, "title": "Unknown"}, {"color": "#6FA8DC", "id": "Ting Zhang", "label": "Ting Zhang", "shape": "dot", "size": 10.089285714285714, "title": "Ting Zhang"}, {"color": "#6FA8DC", "id": "Nanjing University of Science and Technology", "label": "Nanjing University of Science and Technology", "shape": "dot", "size": 10.089285714285714, "title": "Nanjing University of Science and Technology"}, {"color": "#6FA8DC", "id": "Jingding Wang", "label": "Jingding Wang", "shape": "dot", "size": 10.089285714285714, "title": "Jingding Wang"}, {"color": "#6FA8DC", "id": "Ioannis Gkioulekalas", "label": "Ioannis Gkioulekalas", "shape": "dot", "size": 10.089285714285714, "title": "Ioannis Gkioulekalas"}, {"color": "#6FA8DC", "id": "On the Appearance of Translueceny Edges", "label": "On the Appearance of Translueceny Edges", "shape": "dot", "size": 10.357142857142858, "title": "On the Appearance of Translueceny Edges"}, {"color": "#6FA8DC", "id": "On the Appearence of Translueceny Edges", "label": "On the Appearence of Translueceny Edges", "shape": "dot", "size": 10.267857142857142, "title": "On the Appearence of Translueceny Edges"}, {"color": "#6FA8DC", "id": "Gkiooulekas_On_the_Appearance_2015_CVPR_paper.pdf", "label": "Gkiooulekas_On_the_Appearance_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Gkiooulekas_On_the_Appearance_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Edges in images", "label": "Edges in images", "shape": "dot", "size": 10.089285714285714, "title": "Edges in images"}, {"color": "#6FA8DC", "id": "Edges in opaque objects", "label": "Edges in opaque objects", "shape": "dot", "size": 10.089285714285714, "title": "Edges in opaque objects"}, {"color": "#6FA8DC", "id": "Edges", "label": "Edges", "shape": "dot", "size": 10.089285714285714, "title": "Edges"}, {"color": "#6FA8DC", "id": "Discontinuity in surface orientation", "label": "Discontinuity in surface orientation", "shape": "dot", "size": 10.089285714285714, "title": "Discontinuity in surface orientation"}, {"color": "#6FA8DC", "id": "Authors", "label": "Authors", "shape": "dot", "size": 10.089285714285714, "title": "Authors"}, {"color": "#6FA8DC", "id": "Edge patterns", "label": "Edge patterns", "shape": "dot", "size": 10.178571428571429, "title": "Edge patterns"}, {"color": "#6FA8DC", "id": "Simulations", "label": "Simulations", "shape": "dot", "size": 10.089285714285714, "title": "Simulations"}, {"color": "#6FA8DC", "id": "Scattering parameters", "label": "Scattering parameters", "shape": "dot", "size": 10.089285714285714, "title": "Scattering parameters"}, {"color": "#6FA8DC", "id": "Material Metamers", "label": "Material Metamers", "shape": "dot", "size": 10.089285714285714, "title": "Material Metamers"}, {"color": "#6FA8DC", "id": "Visual Inference tasks", "label": "Visual Inference tasks", "shape": "dot", "size": 10.267857142857142, "title": "Visual Inference tasks"}, {"color": "#6FA8DC", "id": "Shape estimation", "label": "Shape estimation", "shape": "dot", "size": 10.089285714285714, "title": "Shape estimation"}, {"color": "#6FA8DC", "id": "Material estimation", "label": "Material estimation", "shape": "dot", "size": 10.089285714285714, "title": "Material estimation"}, {"color": "#6FA8DC", "id": "Light Transport", "label": "Light Transport", "shape": "dot", "size": 10.357142857142858, "title": "Light Transport"}, {"color": "#6FA8DC", "id": "Wave Propagation", "label": "Wave Propagation", "shape": "dot", "size": 10.178571428571429, "title": "Wave Propagation"}, {"color": "#6FA8DC", "id": "Ishimaru (1978)", "label": "Ishimaru (1978)", "shape": "dot", "size": 10.089285714285714, "title": "Ishimaru (1978)"}, {"color": "#6FA8DC", "id": "Stereo Reconstruction", "label": "Stereo Reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "Stereo Reconstruction"}, {"color": "#6FA8DC", "id": "Human Perception", "label": "Human Perception", "shape": "dot", "size": 10.178571428571429, "title": "Human Perception"}, {"color": "#6FA8DC", "id": "Adelson (2001)", "label": "Adelson (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Adelson (2001)"}, {"color": "#6FA8DC", "id": "Machine Vision", "label": "Machine Vision", "shape": "dot", "size": 10.089285714285714, "title": "Machine Vision"}, {"color": "#6FA8DC", "id": "Jensen et al. (2001)", "label": "Jensen et al. (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Jensen et al. (2001)"}, {"color": "#6FA8DC", "id": "Rendering", "label": "Rendering", "shape": "dot", "size": 10.089285714285714, "title": "Rendering"}, {"color": "#6FA8DC", "id": "Reconstruction", "label": "Reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "Reconstruction"}, {"color": "#6FA8DC", "id": "Translucent Objects", "label": "Translucent Objects", "shape": "dot", "size": 10.267857142857142, "title": "Translucent Objects"}, {"color": "#6FA8DC", "id": "Material Estimation", "label": "Material Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Material Estimation"}, {"color": "#6FA8DC", "id": "Material Metameters", "label": "Material Metameters", "shape": "dot", "size": 10.089285714285714, "title": "Material Metameters"}, {"color": "#6FA8DC", "id": "light transport complexities", "label": "light transport complexities", "shape": "dot", "size": 10.089285714285714, "title": "light transport complexities"}, {"color": "#6FA8DC", "id": "light transport", "label": "light transport", "shape": "dot", "size": 10.089285714285714, "title": "light transport"}, {"color": "#6FA8DC", "id": "translucient materials", "label": "translucient materials", "shape": "dot", "size": 10.089285714285714, "title": "translucient materials"}, {"color": "#6FA8DC", "id": "rendering", "label": "rendering", "shape": "dot", "size": 10.089285714285714, "title": "rendering"}, {"color": "#6FA8DC", "id": "accurate light transport", "label": "accurate light transport", "shape": "dot", "size": 10.089285714285714, "title": "accurate light transport"}, {"color": "#6FA8DC", "id": "artifacts", "label": "artifacts", "shape": "dot", "size": 10.089285714285714, "title": "artifacts"}, {"color": "#6FA8DC", "id": "translucent materials", "label": "translucent materials", "shape": "dot", "size": 10.267857142857142, "title": "translucent materials"}, {"color": "#6FA8DC", "id": "translucent appearance", "label": "translucent appearance", "shape": "dot", "size": 10.267857142857142, "title": "translucent appearance"}, {"color": "#6FA8DC", "id": "phase functions", "label": "phase functions", "shape": "dot", "size": 10.089285714285714, "title": "phase functions"}, {"color": "#6FA8DC", "id": "reconstruction", "label": "reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "reconstruction"}, {"color": "#6FA8DC", "id": "accurate rendering", "label": "accurate rendering", "shape": "dot", "size": 10.089285714285714, "title": "accurate rendering"}, {"color": "#6FA8DC", "id": "translucency", "label": "translucency", "shape": "dot", "size": 10.089285714285714, "title": "translucency"}, {"color": "#6FA8DC", "id": "phase function", "label": "phase function", "shape": "dot", "size": 10.089285714285714, "title": "phase function"}, {"color": "#6FA8DC", "id": "photon diffusion", "label": "photon diffusion", "shape": "dot", "size": 10.089285714285714, "title": "photon diffusion"}, {"color": "#6FA8DC", "id": "Open-surfaces catalog", "label": "Open-surfaces catalog", "shape": "dot", "size": 10.089285714285714, "title": "Open-surfaces catalog"}, {"color": "#6FA8DC", "id": "surface appearances", "label": "surface appearances", "shape": "dot", "size": 10.267857142857142, "title": "surface appearances"}, {"color": "#6FA8DC", "id": "evaluation", "label": "evaluation", "shape": "dot", "size": 10.178571428571429, "title": "evaluation"}, {"color": "#6FA8DC", "id": "ACM Transactions on Graphics", "label": "ACM Transactions on Graphics", "shape": "dot", "size": 10.267857142857142, "title": "ACM Transactions on Graphics"}, {"color": "#6FA8DC", "id": "research on phase function", "label": "research on phase function", "shape": "dot", "size": 10.089285714285714, "title": "research on phase function"}, {"color": "#6FA8DC", "id": "Journal of Vision", "label": "Journal of Vision", "shape": "dot", "size": 10.089285714285714, "title": "Journal of Vision"}, {"color": "#6FA8DC", "id": "research on translucency", "label": "research on translucency", "shape": "dot", "size": 10.089285714285714, "title": "research on translucency"}, {"color": "#6FA8DC", "id": "ACM SIGGRAPH", "label": "ACM SIGGRAPH", "shape": "dot", "size": 10.089285714285714, "title": "ACM SIGGRAPH"}, {"color": "#6FA8DC", "id": "research on rendering techniques", "label": "research on rendering techniques", "shape": "dot", "size": 10.089285714285714, "title": "research on rendering techniques"}, {"color": "#6FA8DC", "id": "Bala. Open-surfaces", "label": "Bala. Open-surfaces", "shape": "dot", "size": 10.178571428571429, "title": "Bala. Open-surfaces"}, {"color": "#6FA8DC", "id": "dataset of surface appearances", "label": "dataset of surface appearances", "shape": "dot", "size": 10.089285714285714, "title": "dataset of surface appearances"}, {"color": "#6FA8DC", "id": "Gkiouslekas et al.", "label": "Gkiouslekas et al.", "shape": "dot", "size": 10.089285714285714, "title": "Gkiouslekas et al."}, {"color": "#6FA8DC", "id": "phase function in translucent appearance", "label": "phase function in translucent appearance", "shape": "dot", "size": 10.089285714285714, "title": "phase function in translucent appearance"}, {"color": "#6FA8DC", "id": "materials in context database", "label": "materials in context database", "shape": "dot", "size": 10.089285714285714, "title": "materials in context database"}, {"color": "#6FA8DC", "id": "translucent objects", "label": "translucent objects", "shape": "dot", "size": 10.089285714285714, "title": "translucent objects"}, {"color": "#6FA8DC", "id": "Bell et al.", "label": "Bell et al.", "shape": "dot", "size": 10.089285714285714, "title": "Bell et al."}, {"color": "#6FA8DC", "id": "Mingkui Tan", "label": "Mingkui Tan", "shape": "dot", "size": 10.178571428571429, "title": "Mingkui Tan"}, {"color": "#6FA8DC", "id": "Learning graph structure...", "label": "Learning graph structure...", "shape": "dot", "size": 10.714285714285714, "title": "Learning graph structure..."}, {"color": "#6FA8DC", "id": "Qinfeng Shi", "label": "Qinfeng Shi", "shape": "dot", "size": 10.178571428571429, "title": "Qinfeng Shi"}, {"color": "#6FA8DC", "id": "Fuyuan Hu", "label": "Fuyuan Hu", "shape": "dot", "size": 10.178571428571429, "title": "Fuyuan Hu"}, {"color": "#6FA8DC", "id": "Zhen Zhang", "label": "Zhen Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Zhen Zhang"}, {"color": "#6FA8DC", "id": "Tan_Learning_Graph_Structure_2015_CVPR_paper.pdf", "label": "Tan_Learning_Graph_Structure_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Tan_Learning_Graph_Structure_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Multi-label image classification", "label": "Multi-label image classification", "shape": "dot", "size": 10.178571428571429, "title": "Multi-label image classification"}, {"color": "#6FA8DC", "id": "Classification performance", "label": "Classification performance", "shape": "dot", "size": 10.089285714285714, "title": "Classification performance"}, {"color": "#6FA8DC", "id": "Probabilistic Graphical Models", "label": "Probabilistic Graphical Models", "shape": "dot", "size": 10.089285714285714, "title": "Probabilistic Graphical Models"}, {"color": "#6FA8DC", "id": "Label dependency", "label": "Label dependency", "shape": "dot", "size": 10.089285714285714, "title": "Label dependency"}, {"color": "#6FA8DC", "id": "Graphical model structure", "label": "Graphical model structure", "shape": "dot", "size": 10.178571428571429, "title": "Graphical model structure"}, {"color": "#6FA8DC", "id": "Heuristic methods", "label": "Heuristic methods", "shape": "dot", "size": 10.089285714285714, "title": "Heuristic methods"}, {"color": "#6FA8DC", "id": "Limited information", "label": "Limited information", "shape": "dot", "size": 10.089285714285714, "title": "Limited information"}, {"color": "#6FA8DC", "id": "Input features", "label": "Input features", "shape": "dot", "size": 10.089285714285714, "title": "Input features"}, {"color": "#6FA8DC", "id": "Labels", "label": "Labels", "shape": "dot", "size": 10.089285714285714, "title": "Labels"}, {"color": "#6FA8DC", "id": "Problem", "label": "Problem", "shape": "dot", "size": 10.178571428571429, "title": "Problem"}, {"color": "#6FA8DC", "id": "Max-margin framework", "label": "Max-margin framework", "shape": "dot", "size": 10.178571428571429, "title": "Max-margin framework"}, {"color": "#6FA8DC", "id": "Convex programming problem", "label": "Convex programming problem", "shape": "dot", "size": 10.089285714285714, "title": "Convex programming problem"}, {"color": "#6FA8DC", "id": "Procedure", "label": "Procedure", "shape": "dot", "size": 10.089285714285714, "title": "Procedure"}, {"color": "#6FA8DC", "id": "Set of cliques", "label": "Set of cliques", "shape": "dot", "size": 10.089285714285714, "title": "Set of cliques"}, {"color": "#6FA8DC", "id": "Strong theoretical properties", "label": "Strong theoretical properties", "shape": "dot", "size": 10.089285714285714, "title": "Strong theoretical properties"}, {"color": "#6FA8DC", "id": "Performance", "label": "Performance", "shape": "dot", "size": 10.089285714285714, "title": "Performance"}, {"color": "#6FA8DC", "id": "set of cliques", "label": "set of cliques", "shape": "dot", "size": 10.178571428571429, "title": "set of cliques"}, {"color": "#6FA8DC", "id": "theoretical properties", "label": "theoretical properties", "shape": "dot", "size": 10.178571428571429, "title": "theoretical properties"}, {"color": "#6FA8DC", "id": "synthetic data sets", "label": "synthetic data sets", "shape": "dot", "size": 10.089285714285714, "title": "synthetic data sets"}, {"color": "#6FA8DC", "id": "cliques", "label": "cliques", "shape": "dot", "size": 10.089285714285714, "title": "cliques"}, {"color": "#6FA8DC", "id": "real-world data sets", "label": "real-world data sets", "shape": "dot", "size": 10.089285714285714, "title": "real-world data sets"}, {"color": "#6FA8DC", "id": "performance improvement", "label": "performance improvement", "shape": "dot", "size": 10.178571428571429, "title": "performance improvement"}, {"color": "#6FA8DC", "id": "Probablistic Graphical Models", "label": "Probablistic Graphical Models", "shape": "dot", "size": 10.178571428571429, "title": "Probablistic Graphical Models"}, {"color": "#6FA8DC", "id": "Graph structure learning", "label": "Graph structure learning", "shape": "dot", "size": 10.178571428571429, "title": "Graph structure learning"}, {"color": "#6FA8DC", "id": "Clique generation", "label": "Clique generation", "shape": "dot", "size": 10.089285714285714, "title": "Clique generation"}, {"color": "#6FA8DC", "id": "learning", "label": "learning", "shape": "dot", "size": 10.089285714285714, "title": "learning"}, {"color": "#6FA8DC", "id": "Boutell et al. (2004)", "label": "Boutell et al. (2004)", "shape": "dot", "size": 10.089285714285714, "title": "Boutell et al. (2004)"}, {"color": "#6FA8DC", "id": "Bradley \u0026 Guestrin (2010)", "label": "Bradley \u0026 Guestrin (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Bradley \u0026 Guestrin (2010)"}, {"color": "#6FA8DC", "id": "tree conditional random fields", "label": "tree conditional random fields", "shape": "dot", "size": 10.089285714285714, "title": "tree conditional random fields"}, {"color": "#6FA8DC", "id": "Bucak et al. (2009)", "label": "Bucak et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Bucak et al. (2009)"}, {"color": "#6FA8DC", "id": "multi-label ranking", "label": "multi-label ranking", "shape": "dot", "size": 10.089285714285714, "title": "multi-label ranking"}, {"color": "#6FA8DC", "id": "R.", "label": "R.", "shape": "dot", "size": 10.089285714285714, "title": "R."}, {"color": "#6FA8DC", "id": "Efficient multi-label ranking", "label": "Efficient multi-label ranking", "shape": "dot", "size": 10.267857142857142, "title": "Efficient multi-label ranking"}, {"color": "#6FA8DC", "id": "Jain, A. K.", "label": "Jain, A. K.", "shape": "dot", "size": 10.089285714285714, "title": "Jain, A. K."}, {"color": "#6FA8DC", "id": "Cai, X.", "label": "Cai, X.", "shape": "dot", "size": 10.089285714285714, "title": "Cai, X."}, {"color": "#6FA8DC", "id": "Graph structured sparsity model", "label": "Graph structured sparsity model", "shape": "dot", "size": 10.178571428571429, "title": "Graph structured sparsity model"}, {"color": "#6FA8DC", "id": "Chow, C.", "label": "Chow, C.", "shape": "dot", "size": 10.089285714285714, "title": "Chow, C."}, {"color": "#6FA8DC", "id": "Approximating discrete probability distributions", "label": "Approximating discrete probability distributions", "shape": "dot", "size": 10.267857142857142, "title": "Approximating discrete probability distributions"}, {"color": "#6FA8DC", "id": "Liu, C.", "label": "Liu, C.", "shape": "dot", "size": 10.089285714285714, "title": "Liu, C."}, {"color": "#6FA8DC", "id": "Dembczy\u0144ski, K.", "label": "Dembczy\u0144ski, K.", "shape": "dot", "size": 10.089285714285714, "title": "Dembczy\u0144ski, K."}, {"color": "#6FA8DC", "id": "Label dependence and loss minimization", "label": "Label dependence and loss minimization", "shape": "dot", "size": 10.446428571428571, "title": "Label dependence and loss minimization"}, {"color": "#6FA8DC", "id": "Waegeman, W.", "label": "Waegeman, W.", "shape": "dot", "size": 10.178571428571429, "title": "Waegeman, W."}, {"color": "#6FA8DC", "id": "Cheng, W.", "label": "Cheng, W.", "shape": "dot", "size": 10.089285714285714, "title": "Cheng, W."}, {"color": "#6FA8DC", "id": "H\u00fcllermeier, E.", "label": "H\u00fcllermeier, E.", "shape": "dot", "size": 10.178571428571429, "title": "H\u00fcllermeier, E."}, {"color": "#6FA8DC", "id": "Dembczynski, K.", "label": "Dembczynski, K.", "shape": "dot", "size": 10.089285714285714, "title": "Dembczynski, K."}, {"color": "#6FA8DC", "id": "Analysis of chaining", "label": "Analysis of chaining", "shape": "dot", "size": 10.357142857142858, "title": "Analysis of chaining"}, {"color": "#6FA8DC", "id": "European Conference on Artificial Intelligence", "label": "European Conference on Artificial Intelligence", "shape": "dot", "size": 10.178571428571429, "title": "European Conference on Artificial Intelligence"}, {"color": "#6FA8DC", "id": "Dembczynski", "label": "Dembczynski", "shape": "dot", "size": 10.178571428571429, "title": "Dembczynski"}, {"color": "#6FA8DC", "id": "analysis of chaining", "label": "analysis of chaining", "shape": "dot", "size": 10.089285714285714, "title": "analysis of chaining"}, {"color": "#6FA8DC", "id": "Learning higher-order graph structure", "label": "Learning higher-order graph structure", "shape": "dot", "size": 10.089285714285714, "title": "Learning higher-order graph structure"}, {"color": "#6FA8DC", "id": "Everingham", "label": "Everingham", "shape": "dot", "size": 10.089285714285714, "title": "Everingham"}, {"color": "#6FA8DC", "id": "PASUAL Visual Object Classes Challenge 2012", "label": "PASUAL Visual Object Classes Challenge 2012", "shape": "dot", "size": 10.089285714285714, "title": "PASUAL Visual Object Classes Challenge 2012"}, {"color": "#6FA8DC", "id": "Bolei Zhou", "label": "Bolei Zhou", "shape": "dot", "size": 10.267857142857142, "title": "Bolei Zhou"}, {"color": "#6FA8DC", "id": "ConceptLearner", "label": "ConceptLearner", "shape": "dot", "size": 10.714285714285714, "title": "ConceptLearner"}, {"color": "#6FA8DC", "id": "Vignesh Jagadeesh", "label": "Vignesh Jagadeesh", "shape": "dot", "size": 10.178571428571429, "title": "Vignesh Jagadeesh"}, {"color": "#6FA8DC", "id": "Zhou_ConceptLearner_Discovering_Visual_2015_CVPR_paper.pdf", "label": "Zhou_ConceptLearner_Discovering_Visual_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Zhou_ConceptLearner_Discovering_Visual_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Charles Sturt University", "label": "Charles Sturt University", "shape": "dot", "size": 10.089285714285714, "title": "Charles Sturt University"}, {"color": "#6FA8DC", "id": "Junbin Gao", "label": "Junbin Gao", "shape": "dot", "size": 10.089285714285714, "title": "Junbin Gao"}, {"color": "#6FA8DC", "id": "computer vision recognition systems", "label": "computer vision recognition systems", "shape": "dot", "size": 10.089285714285714, "title": "computer vision recognition systems"}, {"color": "#6FA8DC", "id": "visual knowledge", "label": "visual knowledge", "shape": "dot", "size": 10.089285714285714, "title": "visual knowledge"}, {"color": "#6FA8DC", "id": "fully labeled data", "label": "fully labeled data", "shape": "dot", "size": 10.089285714285714, "title": "fully labeled data"}, {"color": "#6FA8DC", "id": "expensive", "label": "expensive", "shape": "dot", "size": 10.089285714285714, "title": "expensive"}, {"color": "#6FA8DC", "id": "scalable approach", "label": "scalable approach", "shape": "dot", "size": 10.089285714285714, "title": "scalable approach"}, {"color": "#6FA8DC", "id": "visual concept detectors", "label": "visual concept detectors", "shape": "dot", "size": 10.178571428571429, "title": "visual concept detectors"}, {"color": "#6FA8DC", "id": "automatically", "label": "automatically", "shape": "dot", "size": 10.089285714285714, "title": "automatically"}, {"color": "#6FA8DC", "id": "image region-level detection", "label": "image region-level detection", "shape": "dot", "size": 10.089285714285714, "title": "image region-level detection"}, {"color": "#6FA8DC", "id": "learned concepts", "label": "learned concepts", "shape": "dot", "size": 10.178571428571429, "title": "learned concepts"}, {"color": "#6FA8DC", "id": "scene recognition", "label": "scene recognition", "shape": "dot", "size": 10.178571428571429, "title": "scene recognition"}, {"color": "#6FA8DC", "id": "promising performance", "label": "promising performance", "shape": "dot", "size": 10.089285714285714, "title": "promising performance"}, {"color": "#6FA8DC", "id": "fully supervised methods", "label": "fully supervised methods", "shape": "dot", "size": 10.178571428571429, "title": "fully supervised methods"}, {"color": "#6FA8DC", "id": "weakly supervised methods", "label": "weakly supervised methods", "shape": "dot", "size": 10.267857142857142, "title": "weakly supervised methods"}, {"color": "#6FA8DC", "id": "domain-specific supervision", "label": "domain-specific supervision", "shape": "dot", "size": 10.089285714285714, "title": "domain-specific supervision"}, {"color": "#6FA8DC", "id": "automatic attribute discovery", "label": "automatic attribute discovery", "shape": "dot", "size": 10.089285714285714, "title": "automatic attribute discovery"}, {"color": "#6FA8DC", "id": "noisy web data", "label": "noisy web data", "shape": "dot", "size": 10.089285714285714, "title": "noisy web data"}, {"color": "#6FA8DC", "id": "pictures", "label": "pictures", "shape": "dot", "size": 10.089285714285714, "title": "pictures"}, {"color": "#6FA8DC", "id": "Im2text", "label": "Im2text", "shape": "dot", "size": 10.178571428571429, "title": "Im2text"}, {"color": "#6FA8DC", "id": "captioned photographs", "label": "captioned photographs", "shape": "dot", "size": 10.089285714285714, "title": "captioned photographs"}, {"color": "#6FA8DC", "id": "object detectors", "label": "object detectors", "shape": "dot", "size": 10.267857142857142, "title": "object detectors"}, {"color": "#6FA8DC", "id": "hierarchical images", "label": "hierarchical images", "shape": "dot", "size": 10.089285714285714, "title": "hierarchical images"}, {"color": "#6FA8DC", "id": "Deng et al.", "label": "Deng et al.", "shape": "dot", "size": 10.089285714285714, "title": "Deng et al."}, {"color": "#6FA8DC", "id": "Places database", "label": "Places database", "shape": "dot", "size": 10.178571428571429, "title": "Places database"}, {"color": "#6FA8DC", "id": "Zhou et al.", "label": "Zhou et al.", "shape": "dot", "size": 10.089285714285714, "title": "Zhou et al."}, {"color": "#6FA8DC", "id": "Piction", "label": "Piction", "shape": "dot", "size": 10.178571428571429, "title": "Piction"}, {"color": "#6FA8DC", "id": "human faces", "label": "human faces", "shape": "dot", "size": 10.089285714285714, "title": "human faces"}, {"color": "#6FA8DC", "id": "Srihari", "label": "Srihari", "shape": "dot", "size": 10.089285714285714, "title": "Srihari"}, {"color": "#6FA8DC", "id": "Divvala et al.", "label": "Divvala et al.", "shape": "dot", "size": 10.089285714285714, "title": "Divvala et al."}, {"color": "#6FA8DC", "id": "webly-supervised visual concept learning", "label": "webly-supervised visual concept learning", "shape": "dot", "size": 10.089285714285714, "title": "webly-supervised visual concept learning"}, {"color": "#6FA8DC", "id": "Tang et al.", "label": "Tang et al.", "shape": "dot", "size": 10.089285714285714, "title": "Tang et al."}, {"color": "#6FA8DC", "id": "machine learning research", "label": "machine learning research", "shape": "dot", "size": 10.089285714285714, "title": "machine learning research"}, {"color": "#6FA8DC", "id": "AAAI", "label": "AAAI", "shape": "dot", "size": 10.178571428571429, "title": "AAAI"}, {"color": "#6FA8DC", "id": "AAAI Press", "label": "AAAI Press", "shape": "dot", "size": 10.089285714285714, "title": "AAAI Press"}, {"color": "#6FA8DC", "id": "The MIT Press", "label": "The MIT Press", "shape": "dot", "size": 10.089285714285714, "title": "The MIT Press"}, {"color": "#6FA8DC", "id": "Divvala, S. K.", "label": "Divvala, S. K.", "shape": "dot", "size": 10.089285714285714, "title": "Divvala, S. K."}, {"color": "#6FA8DC", "id": "MIT", "label": "MIT", "shape": "dot", "size": 10.089285714285714, "title": "MIT"}, {"color": "#6FA8DC", "id": "eBay Research Labs", "label": "eBay Research Labs", "shape": "dot", "size": 10.178571428571429, "title": "eBay Research Labs"}, {"color": "#6FA8DC", "id": "Robinson Piramuthu", "label": "Robinson Piramuthu", "shape": "dot", "size": 10.089285714285714, "title": "Robinson Piramuthu"}, {"color": "#6FA8DC", "id": "Yumin Suh", "label": "Yumin Suh", "shape": "dot", "size": 10.178571428571429, "title": "Yumin Suh"}, {"color": "#6FA8DC", "id": "Subgraph Matching using Compactness Prior", "label": "Subgraph Matching using Compactness Prior", "shape": "dot", "size": 10.357142857142858, "title": "Subgraph Matching using Compactness Prior"}, {"color": "#6FA8DC", "id": "Kamil Adamczewski", "label": "Kamil Adamczewski", "shape": "dot", "size": 10.178571428571429, "title": "Kamil Adamczewski"}, {"color": "#6FA8DC", "id": "Suh_Subgraph_Matching_Using_2015_CVPR_paper.pdf", "label": "Suh_Subgraph_Matching_Using_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Suh_Subgraph_Matching_Using_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Feature correspondence", "label": "Feature correspondence", "shape": "dot", "size": 10.267857142857142, "title": "Feature correspondence"}, {"color": "#6FA8DC", "id": "computer vision applications", "label": "computer vision applications", "shape": "dot", "size": 10.089285714285714, "title": "computer vision applications"}, {"color": "#6FA8DC", "id": "Graph matching", "label": "Graph matching", "shape": "dot", "size": 10.089285714285714, "title": "Graph matching"}, {"color": "#6FA8DC", "id": "Graph matching algorithms", "label": "Graph matching algorithms", "shape": "dot", "size": 10.089285714285714, "title": "Graph matching algorithms"}, {"color": "#6FA8DC", "id": "precision", "label": "precision", "shape": "dot", "size": 10.089285714285714, "title": "precision"}, {"color": "#6FA8DC", "id": "Solutions", "label": "Solutions", "shape": "dot", "size": 10.089285714285714, "title": "Solutions"}, {"color": "#6FA8DC", "id": "subgraph matching formulation", "label": "subgraph matching formulation", "shape": "dot", "size": 10.089285714285714, "title": "subgraph matching formulation"}, {"color": "#6FA8DC", "id": "Subgraph matching formulation", "label": "Subgraph matching formulation", "shape": "dot", "size": 10.089285714285714, "title": "Subgraph matching formulation"}, {"color": "#6FA8DC", "id": "compactness prior", "label": "compactness prior", "shape": "dot", "size": 10.267857142857142, "title": "compactness prior"}, {"color": "#6FA8DC", "id": "Meta-algorithm", "label": "Meta-algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Meta-algorithm"}, {"color": "#6FA8DC", "id": "Markov chain Monte Carlo", "label": "Markov chain Monte Carlo", "shape": "dot", "size": 10.089285714285714, "title": "Markov chain Monte Carlo"}, {"color": "#6FA8DC", "id": "Formulation and algorithm", "label": "Formulation and algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Formulation and algorithm"}, {"color": "#6FA8DC", "id": "baseline performance", "label": "baseline performance", "shape": "dot", "size": 10.089285714285714, "title": "baseline performance"}, {"color": "#6FA8DC", "id": "improvement", "label": "improvement", "shape": "dot", "size": 10.089285714285714, "title": "improvement"}, {"color": "#6FA8DC", "id": "Cho, M.", "label": "Cho, M.", "shape": "dot", "size": 10.357142857142858, "title": "Cho, M."}, {"color": "#6FA8DC", "id": "Reweighted random walks", "label": "Reweighted random walks", "shape": "dot", "size": 10.178571428571429, "title": "Reweighted random walks"}, {"color": "#6FA8DC", "id": "Proceedings of the IEEE International Conference on Computer Vision", "label": "Proceedings of the IEEE International Conference on Computer Vision", "shape": "dot", "size": 10.089285714285714, "title": "Proceedings of the IEEE International Conference on Computer Vision"}, {"color": "#6FA8DC", "id": "2009 IEEE 12th International Conference on Computer Vision", "label": "2009 IEEE 12th International Conference on Computer Vision", "shape": "dot", "size": 10.089285714285714, "title": "2009 IEEE 12th International Conference on Computer Vision"}, {"color": "#6FA8DC", "id": "Computer Vision\u2013ECCV 2010", "label": "Computer Vision\u2013ECCV 2010", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision\u2013ECCV 2010"}, {"color": "#6FA8DC", "id": "Progressive graph matching", "label": "Progressive graph matching", "shape": "dot", "size": 10.089285714285714, "title": "Progressive graph matching"}, {"color": "#6FA8DC", "id": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on", "label": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on"}, {"color": "#6FA8DC", "id": "Alahari, K.", "label": "Alahari, K.", "shape": "dot", "size": 10.089285714285714, "title": "Alahari, K."}, {"color": "#6FA8DC", "id": "Ponce, J.", "label": "Ponce, J.", "shape": "dot", "size": 10.089285714285714, "title": "Ponce, J."}, {"color": "#6FA8DC", "id": "Lee, Kyoung Mu", "label": "Lee, Kyoung Mu", "shape": "dot", "size": 10.178571428571429, "title": "Lee, Kyoung Mu"}, {"color": "#6FA8DC", "id": "Seoul National University", "label": "Seoul National University", "shape": "dot", "size": 10.446428571428571, "title": "Seoul National University"}, {"color": "#6FA8DC", "id": "Adamczewski, Kamil", "label": "Adamczewski, Kamil", "shape": "dot", "size": 10.089285714285714, "title": "Adamczewski, Kamil"}, {"color": "#6FA8DC", "id": "Suh, Yumin", "label": "Suh, Yumin", "shape": "dot", "size": 10.089285714285714, "title": "Suh, Yumin"}, {"color": "#6FA8DC", "id": "Duchenne, O.", "label": "Duchenne, O.", "shape": "dot", "size": 10.178571428571429, "title": "Duchenne, O."}, {"color": "#6FA8DC", "id": "tensor-based algorithm", "label": "tensor-based algorithm", "shape": "dot", "size": 10.089285714285714, "title": "tensor-based algorithm"}, {"color": "#6FA8DC", "id": "Gilks, W. R.", "label": "Gilks, W. R.", "shape": "dot", "size": 10.089285714285714, "title": "Gilks, W. R."}, {"color": "#6FA8DC", "id": "Markov chain monte carlo", "label": "Markov chain monte carlo", "shape": "dot", "size": 10.089285714285714, "title": "Markov chain monte carlo"}, {"color": "#6FA8DC", "id": "max-pooling strategy", "label": "max-pooling strategy", "shape": "dot", "size": 10.089285714285714, "title": "max-pooling strategy"}, {"color": "#6FA8DC", "id": "Cour, T.", "label": "Cour, T.", "shape": "dot", "size": 10.089285714285714, "title": "Cour, T."}, {"color": "#6FA8DC", "id": "balanced graph matching", "label": "balanced graph matching", "shape": "dot", "size": 10.089285714285714, "title": "balanced graph matching"}, {"color": "#6FA8DC", "id": "progressive graph matching", "label": "progressive graph matching", "shape": "dot", "size": 10.178571428571429, "title": "progressive graph matching"}, {"color": "#6FA8DC", "id": "Guancong Zhang", "label": "Guancong Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Guancong Zhang"}, {"color": "#6FA8DC", "id": "Good Features to Track for Visual SLAM", "label": "Good Features to Track for Visual SLAM", "shape": "dot", "size": 10.357142857142858, "title": "Good Features to Track for Visual SLAM"}, {"color": "#6FA8DC", "id": "Patricio A. Vela", "label": "Patricio A. Vela", "shape": "dot", "size": 10.267857142857142, "title": "Patricio A. Vela"}, {"color": "#6FA8DC", "id": "Zhang_Good_Features_to_2015_CVPR_paper.pdf", "label": "Zhang_Good_Features_to_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.267857142857142, "title": "Zhang_Good_Features_to_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "measured features", "label": "measured features", "shape": "dot", "size": 10.089285714285714, "title": "measured features"}, {"color": "#6FA8DC", "id": "accurate localization", "label": "accurate localization", "shape": "dot", "size": 10.089285714285714, "title": "accurate localization"}, {"color": "#6FA8DC", "id": "method for selecting features", "label": "method for selecting features", "shape": "dot", "size": 10.446428571428571, "title": "method for selecting features"}, {"color": "#6FA8DC", "id": "observability of SLAM", "label": "observability of SLAM", "shape": "dot", "size": 10.089285714285714, "title": "observability of SLAM"}, {"color": "#6FA8DC", "id": "existing SLAM systems", "label": "existing SLAM systems", "shape": "dot", "size": 10.089285714285714, "title": "existing SLAM systems"}, {"color": "#6FA8DC", "id": "estimation utility", "label": "estimation utility", "shape": "dot", "size": 10.089285714285714, "title": "estimation utility"}, {"color": "#6FA8DC", "id": "observability indices", "label": "observability indices", "shape": "dot", "size": 10.357142857142858, "title": "observability indices"}, {"color": "#6FA8DC", "id": "incremental singular value decomposition (SVD)", "label": "incremental singular value decomposition (SVD)", "shape": "dot", "size": 10.089285714285714, "title": "incremental singular value decomposition (SVD)"}, {"color": "#6FA8DC", "id": "greedy selection", "label": "greedy selection", "shape": "dot", "size": 10.267857142857142, "title": "greedy selection"}, {"color": "#6FA8DC", "id": "SLAM", "label": "SLAM", "shape": "dot", "size": 10.089285714285714, "title": "SLAM"}, {"color": "#6FA8DC", "id": "SfM", "label": "SfM", "shape": "dot", "size": 10.089285714285714, "title": "SfM"}, {"color": "#6FA8DC", "id": "localization accuracy", "label": "localization accuracy", "shape": "dot", "size": 10.178571428571429, "title": "localization accuracy"}, {"color": "#6FA8DC", "id": "incremental singular value decomposition", "label": "incremental singular value decomposition", "shape": "dot", "size": 10.178571428571429, "title": "incremental singular value decomposition"}, {"color": "#6FA8DC", "id": "submodular", "label": "submodular", "shape": "dot", "size": 10.089285714285714, "title": "submodular"}, {"color": "#6FA8DC", "id": "synthetic experiments", "label": "synthetic experiments", "shape": "dot", "size": 10.089285714285714, "title": "synthetic experiments"}, {"color": "#6FA8DC", "id": "improved localization accuracy", "label": "improved localization accuracy", "shape": "dot", "size": 10.089285714285714, "title": "improved localization accuracy"}, {"color": "#6FA8DC", "id": "SLAM experiments", "label": "SLAM experiments", "shape": "dot", "size": 10.089285714285714, "title": "SLAM experiments"}, {"color": "#6FA8DC", "id": "improved data association", "label": "improved data association", "shape": "dot", "size": 10.089285714285714, "title": "improved data association"}, {"color": "#6FA8DC", "id": "temporal observability indices", "label": "temporal observability indices", "shape": "dot", "size": 10.089285714285714, "title": "temporal observability indices"}, {"color": "#6FA8DC", "id": "near-optimal", "label": "near-optimal", "shape": "dot", "size": 10.089285714285714, "title": "near-optimal"}, {"color": "#6FA8DC", "id": "Visual SLAM", "label": "Visual SLAM", "shape": "dot", "size": 10.089285714285714, "title": "Visual SLAM"}, {"color": "#6FA8DC", "id": "Data Association", "label": "Data Association", "shape": "dot", "size": 10.178571428571429, "title": "Data Association"}, {"color": "#6FA8DC", "id": "Incremental SVD", "label": "Incremental SVD", "shape": "dot", "size": 10.089285714285714, "title": "Incremental SVD"}, {"color": "#6FA8DC", "id": "Observability Analysis", "label": "Observability Analysis", "shape": "dot", "size": 10.089285714285714, "title": "Observability Analysis"}, {"color": "#6FA8DC", "id": "map_building", "label": "map_building", "shape": "dot", "size": 10.089285714285714, "title": "map_building"}, {"color": "#6FA8DC", "id": "MonoSLAM", "label": "MonoSLAM", "shape": "dot", "size": 10.178571428571429, "title": "MonoSLAM"}, {"color": "#6FA8DC", "id": "real-time SLAM", "label": "real-time SLAM", "shape": "dot", "size": 10.089285714285714, "title": "real-time SLAM"}, {"color": "#6FA8DC", "id": "LSD-SLAM", "label": "LSD-SLAM", "shape": "dot", "size": 10.267857142857142, "title": "LSD-SLAM"}, {"color": "#6FA8DC", "id": "direct monocular SLAM", "label": "direct monocular SLAM", "shape": "dot", "size": 10.089285714285714, "title": "direct monocular SLAM"}, {"color": "#6FA8DC", "id": "Covariance recovery", "label": "Covariance recovery", "shape": "dot", "size": 10.089285714285714, "title": "Covariance recovery"}, {"color": "#6FA8DC", "id": "data association", "label": "data association", "shape": "dot", "size": 10.089285714285714, "title": "data association"}, {"color": "#6FA8DC", "id": "Feature Selection", "label": "Feature Selection", "shape": "dot", "size": 10.089285714285714, "title": "Feature Selection"}, {"color": "#6FA8DC", "id": "Andrade-Cetto and Sanfeliu", "label": "Andrade-Cetto and Sanfeliu", "shape": "dot", "size": 10.089285714285714, "title": "Andrade-Cetto and Sanfeliu"}, {"color": "#6FA8DC", "id": "partial observability", "label": "partial observability", "shape": "dot", "size": 10.089285714285714, "title": "partial observability"}, {"color": "#6FA8DC", "id": "Kaess and Dellaert", "label": "Kaess and Dellaert", "shape": "dot", "size": 10.089285714285714, "title": "Kaess and Dellaert"}, {"color": "#6FA8DC", "id": "covariance recovery", "label": "covariance recovery", "shape": "dot", "size": 10.089285714285714, "title": "covariance recovery"}, {"color": "#6FA8DC", "id": "Davison et al.", "label": "Davison et al.", "shape": "dot", "size": 10.089285714285714, "title": "Davison et al."}, {"color": "#6FA8DC", "id": "Engel et al.", "label": "Engel et al.", "shape": "dot", "size": 10.089285714285714, "title": "Engel et al."}, {"color": "#6FA8DC", "id": "Slam_Algorithm", "label": "Slam_Algorithm", "shape": "dot", "size": 10.178571428571429, "title": "Slam_Algorithm"}, {"color": "#6FA8DC", "id": "iSAM2", "label": "iSAM2", "shape": "dot", "size": 10.267857142857142, "title": "iSAM2"}, {"color": "#6FA8DC", "id": "Bayes Tree", "label": "Bayes Tree", "shape": "dot", "size": 10.089285714285714, "title": "Bayes Tree"}, {"color": "#6FA8DC", "id": "Incremental Smoothing", "label": "Incremental Smoothing", "shape": "dot", "size": 10.089285714285714, "title": "Incremental Smoothing"}, {"color": "#6FA8DC", "id": "Active search", "label": "Active search", "shape": "dot", "size": 10.089285714285714, "title": "Active search"}, {"color": "#6FA8DC", "id": "Live dense reconstruction", "label": "Live dense reconstruction", "shape": "dot", "size": 10.089285714285714, "title": "Live dense reconstruction"}, {"color": "#6FA8DC", "id": "Single moving camera", "label": "Single moving camera", "shape": "dot", "size": 10.089285714285714, "title": "Single moving camera"}, {"color": "#6FA8DC", "id": "Machine Intelligence", "label": "Machine Intelligence", "shape": "dot", "size": 10.089285714285714, "title": "Machine Intelligence"}, {"color": "#6FA8DC", "id": "Slam", "label": "Slam", "shape": "dot", "size": 10.089285714285714, "title": "Slam"}, {"color": "#6FA8DC", "id": "Zheng Ma", "label": "Zheng Ma", "shape": "dot", "size": 10.267857142857142, "title": "Zheng Ma"}, {"color": "#6FA8DC", "id": "School of ECR", "label": "School of ECR", "shape": "dot", "size": 10.267857142857142, "title": "School of ECR"}, {"color": "#6FA8DC", "id": "Lei Yu", "label": "Lei Yu", "shape": "dot", "size": 10.178571428571429, "title": "Lei Yu"}, {"color": "#6FA8DC", "id": "Antoni B. Chan", "label": "Antoni B. Chan", "shape": "dot", "size": 10.267857142857142, "title": "Antoni B. Chan"}, {"color": "#6FA8DC", "id": "Georgia Tech", "label": "Georgia Tech", "shape": "dot", "size": 10.089285714285714, "title": "Georgia Tech"}, {"color": "#6FA8DC", "id": "School of ECE", "label": "School of ECE", "shape": "dot", "size": 10.089285714285714, "title": "School of ECE"}, {"color": "#6FA8DC", "id": "zhanggc@gatech.edu", "label": "zhanggc@gatech.edu", "shape": "dot", "size": 10.089285714285714, "title": "zhanggc@gatech.edu"}, {"color": "#6FA8DC", "id": "pvela@gatech.edu", "label": "pvela@gatech.edu", "shape": "dot", "size": 10.089285714285714, "title": "pvela@gatech.edu"}, {"color": "#6FA8DC", "id": "Ma_Small_Instance_Detection_2015_CVPR_paper", "label": "Ma_Small_Instance_Detection_2015_CVPR_paper", "shape": "dot", "size": 10.178571428571429, "title": "Ma_Small_Instance_Detection_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Small Instance Detection", "label": "Small Instance Detection", "shape": "dot", "size": 10.267857142857142, "title": "Small Instance Detection"}, {"color": "#6FA8DC", "id": "Integer Programming", "label": "Integer Programming", "shape": "dot", "size": 10.178571428571429, "title": "Integer Programming"}, {"color": "#6FA8DC", "id": "Object Density Maps", "label": "Object Density Maps", "shape": "dot", "size": 10.178571428571429, "title": "Object Density Maps"}, {"color": "#6FA8DC", "id": "partially-occluded small instances", "label": "partially-occluded small instances", "shape": "dot", "size": 10.178571428571429, "title": "partially-occluded small instances"}, {"color": "#6FA8DC", "id": "pedestrians", "label": "pedestrians", "shape": "dot", "size": 10.089285714285714, "title": "pedestrians"}, {"color": "#6FA8DC", "id": "cells", "label": "cells", "shape": "dot", "size": 10.089285714285714, "title": "cells"}, {"color": "#6FA8DC", "id": "partially-occluding small instances", "label": "partially-occluding small instances", "shape": "dot", "size": 10.089285714285714, "title": "partially-occluding small instances"}, {"color": "#6FA8DC", "id": "2D integer programming", "label": "2D integer programming", "shape": "dot", "size": 10.267857142857142, "title": "2D integer programming"}, {"color": "#6FA8DC", "id": "recover object instance locations", "label": "recover object instance locations", "shape": "dot", "size": 10.089285714285714, "title": "recover object instance locations"}, {"color": "#6FA8DC", "id": "ROI counts", "label": "ROI counts", "shape": "dot", "size": 10.089285714285714, "title": "ROI counts"}, {"color": "#6FA8DC", "id": "density map", "label": "density map", "shape": "dot", "size": 10.089285714285714, "title": "density map"}, {"color": "#6FA8DC", "id": "local density map", "label": "local density map", "shape": "dot", "size": 10.089285714285714, "title": "local density map"}, {"color": "#6FA8DC", "id": "fluorescence microscopy cell images", "label": "fluorescence microscopy cell images", "shape": "dot", "size": 10.089285714285714, "title": "fluorescence microscopy cell images"}, {"color": "#6FA8DC", "id": "UCSD pedestrians", "label": "UCSD pedestrians", "shape": "dot", "size": 10.089285714285714, "title": "UCSD pedestrians"}, {"color": "#6FA8DC", "id": "small animals", "label": "small animals", "shape": "dot", "size": 10.089285714285714, "title": "small animals"}, {"color": "#6FA8DC", "id": "insects", "label": "insects", "shape": "dot", "size": 10.089285714285714, "title": "insects"}, {"color": "#6FA8DC", "id": "object instances", "label": "object instances", "shape": "dot", "size": 10.089285714285714, "title": "object instances"}, {"color": "#6FA8DC", "id": "HOG features", "label": "HOG features", "shape": "dot", "size": 10.446428571428571, "title": "HOG features"}, {"color": "#6FA8DC", "id": "Bayesian regression", "label": "Bayesian regression", "shape": "dot", "size": 10.178571428571429, "title": "Bayesian regression"}, {"color": "#6FA8DC", "id": "Crowd counting", "label": "Crowd counting", "shape": "dot", "size": 10.178571428571429, "title": "Crowd counting"}, {"color": "#6FA8DC", "id": "multiple local features", "label": "multiple local features", "shape": "dot", "size": 10.178571428571429, "title": "multiple local features"}, {"color": "#6FA8DC", "id": "IEEE Conf. Computer Vision and Pattern Recognition", "label": "IEEE Conf. Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Conf. Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "IEEE Trans. on Image Processing", "label": "IEEE Trans. on Image Processing", "shape": "dot", "size": 10.089285714285714, "title": "IEEE Trans. on Image Processing"}, {"color": "#6FA8DC", "id": "Learning to count objects in images", "label": "Learning to count objects in images", "shape": "dot", "size": 10.089285714285714, "title": "Learning to count objects in images"}, {"color": "#6FA8DC", "id": "Digital Image Computing: Techniques and Applications", "label": "Digital Image Computing: Techniques and Applications", "shape": "dot", "size": 10.089285714285714, "title": "Digital Image Computing: Techniques and Applications"}, {"color": "#6FA8DC", "id": "Crowd counting using multiple local features", "label": "Crowd counting using multiple local features", "shape": "dot", "size": 10.089285714285714, "title": "Crowd counting using multiple local features"}, {"color": "#6FA8DC", "id": "Human detection", "label": "Human detection", "shape": "dot", "size": 10.089285714285714, "title": "Human detection"}, {"color": "#6FA8DC", "id": "Sridharan (2009)", "label": "Sridharan (2009)", "shape": "dot", "size": 10.178571428571429, "title": "Sridharan (2009)"}, {"color": "#6FA8DC", "id": "Lowe (2004)", "label": "Lowe (2004)", "shape": "dot", "size": 10.089285714285714, "title": "Lowe (2004)"}, {"color": "#6FA8DC", "id": "feature detection", "label": "feature detection", "shape": "dot", "size": 10.089285714285714, "title": "feature detection"}, {"color": "#6FA8DC", "id": "feature matching", "label": "feature matching", "shape": "dot", "size": 10.089285714285714, "title": "feature matching"}, {"color": "#6FA8DC", "id": "Chan (2008)", "label": "Chan (2008)", "shape": "dot", "size": 10.178571428571429, "title": "Chan (2008)"}, {"color": "#6FA8DC", "id": "privacy concerns", "label": "privacy concerns", "shape": "dot", "size": 10.089285714285714, "title": "privacy concerns"}, {"color": "#6FA8DC", "id": "crowd monitoring", "label": "crowd monitoring", "shape": "dot", "size": 10.089285714285714, "title": "crowd monitoring"}, {"color": "#6FA8DC", "id": "Zhao (2003)", "label": "Zhao (2003)", "shape": "dot", "size": 10.089285714285714, "title": "Zhao (2003)"}, {"color": "#6FA8DC", "id": "Bayesian segmentation", "label": "Bayesian segmentation", "shape": "dot", "size": 10.267857142857142, "title": "Bayesian segmentation"}, {"color": "#6FA8DC", "id": "crowded scenes", "label": "crowded scenes", "shape": "dot", "size": 10.089285714285714, "title": "crowded scenes"}, {"color": "#6FA8DC", "id": "R. ia", "label": "R. ia", "shape": "dot", "size": 10.089285714285714, "title": "R. ia"}, {"color": "#6FA8DC", "id": "Lemtipsky, V.", "label": "Lemtipsky, V.", "shape": "dot", "size": 10.089285714285714, "title": "Lemtipsky, V."}, {"color": "#6FA8DC", "id": "PASCAL VOC challenge", "label": "PASCAL VOC challenge", "shape": "dot", "size": 10.178571428571429, "title": "PASCAL VOC challenge"}, {"color": "#6FA8DC", "id": "PASCAL VOC challenge description", "label": "PASCAL VOC challenge description", "shape": "dot", "size": 10.089285714285714, "title": "PASCAL VOC challenge description"}, {"color": "#6FA8DC", "id": "City University of Hong Kong", "label": "City University of Hong Kong", "shape": "dot", "size": 10.357142857142858, "title": "City University of Hong Kong"}, {"color": "#6FA8DC", "id": "Mohammad Rastegari", "label": "Mohammad Rastegari", "shape": "dot", "size": 10.267857142857142, "title": "Mohammad Rastegari"}, {"color": "#6FA8DC", "id": "Computationally Bound Retrieval", "label": "Computationally Bound Retrieval", "shape": "dot", "size": 10.089285714285714, "title": "Computationally Bound Retrieval"}, {"color": "#6FA8DC", "id": "Computationally Bounded Retrieval", "label": "Computationally Bounded Retrieval", "shape": "dot", "size": 10.625, "title": "Computationally Bounded Retrieval"}, {"color": "#6FA8DC", "id": "Cem Keskin", "label": "Cem Keskin", "shape": "dot", "size": 10.267857142857142, "title": "Cem Keskin"}, {"color": "#6FA8DC", "id": "Shahram Izadi", "label": "Shahram Izadi", "shape": "dot", "size": 10.267857142857142, "title": "Shahram Izadi"}, {"color": "#6FA8DC", "id": "Rastegari_Computationally_Bounded_Retrieval_2015_CVPR_paper.pdf", "label": "Rastegari_Computationally_Bounded_Retrieval_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Rastegari_Computationally_Bounded_Retrieval_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Rastegari_Computationality_Bounded_Retrieval_2015_CVPR_paper", "label": "Rastegari_Computationality_Bounded_Retrieval_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Rastegari_Computationality_Bounded_Retrieval_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "large image databases", "label": "large image databases", "shape": "dot", "size": 10.089285714285714, "title": "large image databases"}, {"color": "#6FA8DC", "id": "efficient retrieval challenging", "label": "efficient retrieval challenging", "shape": "dot", "size": 10.089285714285714, "title": "efficient retrieval challenging"}, {"color": "#6FA8DC", "id": "high dimensional data", "label": "high dimensional data", "shape": "dot", "size": 10.089285714285714, "title": "high dimensional data"}, {"color": "#6FA8DC", "id": "retrieval challenge", "label": "retrieval challenge", "shape": "dot", "size": 10.089285714285714, "title": "retrieval challenge"}, {"color": "#6FA8DC", "id": "hashing methods", "label": "hashing methods", "shape": "dot", "size": 10.089285714285714, "title": "hashing methods"}, {"color": "#6FA8DC", "id": "accuracy for speed", "label": "accuracy for speed", "shape": "dot", "size": 10.089285714285714, "title": "accuracy for speed"}, {"color": "#6FA8DC", "id": "speed of image retrieval", "label": "speed of image retrieval", "shape": "dot", "size": 10.089285714285714, "title": "speed of image retrieval"}, {"color": "#6FA8DC", "id": "computationally bounded sparse projections", "label": "computationally bounded sparse projections", "shape": "dot", "size": 10.089285714285714, "title": "computationally bounded sparse projections"}, {"color": "#6FA8DC", "id": "orthogonality constraint", "label": "orthogonality constraint", "shape": "dot", "size": 10.178571428571429, "title": "orthogonality constraint"}, {"color": "#6FA8DC", "id": "bit correlation", "label": "bit correlation", "shape": "dot", "size": 10.089285714285714, "title": "bit correlation"}, {"color": "#6FA8DC", "id": "iterative scheme", "label": "iterative scheme", "shape": "dot", "size": 10.089285714285714, "title": "iterative scheme"}, {"color": "#6FA8DC", "id": "speed-up of up to a factor of 100", "label": "speed-up of up to a factor of 100", "shape": "dot", "size": 10.089285714285714, "title": "speed-up of up to a factor of 100"}, {"color": "#6FA8DC", "id": "ImageNET", "label": "ImageNET", "shape": "dot", "size": 10.089285714285714, "title": "ImageNET"}, {"color": "#6FA8DC", "id": "GIST1M", "label": "GIST1M", "shape": "dot", "size": 10.089285714285714, "title": "GIST1M"}, {"color": "#6FA8DC", "id": "SUN-attribute", "label": "SUN-attribute", "shape": "dot", "size": 10.089285714285714, "title": "SUN-attribute"}, {"color": "#6FA8DC", "id": "fast and efficient projections", "label": "fast and efficient projections", "shape": "dot", "size": 10.089285714285714, "title": "fast and efficient projections"}, {"color": "#6FA8DC", "id": "factor of 100", "label": "factor of 100", "shape": "dot", "size": 10.178571428571429, "title": "factor of 100"}, {"color": "#6FA8DC", "id": "Near-optimal Hasing Algorithms", "label": "Near-optimal Hasing Algorithms", "shape": "dot", "size": 10.178571428571429, "title": "Near-optimal Hasing Algorithms"}, {"color": "#6FA8DC", "id": "Approximate Nearest Neighbor", "label": "Approximate Nearest Neighbor", "shape": "dot", "size": 10.089285714285714, "title": "Approximate Nearest Neighbor"}, {"color": "#6FA8DC", "id": "High Dimensions", "label": "High Dimensions", "shape": "dot", "size": 10.089285714285714, "title": "High Dimensions"}, {"color": "#6FA8DC", "id": "Datar et al. (2004)", "label": "Datar et al. (2004)", "shape": "dot", "size": 10.089285714285714, "title": "Datar et al. (2004)"}, {"color": "#6FA8DC", "id": "Locality-Sensitive Hashing Scheme", "label": "Locality-Sensitive Hashing Scheme", "shape": "dot", "size": 10.178571428571429, "title": "Locality-Sensitive Hashing Scheme"}, {"color": "#6FA8DC", "id": "P-stable Distributions", "label": "P-stable Distributions", "shape": "dot", "size": 10.089285714285714, "title": "P-stable Distributions"}, {"color": "#6FA8DC", "id": "Methods", "label": "Methods", "shape": "dot", "size": 10.089285714285714, "title": "Methods"}, {"color": "#6FA8DC", "id": "Speed-up", "label": "Speed-up", "shape": "dot", "size": 10.178571428571429, "title": "Speed-up"}, {"color": "#6FA8DC", "id": "Computer Vision and Pattern Recognition, 2009", "label": "Computer Vision and Pattern Recognition, 2009", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision and Pattern Recognition, 2009"}, {"color": "#6FA8DC", "id": "Gong et al. (2013)", "label": "Gong et al. (2013)", "shape": "dot", "size": 10.178571428571429, "title": "Gong et al. (2013)"}, {"color": "#6FA8DC", "id": "Computer Vision and Pattern Recognition (CVPR), 2013", "label": "Computer Vision and Pattern Recognition (CVPR), 2013", "shape": "dot", "size": 10.089285714285714, "title": "Computer Vision and Pattern Recognition (CVPR), 2013"}, {"color": "#6FA8DC", "id": "Gong \u0026 Lazebnik (2011)", "label": "Gong \u0026 Lazebnik (2011)", "shape": "dot", "size": 10.178571428571429, "title": "Gong \u0026 Lazebnik (2011)"}, {"color": "#6FA8DC", "id": "2011 IEEE Conference on Computer Vision and Pattern Recognition", "label": "2011 IEEE Conference on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10.089285714285714, "title": "2011 IEEE Conference on Computer Vision and Pattern Recognition"}, {"color": "#6FA8DC", "id": "J\u00e9goeu et al. (2009)", "label": "J\u00e9goeu et al. (2009)", "shape": "dot", "size": 10.089285714285714, "title": "J\u00e9goeu et al. (2009)"}, {"color": "#6FA8DC", "id": "Searching with quantization", "label": "Searching with quantization", "shape": "dot", "size": 10.178571428571429, "title": "Searching with quantization"}, {"color": "#6FA8DC", "id": "short codes", "label": "short codes", "shape": "dot", "size": 10.089285714285714, "title": "short codes"}, {"color": "#6FA8DC", "id": "iterative quantization", "label": "iterative quantization", "shape": "dot", "size": 10.089285714285714, "title": "iterative quantization"}, {"color": "#6FA8DC", "id": "J\u00e9gou et al (2009)", "label": "J\u00e9gou et al (2009)", "shape": "dot", "size": 10.089285714285714, "title": "J\u00e9gou et al (2009)"}, {"color": "#6FA8DC", "id": "Krizhevskya et al (2012)", "label": "Krizhevskya et al (2012)", "shape": "dot", "size": 10.178571428571429, "title": "Krizhevskya et al (2012)"}, {"color": "#6FA8DC", "id": "Majia et al (2013)", "label": "Majia et al (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Majia et al (2013)"}, {"color": "#6FA8DC", "id": "efficient classification", "label": "efficient classification", "shape": "dot", "size": 10.089285714285714, "title": "efficient classification"}, {"color": "#6FA8DC", "id": "Norouzia et al (2011)", "label": "Norouzia et al (2011)", "shape": "dot", "size": 10.089285714285714, "title": "Norouzia et al (2011)"}, {"color": "#6FA8DC", "id": "New Insights into Laplacian Similarity Search", "label": "New Insights into Laplacian Similarity Search", "shape": "dot", "size": 10.357142857142858, "title": "New Insights into Laplacian Similarity Search"}, {"color": "#6FA8DC", "id": "New Insights into Laplacian Similarity Research", "label": "New Insights into Laplacian Similarity Research", "shape": "dot", "size": 10.089285714285714, "title": "New Insights into Laplacian Similarity Research"}, {"color": "#6FA8DC", "id": "Wu_New_Insights_Into_2015_CVPR_paper.pdf", "label": "Wu_New_Insights_Into_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Wu_New_Insights_Into_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Graph-based computer vision applications", "label": "Graph-based computer vision applications", "shape": "dot", "size": 10.089285714285714, "title": "Graph-based computer vision applications"}, {"color": "#6FA8DC", "id": "similarity metrics", "label": "similarity metrics", "shape": "dot", "size": 10.178571428571429, "title": "similarity metrics"}, {"color": "#6FA8DC", "id": "pairwise similarity", "label": "pairwise similarity", "shape": "dot", "size": 10.178571428571429, "title": "pairwise similarity"}, {"color": "#6FA8DC", "id": "vertices", "label": "vertices", "shape": "dot", "size": 10.089285714285714, "title": "vertices"}, {"color": "#6FA8DC", "id": "(L + \u03b1\u039b)\u22121", "label": "(L + \u03b1\u039b)\u22121", "shape": "dot", "size": 10.267857142857142, "title": "(L + \u03b1\u039b)\u22121"}, {"color": "#6FA8DC", "id": "graph Laplacian", "label": "graph Laplacian", "shape": "dot", "size": 10.089285714285714, "title": "graph Laplacian"}, {"color": "#6FA8DC", "id": "positive diagonal matrix", "label": "positive diagonal matrix", "shape": "dot", "size": 10.178571428571429, "title": "positive diagonal matrix"}, {"color": "#6FA8DC", "id": "regularizer", "label": "regularizer", "shape": "dot", "size": 10.267857142857142, "title": "regularizer"}, {"color": "#6FA8DC", "id": "graph topology", "label": "graph topology", "shape": "dot", "size": 10.089285714285714, "title": "graph topology"}, {"color": "#6FA8DC", "id": "cluster density", "label": "cluster density", "shape": "dot", "size": 10.089285714285714, "title": "cluster density"}, {"color": "#6FA8DC", "id": "choices", "label": "choices", "shape": "dot", "size": 10.089285714285714, "title": "choices"}, {"color": "#6FA8DC", "id": "complementary behaviors", "label": "complementary behaviors", "shape": "dot", "size": 10.089285714285714, "title": "complementary behaviors"}, {"color": "#6FA8DC", "id": "analysis of impact", "label": "analysis of impact", "shape": "dot", "size": 10.089285714285714, "title": "analysis of impact"}, {"color": "#6FA8DC", "id": "\u039b", "label": "\u039b", "shape": "dot", "size": 10.089285714285714, "title": "\u039b"}, {"color": "#6FA8DC", "id": "Paper (1999)", "label": "Paper (1999)", "shape": "dot", "size": 10.178571428571429, "title": "Paper (1999)"}, {"color": "#6FA8DC", "id": "Pagerank Citation Ranking", "label": "Pagerank Citation Ranking", "shape": "dot", "size": 10.178571428571429, "title": "Pagerank Citation Ranking"}, {"color": "#6FA8DC", "id": "bring order to web", "label": "bring order to web", "shape": "dot", "size": 10.089285714285714, "title": "bring order to web"}, {"color": "#6FA8DC", "id": "Chung (1997)", "label": "Chung (1997)", "shape": "dot", "size": 10.089285714285714, "title": "Chung (1997)"}, {"color": "#6FA8DC", "id": "Spectral Graph Theory", "label": "Spectral Graph Theory", "shape": "dot", "size": 10.178571428571429, "title": "Spectral Graph Theory"}, {"color": "#6FA8DC", "id": "Graph Topology", "label": "Graph Topology", "shape": "dot", "size": 10.089285714285714, "title": "Graph Topology"}, {"color": "#6FA8DC", "id": "Andersen et al. (2006)", "label": "Andersen et al. (2006)", "shape": "dot", "size": 10.178571428571429, "title": "Andersen et al. (2006)"}, {"color": "#6FA8DC", "id": "Pagerank Vectors", "label": "Pagerank Vectors", "shape": "dot", "size": 10.089285714285714, "title": "Pagerank Vectors"}, {"color": "#6FA8DC", "id": "Local Graph Partitioning", "label": "Local Graph Partitioning", "shape": "dot", "size": 10.089285714285714, "title": "Local Graph Partitioning"}, {"color": "#6FA8DC", "id": "Belkin \u0026 Niyogi (2001)", "label": "Belkin \u0026 Niyogi (2001)", "shape": "dot", "size": 10.089285714285714, "title": "Belkin \u0026 Niyogi (2001)"}, {"color": "#6FA8DC", "id": "Shi \u0026 Malik (2000)", "label": "Shi \u0026 Malik (2000)", "shape": "dot", "size": 10.089285714285714, "title": "Shi \u0026 Malik (2000)"}, {"color": "#6FA8DC", "id": "Laplacianfaces", "label": "Laplacianfaces", "shape": "dot", "size": 10.089285714285714, "title": "Laplacianfaces"}, {"color": "#6FA8DC", "id": "Random walks", "label": "Random walks", "shape": "dot", "size": 10.089285714285714, "title": "Random walks"}, {"color": "#6FA8DC", "id": "Wu, X.-M.", "label": "Wu, X.-M.", "shape": "dot", "size": 10.446428571428571, "title": "Wu, X.-M."}, {"color": "#6FA8DC", "id": "Electrical Engineering", "label": "Electrical Engineering", "shape": "dot", "size": 10.089285714285714, "title": "Electrical Engineering"}, {"color": "#6FA8DC", "id": "graph-based learning", "label": "graph-based learning", "shape": "dot", "size": 10.178571428571429, "title": "graph-based learning"}, {"color": "#6FA8DC", "id": "harmonic structure", "label": "harmonic structure", "shape": "dot", "size": 10.178571428571429, "title": "harmonic structure"}, {"color": "#6FA8DC", "id": "Chang, S.-F.", "label": "Chang, S.-F.", "shape": "dot", "size": 10.089285714285714, "title": "Chang, S.-F."}, {"color": "#6FA8DC", "id": "Wenguan Wang", "label": "Wenguan Wang", "shape": "dot", "size": 10.357142857142858, "title": "Wenguan Wang"}, {"color": "#6FA8DC", "id": "Saliency-Aware Geodesic Video Object Segmentation", "label": "Saliency-Aware Geodesic Video Object Segmentation", "shape": "dot", "size": 10.357142857142858, "title": "Saliency-Aware Geodesic Video Object Segmentation"}, {"color": "#6FA8DC", "id": "Jianbing Shen", "label": "Jianbing Shen", "shape": "dot", "size": 10.267857142857142, "title": "Jianbing Shen"}, {"color": "#6FA8DC", "id": "Fatih Porikli", "label": "Fatih Porikli", "shape": "dot", "size": 10.357142857142858, "title": "Fatih Porikli"}, {"color": "#6FA8DC", "id": "Saliency-Aware Geosesic Video Object Segmentation", "label": "Saliency-Aware Geosesic Video Object Segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Saliency-Aware Geosesic Video Object Segmentation"}, {"color": "#6FA8DC", "id": "unsupervised method", "label": "unsupervised method", "shape": "dot", "size": 10.267857142857142, "title": "unsupervised method"}, {"color": "#6FA8DC", "id": "geodesic distance", "label": "geodesic distance", "shape": "dot", "size": 10.089285714285714, "title": "geodesic distance"}, {"color": "#6FA8DC", "id": "salience as prior", "label": "salience as prior", "shape": "dot", "size": 10.089285714285714, "title": "salience as prior"}, {"color": "#6FA8DC", "id": "spatial edges", "label": "spatial edges", "shape": "dot", "size": 10.178571428571429, "title": "spatial edges"}, {"color": "#6FA8DC", "id": "temporal motion boundaries", "label": "temporal motion boundaries", "shape": "dot", "size": 10.089285714285714, "title": "temporal motion boundaries"}, {"color": "#6FA8DC", "id": "spatiotemporal salience maps", "label": "spatiotemporal salience maps", "shape": "dot", "size": 10.089285714285714, "title": "spatiotemporal salience maps"}, {"color": "#6FA8DC", "id": "global appearance models", "label": "global appearance models", "shape": "dot", "size": 10.089285714285714, "title": "global appearance models"}, {"color": "#6FA8DC", "id": "dynamic location models", "label": "dynamic location models", "shape": "dot", "size": 10.089285714285714, "title": "dynamic location models"}, {"color": "#6FA8DC", "id": "elements within energy minimization framework", "label": "elements within energy minimization framework", "shape": "dot", "size": 10.089285714285714, "title": "elements within energy minimization framework"}, {"color": "#6FA8DC", "id": "superiority over existing algorithms", "label": "superiority over existing algorithms", "shape": "dot", "size": 10.089285714285714, "title": "superiority over existing algorithms"}, {"color": "#6FA8DC", "id": "Video Object Segmentation", "label": "Video Object Segmentation", "shape": "dot", "size": 10.357142857142858, "title": "Video Object Segmentation"}, {"color": "#6FA8DC", "id": "spatially and temporally coherent object segmentation", "label": "spatially and temporally coherent object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "spatially and temporally coherent object segmentation"}, {"color": "#6FA8DC", "id": "Geos image segmentation", "label": "Geos image segmentation", "shape": "dot", "size": 10.178571428571429, "title": "Geos image segmentation"}, {"color": "#6FA8DC", "id": "ECCV, 2008", "label": "ECCV, 2008", "shape": "dot", "size": 10.089285714285714, "title": "ECCV, 2008"}, {"color": "#6FA8DC", "id": "CVPR, 2012", "label": "CVPR, 2012", "shape": "dot", "size": 10.089285714285714, "title": "CVPR, 2012"}, {"color": "#6FA8DC", "id": "state-of-the-art superpixel methods", "label": "state-of-the-art superpixel methods", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art superpixel methods"}, {"color": "#6FA8DC", "id": "IEEE TPAM, 2012", "label": "IEEE TPAM, 2012", "shape": "dot", "size": 10.089285714285714, "title": "IEEE TPAM, 2012"}, {"color": "#6FA8DC", "id": "Motion Boundaries", "label": "Motion Boundaries", "shape": "dot", "size": 10.089285714285714, "title": "Motion Boundaries"}, {"color": "#6FA8DC", "id": "geodesic image segmentation approach", "label": "geodesic image segmentation approach", "shape": "dot", "size": 10.089285714285714, "title": "geodesic image segmentation approach"}, {"color": "#6FA8DC", "id": "Geos", "label": "Geos", "shape": "dot", "size": 10.178571428571429, "title": "Geos"}, {"color": "#6FA8DC", "id": "geospatial image segmentation approach", "label": "geospatial image segmentation approach", "shape": "dot", "size": 10.178571428571429, "title": "geospatial image segmentation approach"}, {"color": "#6FA8DC", "id": "Geodesic graph cut", "label": "Geodesic graph cut", "shape": "dot", "size": 10.089285714285714, "title": "Geodesic graph cut"}, {"color": "#6FA8DC", "id": "interactive image segmentation", "label": "interactive image segmentation", "shape": "dot", "size": 10.089285714285714, "title": "interactive image segmentation"}, {"color": "#6FA8DC", "id": "Grabcut", "label": "Grabcut", "shape": "dot", "size": 10.178571428571429, "title": "Grabcut"}, {"color": "#6FA8DC", "id": "interactive foreground extraction", "label": "interactive foreground extraction", "shape": "dot", "size": 10.089285714285714, "title": "interactive foreground extraction"}, {"color": "#6FA8DC", "id": "iterated graph cuts", "label": "iterated graph cuts", "shape": "dot", "size": 10.089285714285714, "title": "iterated graph cuts"}, {"color": "#6FA8DC", "id": "Object segmentation", "label": "Object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Object segmentation"}, {"color": "#6FA8DC", "id": "trajectory analysis", "label": "trajectory analysis", "shape": "dot", "size": 10.089285714285714, "title": "trajectory analysis"}, {"color": "#6FA8DC", "id": "automatic object segmentation", "label": "automatic object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "automatic object segmentation"}, {"color": "#6FA8DC", "id": "min-cut approach", "label": "min-cut approach", "shape": "dot", "size": 10.089285714285714, "title": "min-cut approach"}, {"color": "#6FA8DC", "id": "constrained parametric min-cuts", "label": "constrained parametric min-cuts", "shape": "dot", "size": 10.089285714285714, "title": "constrained parametric min-cuts"}, {"color": "#6FA8DC", "id": "Video object segmentation", "label": "Video object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Video object segmentation"}, {"color": "#6FA8DC", "id": "W. Brendel and S. Todorovic", "label": "W. Brendel and S. Todorovic", "shape": "dot", "size": 10.089285714285714, "title": "W. Brendel and S. Todorovic"}, {"color": "#6FA8DC", "id": "Geodesic image and video editing", "label": "Geodesic image and video editing", "shape": "dot", "size": 10.178571428571429, "title": "Geodesic image and video editing"}, {"color": "#6FA8DC", "id": "geodesic methods", "label": "geodesic methods", "shape": "dot", "size": 10.089285714285714, "title": "geodesic methods"}, {"color": "#6FA8DC", "id": "J. Carreira", "label": "J. Carreira", "shape": "dot", "size": 10.089285714285714, "title": "J. Carreira"}, {"color": "#6FA8DC", "id": "W. Brendel", "label": "W. Brendel", "shape": "dot", "size": 10.089285714285714, "title": "W. Brendel"}, {"color": "#6FA8DC", "id": "Video object segmentation by tracking regions", "label": "Video object segmentation by tracking regions", "shape": "dot", "size": 10.089285714285714, "title": "Video object segmentation by tracking regions"}, {"color": "#6FA8DC", "id": "D. Tsai", "label": "D. Tsai", "shape": "dot", "size": 10.089285714285714, "title": "D. Tsai"}, {"color": "#6FA8DC", "id": "Motion coherent tracking using multi-label mrf optimization", "label": "Motion coherent tracking using multi-label mrf optimization", "shape": "dot", "size": 10.089285714285714, "title": "Motion coherent tracking using multi-label mrf optimization"}, {"color": "#6FA8DC", "id": "NICTA Australia", "label": "NICTA Australia", "shape": "dot", "size": 10.089285714285714, "title": "NICTA Australia"}, {"color": "#6FA8DC", "id": "Tali Dekel", "label": "Tali Dekel", "shape": "dot", "size": 10.178571428571429, "title": "Tali Dekel"}, {"color": "#6FA8DC", "id": "Best-Buddies Similarity", "label": "Best-Buddies Similarity", "shape": "dot", "size": 10.267857142857142, "title": "Best-Buddies Similarity"}, {"color": "#6FA8DC", "id": "template matching", "label": "template matching", "shape": "dot", "size": 10.178571428571429, "title": "template matching"}, {"color": "#6FA8DC", "id": "unconstrained environments", "label": "unconstrained environments", "shape": "dot", "size": 10.089285714285714, "title": "unconstrained environments"}, {"color": "#6FA8DC", "id": "Best-Buddies Similarity (BBS)", "label": "Best-Buddies Similarity (BBS)", "shape": "dot", "size": 10.357142857142858, "title": "Best-Buddies Similarity (BBS)"}, {"color": "#6FA8DC", "id": "Best-Buddies Similarity (BSS)", "label": "Best-Buddies Similarity (BSS)", "shape": "dot", "size": 10.089285714285714, "title": "Best-Buddies Similarity (BSS)"}, {"color": "#6FA8DC", "id": "parameter-free", "label": "parameter-free", "shape": "dot", "size": 10.089285714285714, "title": "parameter-free"}, {"color": "#6FA8DC", "id": "counting Best-Buddie Pairs (BBPs)", "label": "counting Best-Buddie Pairs (BBPs)", "shape": "dot", "size": 10.089285714285714, "title": "counting Best-Buddie Pairs (BBPs)"}, {"color": "#6FA8DC", "id": "Best-Buddie Pairs (BBPs)", "label": "Best-Buddie Pairs (BBPs)", "shape": "dot", "size": 10.089285714285714, "title": "Best-Buddie Pairs (BBPs)"}, {"color": "#6FA8DC", "id": "pairs of points", "label": "pairs of points", "shape": "dot", "size": 10.089285714285714, "title": "pairs of points"}, {"color": "#6FA8DC", "id": "geometric deformations", "label": "geometric deformations", "shape": "dot", "size": 10.089285714285714, "title": "geometric deformations"}, {"color": "#6FA8DC", "id": "background clutter", "label": "background clutter", "shape": "dot", "size": 10.089285714285714, "title": "background clutter"}, {"color": "#6FA8DC", "id": "BBS", "label": "BBS", "shape": "dot", "size": 10.446428571428571, "title": "BBS"}, {"color": "#6FA8DC", "id": "non-rigid object tracking", "label": "non-rigid object tracking", "shape": "dot", "size": 10.178571428571429, "title": "non-rigid object tracking"}, {"color": "#6FA8DC", "id": "Comaniciu, D. et al.", "label": "Comaniciu, D. et al.", "shape": "dot", "size": 10.089285714285714, "title": "Comaniciu, D. et al."}, {"color": "#6FA8DC", "id": "mean shift tracking", "label": "mean shift tracking", "shape": "dot", "size": 10.178571428571429, "title": "mean shift tracking"}, {"color": "#6FA8DC", "id": "Rubner, Y. et al.", "label": "Rubner, Y. et al.", "shape": "dot", "size": 10.089285714285714, "title": "Rubner, Y. et al."}, {"color": "#6FA8DC", "id": "Earth Mover\u0027s Distance", "label": "Earth Mover\u0027s Distance", "shape": "dot", "size": 10.357142857142858, "title": "Earth Mover\u0027s Distance"}, {"color": "#6FA8DC", "id": "metric for image retrieval", "label": "metric for image retrieval", "shape": "dot", "size": 10.089285714285714, "title": "metric for image retrieval"}, {"color": "#6FA8DC", "id": "consistent success", "label": "consistent success", "shape": "dot", "size": 10.089285714285714, "title": "consistent success"}, {"color": "#6FA8DC", "id": "Similarity Measures", "label": "Similarity Measures", "shape": "dot", "size": 10.089285714285714, "title": "Similarity Measures"}, {"color": "#6FA8DC", "id": "Outlier Robustness", "label": "Outlier Robustness", "shape": "dot", "size": 10.089285714285714, "title": "Outlier Robustness"}, {"color": "#6FA8DC", "id": "Geometric Deformations", "label": "Geometric Deformations", "shape": "dot", "size": 10.089285714285714, "title": "Geometric Deformations"}, {"color": "#6FA8DC", "id": "image comparison", "label": "image comparison", "shape": "dot", "size": 10.089285714285714, "title": "image comparison"}, {"color": "#6FA8DC", "id": "Rubner et al. (2000)", "label": "Rubner et al. (2000)", "shape": "dot", "size": 10.089285714285714, "title": "Rubner et al. (2000)"}, {"color": "#6FA8DC", "id": "Pele et al. (2008)", "label": "Pele et al. (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Pele et al. (2008)"}, {"color": "#6FA8DC", "id": "robust pattern matching", "label": "robust pattern matching", "shape": "dot", "size": 10.089285714285714, "title": "robust pattern matching"}, {"color": "#6FA8DC", "id": "Simaov et al. (2008)", "label": "Simaov et al. (2008)", "shape": "dot", "size": 10.178571428571429, "title": "Simaov et al. (2008)"}, {"color": "#6FA8DC", "id": "summarizing visual data", "label": "summarizing visual data", "shape": "dot", "size": 10.089285714285714, "title": "summarizing visual data"}, {"color": "#6FA8DC", "id": "similarity measures", "label": "similarity measures", "shape": "dot", "size": 10.089285714285714, "title": "similarity measures"}, {"color": "#6FA8DC", "id": "Hel-Or et al. (2014)", "label": "Hel-Or et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Hel-Or et al. (2014)"}, {"color": "#6FA8DC", "id": "photometric invariant template matching", "label": "photometric invariant template matching", "shape": "dot", "size": 10.178571428571429, "title": "photometric invariant template matching"}, {"color": "#6FA8DC", "id": "Tian et al. (2012)", "label": "Tian et al. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Tian et al. (2012)"}, {"color": "#6FA8DC", "id": "estimating nonrigid image distortions", "label": "estimating nonrigid image distortions", "shape": "dot", "size": 10.089285714285714, "title": "estimating nonrigid image distortions"}, {"color": "#6FA8DC", "id": "matching technique", "label": "matching technique", "shape": "dot", "size": 10.089285714285714, "title": "matching technique"}, {"color": "#6FA8DC", "id": "nonrigid image distortions", "label": "nonrigid image distortions", "shape": "dot", "size": 10.178571428571429, "title": "nonrigid image distortions"}, {"color": "#6FA8DC", "id": "image estimation", "label": "image estimation", "shape": "dot", "size": 10.089285714285714, "title": "image estimation"}, {"color": "#6FA8DC", "id": "Tian \u0026 Narasimhan (2012)", "label": "Tian \u0026 Narasimhan (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Tian \u0026 Narasimhan (2012)"}, {"color": "#6FA8DC", "id": "Korman et al. (2013)", "label": "Korman et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Korman et al. (2013)"}, {"color": "#6FA8DC", "id": "fast affine template matching algorithm", "label": "fast affine template matching algorithm", "shape": "dot", "size": 10.089285714285714, "title": "fast affine template matching algorithm"}, {"color": "#6FA8DC", "id": "Wu et al. (2013)", "label": "Wu et al. (2013)", "shape": "dot", "size": 10.089285714285714, "title": "Wu et al. (2013)"}, {"color": "#6FA8DC", "id": "online object tracking benchmark", "label": "online object tracking benchmark", "shape": "dot", "size": 10.089285714285714, "title": "online object tracking benchmark"}, {"color": "#6FA8DC", "id": "Olson (2002)", "label": "Olson (2002)", "shape": "dot", "size": 10.089285714285714, "title": "Olson (2002)"}, {"color": "#6FA8DC", "id": "maximum-likelihood image matching", "label": "maximum-likelihood image matching", "shape": "dot", "size": 10.089285714285714, "title": "maximum-likelihood image matching"}, {"color": "#6FA8DC", "id": "Michael Rubinstein", "label": "Michael Rubinstein", "shape": "dot", "size": 10.089285714285714, "title": "Michael Rubinstein"}, {"color": "#6FA8DC", "id": "Shai Avidan", "label": "Shai Avidan", "shape": "dot", "size": 10.178571428571429, "title": "Shai Avidan"}, {"color": "#6FA8DC", "id": "Tel Aviv University", "label": "Tel Aviv University", "shape": "dot", "size": 10.178571428571429, "title": "Tel Aviv University"}, {"color": "#6FA8DC", "id": "Nianyi Li", "label": "Nianyi Li", "shape": "dot", "size": 10.357142857142858, "title": "Nianyi Li"}, {"color": "#6FA8DC", "id": "A Weighted Sparse Coding Framework for Saliency Detection", "label": "A Weighted Sparse Coding Framework for Saliency Detection", "shape": "dot", "size": 10.267857142857142, "title": "A Weighted Sparse Coding Framework for Saliency Detection"}, {"color": "#6FA8DC", "id": "Bilin Sun", "label": "Bilin Sun", "shape": "dot", "size": 10.178571428571429, "title": "Bilin Sun"}, {"color": "#6FA8DC", "id": "Jingyi", "label": "Jingyi", "shape": "dot", "size": 10.089285714285714, "title": "Jingyi"}, {"color": "#6FA8DC", "id": "A Weighted Sparse Coding Framework", "label": "A Weighted Sparse Coding Framework", "shape": "dot", "size": 10.446428571428571, "title": "A Weighted Sparse Coding Framework"}, {"color": "#6FA8DC", "id": "Jingyi Yu", "label": "Jingyi Yu", "shape": "dot", "size": 10.089285714285714, "title": "Jingyi Yu"}, {"color": "#6FA8DC", "id": "Saliency Detection", "label": "Saliency Detection", "shape": "dot", "size": 10.089285714285714, "title": "Saliency Detection"}, {"color": "#6FA8DC", "id": "avidan@eng.tau.ac.il", "label": "avidan@eng.tau.ac.il", "shape": "dot", "size": 10.178571428571429, "title": "avidan@eng.tau.ac.il"}, {"color": "#6FA8DC", "id": "billf@mit.edu", "label": "billf@mit.edu", "shape": "dot", "size": 10.178571428571429, "title": "billf@mit.edu"}, {"color": "#6FA8DC", "id": "Li_A_Weighted_Sparse_2015_CVPR_paper", "label": "Li_A_Weighted_Sparse_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Li_A_Weighted_Sparse_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "pdf", "label": "pdf", "shape": "dot", "size": 10.089285714285714, "title": "pdf"}, {"color": "#6FA8DC", "id": "salience detection", "label": "salience detection", "shape": "dot", "size": 10.089285714285714, "title": "salience detection"}, {"color": "#6FA8DC", "id": "high-dimensional datasets", "label": "high-dimensional datasets", "shape": "dot", "size": 10.089285714285714, "title": "high-dimensional datasets"}, {"color": "#6FA8DC", "id": "solution frameworks", "label": "solution frameworks", "shape": "dot", "size": 10.089285714285714, "title": "solution frameworks"}, {"color": "#6FA8DC", "id": "uni\ufb01ed saliency detection framework", "label": "uni\ufb01ed saliency detection framework", "shape": "dot", "size": 10.089285714285714, "title": "uni\ufb01ed saliency detection framework"}, {"color": "#6FA8DC", "id": "heterogenous types of input data", "label": "heterogenous types of input data", "shape": "dot", "size": 10.089285714285714, "title": "heterogenous types of input data"}, {"color": "#6FA8DC", "id": "dictionaries", "label": "dictionaries", "shape": "dot", "size": 10.089285714285714, "title": "dictionaries"}, {"color": "#6FA8DC", "id": "data-speci\ufb01c features", "label": "data-speci\ufb01c features", "shape": "dot", "size": 10.089285714285714, "title": "data-speci\ufb01c features"}, {"color": "#6FA8DC", "id": "primitive saliency dictionary", "label": "primitive saliency dictionary", "shape": "dot", "size": 10.089285714285714, "title": "primitive saliency dictionary"}, {"color": "#6FA8DC", "id": "dictionary", "label": "dictionary", "shape": "dot", "size": 10.178571428571429, "title": "dictionary"}, {"color": "#6FA8DC", "id": "state-of-the-art solution", "label": "state-of-the-art solution", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art solution"}, {"color": "#6FA8DC", "id": "2D, 3D and 4D", "label": "2D, 3D and 4D", "shape": "dot", "size": 10.089285714285714, "title": "2D, 3D and 4D"}, {"color": "#6FA8DC", "id": "Sparse Coding", "label": "Sparse Coding", "shape": "dot", "size": 10.089285714285714, "title": "Sparse Coding"}, {"color": "#6FA8DC", "id": "Liu et al. (2011)", "label": "Liu et al. (2011)", "shape": "dot", "size": 10.178571428571429, "title": "Liu et al. (2011)"}, {"color": "#6FA8DC", "id": "Achanta et al. (2012)", "label": "Achanta et al. (2012)", "shape": "dot", "size": 10.178571428571429, "title": "Achanta et al. (2012)"}, {"color": "#6FA8DC", "id": "Borji \u0026 Itti (2012)", "label": "Borji \u0026 Itti (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Borji \u0026 Itti (2012)"}, {"color": "#6FA8DC", "id": "Patch Rarities", "label": "Patch Rarities", "shape": "dot", "size": 10.089285714285714, "title": "Patch Rarities"}, {"color": "#6FA8DC", "id": "Borji, Sihite, \u0026 Itti (2012)", "label": "Borji, Sihite, \u0026 Itti (2012)", "shape": "dot", "size": 10.178571428571429, "title": "Borji, Sihite, \u0026 Itti (2012)"}, {"color": "#6FA8DC", "id": "Salient Object Detection Benchmark", "label": "Salient Object Detection Benchmark", "shape": "dot", "size": 10.089285714285714, "title": "Salient Object Detection Benchmark"}, {"color": "#6FA8DC", "id": "2D, 3D and 4D data", "label": "2D, 3D and 4D data", "shape": "dot", "size": 10.089285714285714, "title": "2D, 3D and 4D data"}, {"color": "#6FA8DC", "id": "Reynolds \u0026 Desimone", "label": "Reynolds \u0026 Desimone", "shape": "dot", "size": 10.267857142857142, "title": "Reynolds \u0026 Desimone"}, {"color": "#6FA8DC", "id": "V4", "label": "V4", "shape": "dot", "size": 10.178571428571429, "title": "V4"}, {"color": "#6FA8DC", "id": "attention", "label": "attention", "shape": "dot", "size": 10.089285714285714, "title": "attention"}, {"color": "#6FA8DC", "id": "Nothdurft", "label": "Nothdurft", "shape": "dot", "size": 10.178571428571429, "title": "Nothdurft"}, {"color": "#6FA8DC", "id": "additivity across dimensions", "label": "additivity across dimensions", "shape": "dot", "size": 10.089285714285714, "title": "additivity across dimensions"}, {"color": "#6FA8DC", "id": "Perazzi et al.", "label": "Perazzi et al.", "shape": "dot", "size": 10.178571428571429, "title": "Perazzi et al."}, {"color": "#6FA8DC", "id": "salience filters", "label": "salience filters", "shape": "dot", "size": 10.089285714285714, "title": "salience filters"}, {"color": "#6FA8DC", "id": "contrast based filtering", "label": "contrast based filtering", "shape": "dot", "size": 10.089285714285714, "title": "contrast based filtering"}, {"color": "#6FA8DC", "id": "Cheng et al.", "label": "Cheng et al.", "shape": "dot", "size": 10.089285714285714, "title": "Cheng et al."}, {"color": "#6FA8DC", "id": "Borji et al.", "label": "Borji et al.", "shape": "dot", "size": 10.089285714285714, "title": "Borji et al."}, {"color": "#6FA8DC", "id": "cal and global patch rarities", "label": "cal and global patch rarities", "shape": "dot", "size": 10.089285714285714, "title": "cal and global patch rarities"}, {"color": "#6FA8DC", "id": "Movahedi \u0026 Elder", "label": "Movahedi \u0026 Elder", "shape": "dot", "size": 10.089285714285714, "title": "Movahedi \u0026 Elder"}, {"color": "#6FA8DC", "id": "salience from feature contrast", "label": "salience from feature contrast", "shape": "dot", "size": 10.089285714285714, "title": "salience from feature contrast"}, {"color": "#6FA8DC", "id": "Neuron", "label": "Neuron", "shape": "dot", "size": 10.089285714285714, "title": "Neuron"}, {"color": "#6FA8DC", "id": "Reynolds \u0026 Desimnone", "label": "Reynolds \u0026 Desimnone", "shape": "dot", "size": 10.089285714285714, "title": "Reynolds \u0026 Desimnone"}, {"color": "#6FA8DC", "id": "Itti \u0026 Koch", "label": "Itti \u0026 Koch", "shape": "dot", "size": 10.089285714285714, "title": "Itti \u0026 Koch"}, {"color": "#6FA8DC", "id": "Nature Reviews Neuroscience", "label": "Nature Reviews Neuroscience", "shape": "dot", "size": 10.089285714285714, "title": "Nature Reviews Neuroscience"}, {"color": "#6FA8DC", "id": "Reynolds", "label": "Reynolds", "shape": "dot", "size": 10.089285714285714, "title": "Reynolds"}, {"color": "#6FA8DC", "id": "University of Delaware", "label": "University of Delaware", "shape": "dot", "size": 10.178571428571429, "title": "University of Delaware"}, {"color": "#6FA8DC", "id": "Souvenir", "label": "Souvenir", "shape": "dot", "size": 10.178571428571429, "title": "Souvenir"}, {"color": "#6FA8DC", "id": "Robust Regression on Image Manifolds", "label": "Robust Regression on Image Manifolds", "shape": "dot", "size": 10.178571428571429, "title": "Robust Regression on Image Manifolds"}, {"color": "#6FA8DC", "id": "nianyi@eecis.udel.edu", "label": "nianyi@eecis.udel.edu", "shape": "dot", "size": 10.089285714285714, "title": "nianyi@eecis.udel.edu"}, {"color": "#6FA8DC", "id": "Sun", "label": "Sun", "shape": "dot", "size": 10.089285714285714, "title": "Sun"}, {"color": "#6FA8DC", "id": "sunbilin@eecis.udel.edu", "label": "sunbilin@eecis.udel.edu", "shape": "dot", "size": 10.089285714285714, "title": "sunbilin@eecis.udel.edu"}, {"color": "#6FA8DC", "id": "Yu", "label": "Yu", "shape": "dot", "size": 10.089285714285714, "title": "Yu"}, {"color": "#6FA8DC", "id": "yu@eecis.udel.edu", "label": "yu@eecis.udel.edu", "shape": "dot", "size": 10.089285714285714, "title": "yu@eecis.udel.edu"}, {"color": "#6FA8DC", "id": "robust regression method", "label": "robust regression method", "shape": "dot", "size": 10.178571428571429, "title": "robust regression method"}, {"color": "#6FA8DC", "id": "non-parametric", "label": "non-parametric", "shape": "dot", "size": 10.089285714285714, "title": "non-parametric"}, {"color": "#6FA8DC", "id": "mis-labeled examples", "label": "mis-labeled examples", "shape": "dot", "size": 10.178571428571429, "title": "mis-labeled examples"}, {"color": "#6FA8DC", "id": "ordered labels", "label": "ordered labels", "shape": "dot", "size": 10.089285714285714, "title": "ordered labels"}, {"color": "#6FA8DC", "id": "superior denois-ing accuracy", "label": "superior denois-ing accuracy", "shape": "dot", "size": 10.089285714285714, "title": "superior denois-ing accuracy"}, {"color": "#6FA8DC", "id": "label corruption levels", "label": "label corruption levels", "shape": "dot", "size": 10.178571428571429, "title": "label corruption levels"}, {"color": "#6FA8DC", "id": "80%", "label": "80%", "shape": "dot", "size": 10.089285714285714, "title": "80%"}, {"color": "#6FA8DC", "id": "image labels", "label": "image labels", "shape": "dot", "size": 10.267857142857142, "title": "image labels"}, {"color": "#6FA8DC", "id": "associated images", "label": "associated images", "shape": "dot", "size": 10.089285714285714, "title": "associated images"}, {"color": "#6FA8DC", "id": "Ordered Labels", "label": "Ordered Labels", "shape": "dot", "size": 10.089285714285714, "title": "Ordered Labels"}, {"color": "#6FA8DC", "id": "Ordinal Data", "label": "Ordinal Data", "shape": "dot", "size": 10.089285714285714, "title": "Ordinal Data"}, {"color": "#6FA8DC", "id": "Label Denoising", "label": "Label Denoising", "shape": "dot", "size": 10.089285714285714, "title": "Label Denoising"}, {"color": "#6FA8DC", "id": "accuracy of image labels", "label": "accuracy of image labels", "shape": "dot", "size": 10.089285714285714, "title": "accuracy of image labels"}, {"color": "#6FA8DC", "id": "locally linear embedding technique", "label": "locally linear embedding technique", "shape": "dot", "size": 10.089285714285714, "title": "locally linear embedding technique"}, {"color": "#6FA8DC", "id": "gigantic image collections", "label": "gigantic image collections", "shape": "dot", "size": 10.089285714285714, "title": "gigantic image collections"}, {"color": "#6FA8DC", "id": "Building Rome in a day", "label": "Building Rome in a day", "shape": "dot", "size": 10.089285714285714, "title": "Building Rome in a day"}, {"color": "#6FA8DC", "id": "IEEE International Conference on Computer Visions", "label": "IEEE International Conference on Computer Visions", "shape": "dot", "size": 10.089285714285714, "title": "IEEE International Conference on Computer Visions"}, {"color": "#6FA8DC", "id": "high-dimensional data", "label": "high-dimensional data", "shape": "dot", "size": 10.089285714285714, "title": "high-dimensional data"}, {"color": "#6FA8DC", "id": "R. C. Bolles", "label": "R. C. Bolles", "shape": "dot", "size": 10.089285714285714, "title": "R. C. Bolles"}, {"color": "#6FA8DC", "id": "C.-C. Chang", "label": "C.-C. Chang", "shape": "dot", "size": 10.089285714285714, "title": "C.-C. Chang"}, {"color": "#6FA8DC", "id": "C.-J. Lin", "label": "C.-J. Lin", "shape": "dot", "size": 10.089285714285714, "title": "C.-J. Lin"}, {"color": "#6FA8DC", "id": "USAC", "label": "USAC", "shape": "dot", "size": 10.178571428571429, "title": "USAC"}, {"color": "#6FA8DC", "id": "R. Raguram", "label": "R. Raguram", "shape": "dot", "size": 10.089285714285714, "title": "R. Raguram"}, {"color": "#6FA8DC", "id": "l-curve", "label": "l-curve", "shape": "dot", "size": 10.089285714285714, "title": "l-curve"}, {"color": "#6FA8DC", "id": "Analysis of discrete ill-posed problems", "label": "Analysis of discrete ill-posed problems", "shape": "dot", "size": 10.178571428571429, "title": "Analysis of discrete ill-posed problems"}, {"color": "#6FA8DC", "id": "P. C. Hansen", "label": "P. C. Hansen", "shape": "dot", "size": 10.089285714285714, "title": "P. C. Hansen"}, {"color": "#6FA8DC", "id": "Internet photo collections", "label": "Internet photo collections", "shape": "dot", "size": 10.089285714285714, "title": "Internet photo collections"}, {"color": "#6FA8DC", "id": "Modeling the world", "label": "Modeling the world", "shape": "dot", "size": 10.178571428571429, "title": "Modeling the world"}, {"color": "#6FA8DC", "id": "N. Snavely", "label": "N. Snavely", "shape": "dot", "size": 10.089285714285714, "title": "N. Snavely"}, {"color": "#6FA8DC", "id": "SIAM review", "label": "SIAM review", "shape": "dot", "size": 10.089285714285714, "title": "SIAM review"}, {"color": "#6FA8DC", "id": "Kai Han", "label": "Kai Han", "shape": "dot", "size": 10.178571428571429, "title": "Kai Han"}, {"color": "#6FA8DC", "id": "A Fixed Viewpoint Approach", "label": "A Fixed Viewpoint Approach", "shape": "dot", "size": 10.267857142857142, "title": "A Fixed Viewpoint Approach"}, {"color": "#6FA8DC", "id": "Kwan-Yee K. Wong", "label": "Kwan-Yee K. Wong", "shape": "dot", "size": 10.178571428571429, "title": "Kwan-Yee K. Wong"}, {"color": "#6FA8DC", "id": "Miaomiao Liu", "label": "Miaomiao Liu", "shape": "dot", "size": 10.267857142857142, "title": "Miaomiao Liu"}, {"color": "#6FA8DC", "id": "A Fixed View Point Approach", "label": "A Fixed View Point Approach", "shape": "dot", "size": 10.089285714285714, "title": "A Fixed View Point Approach"}, {"color": "#6FA8DC", "id": "surface shape reconstruction problem", "label": "surface shape reconstruction problem", "shape": "dot", "size": 10.089285714285714, "title": "surface shape reconstruction problem"}, {"color": "#6FA8DC", "id": "transparent object reconstruction", "label": "transparent object reconstruction", "shape": "dot", "size": 10.178571428571429, "title": "transparent object reconstruction"}, {"color": "#6FA8DC", "id": "light path triangulation", "label": "light path triangulation", "shape": "dot", "size": 10.178571428571429, "title": "light path triangulation"}, {"color": "#6FA8DC", "id": "unknown refractive indices", "label": "unknown refractive indices", "shape": "dot", "size": 10.089285714285714, "title": "unknown refractive indices"}, {"color": "#6FA8DC", "id": "complex transparent objects", "label": "complex transparent objects", "shape": "dot", "size": 10.089285714285714, "title": "complex transparent objects"}, {"color": "#6FA8DC", "id": "M. Ben-Ezra and S. K. Nayr", "label": "M. Ben-Ezra and S. K. Nayr", "shape": "dot", "size": 10.089285714285714, "title": "M. Ben-Ezra and S. K. Nayr"}, {"color": "#6FA8DC", "id": "transparency analysis", "label": "transparency analysis", "shape": "dot", "size": 10.089285714285714, "title": "transparency analysis"}, {"color": "#6FA8DC", "id": "G. Eren et al.", "label": "G. Eren et al.", "shape": "dot", "size": 10.089285714285714, "title": "G. Eren et al."}, {"color": "#6FA8DC", "id": "shape estimation", "label": "shape estimation", "shape": "dot", "size": 10.357142857142858, "title": "shape estimation"}, {"color": "#6FA8DC", "id": "local surface heating", "label": "local surface heating", "shape": "dot", "size": 10.178571428571429, "title": "local surface heating"}, {"color": "#6FA8DC", "id": "refractive photo-light-path", "label": "refractive photo-light-path", "shape": "dot", "size": 10.089285714285714, "title": "refractive photo-light-path"}, {"color": "#6FA8DC", "id": "feasibility", "label": "feasibility", "shape": "dot", "size": 10.089285714285714, "title": "feasibility"}, {"color": "#6FA8DC", "id": "Fischler and Bolles", "label": "Fischler and Bolles", "shape": "dot", "size": 10.089285714285714, "title": "Fischler and Bolles"}, {"color": "#6FA8DC", "id": "Hata et al.", "label": "Hata et al.", "shape": "dot", "size": 10.089285714285714, "title": "Hata et al."}, {"color": "#6FA8DC", "id": "genetic algorithm", "label": "genetic algorithm", "shape": "dot", "size": 10.178571428571429, "title": "genetic algorithm"}, {"color": "#6FA8DC", "id": "shape extraction", "label": "shape extraction", "shape": "dot", "size": 10.089285714285714, "title": "shape extraction"}, {"color": "#6FA8DC", "id": "Ihrke et al. (2005)", "label": "Ihrke et al. (2005)", "shape": "dot", "size": 10.089285714285714, "title": "Ihrke et al. (2005)"}, {"color": "#6FA8DC", "id": "geometry reconstruction", "label": "geometry reconstruction", "shape": "dot", "size": 10.178571428571429, "title": "geometry reconstruction"}, {"color": "#6FA8DC", "id": "dynamic environments", "label": "dynamic environments", "shape": "dot", "size": 10.089285714285714, "title": "dynamic environments"}, {"color": "#6FA8DC", "id": "Ihrke et al. (2008)", "label": "Ihrke et al. (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Ihrke et al. (2008)"}, {"color": "#6FA8DC", "id": "Transparent objects", "label": "Transparent objects", "shape": "dot", "size": 10.089285714285714, "title": "Transparent objects"}, {"color": "#6FA8DC", "id": "The University of Hokkaido", "label": "The University of Hokkaido", "shape": "dot", "size": 10.178571428571429, "title": "The University of Hokkaido"}, {"color": "#6FA8DC", "id": "CECS, ANU", "label": "CECS, ANU", "shape": "dot", "size": 10.089285714285714, "title": "CECS, ANU"}, {"color": "#6FA8DC", "id": "Benjamin Allain", "label": "Benjamin Allain", "shape": "dot", "size": 10.357142857142858, "title": "Benjamin Allain"}, {"color": "#6FA8DC", "id": "An Efficient Volumetric Framework for Shape Tracking", "label": "An Efficient Volumetric Framework for Shape Tracking", "shape": "dot", "size": 10.446428571428571, "title": "An Efficient Volumetric Framework for Shape Tracking"}, {"color": "#6FA8DC", "id": "Jean-S\u00e9batian Franco", "label": "Jean-S\u00e9batian Franco", "shape": "dot", "size": 10.089285714285714, "title": "Jean-S\u00e9batian Franco"}, {"color": "#6FA8DC", "id": "Edmond Boyer", "label": "Edmond Boyer", "shape": "dot", "size": 10.178571428571429, "title": "Edmond Boyer"}, {"color": "#6FA8DC", "id": "Allain_An_Efficient_Volumetric_2015_CVPR_paper.pdf", "label": "Allain_An_Efficient_Volumetric_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Allain_An_Efficient_Volumetric_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "3D shape motion recovery", "label": "3D shape motion recovery", "shape": "dot", "size": 10.089285714285714, "title": "3D shape motion recovery"}, {"color": "#6FA8DC", "id": "surface-based strategies", "label": "surface-based strategies", "shape": "dot", "size": 10.178571428571429, "title": "surface-based strategies"}, {"color": "#6FA8DC", "id": "observations define several feasible surfaces", "label": "observations define several feasible surfaces", "shape": "dot", "size": 10.089285714285714, "title": "observations define several feasible surfaces"}, {"color": "#6FA8DC", "id": "this work", "label": "this work", "shape": "dot", "size": 10.089285714285714, "title": "this work"}, {"color": "#6FA8DC", "id": "volumetric shape parametrization", "label": "volumetric shape parametrization", "shape": "dot", "size": 10.178571428571429, "title": "volumetric shape parametrization"}, {"color": "#6FA8DC", "id": "Centroidal Voronoi Tesselations (CVT)", "label": "Centroidal Voronoi Tesselations (CVT)", "shape": "dot", "size": 10.178571428571429, "title": "Centroidal Voronoi Tesselations (CVT)"}, {"color": "#6FA8DC", "id": "volumetric deformation model", "label": "volumetric deformation model", "shape": "dot", "size": 10.267857142857142, "title": "volumetric deformation model"}, {"color": "#6FA8DC", "id": "hybrid multi-camera and marker-based capture dataset", "label": "hybrid multi-camera and marker-based capture dataset", "shape": "dot", "size": 10.089285714285714, "title": "hybrid multi-camera and marker-based capture dataset"}, {"color": "#6FA8DC", "id": "improved precision and robustness", "label": "improved precision and robustness", "shape": "dot", "size": 10.089285714285714, "title": "improved precision and robustness"}, {"color": "#6FA8DC", "id": "volumetric shape tracking", "label": "volumetric shape tracking", "shape": "dot", "size": 10.089285714285714, "title": "volumetric shape tracking"}, {"color": "#6FA8DC", "id": "Volumetric Shape Tracking", "label": "Volumetric Shape Tracking", "shape": "dot", "size": 10.089285714285714, "title": "Volumetric Shape Tracking"}, {"color": "#6FA8DC", "id": "Centroidal Voronoi Tesselations", "label": "Centroidal Voronoi Tesselations", "shape": "dot", "size": 10.089285714285714, "title": "Centroidal Voronoi Tesselations"}, {"color": "#6FA8DC", "id": "Dynamic Shape Capture", "label": "Dynamic Shape Capture", "shape": "dot", "size": 10.089285714285714, "title": "Dynamic Shape Capture"}, {"color": "#6FA8DC", "id": "Motion Estimation", "label": "Motion Estimation", "shape": "dot", "size": 10.089285714285714, "title": "Motion Estimation"}, {"color": "#6FA8DC", "id": "Surface-based Methods", "label": "Surface-based Methods", "shape": "dot", "size": 10.089285714285714, "title": "Surface-based Methods"}, {"color": "#6FA8DC", "id": "Volume-based Methods", "label": "Volume-based Methods", "shape": "dot", "size": 10.089285714285714, "title": "Volume-based Methods"}, {"color": "#6FA8DC", "id": "Alexa et al. (2000)", "label": "Alexa et al. (2000)", "shape": "dot", "size": 10.089285714285714, "title": "Alexa et al. (2000)"}, {"color": "#6FA8DC", "id": "As-rigid-as-possible shape interpolation", "label": "As-rigid-as-possible shape interpolation", "shape": "dot", "size": 10.089285714285714, "title": "As-rigid-as-possible shape interpolation"}, {"color": "#6FA8DC", "id": "Allain et al. (2014)", "label": "Allain et al. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Allain et al. (2014)"}, {"color": "#6FA8DC", "id": "On mean pose and variability of 3d deformable models", "label": "On mean pose and variability of 3d deformable models", "shape": "dot", "size": 10.089285714285714, "title": "On mean pose and variability of 3d deformable models"}, {"color": "#6FA8DC", "id": "Ballan \u0026 Cortelazzo (2008)", "label": "Ballan \u0026 Cortelazzo (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Ballan \u0026 Cortelazzo (2008)"}, {"color": "#6FA8DC", "id": "Marker-less motion capture of skinned models", "label": "Marker-less motion capture of skinned models", "shape": "dot", "size": 10.089285714285714, "title": "Marker-less motion capture of skinned models"}, {"color": "#6FA8DC", "id": "Bishop (2006)", "label": "Bishop (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Bishop (2006)"}, {"color": "#6FA8DC", "id": "Pattern Recognition and Machine Learning", "label": "Pattern Recognition and Machine Learning", "shape": "dot", "size": 10.089285714285714, "title": "Pattern Recognition and Machine Learning"}, {"color": "#6FA8DC", "id": "Botsu et al. (2007)", "label": "Botsu et al. (2007)", "shape": "dot", "size": 10.089285714285714, "title": "Botsu et al. (2007)"}, {"color": "#6FA8DC", "id": "Adaptive space deformations based on rigid cells", "label": "Adaptive space deformations based on rigid cells", "shape": "dot", "size": 10.267857142857142, "title": "Adaptive space deformations based on rigid cells"}, {"color": "#6FA8DC", "id": "Botsu, M.", "label": "Botsu, M.", "shape": "dot", "size": 10.089285714285714, "title": "Botsu, M."}, {"color": "#6FA8DC", "id": "Cagniart, C.", "label": "Cagniart, C.", "shape": "dot", "size": 10.178571428571429, "title": "Cagniart, C."}, {"color": "#6FA8DC", "id": "Free-form mesh tracking: a patch-based approach", "label": "Free-form mesh tracking: a patch-based approach", "shape": "dot", "size": 10.178571428571429, "title": "Free-form mesh tracking: a patch-based approach"}, {"color": "#6FA8DC", "id": "Probabilistic deformable surface tracking from multiple videos", "label": "Probabilistic deformable surface tracking from multiple videos", "shape": "dot", "size": 10.178571428571429, "title": "Probabilistic deformable surface tracking from multiple videos"}, {"color": "#6FA8DC", "id": "de Aguiar, E.", "label": "de Aguiar, E.", "shape": "dot", "size": 10.089285714285714, "title": "de Aguiar, E."}, {"color": "#6FA8DC", "id": "Performance capture from sparse multi-view video", "label": "Performance capture from sparse multi-view video", "shape": "dot", "size": 10.178571428571429, "title": "Performance capture from sparse multi-view video"}, {"color": "#6FA8DC", "id": "de Aguliar, E.", "label": "de Aguliar, E.", "shape": "dot", "size": 10.089285714285714, "title": "de Aguliar, E."}, {"color": "#6FA8DC", "id": "Marker-less deformable mesh tracking for human shape and motion capture", "label": "Marker-less deformable mesh tracking for human shape and motion capture", "shape": "dot", "size": 10.089285714285714, "title": "Marker-less deformable mesh tracking for human shape and motion capture"}, {"color": "#6FA8DC", "id": "Inria Grenoble Rh\u02c6one-Alpes - LJK", "label": "Inria Grenoble Rh\u02c6one-Alpes - LJK", "shape": "dot", "size": 10.178571428571429, "title": "Inria Grenoble Rh\u02c6one-Alpes - LJK"}, {"color": "#6FA8DC", "id": "Comput. Graph. Forum", "label": "Comput. Graph. Forum", "shape": "dot", "size": 10.089285714285714, "title": "Comput. Graph. Forum"}, {"color": "#6FA8DC", "id": "Inria Grenoble Rh\u02c6one- Alpes", "label": "Inria Grenoble Rh\u02c6one- Alpes", "shape": "dot", "size": 10.089285714285714, "title": "Inria Grenoble Rh\u02c6one- Alpes"}, {"color": "#6FA8DC", "id": "LJK", "label": "LJK", "shape": "dot", "size": 10.089285714285714, "title": "LJK"}, {"color": "#6FA8DC", "id": "Benjamin Allaine", "label": "Benjamin Allaine", "shape": "dot", "size": 10.089285714285714, "title": "Benjamin Allaine"}, {"color": "#6FA8DC", "id": "firstname.lastname@inria.fr", "label": "firstname.lastname@inria.fr", "shape": "dot", "size": 10.089285714285714, "title": "firstname.lastname@inria.fr"}, {"color": "#6FA8DC", "id": "Maximum likelihood", "label": "Maximum likelihood", "shape": "dot", "size": 10.089285714285714, "title": "Maximum likelihood"}, {"color": "#6FA8DC", "id": "em algorithm", "label": "em algorithm", "shape": "dot", "size": 10.178571428571429, "title": "em algorithm"}, {"color": "#6FA8DC", "id": "Maximum likelihood from incomplete data", "label": "Maximum likelihood from incomplete data", "shape": "dot", "size": 10.089285714285714, "title": "Maximum likelihood from incomplete data"}, {"color": "#6FA8DC", "id": "Journal of the Royal Statistical Society, series B", "label": "Journal of the Royal Statistical Society, series B", "shape": "dot", "size": 10.089285714285714, "title": "Journal of the Royal Statistical Society, series B"}, {"color": "#6FA8DC", "id": "Maximum likelihood from incomplete data via the em algorithm", "label": "Maximum likelihood from incomplete data via the em algorithm", "shape": "dot", "size": 10.089285714285714, "title": "Maximum likelihood from incomplete data via the em algorithm"}, {"color": "#6FA8DC", "id": "Jean-S\u00e9bastien Franco", "label": "Jean-S\u00e9bastien Franco", "shape": "dot", "size": 10.089285714285714, "title": "Jean-S\u00e9bastien Franco"}, {"color": "#6FA8DC", "id": "Inria Grenoble Rh\u02c6one-Alpes - LHK", "label": "Inria Grenoble Rh\u02c6one-Alpes - LHK", "shape": "dot", "size": 10.089285714285714, "title": "Inria Grenoble Rh\u02c6one-Alpes - LHK"}, {"color": "#6FA8DC", "id": "Yi-Hsuan Tsai", "label": "Yi-Hsuan Tsai", "shape": "dot", "size": 10.178571428571429, "title": "Yi-Hsuan Tsai"}, {"color": "#6FA8DC", "id": "Adaptive Region Pooling for Object Detection", "label": "Adaptive Region Pooling for Object Detection", "shape": "dot", "size": 10.535714285714286, "title": "Adaptive Region Pooling for Object Detection"}, {"color": "#6FA8DC", "id": "Onur C. Hamsici", "label": "Onur C. Hamsici", "shape": "dot", "size": 10.178571428571429, "title": "Onur C. Hamsici"}, {"color": "#6FA8DC", "id": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental.pdf", "label": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental.pdf", "shape": "dot", "size": 10.089285714285714, "title": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental.pdf"}, {"color": "#6FA8DC", "id": "Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental", "label": "Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental", "shape": "dot", "size": 10.089285714285714, "title": "Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental"}, {"color": "#6FA8DC", "id": "Adaptive Region Pooling", "label": "Adaptive Region Pooling", "shape": "dot", "size": 10.446428571428571, "title": "Adaptive Region Pooling"}, {"color": "#6FA8DC", "id": "discriminative object parts", "label": "discriminative object parts", "shape": "dot", "size": 10.089285714285714, "title": "discriminative object parts"}, {"color": "#6FA8DC", "id": "Adaptive Region Processing", "label": "Adaptive Region Processing", "shape": "dot", "size": 10.089285714285714, "title": "Adaptive Region Processing"}, {"color": "#6FA8DC", "id": "improving object detection", "label": "improving object detection", "shape": "dot", "size": 10.089285714285714, "title": "improving object detection"}, {"color": "#6FA8DC", "id": "representative parts", "label": "representative parts", "shape": "dot", "size": 10.178571428571429, "title": "representative parts"}, {"color": "#6FA8DC", "id": "detected objects", "label": "detected objects", "shape": "dot", "size": 10.089285714285714, "title": "detected objects"}, {"color": "#6FA8DC", "id": "challenging conditions", "label": "challenging conditions", "shape": "dot", "size": 10.267857142857142, "title": "challenging conditions"}, {"color": "#6FA8DC", "id": "effectiveness of ARP", "label": "effectiveness of ARP", "shape": "dot", "size": 10.089285714285714, "title": "effectiveness of ARP"}, {"color": "#6FA8DC", "id": "ARP", "label": "ARP", "shape": "dot", "size": 10.089285714285714, "title": "ARP"}, {"color": "#6FA8DC", "id": "ESVM", "label": "ESVM", "shape": "dot", "size": 10.089285714285714, "title": "ESVM"}, {"color": "#6FA8DC", "id": "Ensemble of exemplar-svms", "label": "Ensemble of exemplar-svms", "shape": "dot", "size": 10.178571428571429, "title": "Ensemble of exemplar-svms"}, {"color": "#6FA8DC", "id": "Keypoint Transfer", "label": "Keypoint Transfer", "shape": "dot", "size": 10.089285714285714, "title": "Keypoint Transfer"}, {"color": "#6FA8DC", "id": "Object Parts Discovery", "label": "Object Parts Discovery", "shape": "dot", "size": 10.089285714285714, "title": "Object Parts Discovery"}, {"color": "#6FA8DC", "id": "Long-term Recurrent Convolutional Networks", "label": "Long-term Recurrent Convolutional Networks", "shape": "dot", "size": 10.357142857142858, "title": "Long-term Recurrent Convolutional Networks"}, {"color": "#6FA8DC", "id": "Visual Description", "label": "Visual Description", "shape": "dot", "size": 10.089285714285714, "title": "Visual Description"}, {"color": "#6FA8DC", "id": "Jeff Donahue", "label": "Jeff Donahue", "shape": "dot", "size": 10.178571428571429, "title": "Jeff Donahue"}, {"color": "#6FA8DC", "id": "Lisa Anne Hendricks", "label": "Lisa Anne Hendricks", "shape": "dot", "size": 10.178571428571429, "title": "Lisa Anne Hendricks"}, {"color": "#6FA8DC", "id": "UC Merced", "label": "UC Merced", "shape": "dot", "size": 10.178571428571429, "title": "UC Merced"}, {"color": "#6FA8DC", "id": "Qualcomm Research", "label": "Qualcomm Research", "shape": "dot", "size": 10.089285714285714, "title": "Qualcomm Research"}, {"color": "#6FA8DC", "id": "Sergio Guadarrama", "label": "Sergio Guadarrama", "shape": "dot", "size": 10.178571428571429, "title": "Sergio Guadarrama"}, {"color": "#6FA8DC", "id": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "label": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "shape": "dot", "size": 10.803571428571429, "title": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "Marcus Rohrbach", "label": "Marcus Rohrbach", "shape": "dot", "size": 10.089285714285714, "title": "Marcus Rohrbach"}, {"color": "#6FA8DC", "id": "Subhashini Venugopalan", "label": "Subhashini Venugopalan", "shape": "dot", "size": 10.178571428571429, "title": "Subhashini Venugopalan"}, {"color": "#6FA8DC", "id": "Kate Saenko", "label": "Kate Saenko", "shape": "dot", "size": 10.178571428571429, "title": "Kate Saenko"}, {"color": "#6FA8DC", "id": "Trevor Darrell", "label": "Trevor Darrell", "shape": "dot", "size": 10.178571428571429, "title": "Trevor Darrell"}, {"color": "#6FA8DC", "id": "Visual Features", "label": "Visual Features", "shape": "dot", "size": 10.178571428571429, "title": "Visual Features"}, {"color": "#6FA8DC", "id": "Predictions", "label": "Predictions", "shape": "dot", "size": 10.089285714285714, "title": "Predictions"}, {"color": "#6FA8DC", "id": "Visual Input", "label": "Visual Input", "shape": "dot", "size": 10.089285714285714, "title": "Visual Input"}, {"color": "#6FA8DC", "id": "Models", "label": "Models", "shape": "dot", "size": 10.535714285714286, "title": "Models"}, {"color": "#6FA8DC", "id": "recurrent", "label": "recurrent", "shape": "dot", "size": 10.089285714285714, "title": "recurrent"}, {"color": "#6FA8DC", "id": "temporally deep", "label": "temporally deep", "shape": "dot", "size": 10.089285714285714, "title": "temporally deep"}, {"color": "#6FA8DC", "id": "recurrent convolutional", "label": "recurrent convolutional", "shape": "dot", "size": 10.089285714285714, "title": "recurrent convolutional"}, {"color": "#6FA8DC", "id": "large-scale visual learning", "label": "large-scale visual learning", "shape": "dot", "size": 10.089285714285714, "title": "large-scale visual learning"}, {"color": "#6FA8DC", "id": "video recognition tasks", "label": "video recognition tasks", "shape": "dot", "size": 10.089285714285714, "title": "video recognition tasks"}, {"color": "#6FA8DC", "id": "image description", "label": "image description", "shape": "dot", "size": 10.089285714285714, "title": "image description"}, {"color": "#6FA8DC", "id": "video narration challenges", "label": "video narration challenges", "shape": "dot", "size": 10.089285714285714, "title": "video narration challenges"}, {"color": "#6FA8DC", "id": "recurrent convolutional models", "label": "recurrent convolutional models", "shape": "dot", "size": 10.267857142857142, "title": "recurrent convolutional models"}, {"color": "#6FA8DC", "id": "doubly deep", "label": "doubly deep", "shape": "dot", "size": 10.089285714285714, "title": "doubly deep"}, {"color": "#6FA8DC", "id": "compositional", "label": "compositional", "shape": "dot", "size": 10.089285714285714, "title": "compositional"}, {"color": "#6FA8DC", "id": "complex target concepts", "label": "complex target concepts", "shape": "dot", "size": 10.089285714285714, "title": "complex target concepts"}, {"color": "#6FA8DC", "id": "limited training data", "label": "limited training data", "shape": "dot", "size": 10.089285714285714, "title": "limited training data"}, {"color": "#6FA8DC", "id": "network state updates", "label": "network state updates", "shape": "dot", "size": 10.089285714285714, "title": "network state updates"}, {"color": "#6FA8DC", "id": "long-term dependencies", "label": "long-term dependencies", "shape": "dot", "size": 10.089285714285714, "title": "long-term dependencies"}, {"color": "#6FA8DC", "id": "long-term RNN models", "label": "long-term RNN models", "shape": "dot", "size": 10.178571428571429, "title": "long-term RNN models"}, {"color": "#6FA8DC", "id": "variable length outputs", "label": "variable length outputs", "shape": "dot", "size": 10.089285714285714, "title": "variable length outputs"}, {"color": "#6FA8DC", "id": "complex temporal dynamics", "label": "complex temporal dynamics", "shape": "dot", "size": 10.089285714285714, "title": "complex temporal dynamics"}, {"color": "#6FA8DC", "id": "backpropagation", "label": "backpropagation", "shape": "dot", "size": 10.089285714285714, "title": "backpropagation"}, {"color": "#6FA8DC", "id": "recurrent long-term models", "label": "recurrent long-term models", "shape": "dot", "size": 10.089285714285714, "title": "recurrent long-term models"}, {"color": "#6FA8DC", "id": "visual convnet models", "label": "visual convnet models", "shape": "dot", "size": 10.089285714285714, "title": "visual convnet models"}, {"color": "#6FA8DC", "id": "temporal dynamics", "label": "temporal dynamics", "shape": "dot", "size": 10.089285714285714, "title": "temporal dynamics"}, {"color": "#6FA8DC", "id": "convolutional perceptual representations", "label": "convolutional perceptual representations", "shape": "dot", "size": 10.089285714285714, "title": "convolutional perceptual representations"}, {"color": "#6FA8DC", "id": "distinct advantages", "label": "distinct advantages", "shape": "dot", "size": 10.089285714285714, "title": "distinct advantages"}, {"color": "#6FA8DC", "id": "Recurrent Convolutional Networks (LRCNs)", "label": "Recurrent Convolutional Networks (LRCNs)", "shape": "dot", "size": 10.446428571428571, "title": "Recurrent Convolutional Networks (LRCNs)"}, {"color": "#6FA8DC", "id": "Video Recognition", "label": "Video Recognition", "shape": "dot", "size": 10.357142857142858, "title": "Video Recognition"}, {"color": "#6FA8DC", "id": "Long-Term Dependencies", "label": "Long-Term Dependencies", "shape": "dot", "size": 10.357142857142858, "title": "Long-Term Dependencies"}, {"color": "#6FA8DC", "id": "Sequence Learning", "label": "Sequence Learning", "shape": "dot", "size": 10.267857142857142, "title": "Sequence Learning"}, {"color": "#6FA8DC", "id": "state-of-the-art models", "label": "state-of-the-art models", "shape": "dot", "size": 10.178571428571429, "title": "state-of-the-art models"}, {"color": "#6FA8DC", "id": "separately optimized", "label": "separately optimized", "shape": "dot", "size": 10.089285714285714, "title": "separately optimized"}, {"color": "#6FA8DC", "id": "perceptual representations", "label": "perceptual representations", "shape": "dot", "size": 10.089285714285714, "title": "perceptual representations"}, {"color": "#6FA8DC", "id": "Action Classification", "label": "Action Classification", "shape": "dot", "size": 10.178571428571429, "title": "Action Classification"}, {"color": "#6FA8DC", "id": "Long short-term memory recurrent neural networks", "label": "Long short-term memory recurrent neural networks", "shape": "dot", "size": 10.178571428571429, "title": "Long short-term memory recurrent neural networks"}, {"color": "#6FA8DC", "id": "Multimodal neural language models", "label": "Multimodal neural language models", "shape": "dot", "size": 10.178571428571429, "title": "Multimodal neural language models"}, {"color": "#6FA8DC", "id": "visual-semantic embeddings", "label": "visual-semantic embeddings", "shape": "dot", "size": 10.089285714285714, "title": "visual-semantic embeddings"}, {"color": "#6FA8DC", "id": "Unifying visual-semantic embeddings", "label": "Unifying visual-semantic embeddings", "shape": "dot", "size": 10.089285714285714, "title": "Unifying visual-semantic embeddings"}, {"color": "#6FA8DC", "id": "Video in sentences out", "label": "Video in sentences out", "shape": "dot", "size": 10.178571428571429, "title": "Video in sentences out"}, {"color": "#6FA8DC", "id": "soccer videos", "label": "soccer videos", "shape": "dot", "size": 10.089285714285714, "title": "soccer videos"}, {"color": "#6FA8DC", "id": "UAI", "label": "UAI", "shape": "dot", "size": 10.089285714285714, "title": "UAI"}, {"color": "#6FA8DC", "id": "High accuracy optical flow estimation", "label": "High accuracy optical flow estimation", "shape": "dot", "size": 10.089285714285714, "title": "High accuracy optical flow estimation"}, {"color": "#6FA8DC", "id": "3D convolutional neural networks", "label": "3D convolutional neural networks", "shape": "dot", "size": 10.089285714285714, "title": "3D convolutional neural networks"}, {"color": "#6FA8DC", "id": "Generating sequences", "label": "Generating sequences", "shape": "dot", "size": 10.089285714285714, "title": "Generating sequences"}, {"color": "#6FA8DC", "id": "arXiv preprint arXiv:1308.0850", "label": "arXiv preprint arXiv:1308.0850", "shape": "dot", "size": 10.089285714285714, "title": "arXiv preprint arXiv:1308.0850"}, {"color": "#6FA8DC", "id": "Recurrent neural networks", "label": "Recurrent neural networks", "shape": "dot", "size": 10.089285714285714, "title": "Recurrent neural networks"}, {"color": "#6FA8DC", "id": "generating sequences", "label": "generating sequences", "shape": "dot", "size": 10.089285714285714, "title": "generating sequences"}, {"color": "#6FA8DC", "id": "J. Deng", "label": "J. Deng", "shape": "dot", "size": 10.089285714285714, "title": "J. Deng"}, {"color": "#6FA8DC", "id": "W. Dong", "label": "W. Dong", "shape": "dot", "size": 10.089285714285714, "title": "W. Dong"}, {"color": "#6FA8DC", "id": "R. Socher", "label": "R. Socher", "shape": "dot", "size": 10.089285714285714, "title": "R. Socher"}, {"color": "#6FA8DC", "id": "L.-J. Li", "label": "L.-J. Li", "shape": "dot", "size": 10.089285714285714, "title": "L.-J. Li"}, {"color": "#6FA8DC", "id": "K. Li", "label": "K. Li", "shape": "dot", "size": 10.089285714285714, "title": "K. Li"}, {"color": "#6FA8DC", "id": "L. Fei-Fei", "label": "L. Fei-Fei", "shape": "dot", "size": 10.089285714285714, "title": "L. Fei-Fei"}, {"color": "#6FA8DC", "id": "A. Frome", "label": "A. Frome", "shape": "dot", "size": 10.089285714285714, "title": "A. Frome"}, {"color": "#6FA8DC", "id": "UT Austin", "label": "UT Austin", "shape": "dot", "size": 10.178571428571429, "title": "UT Austin"}, {"color": "#6FA8DC", "id": "UMass Lowell", "label": "UMass Lowell", "shape": "dot", "size": 10.089285714285714, "title": "UMass Lowell"}, {"color": "#6FA8DC", "id": "ubhashini Venugopalan", "label": "ubhashini Venugopalan", "shape": "dot", "size": 10.089285714285714, "title": "ubhashini Venugopalan"}, {"color": "#6FA8DC", "id": "SOM", "label": "SOM", "shape": "dot", "size": 10.714285714285714, "title": "SOM"}, {"color": "#6FA8DC", "id": "Semantic Obviousness Metric", "label": "Semantic Obviousness Metric", "shape": "dot", "size": 10.089285714285714, "title": "Semantic Obviousness Metric"}, {"color": "#6FA8DC", "id": "Image Quality Assessment", "label": "Image Quality Assessment", "shape": "dot", "size": 10.089285714285714, "title": "Image Quality Assessment"}, {"color": "#6FA8DC", "id": "Peng Zhang", "label": "Peng Zhang", "shape": "dot", "size": 10.178571428571429, "title": "Peng Zhang"}, {"color": "#6FA8DC", "id": "Wengang Zhou", "label": "Wengang Zhou", "shape": "dot", "size": 10.178571428571429, "title": "Wengang Zhou"}, {"color": "#6FA8DC", "id": "Lei Wu", "label": "Lei Wu", "shape": "dot", "size": 10.178571428571429, "title": "Lei Wu"}, {"color": "#6FA8DC", "id": "Houqiang Li", "label": "Houqiang Li", "shape": "dot", "size": 10.178571428571429, "title": "Houqiang Li"}, {"color": "#6FA8DC", "id": "Zhang_SOM_Semantic_Obviousness_2015_CVPR_paper.pdf", "label": "Zhang_SOM_Semantic_Obviousness_2015_CVPR_paper.pdf", "shape": "dot", "size": 10.089285714285714, "title": "Zhang_SOM_Semantic_Obviousness_2015_CVPR_paper.pdf"}, {"color": "#6FA8DC", "id": "Image quality assessment (IQA)", "label": "Image quality assessment (IQA)", "shape": "dot", "size": 10.178571428571429, "title": "Image quality assessment (IQA)"}, {"color": "#6FA8DC", "id": "objectively estimate human perception", "label": "objectively estimate human perception", "shape": "dot", "size": 10.089285714285714, "title": "objectively estimate human perception"}, {"color": "#6FA8DC", "id": "new no-referece (NR) image quality assessment (IQA) framework", "label": "new no-referece (NR) image quality assessment (IQA) framework", "shape": "dot", "size": 10.089285714285714, "title": "new no-referece (NR) image quality assessment (IQA) framework"}, {"color": "#6FA8DC", "id": "no-referece (NR) image quality assessment (IQA) framework", "label": "no-referece (NR) image quality assessment (IQA) framework", "shape": "dot", "size": 10.089285714285714, "title": "no-referece (NR) image quality assessment (IQA) framework"}, {"color": "#6FA8DC", "id": "semantic obviousness", "label": "semantic obviousness", "shape": "dot", "size": 10.178571428571429, "title": "semantic obviousness"}, {"color": "#6FA8DC", "id": "semantic-level factors", "label": "semantic-level factors", "shape": "dot", "size": 10.089285714285714, "title": "semantic-level factors"}, {"color": "#6FA8DC", "id": "human perception of image quality", "label": "human perception of image quality", "shape": "dot", "size": 10.089285714285714, "title": "human perception of image quality"}, {"color": "#6FA8DC", "id": "local characteristics", "label": "local characteristics", "shape": "dot", "size": 10.089285714285714, "title": "local characteristics"}, {"color": "#6FA8DC", "id": "LIVE dataset", "label": "LIVE dataset", "shape": "dot", "size": 10.089285714285714, "title": "LIVE dataset"}, {"color": "#6FA8DC", "id": "comparable results", "label": "comparable results", "shape": "dot", "size": 10.357142857142858, "title": "comparable results"}, {"color": "#6FA8DC", "id": "existing NR-IQA algorithms", "label": "existing NR-IQA algorithms", "shape": "dot", "size": 10.089285714285714, "title": "existing NR-IQA algorithms"}, {"color": "#6FA8DC", "id": "state-of-the-art full-referece IQA (FR-IQA) methods", "label": "state-of-the-art full-referece IQA (FR-IQA) methods", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art full-referece IQA (FR-IQA) methods"}, {"color": "#6FA8DC", "id": "generalization ability", "label": "generalization ability", "shape": "dot", "size": 10.178571428571429, "title": "generalization ability"}, {"color": "#6FA8DC", "id": "NR-IQA algorithms", "label": "NR-IQA algorithms", "shape": "dot", "size": 10.178571428571429, "title": "NR-IQA algorithms"}, {"color": "#6FA8DC", "id": "IQA algorithms", "label": "IQA algorithms", "shape": "dot", "size": 10.089285714285714, "title": "IQA algorithms"}, {"color": "#6FA8DC", "id": "full-referece IQA (FR-IQA) methods", "label": "full-referece IQA (FR-IQA) methods", "shape": "dot", "size": 10.089285714285714, "title": "full-referece IQA (FR-IQA) methods"}, {"color": "#6FA8DC", "id": "IQA methods", "label": "IQA methods", "shape": "dot", "size": 10.089285714285714, "title": "IQA methods"}, {"color": "#6FA8DC", "id": "Image Quality Assessment (IQA)", "label": "Image Quality Assessment (IQA)", "shape": "dot", "size": 10.089285714285714, "title": "Image Quality Assessment (IQA)"}, {"color": "#6FA8DC", "id": "assessment method", "label": "assessment method", "shape": "dot", "size": 10.089285714285714, "title": "assessment method"}, {"color": "#6FA8DC", "id": "No-Reference Image Quality Assessment (NR-IQA)", "label": "No-Reference Image Quality Assessment (NR-IQA)", "shape": "dot", "size": 10.089285714285714, "title": "No-Reference Image Quality Assessment (NR-IQA)"}, {"color": "#6FA8DC", "id": "IQA method", "label": "IQA method", "shape": "dot", "size": 10.089285714285714, "title": "IQA method"}, {"color": "#6FA8DC", "id": "existing algorithms", "label": "existing algorithms", "shape": "dot", "size": 10.089285714285714, "title": "existing algorithms"}, {"color": "#6FA8DC", "id": "NR-IQA", "label": "NR-IQA", "shape": "dot", "size": 10.089285714285714, "title": "NR-IQA"}, {"color": "#6FA8DC", "id": "pzhangoo@mail.ustc.edu.cn", "label": "pzhangoo@mail.ustc.edu.cn", "shape": "dot", "size": 10.089285714285714, "title": "pzhangoo@mail.ustc.edu.cn"}, {"color": "#6FA8DC", "id": "zhwg@ustc.edu.cn", "label": "zhwg@ustc.edu.cn", "shape": "dot", "size": 10.089285714285714, "title": "zhwg@ustc.edu.cn"}, {"color": "#6FA8DC", "id": "wuleibig@gmail.com", "label": "wuleibig@gmail.com", "shape": "dot", "size": 10.089285714285714, "title": "wuleibig@gmail.com"}, {"color": "#6FA8DC", "id": "lihq@ustc.edu.cn", "label": "lihq@ustc.edu.cn", "shape": "dot", "size": 10.089285714285714, "title": "lihq@ustc.edu.cn"}, {"color": "#6FA8DC", "id": "Damien Teney", "label": "Damien Teney", "shape": "dot", "size": 10.089285714285714, "title": "Damien Teney"}, {"color": "#6FA8DC", "id": "Learning Similarity Metrics", "label": "Learning Similarity Metrics", "shape": "dot", "size": 10.267857142857142, "title": "Learning Similarity Metrics"}, {"color": "#6FA8DC", "id": "Matthew Brown", "label": "Matthew Brown", "shape": "dot", "size": 10.089285714285714, "title": "Matthew Brown"}, {"color": "#6FA8DC", "id": "Dynamic Scene Segmentation", "label": "Dynamic Scene Segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Dynamic Scene Segmentation"}, {"color": "#6FA8DC", "id": "dynamic textures", "label": "dynamic textures", "shape": "dot", "size": 10.267857142857142, "title": "dynamic textures"}, {"color": "#6FA8DC", "id": "complex patterns", "label": "complex patterns", "shape": "dot", "size": 10.089285714285714, "title": "complex patterns"}, {"color": "#6FA8DC", "id": "spatiotemporal filters", "label": "spatiotemporal filters", "shape": "dot", "size": 10.089285714285714, "title": "spatiotemporal filters"}, {"color": "#6FA8DC", "id": "metric-learning framework", "label": "metric-learning framework", "shape": "dot", "size": 10.178571428571429, "title": "metric-learning framework"}, {"color": "#6FA8DC", "id": "hierarchical", "label": "hierarchical", "shape": "dot", "size": 10.089285714285714, "title": "hierarchical"}, {"color": "#6FA8DC", "id": "graph-based", "label": "graph-based", "shape": "dot", "size": 10.089285714285714, "title": "graph-based"}, {"color": "#6FA8DC", "id": "applicability to object segmentation", "label": "applicability to object segmentation", "shape": "dot", "size": 10.089285714285714, "title": "applicability to object segmentation"}, {"color": "#6FA8DC", "id": "object and motion segmentation", "label": "object and motion segmentation", "shape": "dot", "size": 10.357142857142858, "title": "object and motion segmentation"}, {"color": "#6FA8DC", "id": "general object and motion segmentation", "label": "general object and motion segmentation", "shape": "dot", "size": 10.089285714285714, "title": "general object and motion segmentation"}, {"color": "#6FA8DC", "id": "unsupervised segmentation", "label": "unsupervised segmentation", "shape": "dot", "size": 10.089285714285714, "title": "unsupervised segmentation"}, {"color": "#6FA8DC", "id": "best task-specific approaches", "label": "best task-specific approaches", "shape": "dot", "size": 10.089285714285714, "title": "best task-specific approaches"}, {"color": "#6FA8DC", "id": "object identification", "label": "object identification", "shape": "dot", "size": 10.089285714285714, "title": "object identification"}, {"color": "#6FA8DC", "id": "motion analysis", "label": "motion analysis", "shape": "dot", "size": 10.178571428571429, "title": "motion analysis"}, {"color": "#6FA8DC", "id": "task-specific approaches", "label": "task-specific approaches", "shape": "dot", "size": 10.089285714285714, "title": "task-specific approaches"}, {"color": "#6FA8DC", "id": "Dynamic textures", "label": "Dynamic textures", "shape": "dot", "size": 10.357142857142858, "title": "Dynamic textures"}, {"color": "#6FA8DC", "id": "Spatio-temporal filters", "label": "Spatio-temporal filters", "shape": "dot", "size": 10.089285714285714, "title": "Spatio-temporal filters"}, {"color": "#6FA8DC", "id": "Metric learning", "label": "Metric learning", "shape": "dot", "size": 10.089285714285714, "title": "Metric learning"}, {"color": "#6FA8DC", "id": "Graph-based segmentation", "label": "Graph-based segmentation", "shape": "dot", "size": 10.089285714285714, "title": "Graph-based segmentation"}, {"color": "#6FA8DC", "id": "Alpert et al. (2007)", "label": "Alpert et al. (2007)", "shape": "dot", "size": 10.089285714285714, "title": "Alpert et al. (2007)"}, {"color": "#6FA8DC", "id": "Brox \u0026 Malik (2010)", "label": "Brox \u0026 Malik (2010)", "shape": "dot", "size": 10.089285714285714, "title": "Brox \u0026 Malik (2010)"}, {"color": "#6FA8DC", "id": "Chan \u0026 Vasconcelos (2008)", "label": "Chan \u0026 Vasconcelos (2008)", "shape": "dot", "size": 10.089285714285714, "title": "Chan \u0026 Vasconcelos (2008)"}, {"color": "#6FA8DC", "id": "Chan \u0026 Vasconcelos (2009)", "label": "Chan \u0026 Vasconcelos (2009)", "shape": "dot", "size": 10.089285714285714, "title": "Chan \u0026 Vasconcelos (2009)"}, {"color": "#6FA8DC", "id": "textures", "label": "textures", "shape": "dot", "size": 10.089285714285714, "title": "textures"}, {"color": "#6FA8DC", "id": "Variational layered dynamic textures", "label": "Variational layered dynamic textures", "shape": "dot", "size": 10.178571428571429, "title": "Variational layered dynamic textures"}, {"color": "#6FA8DC", "id": "Corso", "label": "Corso", "shape": "dot", "size": 10.089285714285714, "title": "Corso"}, {"color": "#6FA8DC", "id": "CVPR tutorial on video segmentation", "label": "CVPR tutorial on video segmentation", "shape": "dot", "size": 10.089285714285714, "title": "CVPR tutorial on video segmentation"}, {"color": "#6FA8DC", "id": "Spacetime texture representation and recognition", "label": "Spacetime texture representation and recognition", "shape": "dot", "size": 10.178571428571429, "title": "Spacetime texture representation and recognition"}, {"color": "#6FA8DC", "id": "Dynamic texture detection based on motion analysis", "label": "Dynamic texture detection based on motion analysis", "shape": "dot", "size": 10.089285714285714, "title": "Dynamic texture detection based on motion analysis"}, {"color": "#6FA8DC", "id": "spatio-temporal orientation analysis", "label": "spatio-temporal orientation analysis", "shape": "dot", "size": 10.089285714285714, "title": "spatio-temporal orientation analysis"}, {"color": "#6FA8DC", "id": "Dynamic texture detection", "label": "Dynamic texture detection", "shape": "dot", "size": 10.357142857142858, "title": "Dynamic texture detection"}, {"color": "#6FA8DC", "id": "S.", "label": "S.", "shape": "dot", "size": 10.089285714285714, "title": "S."}, {"color": "#6FA8DC", "id": "Wu, Y. N.", "label": "Wu, Y. N.", "shape": "dot", "size": 10.089285714285714, "title": "Wu, Y. N."}, {"color": "#6FA8DC", "id": "Fazekas, S.", "label": "Fazekas, S.", "shape": "dot", "size": 10.089285714285714, "title": "Fazekas, S."}, {"color": "#6FA8DC", "id": "Amiatz, T.", "label": "Amiatz, T.", "shape": "dot", "size": 10.089285714285714, "title": "Amiatz, T."}, {"color": "#6FA8DC", "id": "Chetverikov, D.", "label": "Chetverikov, D.", "shape": "dot", "size": 10.089285714285714, "title": "Chetverikov, D."}, {"color": "#6FA8DC", "id": "Feichtenhofer, C.", "label": "Feichtenhofer, C.", "shape": "dot", "size": 10.089285714285714, "title": "Feichtenhofer, C."}, {"color": "#6FA8DC", "id": "Bags of spacetime energies", "label": "Bags of spacetime energies", "shape": "dot", "size": 10.267857142857142, "title": "Bags of spacetime energies"}, {"color": "#6FA8DC", "id": "Pinz, A.", "label": "Pinz, A.", "shape": "dot", "size": 10.089285714285714, "title": "Pinz, A."}, {"color": "#6FA8DC", "id": "Wilides, R.", "label": "Wilides, R.", "shape": "dot", "size": 10.089285714285714, "title": "Wilides, R."}, {"color": "#6FA8DC", "id": "Teney, Damien", "label": "Teney, Damien", "shape": "dot", "size": 10.089285714285714, "title": "Teney, Damien"}, {"color": "#6FA8DC", "id": "Brown, Matthew", "label": "Brown, Matthew", "shape": "dot", "size": 10.089285714285714, "title": "Brown, Matthew"}, {"color": "#6FA8DC", "id": "University of Bath", "label": "University of Bath", "shape": "dot", "size": 10.267857142857142, "title": "University of Bath"}, {"color": "#6FA8DC", "id": "Kit, Dimitry", "label": "Kit, Dimitry", "shape": "dot", "size": 10.089285714285714, "title": "Kit, Dimitry"}, {"color": "#6FA8DC", "id": "Hall, Peter", "label": "Hall, Peter", "shape": "dot", "size": 10.089285714285714, "title": "Hall, Peter"}, {"color": "#6FA8DC", "id": "Li, Yang", "label": "Li, Yang", "shape": "dot", "size": 10.089285714285714, "title": "Li, Yang"}, {"color": "#6FA8DC", "id": "Reliable Patch Tracers", "label": "Reliable Patch Tracers", "shape": "dot", "size": 10.267857142857142, "title": "Reliable Patch Tracers"}, {"color": "#6FA8DC", "id": "Zhu, Jianke", "label": "Zhu, Jianke", "shape": "dot", "size": 10.089285714285714, "title": "Zhu, Jianke"}, {"color": "#6FA8DC", "id": "Hoi, Steven C.H.", "label": "Hoi, Steven C.H.", "shape": "dot", "size": 10.089285714285714, "title": "Hoi, Steven C.H."}, {"color": "#6FA8DC", "id": "modern trackers", "label": "modern trackers", "shape": "dot", "size": 10.089285714285714, "title": "modern trackers"}, {"color": "#6FA8DC", "id": "tracking results", "label": "tracking results", "shape": "dot", "size": 10.089285714285714, "title": "tracking results"}, {"color": "#6FA8DC", "id": "Reliable Patch Tracers (RPT)", "label": "Reliable Patch Tracers (RPT)", "shape": "dot", "size": 10.178571428571429, "title": "Reliable Patch Tracers (RPT)"}, {"color": "#6FA8DC", "id": "tracking method", "label": "tracking method", "shape": "dot", "size": 10.089285714285714, "title": "tracking method"}, {"color": "#6FA8DC", "id": "identify reliable patches", "label": "identify reliable patches", "shape": "dot", "size": 10.089285714285714, "title": "identify reliable patches"}, {"color": "#6FA8DC", "id": "reliable patches", "label": "reliable patches", "shape": "dot", "size": 10.178571428571429, "title": "reliable patches"}, {"color": "#6FA8DC", "id": "tracked effectively", "label": "tracked effectively", "shape": "dot", "size": 10.089285714285714, "title": "tracked effectively"}, {"color": "#6FA8DC", "id": "tracking reliability metric", "label": "tracking reliability metric", "shape": "dot", "size": 10.089285714285714, "title": "tracking reliability metric"}, {"color": "#6FA8DC", "id": "reliability of patch", "label": "reliability of patch", "shape": "dot", "size": 10.089285714285714, "title": "reliability of patch"}, {"color": "#6FA8DC", "id": "probability model", "label": "probability model", "shape": "dot", "size": 10.178571428571429, "title": "probability model"}, {"color": "#6FA8DC", "id": "distribution of reliable patches", "label": "distribution of reliable patches", "shape": "dot", "size": 10.089285714285714, "title": "distribution of reliable patches"}, {"color": "#6FA8DC", "id": "sequential Monte Carlo framework", "label": "sequential Monte Carlo framework", "shape": "dot", "size": 10.089285714285714, "title": "sequential Monte Carlo framework"}, {"color": "#6FA8DC", "id": "motion trajectories", "label": "motion trajectories", "shape": "dot", "size": 10.089285714285714, "title": "motion trajectories"}, {"color": "#6FA8DC", "id": "reliable patches from background", "label": "reliable patches from background", "shape": "dot", "size": 10.089285714285714, "title": "reliable patches from background"}, {"color": "#6FA8DC", "id": "visual object", "label": "visual object", "shape": "dot", "size": 10.089285714285714, "title": "visual object"}, {"color": "#6FA8DC", "id": "cluster", "label": "cluster", "shape": "dot", "size": 10.089285714285714, "title": "cluster"}, {"color": "#6FA8DC", "id": "Visual Object Tracking", "label": "Visual Object Tracking", "shape": "dot", "size": 10.089285714285714, "title": "Visual Object Tracking"}, {"color": "#6FA8DC", "id": "state-of-the-art trackers", "label": "state-of-the-art trackers", "shape": "dot", "size": 10.089285714285714, "title": "state-of-the-art trackers"}, {"color": "#6FA8DC", "id": "source code", "label": "source code", "shape": "dot", "size": 10.089285714285714, "title": "source code"}, {"color": "#6FA8DC", "id": "public", "label": "public", "shape": "dot", "size": 10.089285714285714, "title": "public"}, {"color": "#6FA8DC", "id": "Adam, A., Rivlin, E., \u0026 Shimshoni, I. (2006)", "label": "Adam, A., Rivlin, E., \u0026 Shimshoni, I. (2006)", "shape": "dot", "size": 10.089285714285714, "title": "Adam, A., Rivlin, E., \u0026 Shimshoni, I. (2006)"}, {"color": "#6FA8DC", "id": "Robust fragments-based tracking", "label": "Robust fragments-based tracking", "shape": "dot", "size": 10.178571428571429, "title": "Robust fragments-based tracking"}, {"color": "#6FA8DC", "id": "Lucas, B. D., \u0026 Kanade, T. (1981)", "label": "Lucas, B. D., \u0026 Kanade, T. (1981)", "shape": "dot", "size": 10.089285714285714, "title": "Lucas, B. D., \u0026 Kanade, T. (1981)"}, {"color": "#6FA8DC", "id": "iterative image registration technique", "label": "iterative image registration technique", "shape": "dot", "size": 10.089285714285714, "title": "iterative image registration technique"}, {"color": "#6FA8DC", "id": "Poling, B., Lerman, G., \u0026 Szlarm, A. (2014)", "label": "Poling, B., Lerman, G., \u0026 Szlarm, A. (2014)", "shape": "dot", "size": 10.089285714285714, "title": "Poling, B., Lerman, G., \u0026 Szlarm, A. (2014)"}, {"color": "#6FA8DC", "id": "Better feature tracking", "label": "Better feature tracking", "shape": "dot", "size": 10.089285714285714, "title": "Better feature tracking"}, {"color": "#6FA8DC", "id": "Cai, Z., Wen, L., Yang, J., Lei, Z., \u0026 Li, S. (2012)", "label": "Cai, Z., Wen, L., Yang, J., Lei, Z., \u0026 Li, S. (2012)", "shape": "dot", "size": 10.089285714285714, "title": "Cai, Z., Wen, L., Yang, J., Lei, Z., \u0026 Li, S. (2012)"}, {"color": "#6FA8DC", "id": "Structured visual tracking", "label": "Structured visual tracking", "shape": "dot", "size": 10.089285714285714, "title": "Structured visual tracking"}, {"color": "#6FA8DC", "id": "integral histogram", "label": "integral histogram", "shape": "dot", "size": 10.089285714285714, "title": "integral histogram"}, {"color": "#6FA8DC", "id": "Sequential Monte Carlo Methods in Practice", "label": "Sequential Monte Carlo Methods in Practice", "shape": "dot", "size": 10.089285714285714, "title": "Sequential Monte Carlo Methods in Practice"}, {"color": "#6FA8DC", "id": "Sequential Monte Carlo Framework", "label": "Sequential Monte Carlo Framework", "shape": "dot", "size": 10.089285714285714, "title": "Sequential Monte Carlo Framework"}, {"color": "#6FA8DC", "id": "Szlarm", "label": "Szlarm", "shape": "dot", "size": 10.089285714285714, "title": "Szlarm"}, {"color": "#6FA8DC", "id": "Cai et al.", "label": "Cai et al.", "shape": "dot", "size": 10.089285714285714, "title": "Cai et al."}, {"color": "#6FA8DC", "id": "ACCV", "label": "ACCV", "shape": "dot", "size": 10.089285714285714, "title": "ACCV"}, {"color": "#6FA8DC", "id": "Mannning et al.", "label": "Mannning et al.", "shape": "dot", "size": 10.089285714285714, "title": "Mannning et al."}, {"color": "#6FA8DC", "id": "Introduction to Information Retrieval", "label": "Introduction to Information Retrieval", "shape": "dot", "size": 10.089285714285714, "title": "Introduction to Information Retrieval"}, {"color": "#6FA8DC", "id": "Danelljan et al.", "label": "Danelljan et al.", "shape": "dot", "size": 10.089285714285714, "title": "Danelljan et al."}, {"color": "#6FA8DC", "id": "Everingham et al.", "label": "Everingham et al.", "shape": "dot", "size": 10.089285714285714, "title": "Everingham et al."}, {"color": "#6FA8DC", "id": "The pascal visual object classes(voc) challenge", "label": "The pascal visual object classes(voc) challenge", "shape": "dot", "size": 10.089285714285714, "title": "The pascal visual object classes(voc) challenge"}, {"color": "#6FA8DC", "id": "Grundmann et al.", "label": "Grundmann et al.", "shape": "dot", "size": 10.089285714285714, "title": "Grundmann et al."}, {"color": "#6FA8DC", "id": "Yang Li", "label": "Yang Li", "shape": "dot", "size": 10.267857142857142, "title": "Yang Li"}, {"color": "#6FA8DC", "id": "College of Computer Science", "label": "College of Computer Science", "shape": "dot", "size": 10.178571428571429, "title": "College of Computer Science"}, {"color": "#6FA8DC", "id": "liyang89@zju.edu.cn", "label": "liyang89@zju.edu.cn", "shape": "dot", "size": 10.089285714285714, "title": "liyang89@zju.edu.cn"}, {"color": "#6FA8DC", "id": "Jianke Zhu", "label": "Jianke Zhu", "shape": "dot", "size": 10.089285714285714, "title": "Jianke Zhu"}, {"color": "#6FA8DC", "id": "V.", "label": "V.", "shape": "dot", "size": 10.089285714285714, "title": "V."}, {"color": "#6FA8DC", "id": "Han, M.", "label": "Han, M.", "shape": "dot", "size": 10.089285714285714, "title": "Han, M."}, {"color": "#6FA8DC", "id": "Essa, I.", "label": "Essa, I.", "shape": "dot", "size": 10.089285714285714, "title": "Essa, I."}, {"color": "#6FA8DC", "id": "SALICON", "label": "SALICON", "shape": "dot", "size": 10.267857142857142, "title": "SALICON"}, {"color": "#6FA8DC", "id": "understand and predict visual attention", "label": "understand and predict visual attention", "shape": "dot", "size": 10.089285714285714, "title": "understand and predict visual attention"}, {"color": "#6FA8DC", "id": "collecting large-scale human data", "label": "collecting large-scale human data", "shape": "dot", "size": 10.089285714285714, "title": "collecting large-scale human data"}, {"color": "#6FA8DC", "id": "mouse-contingent paradigm", "label": "mouse-contingent paradigm", "shape": "dot", "size": 10.089285714285714, "title": "mouse-contingent paradigm"}, {"color": "#6FA8DC", "id": "eye tracker", "label": "eye tracker", "shape": "dot", "size": 10.089285714285714, "title": "eye tracker"}, {"color": "#6FA8DC", "id": "SALICON dataset", "label": "SALICON dataset", "shape": "dot", "size": 10.446428571428571, "title": "SALICON dataset"}, {"color": "#6FA8DC", "id": "human \u0027free-viewing\u0027 data", "label": "human \u0027free-viewing\u0027 data", "shape": "dot", "size": 10.089285714285714, "title": "human \u0027free-viewing\u0027 data"}, {"color": "#6FA8DC", "id": "10,000 images", "label": "10,000 images", "shape": "dot", "size": 10.089285714285714, "title": "10,000 images"}, {"color": "#6FA8DC", "id": "Microsoft COCO dataset", "label": "Microsoft COCO dataset", "shape": "dot", "size": 10.089285714285714, "title": "Microsoft COCO dataset"}, {"color": "#6FA8DC", "id": "ground truth for evaluating salience algorithms", "label": "ground truth for evaluating salience algorithms", "shape": "dot", "size": 10.089285714285714, "title": "ground truth for evaluating salience algorithms"}, {"color": "#6FA8DC", "id": "existing annotations", "label": "existing annotations", "shape": "dot", "size": 10.178571428571429, "title": "existing annotations"}, {"color": "#6FA8DC", "id": "new possibilities for visual understanding", "label": "new possibilities for visual understanding", "shape": "dot", "size": 10.089285714285714, "title": "new possibilities for visual understanding"}, {"color": "#6FA8DC", "id": "ground truth", "label": "ground truth", "shape": "dot", "size": 10.089285714285714, "title": "ground truth"}, {"color": "#6FA8DC", "id": "new possibilities", "label": "new possibilities", "shape": "dot", "size": 10.089285714285714, "title": "new possibilities"}, {"color": "#6FA8DC", "id": "Ming Jiang", "label": "Ming Jiang", "shape": "dot", "size": 10.089285714285714, "title": "Ming Jiang"}, {"color": "#6FA8DC", "id": "Shengshen Huang", "label": "Shengshen Huang", "shape": "dot", "size": 10.089285714285714, "title": "Shengshen Huang"}, {"color": "#6FA8DC", "id": "Juanyong Duan", "label": "Juanyong Duan", "shape": "dot", "size": 10.089285714285714, "title": "Juanyong Duan"}, {"color": "#6FA8DC", "id": "Qi Zhao", "label": "Qi Zhao", "shape": "dot", "size": 10.089285714285714, "title": "Qi Zhao"}, {"color": "#6FA8DC", "id": "Deep LAC", "label": "Deep LAC", "shape": "dot", "size": 10.982142857142858, "title": "Deep LAC"}, {"color": "#6FA8DC", "id": "fine-grained recognition", "label": "fine-grained recognition", "shape": "dot", "size": 10.089285714285714, "title": "fine-grained recognition"}, {"color": "#6FA8DC", "id": "Di Lin", "label": "Di Lin", "shape": "dot", "size": 10.089285714285714, "title": "Di Lin"}, {"color": "#6FA8DC", "id": "Xiaoyong Shen", "label": "Xiaoyong Shen", "shape": "dot", "size": 10.178571428571429, "title": "Xiaoyong Shen"}, {"color": "#6FA8DC", "id": "Cewu Lu", "label": "Cewu Lu", "shape": "dot", "size": 10.089285714285714, "title": "Cewu Lu"}, {"color": "#6FA8DC", "id": "Fine-grained Recognition", "label": "Fine-grained Recognition", "shape": "dot", "size": 10.089285714285714, "title": "Fine-grained Recognition"}, {"color": "#6FA8DC", "id": "Lin_Deep_LAC_Deep_2015_CVPR_paper", "label": "Lin_Deep_LAC_Deep_2015_CVPR_paper", "shape": "dot", "size": 10.089285714285714, "title": "Lin_Deep_LAC_Deep_2015_CVPR_paper"}, {"color": "#6FA8DC", "id": "ineering", "label": "ineering", "shape": "dot", "size": 10.089285714285714, "title": "ineering"}, {"color": "#6FA8DC", "id": "eleqiz@nus.edu.sg", "label": "eleqiz@nus.edu.sg", "shape": "dot", "size": 10.089285714285714, "title": "eleqiz@nus.edu.sg"}, {"color": "#6FA8DC", "id": "Localization", "label": "Localization", "shape": "dot", "size": 10.089285714285714, "title": "Localization"}, {"color": "#6FA8DC", "id": "Classification", "label": "Classification", "shape": "dot", "size": 10.089285714285714, "title": "Classification"}, {"color": "#6FA8DC", "id": "fine-grained recognition system", "label": "fine-grained recognition system", "shape": "dot", "size": 10.267857142857142, "title": "fine-grained recognition system"}, {"color": "#6FA8DC", "id": "part localization", "label": "part localization", "shape": "dot", "size": 10.089285714285714, "title": "part localization"}, {"color": "#6FA8DC", "id": "valve linkage function", "label": "valve linkage function", "shape": "dot", "size": 10.446428571428571, "title": "valve linkage function"}, {"color": "#6FA8DC", "id": "back-propagation chaining", "label": "back-propagation chaining", "shape": "dot", "size": 10.089285714285714, "title": "back-propagation chaining"}, {"color": "#6FA8DC", "id": "deep LAC system", "label": "deep LAC system", "shape": "dot", "size": 10.089285714285714, "title": "deep LAC system"}, {"color": "#6FA8DC", "id": "classification errors", "label": "classification errors", "shape": "dot", "size": 10.089285714285714, "title": "classification errors"}, {"color": "#6FA8DC", "id": "alignment errors", "label": "alignment errors", "shape": "dot", "size": 10.089285714285714, "title": "alignment errors"}, {"color": "#6FA8DC", "id": "update localization", "label": "update localization", "shape": "dot", "size": 10.089285714285714, "title": "update localization"}, {"color": "#6FA8DC", "id": "LAC system", "label": "LAC system", "shape": "dot", "size": 10.089285714285714, "title": "LAC system"}, {"color": "#6FA8DC", "id": "fine-grained object data", "label": "fine-grained object data", "shape": "dot", "size": 10.089285714285714, "title": "fine-grained object data"}]);
                  edges = new vis.DataSet([{"arrows": "to", "color": "#4CAF50", "from": "Saurabh Singh", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Saurabh Singh", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Illinois, Urbana-Champaign", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Saurabh Singh", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Indiana", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Learning a Sequential Search for Landmarks", "label": "is_conference_paper", "title": "Relation: is_conference_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Learning a Sequential Search for Landmarks", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Derek Hoiem", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Derek Hoiem", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Illinois, Urbana-Champaign", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Derek Hoiem", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Indiana", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Derek Hoiem", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Derek Hoiem", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Illinois at Urbana-Champaign", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "David Forsyth", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "David Forsyth", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Illinois, Urbana-Champaign", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "David Forsyth", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Indiana", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_conference", "title": "Relation: is_conference\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gool, L. (2013)", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Bayesian color constancy revisited", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Efficient belief propagation", "width": 5.0}, {"arrows": "to", "color": "#2196F3", "from": "CVPR", "label": "is_conference_of", "title": "Relation: is_conference_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "CVPR", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "conference", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_publication_venue_for", "title": "Relation: is_publication_venue_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "reference [3]", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "multi-column deep neural networks", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "CVPR", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Image Co-segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Visual semantic search", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "person re-identi\ufb01cation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Entropy rate superpixel segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "tric min-cuts paper", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Beyond lambert", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_publication_venue", "title": "Relation: is_publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "research paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Furukawa et al.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "constrained parametric min-cuts", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Variational layered dynamic textures", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Glaucoma", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Glaucoma", "label": "is_analyzed_by", "title": "Relation: is_analyzed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Deep Multiple Instance Learning", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Sequential Search", "label": "is_technique_in", "title": "Relation: is_technique_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Landmarks", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Ollama", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Learning a Sequential Search for Landmarks", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "aims_to_find", "title": "Relation: aims_to_find\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "landmarks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "appearance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "parsing human body layouts", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "finding landmarks in images of birds", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "sequential search", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "spatial model", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "displays", "title": "Relation: displays\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "strong performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "model problems", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "state-of-the-art results", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "applicable_to", "title": "Relation: applicable_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "contour detection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "lacks", "title": "Relation: lacks\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "feature engineering", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "aims_to_achieve", "title": "Relation: aims_to_achieve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "subpixel-level accuracy", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "robustness", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "sparsified_in", "title": "Relation: sparsified_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "images", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "separates", "title": "Relation: separates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "sparse error tensors", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "limitations", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "traditional methods", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "localizes", "title": "Relation: localizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "ground-level query images", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "matches", "title": "Relation: matches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "aerial imagery", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "feature representation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "border ownership assignment", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Structured Random Forests (SRF)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "border ownership structure", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "shape descriptors", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "spectral properties", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "semi-global grouping cues", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Berkeley Segmentation Dataset (BSDS)", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "NYU Depth V2 dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "multi-stage approaches", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "scale invariance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "four simple color features", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "regression trees", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "shows", "title": "Relation: shows\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "high percentage of outliers", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "16x speedup", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deformable Part Model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates_applicability_for", "title": "Relation: demonstrates_applicability_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "parallel computing", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "segments", "title": "Relation: segments\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "frame", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "adjusts", "title": "Relation: adjusts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "enhancement of regions", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "high fidelity", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "temporal consistency", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "applied to", "title": "Relation: applied to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "texture classification", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated on", "title": "Relation: evaluated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "KTH-TIPS2 dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated on", "title": "Relation: evaluated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "FMD dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated on", "title": "Relation: evaluated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "DTD dataset", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "convolutional temporal feature pooling architectures", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "models", "title": "Relation: models\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "video", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "tested on", "title": "Relation: tested on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "datasets", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "unseen target crowd scene", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "fine-tunes", "title": "Relation: fine-tunes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "trained CNN model", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "dense depth optimization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "removes_need_for", "title": "Relation: removes_need_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "view pairing", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "removes_need_for", "title": "Relation: removes_need_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "stereo depth estimation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "allows_for", "title": "Relation: allows_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "per-image paralleization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "is_not_specific_to", "title": "Relation: is_not_specific_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "SfM points", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "work on depth", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "synthesized right views", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "local tangent planes", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "is_composed_of", "title": "Relation: is_composed_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "two steps", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "high completion rate", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "lowest errors", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrated through", "title": "Relation: demonstrated through\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "experimental results", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "replaces", "title": "Relation: replaces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "geodesic-preserving term", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "optical flow field", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "revitalizes", "title": "Relation: revitalizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "piecewise parametric flow model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "homogeneous motions", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "complex motions", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "equity constraint", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "top-tier performances", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Optical flow benchmarks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "unsupervised video salieny detection method", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "human activity recognition", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "training of activity detection algorithms", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "challenging datasets", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "favorable performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "3D pose from 2D joint locations", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "over-complete dictionary of poses", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "shows", "title": "Relation: shows\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "good generalization", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "parameterizes", "title": "Relation: parameterizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "body pose", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D pose", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "over-completes dictionary of poses", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "avoids", "title": "Relation: avoids\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "impossible poses", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compared with", "title": "Relation: compared with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "recent work", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Mcgill dataset", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "optimization algorithm", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "applies", "title": "Relation: applies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "visual attention", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep neural networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "additional annotations", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "state-of-the-art image restoration methods", "width": 2.8600000000000003}, {"arrows": "to", "color": "#9E9E9E", "from": "method", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: operational\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "learning features", "width": 2.96}, {"arrows": "to", "color": "#9E9E9E", "from": "method", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: operational\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "learning similarity metric", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "state of the art", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "is resistant to", "title": "Relation: is resistant to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "over-fitting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "inspired_by", "title": "Relation: inspired_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "linear discriminant embedding", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "establishes", "title": "Relation: establishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "binary tests", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "method", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "localize object", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "takes_as_input", "title": "Relation: takes_as_input\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "collection of images", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "outputs", "title": "Relation: outputs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "bounding box", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "applies_to", "title": "Relation: applies_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "videos", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "localizes", "title": "Relation: localizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "object", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "transfers", "title": "Relation: transfers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "appearance models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "targets", "title": "Relation: targets\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "unseen objects", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "verified_on", "title": "Relation: verified_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "LFW", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "verified_on", "title": "Relation: verified_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "YouTube Faces", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "RGB-D action datasets", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "shows", "title": "Relation: shows\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "promising results", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "tracking inaccuracies", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "segments", "title": "Relation: segments\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "image", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "projects", "title": "Relation: projects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "GIS data", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "insight", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "min-cuts", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ability to separate specular reflection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "preserves", "title": "Relation: preserves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "saturation of underlying surface colors", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "accurate surface shape estimation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "robustness to light source position errors", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates_utility_in", "title": "Relation: demonstrates_utility_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates_utility_in", "title": "Relation: demonstrates_utility_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "object proposal applications", "width": 2.8}, {"arrows": "to", "color": "#FF5722", "from": "method", "label": "leads_to", "title": "Relation: leads_to\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "better accuracy", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "is_faster_than", "title": "Relation: is_faster_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "dense projections", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "is_faster_than", "title": "Relation: is_faster_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "other methods", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "accuracy", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "method", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "computational cost", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "takes_advantage_of", "title": "Relation: takes_advantage_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "depth data", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "noisy images", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "depth channel", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "detection of object-like regions", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "depth-based local features", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "comparable performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "single input image", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaussian Mixture Model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "reflection removal", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "depth maps", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "visual fidelity", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "operates", "title": "Relation: operates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "four orders of magnitude faster", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "small loss in performance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "limited_by", "title": "Relation: limited_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "runtime", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "stereo approaches", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "optical flow approaches", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "scene flow approaches", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "qualitative results", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compares_to", "title": "Relation: compares_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "state-of-the-art stereo", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compares_to", "title": "Relation: compares_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "optical flow", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "compares_to", "title": "Relation: compares_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "scene flow", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "evaluates_on", "title": "Relation: evaluates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "scene flow dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "localization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "has_speed_up", "title": "Relation: has_speed_up\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "factor of 100", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "builds", "title": "Relation: builds\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "global appearance models", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "establishes", "title": "Relation: establishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "dynamic location models", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "elements within energy minimization framework", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "superiority over existing algorithms", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "novel method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "superior denois-ing accuracy", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "label corruption levels", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "transparent object reconstruction", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "landmarks", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "images of objects", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "sequential search", "label": "localizes", "title": "Relation: localizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "landmarks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "landmark addition", "label": "depends_on", "title": "Relation: depends_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "image", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "object proposal windows", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "groups", "label": "scored_using", "title": "Relation: scored_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "learned function", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "learned function", "label": "used to", "title": "Relation: used to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "expand groups", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "landmark group", "label": "scored using", "title": "Relation: scored using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "learned function", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "scoring function", "label": "learned from", "title": "Relation: learned from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "data labelled with landmarks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "scoring function", "label": "derived from", "title": "Relation: derived from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "data", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "spatial model", "label": "models", "title": "Relation: models\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "kinematics of landmark groups", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "landmark", "label": "part of", "title": "Relation: part of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "landmark group", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "initial landmark", "label": "dependent on", "title": "Relation: dependent on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "image", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "data", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "compressed", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "data", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "projected", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "data", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "2D, 3D and 4D", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "spatial model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "displays", "title": "Relation: displays\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "strong performance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "outliers", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Texture Classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "KTH-TIPS2", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "FMD", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "DTD", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "State-of-the-art approaches", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "adapts_to", "title": "Relation: adapts_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "unknown reflectance maps", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "reconstructs", "title": "Relation: reconstructs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "fine detail", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "adapts_to", "title": "Relation: adapts_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Reflectance Maps", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "reconstructs", "title": "Relation: reconstructs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Fine Detail", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "high completion rate", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "lowest errors", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "operates_in", "title": "Relation: operates_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "noisy cases", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Features", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "State-of-the-Art Performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "generalization power", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "RGB-D action datasets", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "state-of-the-art results", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "shows results", "title": "Relation: shows results\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "missing RGB data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "shows results", "title": "Relation: shows results\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "missing depth data", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "more_accurate_than", "title": "Relation: more_accurate_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Other methods", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "speeds_up", "title": "Relation: speeds_up\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "High-Dimensional Binary Encoding", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "noisy images", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Method", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "single input image", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Andriluka et al. (2009)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "People detection", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Andriluka et al. (2009)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "articulated pose estimation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "articulated pose estimation", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "graphical model", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Barto (1998)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Reinforcement learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb and Huttenlocher (2005)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Pictorial structures", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Fergus et al. (2003)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Unsupervised scale-invariant learning", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Doll\u00b4ar et al. (2009)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Integral channel features", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Eichner and Ferrari (2012)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "collective human pose estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Doll\u00e1r, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Integral channel features", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Doll\u00e1r, P.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "BMVC", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Eichner, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Appearance sharing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fei-Fei, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "One-shot learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fei-Fei, L.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb, P. F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cascade object detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb, P. F.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb, P. F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Object detection grammar", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb, P. F.", "label": "writes_paper", "title": "Relation: writes_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Object detection with grammar models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb, P. F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatively trained part-based models", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb, P. F.", "label": "co_author_of", "title": "Relation: co_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Huttenlocher, D. P.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fergus, R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse object category model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fergus, R.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wang, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple tree models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wang, Y.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "BMVC", "label": "is_conference_of", "title": "Relation: is_conference_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "BMVC", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "conference", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "ECCV", "label": "is_publication_venue_for", "title": "Relation: is_publication_venue_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "reference [1]", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ECCV", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "variant co-occurrence local binary pattern", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ECCV", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "ECCV", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "geospatial image segmentation approach", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Gedas Bertasius", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "DeepEdge", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gedas Bertasius", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Pennsylvania", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "DeepEdge", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Deep Network", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "DeepEdge", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Contour Detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "DeepEdge", "label": "is_for", "title": "Relation: is_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Top-Down Contour Detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "DeepEdge", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "DeepEdge", "label": "has_architecture", "title": "Relation: has_architecture\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Bifurcated Deep Network", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "DeepEdge", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "novel method", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Lorenzo Torresani", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "DeepEdge", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lorenzo Torresani", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Dartmouth College", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Contour detection", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "low-level features", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "novel method", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "speed of image retrieval", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "novel method", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "computationally bounded sparse projections", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "novel method", "label": "adds", "title": "Relation: adds\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "orthogonality constraint", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "novel method", "label": "is_for", "title": "Relation: is_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "template matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art results", "label": "achieved_in", "title": "Relation: achieved_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art results", "label": "achieved_in", "title": "Relation: achieved_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art results", "label": "achieved_in", "title": "Relation: achieved_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "retrieval", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "contour detection", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "object recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "object recognition", "label": "based on", "title": "Relation: based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "conv-net", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "object recognition", "label": "related_task_of", "title": "Relation: related_task_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Action Recognition", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "object recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "pictorial structures", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez et al. (2011)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Contour detection and hierarchical image segmentation", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez et al. (2011)", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Hierarchical Image Segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Lim et al. (2013)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Sketch tokens", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Sketch tokens", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "contour detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Long et al. (2014)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fully convolutional networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Fully convolutional networks", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "semantic segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Malik et al. (2001)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Contour and texture analysis", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Rich Feature Hierarchies", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "feature hierarchies", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Rich feature hierarchies", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Object detection", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Rich feature hierarchies", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Semantic segmentation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Rich feature hierarchies", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Rich feature hierarchies", "label": "published_as", "title": "Relation: published_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "arXiv preprint", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Rich feature hierarchies", "label": "focused_on", "title": "Relation: focused_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Rich feature hierarchies", "label": "focused_on", "title": "Relation: focused_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "semantic segmentation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Donahue", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Darrell", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hariharan", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Hypercolumns", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hariharan", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California, Berkeley", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hypercolumns", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Object Segmentation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Hypercolumns", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Universidad de los Andes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Semantic Segmentation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Iandola", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Densenet", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jia", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Caffe", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Jia", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Large-scale object classification", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Caffe", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Convolutional architecture", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Caffe", "label": "is_architecture_for", "title": "Relation: is_architecture_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "fast feature embedding", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Caffe", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "deep learning framework", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Caffe", "label": "has_application_in", "title": "Relation: has_application_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "computer vision tasks", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Caffe", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Girshik", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Object detection", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Object detection", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Object detection", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "part-based models", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Shelhamer et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Caffe", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ren et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Scale-invariant contour completion", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Scale-invariant contour completion", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Condition random fields", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jianbo Shi", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Pennsylvania", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Wen Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Discrimi nant Analysis", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wen Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Key Laboratory of Intelligent Information Processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wen Wang", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Computing Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wen Wang", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "wen.wang@vipl.ict.ac.cn", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Discrimi nant Analysis", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Gaussian Distributions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Discrimi nant Analysis", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Face Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ruiping Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Discrimi nant Analysis", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ruiping Wang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Wang_Discriminant_Analysis_on_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ruiping Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Key Laboratory of Intelligent Information Processing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ruiping Wang", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Computing Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ruiping Wang", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "wangruiping@ict.ac.cn", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Gaussian Mixture Models", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Riemannian Manifold", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Discriminant Analysis", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Kernel Methods", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Face Recognition", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Image Sets", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Face Recognition", "label": "has_challenge", "title": "Relation: has_challenge\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Pose variation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Face Recognition", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "PEP (Probabilistic Elastic Part) Model", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "is_evaluated_on", "title": "Relation: is_evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "LFW", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "participates_in", "title": "Relation: participates_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "PaSC", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Face Recognition", "label": "benefits_from", "title": "Relation: benefits_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Poisson Editing", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Face Recognition", "label": "improves_performance_with", "title": "Relation: improves_performance_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "3D Morphable Models", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Zhiwu Huang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Wang_Discribminant_Analysis_on_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhiwu Huang", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Computing Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhiwu Huang", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "zhiwu.huang@vipl.ict.ac.cn", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Shiguan Shan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Wang_Discriminant_Analysis_on_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shiguan Shan", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Computing Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shiguan Shan", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "sgshan@ict.ac.cn", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Xilin Chen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Wang_Discriminant_Analysis_on_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xilin Chen", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Computing Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xilin Chen", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "xlchen@ict.ac.cn", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Xilin Chen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Key Laboratory of Intelligent Information Processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "DARG", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "face recognition problem", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "DARG", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "novel method", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "DARG", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "image sets", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "DARG", "label": "discriminates", "title": "Relation: discriminates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Gaussian components", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "image sets", "label": "represented_as", "title": "Relation: represented_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaussian Mixture Models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gaussian distributions", "label": "lie_on", "title": "Relation: lie_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Riemannian manifold", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kernel Discrimiant Analysis", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "probabilistic kernels", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "probabilistic kernels", "label": "encode", "title": "Relation: encode\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "geometry", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "face recognition databases", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "superior performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "state-of-the-art algorithms", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "MultiPIE dataset", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "homogeneous motions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "complex motions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "top-tier performances", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "performs_better_than", "title": "Relation: performs_better_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "state of the art", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "retrieves", "title": "Relation: retrieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "similar 3D models", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "proposed method", "label": "transfers", "title": "Relation: transfers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "symmetries", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "face recognition databases", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "challenging", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "superior performance", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "state-of-the-art approaches", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "superior performance", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "existing methods", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Russian components", "label": "from", "title": "Relation: from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "different subjects", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "prior probabilities", "label": "incorporated_in", "title": "Relation: incorporated_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Russian components", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Kernel Methods", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Aranndi et al. (2005)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Face recognition with image sets using manifold density divergence", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Face recognition with image sets using manifold density divergence", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Face Recognition", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Amar \u0026 Nagaoka (2000)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Methods of Information Geometry", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Methods of Information Geometry", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Information Geometry", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Chan et al. (2004)", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Probabilistic Kernels", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Probabilistic Kernels", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Information Divergence", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Probabilistic KernELS", "label": "based on", "title": "Relation: based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Information Divergence", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Chan, A. B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Probabilistic Kernels", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chan, A. B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Modeling, clustering, and segmenting video", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Moreno, P. J.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Probabilistic Kernels", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cevikalp, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Face Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Triggs, B.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Face Recognition", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Image Sets Alignment", "label": "for", "title": "Relation: for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Video-based Face Recognition", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Cui, Z.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Sets Alignment", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Grassmann Discriminant Analysis", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Subspace-based Learning", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Hamm, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Grassmann Discriminant Analysis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lee, D. D.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Grassmann Discriminant Analysis", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Sparse Approximated Nearest Points", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Image Set Classification", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hu, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Sparse Approximated Nearest Points", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hu, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse approximated nearest points", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hu, Y.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE International Conference on Computer Vision and Pattern Recognized (CVPR)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Harandi, M. T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Grasmannian kernels", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jayasumana, S.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Computer Society on Computer Vision and Pattern Recognition (CVPR)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kim, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Face tracking and recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kim, M.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Key Laboratory of Intelligent Information Processing", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Key Laboratory of Intelligent Information Processing", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Institute of Computing Technology", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chinese Academy of Sciences", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "hanics", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chinese Academy of Sciences", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Beijing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Institute of Computing Technology", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Xiao-Yuan Jing", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Xiaoke Zhu", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Fei Wu", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Xinge You", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Qinglong Liu", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Dong Yue", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Ruimin Hu", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Baowen Xu", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution Person Re-identi\ufb01cation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao-Yuan Jing", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "State Key Laboratory of Software Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaoke Zhu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "State Key Laboratory of Software Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fei Wu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "State Key Laboratory of Software Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xinge You", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Huazhong University of Science and Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Qinglong Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "State Key Laboratory of Software Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dong Yue", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Nanjing University of Posts and Telecommunications", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ruimin Hu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "National Engineering Research Center for Multimedia Software", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Baowen Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "State Key Laboratory of Software Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Baowen Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jing_Super-Resolution_Person_Re-Identification_2015_CVPR_paper.pdf", "label": "is_file_of", "title": "Relation: is_file_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Super-resolution Person Re-identi\ufb01cation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Person re-identification", "label": "is_important_in", "title": "Relation: is_important_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "surveillance applications", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Person re-identification", "label": "is_important_in", "title": "Relation: is_important_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "forensics applications", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Person re-identification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "semi-coupled dictionaries", "width": 2.7800000000000002}, {"arrows": "to", "color": "#2196F3", "from": "SLD2L", "label": "has_purpose", "title": "Relation: has_purpose\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "converting LR probe image features", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "SLD2L", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "effectiveness", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "3D shape matching", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "effectiveness", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "3D shape retrieval", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "effectiveness", "label": "of", "title": "Relation: of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "proposed approach", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "discriminant term", "label": "ensures", "title": "Relation: ensures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "converted features are far from different-person HR gallery features", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "low-rank regularization", "label": "characterizes", "title": "Relation: characterizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "intrinsic feature space", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "low-rank regularization", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "HR images", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "low-rank regularization", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "LR images", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "HR images", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "image", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "LR images", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "image", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "HR gallery images", "label": "has_feature", "title": "Relation: has_feature\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "features", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "features", "label": "are", "title": "Relation: are\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "discriminative for categorization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "features", "label": "measures", "title": "Relation: measures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "semantic obviousness", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "features", "label": "discovers", "title": "Relation: discovers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "local characteristics", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "LR probe images", "label": "has_feature", "title": "Relation: has_feature\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "features", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "public datasets", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "SLD2L", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "HR gallery", "label": "features", "title": "Relation: features\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "low-rank regularization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Super-resolution person re-identification", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "research", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "research", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "predicting human gaze", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "research", "label": "is in", "title": "Relation: is in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "early stage", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "research", "label": "is_area_of", "title": "Relation: is_area_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Low-rank discriminant dictionary learning", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "machine learning", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Semi-coupled dictionaries", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "person re-identification", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "person re-identification", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "match pedestrian images", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "person re-identification", "label": "remains", "title": "Relation: remains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.50\u003cbr\u003eSource: unknown", "to": "challenging", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "from": "person re-identification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Mahalanobis distance", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "person re-identification", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "cross-dataset task", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Feature representation learning", "label": "is_field", "title": "Relation: is_field\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "machine learning", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Bak et al. (2010)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Person re-identification", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Bedagkar-Gala \u0026 Shah (2014)", "label": "surveys", "title": "Relation: surveys\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "person re-identi\ufb01cation approaches", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Liu et al. (2014)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "semi-supervised coupled dictionary learning", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Liu, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Semi-supervised coupled dictionary learning for person re-identi\ufb01cation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Semi-supervised coupled dictionary learning for person re-identi\ufb01cation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR, IEEE Conference on", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ma, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse representation for face recognition based on discriminative low-rank dictionary learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ma, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Person re-identi\ufb01cation over camera networks using multi-task distance metric learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ma, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Person re-identi\ufb01cation over camera networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gray, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Evaluating appearance models for recognition, reacquisition, and tracking", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gray, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Viewpoint invariant pedestrian recognition with an ensemble of localized features", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gray, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Viewpoint invariant pedestrian recognition", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Evaluating appearance models for recognition, reacquisition, and tracking", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Performance Evaluation of Tracking and Surveillance, IEEE workshop on", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Viewpoint invariant pedestrian recognition with an ensemble of localized features", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Person re-identi\ufb01cation over camera networks using multi-task distance metric learning", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Processing, IEEE Transactions on", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Image Processing, IEEE Transactions on", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Person re-identi\ufb01cation over camera networks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Image Processing, IEEE Transactions on", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Image super-resolution via sparse representation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Hirzer, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Person re-identi\ufb01cation by descriptive and discriminative classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng, W.-S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reidenti\ufb01cation by relative distance comparison", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "State Key Laboratory of Software Engineering", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of Computer", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Image Analysis", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Person re-identi\ufb01cation by descriptive and discriminative classification", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Pattern Analysis and Machine Intelligence, IEEE Transactions on", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Reidenti\ufb01cation by relative distance comparison", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "re Engineering", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "School of Computer", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Wuhan University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wuhan University", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "China", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "School of Electronic Information and Communications", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Huazhong University of Science and Technology", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "National Engineering Research Center for Multimedia Software", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "School of Computer", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Ronan Collobert", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "From Image-level to Pixel-level Labeling", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ronan Collobert", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Facebook AI Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ronan Collobert", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ronan@coltobert.com", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ronan Collobert", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Menlo Park", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "From Image-level to Pixel-level Labeling", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Multimedia Software", "label": "developed_by", "title": "Relation: developed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "School of Computer", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "We", "label": "are_interested_in", "title": "Relation: are_interested_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "object segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "object segmentation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object class information", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "object segmentation", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "object segmentation", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "object and motion segmentation", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "weakly supervised segmentation task", "label": "fits_framework", "title": "Relation: fits_framework\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Multiple Instance Learning (MIL) framework", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "training image", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "pixel corresponding to image class label", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "segmentation task", "label": "is_rewritten_as", "title": "Relation: is_rewritten_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "inferring pixels belonging to class of object", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Network", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "is_constrained_during", "title": "Relation: is_constrained_during\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "training", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "discriminates", "title": "Relation: discriminates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "pixels", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "discriminates", "title": "Relation: discriminates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "right pixels", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "beats", "title": "Relation: beats\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "state of the art results", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "weakly supervised object segmentation task", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "compared_with", "title": "Relation: compared_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "fully-supervised segmentation approaches", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "unifies", "title": "Relation: unifies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "existing ZSL algorithms", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "performance gains", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "patch representations", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "is_benchmarked_on", "title": "Relation: is_benchmarked_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Intrinsic Images in the Wild dataset", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "model", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "low-rank", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "model", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "generalization power", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "accounts_for", "title": "Relation: accounts_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "global salience effects", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art accuracy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "fits", "title": "Relation: fits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "noisy images", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "constrained_by", "title": "Relation: constrained_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "loss minimization", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "model", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "computer vision models", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "model", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "human input", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "model", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Markov Decision Process", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "model", "label": "is a model of", "title": "Relation: is a model of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "bottom-up segmentation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "We Are Family", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "computations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Stickmen dataset", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "model", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "performance improvements", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "model", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "light transport complexities", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Network", "label": "is_architecture_for", "title": "Relation: is_architecture_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "pose estimation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "training", "label": "prioritizes", "title": "Relation: prioritizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "pixels important for image classification", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "training", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "pixels", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "training", "label": "is_expensive_due_to", "title": "Relation: is_expensive_due_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "structured prediction subroutine", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "network-based model", "label": "constrained_during", "title": "Relation: constrained_during\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "training", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "network-based model", "label": "weights", "title": "Relation: weights\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "important pixels", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "trained_using", "title": "Relation: trained_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Imaginet dataset", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "interest regions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "user\u0027s passive participation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "calibrates itself", "title": "Relation: calibrates itself\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "without user participation", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "system", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "calibration", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "efficient", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "noisy data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "missing data", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "sudden camera motions", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "no training data", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "comparably to batch methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "improves_over", "title": "Relation: improves_over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "sequential methods", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "characterized by", "title": "Relation: characterized by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "elegant structure", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "characterized by", "title": "Relation: characterized by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "speed", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "pixel-level salience computation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "integrated into", "title": "Relation: integrated into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "object proposal generation framework", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "supervised machine learning", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "learns_to", "title": "Relation: learns_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "synthesize images", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "redirection of gaze", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "computationally efficient", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "runs_on", "title": "Relation: runs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "laptop", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "avoids", "title": "Relation: avoids\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "uncanny valley effect", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "takes as input", "title": "Relation: takes as input\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image to annotate", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "takes as input", "title": "Relation: takes as input\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "annotation constraints", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "system", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "object annotations", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "system", "label": "has", "title": "Relation: has\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "relationships", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "system", "label": "has", "title": "Relation: has\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.68\u003cbr\u003eSource: unknown", "to": "dependencies", "width": 2.3600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "segmentation experiments", "label": "performed_on", "title": "Relation: performed_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Pascal VOC dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Model", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state of the art results", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Model", "label": "compared_with", "title": "Relation: compared_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "fully-supervised segmentation approaches", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Model", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Quasi-parametric Model", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Model", "label": "retrieves", "title": "Relation: retrieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "KNN Images", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Model", "label": "matches", "title": "Relation: matches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "Semantic Regions", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Model", "label": "fuses", "title": "Relation: fuses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Matched Regions", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Model", "label": "refines", "title": "Relation: refines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Result", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "Object Segmentation", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "task", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Object Segmentation", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Object Segmentation", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Weakly Supervised Segmentation", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "textured 3D non-rigid models", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "photometric information", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "shape manifold", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "new discretization method", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "high performance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "is_faster_than", "title": "Relation: is_faster_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "existing learning-based methods", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "best results", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "complex non-uniform motion blur", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "non-uniform motion blur", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "deblurring model", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "is useful when", "title": "Relation: is useful when\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "original enhancement algorithms are unknown", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "is useful when", "title": "Relation: is useful when\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "original enhancement algorithms are inaccessible", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "validates_on", "title": "Relation: validates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "first-person point-of-view videos", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "corresponds_to", "title": "Relation: corresponds_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Cutkosky grasp taxonomy", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "consistent performance gain", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "datasets", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "depth estimation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "synthesizing intermediate views", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "depth perception", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "improvements", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "lower computational complexity", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "performs_on", "title": "Relation: performs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Stanford Background dataset", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "performs_on", "title": "Relation: performs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "SIFT Flow datasets", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "public datasets", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "semiglobal matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrated_on", "title": "Relation: demonstrated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "non-flat manifolds", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "Euclidean spaces", "width": 2.7199999999999998}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "relies on", "title": "Relation: relies on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "global representations", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "ensures", "title": "Relation: ensures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "temporal consistency", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "ensures", "title": "Relation: ensures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "spatial consistency", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "robust to", "title": "Relation: robust to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "noisy data", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "robust to", "title": "Relation: robust to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "missing data", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "robust to", "title": "Relation: robust to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "sudden camera motions", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "training data", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "encoding method", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "part-based region matching", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state of the art", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "evaluations", "width": 2.56}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "generating motion part candidates", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "formulates", "title": "Relation: formulates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "objective function", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "avoids", "title": "Relation: avoids\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "expensive annotations", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "significant improvements", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "competitive performance", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "lightness differences between pixels", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "depth features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "RGB visual features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "high efficiency", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "robust performance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "varying camera-to-scene arrangements", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "mutual failures", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "50 fps", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "generalizability", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "tested_on", "title": "Relation: tested_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "LFW", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "data fusion approach", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "projections reliability", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "fuses", "title": "Relation: fuses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "super-pixel segmentations", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "refines", "title": "Relation: refines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "alignment of projections", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "illustrated_with", "title": "Relation: illustrated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Robotics (Sarcos) dataset", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "spatial features", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "generalization", "width": 2.8200000000000003}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "allows_creation_of", "title": "Relation: allows_creation_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "new structures", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates_flexibility_with", "title": "Relation: demonstrates_flexibility_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "furniture design", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates_flexibility_with", "title": "Relation: demonstrates_flexibility_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "archaeology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "validates_on", "title": "Relation: validates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "ILSVRC2014 dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "human-in-the-loop labeling approach", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "highly accurate bottom-up object segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "generates", "title": "Relation: generates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "set of regions", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "trains", "title": "Relation: trains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "ensemble of figure-ground segmentation models", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "capable of learning", "title": "Relation: capable of learning\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "model", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "statistical structure", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "parsing humans", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "evaluated on", "title": "Relation: evaluated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "gaze-enabled egocentric video dataset", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "visual cues", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "textual cues", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "quantitative", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "theoretical properties", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "synthetic data sets", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "improves_performance", "title": "Relation: improves_performance\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "activates", "title": "Relation: activates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "set of cliques", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "real-world data sets", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "salience as prior", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "spatial edges", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "temporal motion boundaries", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "uni\ufb01ed saliency detection framework", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "state-of-the-art solution", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "operates_on", "title": "Relation: operates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "2D, 3D and 4D data", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "results_in", "title": "Relation: results_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "image labels", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "light path triangulation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "unknown refractive indices", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "suitable_for", "title": "Relation: suitable_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "complex transparent objects", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "feasibility", "width": 2.56}, {"arrows": "to", "color": "#2196F3", "from": "approach", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "improving object detection", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "identifies", "title": "Relation: identifies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "representative parts", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "superior performance", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "compares_to", "title": "Relation: compares_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "existing NR-IQA algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "comparable results", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "generalization ability", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "applicability to object segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "applicable_to", "title": "Relation: applicable_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "object and motion segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "demonstrates applicability to", "title": "Relation: demonstrates applicability to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "general object and motion segmentation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "improves_over", "title": "Relation: improves_over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "unsupervised segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "achieves results comparable to", "title": "Relation: achieves results comparable to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "best task-specific approaches", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approach", "label": "comparable_to", "title": "Relation: comparable_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "task-specific approaches", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Neural Networks", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "network type", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "salience", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Neural Networks", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Real-time Performance", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Neural Networks", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Bounding Box Calibration", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Neural Networks", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Architecture", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Multiple Instance Learning", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "method", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Image-level Training", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "training method", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "training method", "label": "applicable_to", "title": "Relation: applicable_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "HMMs", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "training method", "label": "suitable_for", "title": "Relation: suitable_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hidden Markov Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez et al. (2009)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Multiscale combinatorial grouping", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Multiscale combinatorial grouping", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Boyd \u0026 Vandenberghe (2004)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Convex optimization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Convex optimization", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cambridge University Press", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bridle (1990)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Probabilistic interpretation of feedforward classification network outputs", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Probabilistic interpretation", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Statistical pattern recognition", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Feedforward classification network outputs", "label": "has_interpretation", "title": "Relation: has_interpretation\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Probabilistic interpretation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Efficient graph-based image segmentation", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision (IJCV)", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Semantic segmentation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous detection and segmentation", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision (ECCV)", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Simultaneous detection and segmentation", "label": "is_task", "title": "Relation: is_task\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fine-grained Localization", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Graph-based image segmentation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Image segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Image segmentation", "label": "achieved_by", "title": "Relation: achieved_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "probabilistic bottom-up aggregation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Hariharan et al.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hariharan et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Discriminative decorrelation for clustering and classification", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Hariharan et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Hypercolumns for object segmentation and fine-grained localization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky et al.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky et al.", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "deep convolutional neural networks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "NIPS", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Optimal teaching for limited-capacity human learners", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "NIPS", "label": "is_publication_venue", "title": "Relation: is_publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "research paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "NIPS", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Angular quantization", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "NIPS", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "machine learning research", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "NIPS", "label": "is_conference", "title": "Relation: is_conference\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "conference", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "LeCun et al.", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Proceedings of the IEEE", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Maron \u0026 Lozano-P\u00e9rez", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pedro O. Pinheiro", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Idiap Research Institute", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yeqing Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Deep Sparse Representation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Yeqing Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Texas at Arlington", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Sparse Representation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Deep Sparse Representation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image registration technique", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chen Chen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Deep Sparse Representation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Chen Chen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Texas at Arlington", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fei Yang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Deep Sparse Representation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Junzhou Huang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deep Sparse Representation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junzhou Huang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Deep Sparse representation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Junzhou Huang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Texas at Arlington", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Menlo Park", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "USA", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Li_Deep_Sparse_Representation_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Deep Sparse Representation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "similarity measure", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "limitation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "new deep architecture", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Jianping Shi", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Li Xu", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "parametrization of the trifocal tensor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Weighted Heat Kernel Signature (W-HKS)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Human Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "combination models", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "HOG-III features", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "weighted-NMS fusion algorithm", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "fundamental matrix estimation problem", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "problem of estimating and removing non-uniform motion blur", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "problem", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "framework", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "sub-categorization model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Edge Radiance Profiles", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Interactive Machine Teaching algorithm", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "unified co-saliency detection framework", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "disparity refinement", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "impact of parameters", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "depth image enhancement method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "pixel-level segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Long Short Term Memory (LSTM) recurrent neural networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "algorithm", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "designs", "title": "Relation: designs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "pre-training scheme", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "power factorization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "GPCA", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "influenced_by", "title": "Relation: influenced_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Sparse representation", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "CNN architectures", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "unknown sparsity", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "paper", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "visual attributes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "appears in", "title": "Relation: appears in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "semantic class label graph", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "absorbing Markov chain process", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "two principled approaches", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "supplementary material", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "aims_to_improve", "title": "Relation: aims_to_improve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "accuracy", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "compares_against", "title": "Relation: compares_against\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "KITTI dataset", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses_problem", "title": "Relation: addresses_problem\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "coding and dictionary learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "geodesic-preserving method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "solution", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salience model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "KITTI benchmark", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "MPI Sintel benchmark", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Middlebury benchmark", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Suha Kwak", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cordelia Schmid", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "title", "title": "Relation: title\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Discovery", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "generic instance search problem", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "shape feature learning scheme", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "challenge", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "system\u0027s performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "image restoration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "\u21130TV-PADMM", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "BOLD (Binary Online Learned Descriptor)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "multiple instance learning framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "studies_problem", "title": "Relation: studies_problem\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "absolute pose of a perspective camera", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses_problem", "title": "Relation: addresses_problem\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "pose estimation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "structure and motion estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "age invariant face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "measure of salience", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "geo-semantic segmentation method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Markov Chain approach", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "applies", "title": "Relation: applies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Hierarchical approaches", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "efficient computation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "salient region detection", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "applies", "title": "Relation: applies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "visual salience detection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse Kernel Multi-task Learning (SKMTL) models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "argues", "title": "Relation: argues\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "multiple homographies estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "photometric stereo", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "mesh deformation approach", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep hashing (DH) approach", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "develops", "title": "Relation: develops\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "deep neural network", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "brings together", "title": "Relation: brings together\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "object detection advancements", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "brings together", "title": "Relation: brings together\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "crowd engineering", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "problem of learning long binary codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "overcomes", "title": "Relation: overcomes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "lack of effective regularizer", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "overcomes", "title": "Relation: overcomes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "high computational cost", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "sparsity encouraging regularizer", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "presented_by", "title": "Relation: presented_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Chen Xianjie", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Alan Yuilie", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "unified approach", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "egocentric video summarization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image alignment", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "paper", "label": "focuses on", "title": "Relation: focuses on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "complex system", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "problem of recovering a complete 3D model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "viewpoint-based shape matching", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "3D deformation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "3D mesh analysis", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "3D model synthesis", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "limitations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "method for selecting features", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "makes_contribution", "title": "Relation: makes_contribution\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "analysis of impact", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "unsupervised method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "robust regression method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Hui Wu", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Richard Souvenir", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "surface shape reconstruction problem", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "volumetric deformation model", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adaptive Region Pooling", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "effectiveness of ARP", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "new no-referece (NR) image quality assessment (IQA) framework", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "video segmentation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "similarity measure", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "deep sparse representation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "images", "label": "sparsified_in", "title": "Relation: sparsified_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "gradient domain", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "images", "label": "sparsified_in", "title": "Relation: sparsified_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "frequency domain", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "images", "label": "collected_from", "title": "Relation: collected_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "4,665 KM2", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "images", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "altered gaze direction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "images", "label": "contain", "title": "Relation: contain\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "artifacts", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "limitations", "label": "concern", "title": "Relation: concern\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "spatially-varying intensity distortions", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art methods", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "ground-truth eye-gaze", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "RASL", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "spatially-varying intensity distortions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "RASL", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "robustness", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "RASL", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "accuracy", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "RASL", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "efficiency", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "RASL", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "sparse decomposition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "RASL", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "low-rank decomposition", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "accuracy", "label": "is_characteristic_of", "title": "Relation: is_characteristic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "state-of-the-art", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "accuracy", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "comparable", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Deformable medical image registration", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Medical Imaging", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "IEEE Transactions on Medical Imaging", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "journal", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Medical Imaging", "label": "has_volume", "title": "Relation: has_volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "32", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Medical Imaging", "label": "has_issue", "title": "Relation: has_issue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "7", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Robust principal component analysis", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Journal of the ACM", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Journal of the ACM", "label": "has_volume", "title": "Relation: has_volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "58", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Journal of the ACM", "label": "has_issue", "title": "Relation: has_issue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Deep sparse representation", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Deep Learning", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Learning", "label": "surpasses", "title": "Relation: surpasses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Traditional Deep Features", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Learning", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "CNNs", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Deep Learning", "label": "relates to", "title": "Relation: relates to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Convolutional deep belief networks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Intensity Distortions", "label": "limits", "title": "Relation: limits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "existing approaches", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "existing approaches", "label": "rely_on", "title": "Relation: rely_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "predefined weights", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "existing approaches", "label": "suffer_from", "title": "Relation: suffer_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "computational cost", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "existing approaches", "label": "depend_on", "title": "Relation: depend_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "initialization", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "existing approaches", "label": "experience", "title": "Relation: experience\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "error accumulation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "existing approaches", "label": "relies on", "title": "Relation: relies on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "incomplete constraint satisfaction", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "existing approaches", "label": "require", "title": "Relation: require\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "user interaction", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing approaches", "label": "rely_on", "title": "Relation: rely_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "surface-based strategies", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "journal", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Journal of the ACM", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Pattern Recognition", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "journal", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pattern Recognition", "label": "has_volume", "title": "Relation: has_volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "35", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pattern Recognition", "label": "has_issue", "title": "Relation: has_issue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pattern Recognition", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Automatic color constancy algorithm selection and combination", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "IEEE Transactions on Geoscience and Remote Sensing", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "journal", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Geoscience and Remote Sensing", "label": "has_volume", "title": "Relation: has_volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "46", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Geoscience and Remote Sensing", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Automatic analysis of the difference image", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Geoscience and Remote Sensing", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A latent analysis of earth surface dynamic evolution", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Geoscientific and Remote Sensing", "label": "has_issue", "title": "Relation: has_issue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "5", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Medical image analysis", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "journal", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Medical image analysis", "label": "has_volume", "title": "Relation: has_volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "18", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Medical image analysis", "label": "has_issue", "title": "Relation: has_issue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "6", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "H", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Landmark matching based retinal image alignment", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Maguire", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Landmark matching based retinal image alignment", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Brainard", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Landmark matching based retinal image alignment", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tzimiropouulos", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust FFT-based scale-invariant image registration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Argyriou", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust FFT-based scale-invariant image registration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zafeiriou", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust FFT-based scale-invariant image registration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zafeiriou", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Unifying Holistic and Parts-Based Deformable Model Fitting", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stathaki", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust FFT-based scale-invariant image registration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Viola", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Alignment by maximization of mutual information", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Viola", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Rapid object detection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Wells III", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Alignment by maximization of mutual information", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gross", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-pie", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Matthews", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-pie", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cohn", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-pie", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kanade", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-pie", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Baker", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-pie", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zitova", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Image registration methods", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Flusser", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Image registration methods", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tsung-Yi Lin", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tsung-Yi Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cornell Tech", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Image and vision computing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "label": "volume", "title": "Relation: volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "21", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "label": "page_range", "title": "Relation: page_range\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "977\u20131000", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yin Cui", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yin Cui", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cornell Tech", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Serge Belongie", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Serge Belongie", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cornell Tech", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "James Hays", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Lin_Learning_Deep_Representations_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "James Hays", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Brown University", "width": 2.96}, {"arrows": "to", "color": "#FF5722", "from": "geo-tagged images", "label": "spurs", "title": "Relation: spurs\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "image-based geolocalization algorithms", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "image-based geolocalization algorithms", "label": "matches", "title": "Relation: matches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "ground-level images", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Where-CNN", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "deep learning approach", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Where-CNN", "label": "inspired_by", "title": "Relation: inspired_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "face verification", "width": 2.7800000000000002}, {"arrows": "to", "color": "#2196F3", "from": "face verification", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "cross-dataset task", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "78K aligned cross-view image pairs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "108 crowd scenes", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "nearly 200,000 head", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "has_size", "title": "Relation: has_size\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "200,000 head annotations", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "dataset", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "cross-scene crowd counting methods", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "new", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "forms", "title": "Relation: forms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "pose-dependent model of joint limits", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "is_available_for", "title": "Relation: is_available_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "research purposes", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "annotated through crowdsourcing", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "serves_as", "title": "Relation: serves_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ground truth", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "complements", "title": "Relation: complements\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "existing annotations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "dataset", "label": "offers", "title": "Relation: offers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "new possibilities", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "matching views", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "close", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "mismatched views", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "far apart", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Geolocalization", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Aerial Imagery", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Cross-View Matching", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Feature Representation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Cross-View Matching", "label": "generalizes_to", "title": "Relation: generalizes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Novel Locations", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Convolutional Neural Networks", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Classification", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Image Classification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Deep Learning", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Google Street View", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "World", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Distinctive Image Features", "label": "derived_from", "title": "Relation: derived_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Scale-Invariant Keypoints", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Deepface", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Human-Level Performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Learning a Similarity Metric", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Face Verification", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Chopra et al. (2005)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lin et al. (2013)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bansal \u0026 Daniilidis (2014)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "van der Maaten \u0026 Hinton (2008)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "JMLR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "JMLR", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Matching words and pictures", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao et al. (2010)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb et al. (2010)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "PAMI", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "PAMI", "label": "is_publication_venue", "title": "Relation: is_publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "research paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "PAMI", "label": "is_publication_platform_for", "title": "Relation: is_publication_platform_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "minimization in vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cornell Tech", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Serge Belongie", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Junho Yim", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rotating Your Face Using Multi-task Deep Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Heechul Jung", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rotating Your face Using Multi-task Deep Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Heechul Jung", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of Electrical Engineerin, KAIST", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ByungIn Yoo", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rotating Your Face Using Multi-task Deep Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ByungIn Yoo", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Samsung Advanced Institute of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Changkyu Choi", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rotating Your Face Using Multi-task Deep Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Changkyu Choi", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Samsung Advanced Institute of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dusik Park", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rotating Your Face Using Multi-task Deep Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dusik Park", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Samsung Advanced Institute of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junmo Kim", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rotating Your Face Using Multi-task Deep Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junmo Kim", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of Electrical Engineering, KAIST", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junmo Kim", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "School of Electrical Engineering", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Junmo Kim", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "junmo.kim@kaisten.ac.kr", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junmo Kim", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "KAIST", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Junmo Kim", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Unsupervised Simultaneous Orthogonal Basis Clustering Feature Selection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junmo Kim", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Department of Automation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Yim_Rotating_Your_Face_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "CVPR paper", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "publication", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Face recognition", "label": "is_problem_of", "title": "Relation: is_problem_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "viewpoint and illumination changes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Face recognition", "label": "evaluated_by", "title": "Relation: evaluated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Feret methodology", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "new deep architecture", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "novel type of multitask learning", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "target-pose face image", "label": "derived_from", "title": "Relation: derived_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "arbitrary pose and illumination image", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "target pose", "label": "controlled_by", "title": "Relation: controlled_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "user\u2019s intention", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "multi-task model", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "identity preservation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Controlled Pose Image (CPI)", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "pose-illumination- invariant feature", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "MultiPIE dataset", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Face Recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed method", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state-of-the-art algorithms", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed method", "label": "operates_on", "title": "Relation: operates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "MultiPIE dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state-of-the-art detection performance", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed method", "label": "runs_at", "title": "Relation: runs_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "14 FPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed method", "label": "runs_at", "title": "Relation: runs_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "100 FPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ramakrishna Vedantam", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CIDEr", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "CIDEr", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Image Description Evaluation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "CIDEr", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "CIDEr", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "CIDEr", "label": "is_named", "title": "Relation: is_named\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "CIDEr-D", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "CIDEr", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Automated Metrics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "C. Lawrence Zitnick", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CIDEr", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "C. Lawrence Zitnick", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Devi Parikh", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CIDEr", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Devi Parikh", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Virginia Tech", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "KAIST", "label": "has_department", "title": "Relation: has_department\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "School of Electrical Engineering", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Image Description", "label": "is_challenge_in", "title": "Relation: is_challenge_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Image Description", "label": "is_challenge_in", "title": "Relation: is_challenge_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Natural Language Processing", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Image Description", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Sequence Learning", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Image Description", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "perceptual representations", "width": 2.56}, {"arrows": "to", "color": "#2196F3", "from": "Computer Vision", "label": "studies", "title": "Relation: studies\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Hand-Object Interaction", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Computer Vision", "label": "encompasses", "title": "Relation: encompasses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Material Recognition", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Computer Vision", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Computer Vision", "label": "is_conference_of", "title": "Relation: is_conference_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "IEEE", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Natural Language Processing", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Object Detection", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Description", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Object Detection", "label": "field_of_study", "title": "Relation: field_of_study\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Object Detection", "label": "influenced_by", "title": "Relation: influenced_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks (CNNs)", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Object Detection", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "PASCAL VOC 2007", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Object Detection", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "PASCUAL VOC 2012", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Attribute Classification", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Description", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Paradigm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Human Consensus", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Paradigm", "label": "consists_of", "title": "Relation: consists_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Triplet-based Method", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Paradigm", "label": "consists_of", "title": "Relation: consists_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Automated Metric", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Paradigm", "label": "consists_of", "title": "Relation: consists_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Datasets", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Datasets", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "PASCAL-50S", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Datasets", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ABSTRACT-50S", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "PASCAL-50S", "label": "is_dataset", "title": "Relation: is_dataset\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Metric", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Human Judgment", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "nsensus", "label": "is_dataset", "title": "Relation: is_dataset\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "metric", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "human judgment", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "metric", "label": "better_than", "title": "Relation: better_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "existing metrics", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "sentences", "label": "generated_by", "title": "Relation: generated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "various sources", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "CIDEr-D", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "MS COCO evaluation server", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "MS COCO evaluation server", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "systematic evaluation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "image description approaches", "label": "evaluated_by", "title": "Relation: evaluated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "protocol", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Microsoft Research", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Microsoft Research", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cem Keskin", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Microsoft Research", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Pushmeet Kohli", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Microsoft Research", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shahram Izadi", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenzhong Lan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Beyond Gaussian Pyramid", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenzhong Lan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "School of Computer Science, Carnegie Mellon University", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond Gaussian Pyramid", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Alexander G. Hauptmann", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Beyond Gaussian Pyramid", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Alexander G. Hauptmann", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer Science, Carnegie Mellon University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bhiksha Raj", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Beyond Gaussian Pyramid", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Bhiksha Raj", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer Science, Carnegie Mellon University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bhiksha Raj", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "bhiksha@cs.cmu.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lan_Beyond_Gausian_Pyramid_2015_CVPR_supplemental", "label": "supports_paper", "title": "Relation: supports_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond Gaussian Pyramid: Multi-skip Feature Stacking for Action Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lan_Beyond_Gausian_Pyramid_2015_CVPR_supplemental", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "proof of theorem 1", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Lan_Beyond_Gausian_Pyramid_2015_CVPR_supplemental", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "proof of theorem 2", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond Gaussian Pyramid: Multi-skip Feature Stacking for Action Recognition", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Action Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond Gaussian Pyramid: Multi-skip Feature Stacking for Action Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Matrix Bernstein\u0027s Inequality", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Action Recognition", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Feature Stacking", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Action Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Trajectory Group Selection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Action Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "Fisher Vector Representation", "width": 2.56}, {"arrows": "to", "color": "#4CAF50", "from": "Action Recognition", "label": "improves_with", "title": "Relation: improves_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Trajectories", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Ming Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "School of Computer Science, Carnegie Mellon University", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Feature Stacking", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Condition Number", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Alexander G. Hauptman", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "cli@cs.cmu.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kwang In Kim", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Kim_Local_High-Order_Regularization_2015_CVPR_paper.pdf", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "James Tompkin", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Kim_Local_High-Order_Regularization_2015_CVPR_paper.pdf", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hanspeter Pfister", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Kim_Local_High-Order_RegularIZATION_2015_CVPR_paper.pdf", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Kim_Local_High-Order_RegularIZATION_2015_CVPR_paper.pdf", "label": "is_paper_about", "title": "Relation: is_paper_about\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Local High-order Regularization on Data Manifolds", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Christian Theobalt", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Kim_Local_High-Order_RegularIZATION_2015_CVPR_paper.pdf", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Christian Theobalt", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "MPI for Informatics", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Christian Theobalt", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Carnegie Mellon University", "label": "has_school", "title": "Relation: has_school\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Carnegie Mellon University", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Pittsburgh", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "School of Computer Science", "label": "part of", "title": "Relation: part of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Beijing Institute of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Graph Laplacian Regularizer", "label": "suffers_from", "title": "Relation: suffers_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "degeneracy", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Iterated Graph Laplacian", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "degeneracy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Iterated Graph Laplacian", "label": "incurs", "title": "Relation: incurs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "computational complexity", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed Regularizer", "label": "maintains", "title": "Relation: maintains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "sparsity", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed Regularizer", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "local derivative evaluations", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "builds", "title": "Relation: builds\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "manifold approximation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Textured 3D Shape Retrieval", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "public datasets", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "evaluated on", "title": "Relation: evaluated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "SED dataset", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "evaluated on", "title": "Relation: evaluated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "HKU-IS dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Superior Performance", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Precision", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Recall", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "F-measure", "width": 2.7199999999999998}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Mean Absolute Error", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "validated_on", "title": "Relation: validated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ILSVRC2014 object detection dataset", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Approach", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "human input", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Markov Decision Process", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image representation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Input features", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Labels", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Strong theoretical properties", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "theoretical properties", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Approach", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "performance improvement", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "efficiency", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "convincing performance", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "effectiveness of approach", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "RMRC dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "conducted_on", "title": "Relation: conducted_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "four large image datasets", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "superior performance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "faster convergence", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "evaluates_performance_on", "title": "Relation: evaluates_performance_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "large-scale datasets", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "improvement", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "speed-up of up to a factor of 100", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "evaluate_on", "title": "Relation: evaluate_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "ImageNET", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "evaluate_on", "title": "Relation: evaluate_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "GIST1M", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Experiments", "label": "evaluate_on", "title": "Relation: evaluate_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "SUN-attribute", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Manifold Approximation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "surrogate geometry", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Manifold Approximation", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Laplacian eigenmaps", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Graph Laplacian Regularization", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Semi-Supervised Learning", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Semi-Supervised Learning", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Graph Laplacian Regularization", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Laplacian eigenmaps", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "dimensionality reduction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "High-Order Derivatives", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Hessian eigenmaps", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Hessian eigenmaps", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "locally linear embedding technique", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Hessian eigenmaps", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "high-dimensional data", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Hessian eigenMaps", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "locally linear embedding", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Normalized cuts", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "image segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "image segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "lossy data compression", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Reproducing Kernel Hilbert Space (RKHS)", "label": "is_framework_for", "title": "Relation: is_framework_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Semi-Supervised Learning", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Reproducing Kernel Hilbert Space (RKHS)", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Spectral Clustering", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Graph Laplacian Regularization", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Spectral Clustering", "label": "tutorial_on", "title": "Relation: tutorial_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Statistics and Computing", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Spectral Clustering", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "clustering", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Plug-in classifiers", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "fast learning rates", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Supervised Learning", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "MIT Press", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Supervised Learning", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2006", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Supervised Learning", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "learning binary codes", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Normalized Cuts", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Image Segmentation", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Normalized Cuts", "label": "is_work_in", "title": "Relation: is_work_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "graph-based image segmentation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Image Segmentation", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "73.1% mean class accuracy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Real Analysis and Probability", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cambridge University Press", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Graphs", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Manifolds", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Graph Laplacians", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Pointwise Consistency", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Jianping Shi", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Just Noticeable Defocus Blur Detection and Estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jianping Shi", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Jianping Shi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The Chinese University of Hong Kong", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Just Noticeable Defocus Blur Detection and Estimation", "label": "is_paper_of", "title": "Relation: is_paper_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Li Xu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Just Noticeable Defocus Blur Detection and Estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Li Xu", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Li Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Lenovo R\u0026T", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaya Jia", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Just Noticeable Defocus Blur Detectio and Estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaya Jia", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaya Jia", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The Chinese University of Hong Kong", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaya Jia", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deep LAC", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shi_Just_Noticeable_Defocus_2015_CVPR_paper.pdf", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Just Noticeable Defocus Blur Detection and Estimation", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "just noticeable blur", "label": "caused_by", "title": "Relation: caused_by\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "defocus", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "just noticeable blur", "label": "spans", "title": "Relation: spans\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "small number of pixels", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "slight edge blurriness", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "informative clues", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "informative clues", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "depth", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "blur descriptors", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "local information", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "blur feature", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "sparse representation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "blur feature", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "image decomposition", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "sparse edge representation", "label": "corresponds_to", "title": "Relation: corresponds_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "blur strength estimation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "age decomposition", "label": "establishes_correspondence", "title": "Relation: establishes_correspondence\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "sparse edge representation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "feature", "label": "manifests", "title": "Relation: manifests\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "generality", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "feature", "label": "manifests", "title": "Relation: manifests\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "robustness", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Bernt Schiele", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Filtered Channel Features for Pedestrian Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bernt Schiele", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Taking a Deeper Look at Pedestrians", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bernt Schiele", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Filtered Channel Features for Pedestrian Detection", "label": "is_supplemental_to", "title": "Relation: is_supplemental_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental.pdf", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shanshan Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Filtered Channel Features for Pedestrian Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shanshan Zhang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rodrigo Benenson", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Filtered Channel Features for Pedestrian Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Rodrigo Benenson", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Filtered_Feature_Channels_2015_CVPR_supplemental", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rodrigo Benenson", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Taking a Deeper Look at Pedestrians", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Rodrigo Benenson", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Checkerboards4x3 model", "label": "is_model", "title": "Relation: is_model\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "pedestrian detection model", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Roerei model", "label": "is_model", "title": "Relation: is_model\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "weaker model", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "filtered channels", "label": "don\u0027t alter", "title": "Relation: don\u0027t alter\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "areas of pedestrian deemed informative", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "filtered channels", "label": "enable", "title": "Relation: enable\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "extraction of discriminative information", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "channel U", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "face", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "channel L", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "body", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "gradient magnitude channel", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "body", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "filter usage distribution", "label": "is_similar_across", "title": "Relation: is_similar_across\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "filter bank families", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "filter bank families", "label": "influences", "title": "Relation: influences\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "filter usage distribution", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "filter", "label": "used as", "title": "Relation: used as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "feature for decision tree split nodes", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "filter", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "decision tree split node feature", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "text", "label": "referenced_in", "title": "Relation: referenced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Benenson, R., Mathias, M., Tuytelaars, T., \u0026 Van Gools, L. (2013)", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Roerei, et al.", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "filter usage", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "ACF", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "filter usage", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "decision tree split nodes", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "filter features", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "filter features", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "decision tree", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "spatial feature distribution", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "pedestrian detection", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "pedestrian detection", "label": "is_precursor_to", "title": "Relation: is_precursor_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "re-identification", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "pedestrian detection", "label": "is_subject_of", "title": "Relation: is_subject_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "research", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "pedestrian detection", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "image analysis task", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "parametrization of the trifocal tensor", "label": "based on", "title": "Relation: based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "quotient Riemannian manifold", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "parametrization of the trifocal tensor", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "almost symmetric", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "parametrization of the trifocal tensor", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "preferred camera", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "parametrization of the trifocal tensor", "label": "incorporated into", "title": "Relation: incorporated into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "optimization techniques on manifolds", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Riemannian structure", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "notion of distance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "distance between trifocal tensors", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "meaningful results", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "distance between trifocal tensors", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Structure from Motion problem", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "work", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "new formulation of the trifocal tensor", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "work", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "challenge", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "work", "label": "derives", "title": "Relation: derives\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "angular support", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "work", "label": "highlights", "title": "Relation: highlights\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "foundational approaches", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "work", "label": "highlights", "title": "Relation: highlights\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "importance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "work", "label": "builds", "title": "Relation: builds\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "object appearance model", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "work", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "familiar objects", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "trifocal tensor", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "tensor", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Structure from Motion", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Trifocal Tensor", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Structure from Motion", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Geometric Computer Vision", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Trifocal Tensor", "label": "measured between", "title": "Relation: measured between\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "distances", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Camera Calibration", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Geometric Computer Vision", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Camera Calibration", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Absolute Pose Estimation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Optimization Algorithms", "label": "written by", "title": "Relation: written by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Absil, Mahony, and Sepulchre", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Nonlinear Programming", "label": "written by", "title": "Relation: written by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Bertsekas", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Manopt", "label": "developed by", "title": "Relation: developed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Boumal, Mishra, Absil, and Sepulchre", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Lines and points", "label": "described in", "title": "Relation: described in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Hartley\u0027s work", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple View Geometry", "label": "written by", "title": "Relation: written by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hartley and Zisserman", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hartley, R. I.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "views and the trifocal tensor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hartley, R. I.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Projective reconstruction from line correspondences", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Hartley, R. I.", "label": "coauthored", "title": "Relation: coauthored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Multiple View Geometry in Computer Vision", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "views and the trifocal tensor", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Int. J. Comput. Vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Projective reconstruction from line correspondences", "label": "presented at", "title": "Relation: presented at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Conf. on Computer Vision and Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Papapdoulo, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A new characterization of the trifocal tensor", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "A new characterization of the trifocal tensor", "label": "presented at", "title": "Relation: presented at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "European Conference on Computer Vision", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image and Vision Computing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "European Conference on Computer Vision", "label": "is_conference_of", "title": "Relation: is_conference_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "European Conference on Computer Vision", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Numerically stable optimization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kendall, D. G.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Shape Manifolds, Procustean Metrics, and Complex Projective Spaces", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shape Manifolds, Procustean Metrics, and Complex Projective Spaces", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Bulletin of the London Mathematical Society", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Torr, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Robust parameterization and computation of the trifocal tensor", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Torr, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Robust parameterization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Robust parameterization and computation of the trifocal tensor", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Image and Vision Computing", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple View Geometry in Computer Vision", "label": "published by", "title": "Relation: published by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cambridge University Press", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Weng, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Motion and structure", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Grasp Laboratory", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of Pennsylvania", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "tron@seas.upenn.edu", "label": "email_address_of", "title": "Relation: email_address_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Roberto Tron", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "kostas@cis.upenn.edu", "label": "email_address_of", "title": "Relation: email_address_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Kostas Daniilidis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fast 2D Border Ownership Assignment", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cornelia Ferm\u00fcller", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fast 2D Border Ownership Assignment", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Ching L. Teo", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fast 2D Border Ownership Assignment", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Yiannis Aloimonos", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cornelia Ferm\u00fcller", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Lab", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ching L. Teo", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision\u003c0xC2\u003e\u003c0xA0\u003eLab", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Teo_Fast_2D_Border_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PDF document", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Structured Random Forests (SRF)", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "boundary detection", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Structured Random Forests (SRF)", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "shape descriptors", "label": "are_type_of", "title": "Relation: are_type_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "HoG-like descriptors", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "shape descriptors", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "photometric features", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "spectral properties", "label": "analyzed_with", "title": "Relation: analyzed_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "PCA", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "semi-global grouping cues", "label": "indicate", "title": "Relation: indicate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "perceived depth", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Experimental results", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Berkeley Segmentation Dataset", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Experimental results", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NYU Depth V2 dataset", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Experimental results", "label": "show", "title": "Relation: show\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Method\u0027s effectiveness", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Experimental results", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "MoG Regression outperforms subspace clustering methods", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Experimental results", "label": "validate", "title": "Relation: validate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "proposed approach", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Experimental results", "label": "validate", "title": "Relation: validate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "effectiveness of proposed methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Feature Extraction", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "HoG", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Feature Extraction", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "PCA", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng et al. (2014)", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Bing", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Dalal \u0026 Triggs (2005)", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Histograms of oriented gradients", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dalal \u0026 Triggs (2005)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "HOG features", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Histograms of oriented gradients", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "human detection", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Binarized normed gradients", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "objectness estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "objectness estimation", "label": "processed_at", "title": "Relation: processed_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "300fps", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fast edge detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "structured forests", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Fast feature pyramids", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "object detection", "label": "faces_challenge", "title": "Relation: faces_challenge\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "3D scenes", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "object detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "grammar models", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Category-independent object proposals", "label": "has_characteristic", "title": "Relation: has_characteristic\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "diverse ranking", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Extremely randomized trees", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "machine learning algorithm", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Perceptual organization", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "recognition of indoor scenes", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Random decision forests", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "machine learning algorithm", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision Lab", "label": "located_at", "title": "Relation: located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Maryland", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "University of Maryland", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "College Park, MD", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mostafa Abdelrahman", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Heat Diffusion Over Weighted Manifolds", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Mostafa Abdelrahman", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Electrical Engineering Department", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mostafa Abdelrahman", "label": "located_at", "title": "Relation: located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Assiut University", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Heat Diffusion Over Weighted Manifolds", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "descriptor", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Aly Farag", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Heat Diffusion Over Weighted Manifolds", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Aly Farag", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVIP Lab", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Aly Farag", "label": "located_at", "title": "Relation: located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Louisville", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "David Swanson", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Heat Diffusion Over Weighted Manifolds", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "David Swanson", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Mathematics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "David Swanson", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Louisville", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Moumen T. El-Melegy", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Heat Diffusion Over Weighted Manifolds", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Moumen T. El-Melegy", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Electrical Engineering Department", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Moumen T. El-Melegy", "label": "located_at", "title": "Relation: located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Assiut University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "descriptor", "label": "incorporated in", "title": "Relation: incorporated in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Mumford-Shah energy", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "descriptor", "label": "consists_of", "title": "Relation: consists_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "binary strings", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "descriptor", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "masked Hamming distance calculation", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Abdelrahman_Heat_Diffusion_Over_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Heat Diffusion Over Weighted Manifolds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing descriptors", "label": "focus on", "title": "Relation: focus on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "geometric properties", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing descriptors", "label": "focus on", "title": "Relation: focus on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "topological properties", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "discretization method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "finite element approximation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "weighted heat kernel signature", "label": "encodes", "title": "Relation: encodes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "photometric information", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "weighted heat kernel signature", "label": "encodes", "title": "Relation: encodes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "geometric information", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "weighted heat kernel signature", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "method for scale invariance", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "heat kernel signature", "label": "encodes", "title": "Relation: encodes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "photometric information", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "heat kernel signature", "label": "encodes", "title": "Relation: encodes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "geometric information", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "challenges", "label": "arise from", "title": "Relation: arise from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "pure geometric methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "challenges", "label": "arise from", "title": "Relation: arise from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "pure photometric methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "confirm", "title": "Relation: confirm\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "approach\u0027s performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "high fidelity", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "temporal consistency", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "validates", "title": "Relation: validates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "proposed approach", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "on", "title": "Relation: on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "image datasets", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "experimental results", "label": "on", "title": "Relation: on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "video datasets", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "textured shape retrieval", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Challenges", "label": "arise_from", "title": "Relation: arise_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Pure Geometric Methods", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Challenges", "label": "arise_from", "title": "Relation: arise_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Photometric Shape Descriptors", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Weighted Heat Kernel Signature", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Heat Diffusion on Manifold", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Electrical Engineering Department", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Assiut University", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Assiut University", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Assiut", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Si Liu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Si Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "SKLOIs", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaodan Liang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaodan Liang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Luoqi Liu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Luoqi Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaohui Shen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaohui Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaohui Shen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Convolutional Neural Network Cascade", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaohui Shen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Jianchao Yang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Jianchao Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Changshen Xu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Changshen Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IA", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Liang Lin", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Liang Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sun Yat-sen University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaochun Cao", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaochun Cao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "SKLOIs", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Shuicheng Yan", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matching-CNN Meets KNN", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Shuicheng Yan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shuicheng Yan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Motion Part Regularization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Work", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Solution", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Solution", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Human Parsing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Quasi-parametric Model", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "KNN Framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Quasi-parametric Model", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "M-CNN", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "M-CNN", "label": "predicts", "title": "Relation: predicts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Matching Confidence", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "M-CNN", "label": "predicts", "title": "Relation: predicts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Displacements", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "M-CNN", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "superpixel smoothing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "M-CNN", "label": "fuses", "title": "Relation: fuses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "matched regions", "width": 2.92}, {"arrows": "to", "color": "#FF5722", "from": "M-CNN", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Evaluations", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Performance Gains", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "performance", "label": "affected_by", "title": "Relation: affected_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "object characteristics", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "performance", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "performance", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "convincing", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "performance", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "existing methods", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "SKLOIs", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IIE", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "IIE", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "National University of Singapore", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "ineering", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "OIS", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yunsheng Jiang", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Combination Features and Models for Human Detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Combination Features and Models for Human Detection", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Combination Features and Models for Human Detection", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Human Detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jinwen Ma", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Combination Features and Models for Human Description", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jinwen Ma", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Combination Features and Models for Human Detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jinwen Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Peking University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jinwen Ma", "label": "works_in", "title": "Relation: works_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Information Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jiang_Combination_Features_and_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Combination Features and Models for Human Detection", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "combination models", "label": "has_feature", "title": "Relation: has_feature\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "complementary features", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "existing features", "label": "exhibit", "title": "Relation: exhibit\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "biases", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "biases", "label": "limit", "title": "Relation: limit\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "HOG-III features", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "color features", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "approaches", "label": "improve", "title": "Relation: improve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "detection performance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "approaches", "label": "maintain", "title": "Relation: maintain\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computational efficiency", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "approaches", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "flexible", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "conducted_on", "title": "Relation: conducted_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "PASCAL VOC datasets", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "indicate", "title": "Relation: indicate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "more accurate segmentation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "reliability", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "superiority in speed", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "competitive surface quality", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "effect of blur", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "provide", "title": "Relation: provide\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "geometric derivations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "performed_on", "title": "Relation: performed_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "PASPAL VOC 2", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "evaluates_on", "title": "Relation: evaluates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PASPAL VOC 2007", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "evaluates_on", "title": "Relation: evaluates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "KITTI benchmark", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "evaluates_on", "title": "Relation: evaluates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "MPI Sintel benchmark", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "evaluates_on", "title": "Relation: evaluates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Middlebury benchmark", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "classification", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "image annotation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "on", "title": "Relation: on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "RMRC dataset", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "experiments", "label": "use", "title": "Relation: use\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "large-scale datasets", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Belongie et al. (2001)", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Int\u0027l Conf. on Computer Vision (IC CV)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hubel (1995)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Eye, brain, and vision", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Eye, brain, and vision", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.65\u003cbr\u003eSource: unknown", "to": "human detection", "width": 2.3}, {"arrows": "to", "color": "#4CAF50", "from": "Ioffe \u0026 Forsyth (2001)", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dalal (2006)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Finding people in images and videos", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb et al. (2008)", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb et al. (2008)", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deformable part models", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "HOG-III Features", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "human detection", "width": 2.7}, {"arrows": "to", "color": "#FF5722", "from": "Model Fusion", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "detection performance", "width": 2.6}, {"arrows": "to", "color": "#FF5722", "from": "Weighted-NMS", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "detection performance", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Matching Shapes", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "human detection", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "elzenszwalb, P. F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A discriminatively trained, multiscale, deformable part model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick, R. B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick, R. B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatively trained part-based models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Viola, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Robust real-time face detection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Robust real-time face detection", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Object detection grammar", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE Int\u2019l Conf. on Computer Vision (ICCV) Workshops", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Object detection with grammar models", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "Advances in Neural Information Processing Systems", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "A discriminatively trained, mult scale, deformable part model", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "International Journal of Computer Vision", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "appearance models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "International Journal of Computer Vision", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "polynomial equation solving", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "International Journal of Computer Vision", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "journal", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "International Journal of Computer Vision", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "publication", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Advances in Neural Information Processing Systems", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Learning to count objects in images", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Gkioxari, G.", "label": "writes_paper", "title": "Relation: writes_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Using k-poselets for detecting people and localizing their keypoints", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gkioxari, G.", "label": "co-authors_with", "title": "Relation: co-authors_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hariharan, B.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gkioxari, G.", "label": "co-authors_with", "title": "Relation: co-authors_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Malik, J.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hariharan, B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Simultaneous detection and segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "GkioxARI, G.", "label": "co-authors_with", "title": "Relation: co-authors_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Girshick, R.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick, R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies for accurate object detection and semantic segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick, R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Rich feature hierarchies", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Girshick, R.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "YunshEng Jiang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Peking University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "YunshEng Jiang", "label": "works_in", "title": "Relation: works_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Information Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Effective Learning-Based Illuminant Estimation Using Simple Features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng", "label": "co-authors_with", "title": "Relation: co-authors_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Price", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng", "label": "co-authors_with", "title": "Relation: co-authors_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cohen", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng", "label": "co-authors_with", "title": "Relation: co-authors_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Michael S. Brown", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Bing: Binarized normed gradients", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Binarized normed gradients", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Michael S. Brown", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Illumination estimation", "label": "is_process_of", "title": "Relation: is_process_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "determining chromaticity", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Illumination estimation", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "white-balancing", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "computational color constancy", "label": "is_topic_in", "title": "Relation: is_topic_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "problem", "label": "is_nature", "title": "Relation: is_nature\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ill-posed", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "problem", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "nonconvex", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "problem", "label": "solved by", "title": "Relation: solved by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "sequence of convex semi-de\ufb01nite programs", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "problem", "label": "is_about", "title": "Relation: is_about\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 1.00\u003cbr\u003eSource: unknown", "to": "temporally consistent video post-processing", "width": 3.0}, {"arrows": "to", "color": "#2196F3", "from": "problem", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "discovery problem", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "problem", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "localization", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "problem", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "inherently ill-posed", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "problem", "label": "has_application", "title": "Relation: has_application\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "3D shape motion recovery", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "best results", "label": "reported on", "title": "Relation: reported on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "modern color constancy data sets", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "results", "label": "reported_on", "title": "Relation: reported_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "color constancy data sets", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "results", "label": "evaluated on", "title": "Relation: evaluated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "CMU mocap dataset", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "results", "label": "evaluated using", "title": "Relation: evaluated using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "manual annotations", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "our approach", "label": "is faster than", "title": "Relation: is faster than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "existing learning-based methods", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "our approach", "label": "gives", "title": "Relation: gives\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "best results", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Forsyth, D. A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "novel algorithm", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Forsyth, D. A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Variable-source shading analysis", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bani\u0107, N.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Color dog", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Color dog", "label": "guides", "title": "Relation: guides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "global illumination estimation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#FF5722", "from": "Color dog", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "accuracy", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Funt, B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "support vector regression", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "support vector regression", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "illumination chromaticity", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Gao, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "color constancy", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Gao, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Ef\ufb01cient color constancy with local surface re\ufb02ectance statistics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "color constancy", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "local surface reflectance statistics", "width": 2.7800000000000002}, {"arrows": "to", "color": "#2196F3", "from": "color constancy", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "specular reflection", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Learning-Based Methods", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "slower than", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Color and Imaging Conference", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "via support vector regression", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Barnard, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A comparison of computational color constancy algorithms", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Barnard, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "A data set for color research", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "TIP", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "A comparison of computational color constancy algorithms", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "TIP", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Improving color constancy using indoor - outdoor image classification", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "TIP", "label": "is_journal", "title": "Relation: is_journal\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Image Processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Color Research \u0026 Application", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "A data set for color research", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Gehler, P. V.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Bayesian color constancy revisited", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Bianco, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Improving color constancy using indoor - outdoor image classification", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Bianco, S.", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Automatic color constancy algorithm selection and combination", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Image Processing", "label": "has_volume", "title": "Relation: has_volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "16", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Image Processing", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The regularized iteratively reweighted mad method", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Image Processing", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Locally linear regression for pose-invariant face recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Botev, Z.", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Kernel density estimation via diffusion", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "The Annals of Statistics", "label": "is_journal", "title": "Relation: is_journal\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The Annals of Statistics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dongliang Cheng", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Brian Price", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Brian Price", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Scott Cohen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hui Wu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Robust Regression on Image Manifolds for Ordered Label Denoising", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Hui Wu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of North Carolina at Charlotte", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Hui Wu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of North Carolin", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Richard Souvenir", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Robust Regression on Image Manifold for Ordered Label Denoising", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Richard Souvenir", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of North Carolina at Charlotte", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Richard Souvenir", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of North Carolin", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wu_Robust_Regression_on_2015_CVPR_supplemental.pdf", "label": "is_file", "title": "Relation: is_file\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "supplemental material", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wu_Robust_Regression_on_2015_CVPR_supplemental", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust Regression", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Robust Regression", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "image labels", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Wu_Robust_Reservation_on_2015_CVPR_supplemental", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Ordered Label Denoising", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Figures 1-4", "label": "illustrate", "title": "Relation: illustrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "RANSC", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Robust Regression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "K-NN", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Robust Regression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "RBFN", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Robust Regression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "SVR", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Robust Regression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "KSPCA", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Robust Regression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "H3R", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Robust Regression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Statue Data Set", "label": "is_example", "title": "Relation: is_example\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Image Manifolds", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Face Pose Estimation", "label": "is_example", "title": "Relation: is_example\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Image Manifolds", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Cheng", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of North Carolin", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Cheng", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "A Convex Optimization Approach", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Cheng", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "J. A. Lopez", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of North Carolin", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J. A. Lopez", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "O. Camps", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of North Carolin", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "O. Camps", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "M. Sznaier", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of North Carolin", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "M. Sznaier", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Cheng_A_Convex_Optimization_2015_CVPR_paper", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "hwu13@uncc.edu", "label": "email_address_of", "title": "Relation: email_address_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Hui Wu", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "souvenir@uncc.edu", "label": "email_address_of", "title": "Relation: email_address_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Richard Souvenir", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "general nonconvex", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "accounts for", "title": "Relation: accounts for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "rank-2 constraint", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "accounts for", "title": "Relation: accounts for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "noise", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "is_for", "title": "Relation: is_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "damage detection", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "semi-supervised learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "hierarchical shape features", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "novel insights", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "convolutional neural network", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "visually similar neighbors", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "deep information", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "wide information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "is_built_on", "title": "Relation: is_built_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "multiple visual features", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "relationship", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "extracts", "title": "Relation: extracts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "region-keyword pairs", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "labeled 2D samples", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "3D CAD models", "width": 2.7800000000000002}, {"arrows": "to", "color": "#FF5722", "from": "framework", "label": "overcomes", "title": "Relation: overcomes\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "lack of 3D training data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "model-based generative tracking", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "discriminative hand pose detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "confirmed_by", "title": "Relation: confirmed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "experimentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "believed to be", "title": "Relation: believed to be\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "extensible to other range-weighted filters", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "believed_to_be_extensible_to", "title": "Relation: believed_to_be_extensible_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "range-weighted algorithms", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "noisy images", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "can_recover", "title": "Relation: can_recover\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "clustered structures", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "defines", "title": "Relation: defines\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "solutions", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "partially-occluded small instances", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "framework", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "heterogenous types of input data", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "features", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "evaluates_on", "title": "Relation: evaluates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "LIVE dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "superior performance", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "framework", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "comparable results", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "algorithm", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "extensible", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "partially labeled correspondences", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "co-occurrence information", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "computer", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "chooses", "title": "Relation: chooses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "labeled images", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "algorithm", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Adaptive Algorithms", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "proposes_solution_for", "title": "Relation: proposes_solution_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "global maximization of consensus", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "frames_problem_as", "title": "Relation: frames_problem_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "tree search problem", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "A* search", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "orders of magnitude faster performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "improves_performance_compared_to", "title": "Relation: improves_performance_compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "previous exact methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "approximates", "title": "Relation: approximates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "energy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "multi-label graph cut algorithm", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "algorithm", "label": "inspired_by", "title": "Relation: inspired_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Iterively Reweighted Least Squares (IRLS) algorithm", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "demonstrates_effectiveness_on", "title": "Relation: demonstrates_effectiveness_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "stereo correspondence estimation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "demonstrates_effectiveness_on", "title": "Relation: demonstrates_effectiveness_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "image inpainting problems", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "graph-cut-based algorithms", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "yields", "title": "Relation: yields\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "lower energy values", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "algorithm", "label": "is_algorithm_for", "title": "Relation: is_algorithm_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "detection-guided optimization strategy", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "increases", "title": "Relation: increases\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "robustness", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "increases", "title": "Relation: increases\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "speed", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "finds", "title": "Relation: finds\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "region-of-interest", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "extracts", "title": "Relation: extracts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "objects", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "eye tracking data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "spatio-temporal mixed graph", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "binary linear integer programming", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "local estimation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "global search", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "algorithm", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "strengths", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "dominant orientations", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "guides", "title": "Relation: guides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "interpretation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "assigns", "title": "Relation: assigns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "polygon", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "allows for", "title": "Relation: allows for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "creation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "geometrically motivated criterion", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "faster convergence", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "total runtime", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "block-coordinate Frank-Wolfe (BCFW) algorithm", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Gaussian Mixture Model", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "algorithm", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "submodular maximization", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "mis-labeled examples", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "optimization", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "robust", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Multiple view geometry", "label": "is_foundational_to", "title": "Relation: is_foundational_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "topic", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Multiple view geometry", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple view geometry", "label": "is_reference_for", "title": "Relation: is_reference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "geometric relationships", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Hartley, R. \u0026 Zisserman, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Multiple view geometry", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mohan, K. \u0026 Fazel, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Iterative reweighted algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lasserre, J. B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Global optimization with polynomials", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Global optimization with polynomials", "label": "important_for", "title": "Relation: important_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "polynomial optimization methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "outliers", "label": "arise_from", "title": "Relation: arise_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "background clutter", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Fundamental Matrix Estimation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "topic", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Robust Optimization", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "topic", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Rank-Constrained Optimization", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "topic", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Global optimization", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "polynomial methods", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "polynomial methods", "label": "relevant to", "title": "Relation: relevant to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "optimization methods", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lasserre", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Global optimization with polynomials and the problem of moments", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Bugarin et al.", "label": "compared", "title": "Relation: compared\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "polynomial global optimization", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "polynomial global optimization", "label": "is an alternative to", "title": "Relation: is an alternative to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "eight-point algorithm", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "fundamental matrix estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "polynomial global optimization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "fundamental matrix estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "eight-point algorithm", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "fundamental matrix estimation", "label": "is a type of", "title": "Relation: is a type of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision technique", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "fundamental matrix estimation", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "International journal of computer vision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "fundamental matrix estimation", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Computer Vision and Pattern Recognition (CVPR)", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "fundamental matrix estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Mlesac", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "fundamental matrix estimation", "label": "is_studied_in", "title": "Relation: is_studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Computer Vision and Image Understanding", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "fundamental matrix estimation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "algorithm", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "eight-point algorithm", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "fundamental matrix estimation method", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Torr \u0026 Murray", "label": "studied", "title": "Relation: studied\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "fundamental matrix estimation methods", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "International journal of computer vision", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "taxonomies", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision and Pattern Recognition (CVPR)", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "comparative study", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision and Pattern Recognition (CVPR)", "label": "is_publication_venue_for", "title": "Relation: is_publication_venue_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Histograms of oriented gradients", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Mlesac", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "robust estimator", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "SDP relaxations", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "SIAM Journal on Optimization", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "SDP relaxations", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "polynomial optimization", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng, Y., Sugimoto, S., \u0026 Okutomi, M.", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "eight-point algorithm", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lasserre (2006)", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "SDP relaxations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sugaya \u0026 Kanatani (2007)", "label": "focuses on", "title": "Relation: focuses on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "high-accuracy computation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Northeastern University", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Boston", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "RANSA", "label": "applied to", "title": "Relation: applied to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "image analysis", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "RANSA", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "model fitting", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "RANSA", "label": "is_relevant_to", "title": "Relation: is_relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "computer vision problems", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "RANSA", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "number of inliers", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "University", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Boston", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Boston", "label": "is_located_in", "title": "Relation: is_located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Massachusetts", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jian Sun", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning a Convolutional Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jian Sun", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks at Constrained Time Cost", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jian Sun", "label": "is author of", "title": "Relation: is author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Jian Sun", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jian Sun", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A Geodesic-Preserving Method for Image Warping", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jian Sun", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse Projections for High-Dimensional Binary Codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Learning a Convolutional Neural Network", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Learning a Convolutional Neural Network", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Non-uniform Motion Blur Removal", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Wenfei Cao", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning a Convolutional Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jean Ponce", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning a Convolutional Neural Network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jean Ponce", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Detection and Localization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jean Ponce", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Discovery and Localization in the Wild", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jean Ponce", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "\u00c9cole Normale Sup\u00e9rieure", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jean Ponce", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "PSL Research University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "lopez.jo@husky.neu.edu", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "camps@coe.neu.edu", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "msznaier@coe.neu.edu", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "authors", "label": "propose", "title": "Relation: propose\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "deep learning approach", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "authors", "label": "propose_to_utilize", "title": "Relation: propose_to_utilize\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "kernels", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "authors", "label": "introduce", "title": "Relation: introduce\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "general Riemannian coding framework", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "authors", "label": "solve", "title": "Relation: solve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "energy function", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "authors", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Gauss-Newton method", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "authors", "label": "propose", "title": "Relation: propose\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "novel approach", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "CNN", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "convolutional neural network", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CNN", "label": "trained_with", "title": "Relation: trained_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "structured loss", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "motion kernels", "label": "extended_by", "title": "Relation: extended_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "image rotations", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Markov random field model", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "inferring dense non-uniform motion blur field", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Markov random field model", "label": "enforces", "title": "Relation: enforces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "motion smoothness", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Markov random field model", "label": "accounts_for", "title": "Relation: accounts_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "global salience effects", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Markov random field model", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art accuracy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "deblurring model", "label": "removes", "title": "Relation: removes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "motion blur", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "deblurring model", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "patch-level image prior", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "deblurring model", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "non-uniform model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "deblurring model", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "image quality", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "motion blur", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "image artifact", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "patch-level image prior", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "patch-based image processing", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "ion blur", "label": "removed_by", "title": "Relation: removed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deblurring model", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Object detection systems", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "large number of classes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Object detection systems", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep convolutional neural network (CNN)", "width": 2.96}, {"arrows": "to", "color": "#FF5722", "from": "extensive convolution operations", "label": "causes", "title": "Relation: causes\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "long detection times", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "sparse coding methods", "label": "aims_to_reduce", "title": "Relation: aims_to_reduce\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "computational complexity", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "sparse coding methods", "label": "compromises", "title": "Relation: compromises\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "accuracy", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Regularized Sparse Coding", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "filter functionality reconstruction", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Regularized Sparse Coding", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "score map error", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Regularized Sparse Coding", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "16x speedup", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Regularized Sparse Coding", "label": "results_in", "title": "Relation: results_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "0.04 mAP drop", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Regularized Sparse Coding", "label": "demonstrates_applicability_for", "title": "Relation: demonstrates_applicability_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "parallel computing", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "ILSVIRC 2013", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Regularized Sparse Coding", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Deformable Part Model", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Regularized Sparse Coding", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "parallel computing", "label": "occurs_on", "title": "Relation: occurs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "GPUs", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Ting-Hsuan Chao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "National Taiwan University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yen-Liang Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "National Taiwan University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yin-Hsi Kuo", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "National Taiwan University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Winston H. Hsu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "National Taiwan University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao-Ming Wu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "author", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao-Ming Wu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "New Insights into Laplacian Similarity Search", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao-Ming Wu", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Electrical Engineering, Columbia University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao-Ming Wu", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "xmwu@ee.columbia.edu", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenguo Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "author", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenguo Li", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Huawei Noah\u2019s Ark Lab, Hong Kong", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenguo Li", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "li.zhenguo@huawei.com", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenguo Li", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "New Insights into Laplacian Similarity Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shih-Fu Chang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "author", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shih-Fu Chang", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "sfchang@ee.columbia.edu", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Shih-Fu Chang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Attributes and Categories for Generic Instance Search from One Example", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shih-Fu Chang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shih-Fu Chang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "New Insights into Laplacian Similarity Search", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "X.-M. Wu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Electrical Engineering, Columbia University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "X.-M. Wu", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "xmwu@ee.columbia.edu", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "X.-M. Wu", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Analyzing the harmonic structure in graph-based learning", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "X.-M. Wu", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "New insights into laplacian similarity search", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "X.-M. Wu", "label": "co-authored_with", "title": "Relation: co-authored_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Zhenguo Li", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "X.-M. Wu", "label": "co-authored_with", "title": "Relation: co-authored_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shih-Fu Chang", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "sfchang@ee.columbia.edu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Columbia University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Analyzing the harmonic structure in graph-based learning", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Analyzing the harmonic structure in graph-based learning", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "harmonic structure", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Xuan Dong", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Region-based Temporally Consistent Video Post-processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xuan Dong", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Tsinghua University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Region-based Temporally Consistent Video Post-processing", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Boyan Bonev", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Region-based Temporally Consistent Video Post-processing", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Alan L. Yuille", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Region-based Temporally Consistent Video Post-processing", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Region-based Temporally Consistent Video Post-processing", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Region-based Temporally Consistent Video Post-processing", "label": "file_name", "title": "Relation: file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Dong_Region-Based_Temporally_Consistent_2015_CVPR_paper.pdf", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Boyan Bonev", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Region-based Temporically Consistent Video Post-processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Boyan Bonev", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "UC Los Angeles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Region-based Temporately Consistent Video Post-processing", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Yu Zhu", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Yu Zhu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Region-based Temporally Consistent Video Post-processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yu Zhu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Northwestern Polytechnical University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Alan L. Yuille", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Region-based Temporally Consistent Video Post-processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Alan L. Yuille", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "UC Los Angeles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Columbia University", "label": "has_department", "title": "Relation: has_department\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Electrical Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Electrical Engineering", "label": "is_department_of", "title": "Relation: is_department_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Columbia University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "goal", "label": "aims_for", "title": "Relation: aims_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "fidelity", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "goal", "label": "is_to_create", "title": "Relation: is_to_create\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "semantically segmented images", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "goal", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "localizing every object in an image", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "goal", "label": "is to", "title": "Relation: is to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "reconstruct a 3D model automatically", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "enhancement algorithms", "label": "enforces", "title": "Relation: enforces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "spatially consistent prior", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "spatially consistent prior", "label": "relates", "title": "Relation: relates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "pixels with same RGB values", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "enhancement of regions", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "fidelity", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "enhancement of regions", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "temporal consistency", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "enhancement of regions", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "spatial consistency", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "frames", "label": "consider", "title": "Relation: consider\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "fidelity", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Slic superpixels", "label": "compared to", "title": "Relation: compared to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "superpixel methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Slic superpixels", "label": "is described in", "title": "Relation: is described in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Slic superpixels", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "superpixels", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Slic superpixels", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "state-of-the-art superpixel methods", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Slic superpixels", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "IEEE TPAM, 2012", "width": 2.56}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "is_publication_venue_for", "title": "Relation: is_publication_venue_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "reference [4]", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "journal", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Nonparametric Discriminant Analysis for Face Recognition", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Multisculse local phase quantization for robust component-based face recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "local phase quantization", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "publication", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "textures", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Spacetime texture representation and recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "tone management", "label": "is described in", "title": "Relation: is described in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "ACM Trans. on Graph.", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "ACM Trans. on Graph.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Tonal stabilization of video", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "ACM Trans. on Graph.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Patch-based high dynamic range video", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "video color grading", "label": "is described in", "title": "Relation: is described in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "ACM Trans. on Graph.", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "color transformation", "label": "is described in", "title": "Relation: is described in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Image Processing", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "color transformation", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Image Enhancement Algorithms", "label": "are", "title": "Relation: are\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "enhancement algorithms", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Chang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Example-based color transformation of image and video using basic color categories", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Chang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Example-based color transformation", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Example-based color transformation of image and video using basic color categories", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Image Processing", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Example-based color transformation of image and video using basic color categories", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "color transformation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "S. Saito", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Example-based color transformation of image and video using basic color categories", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "S. Saito", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Example-based color transformation", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "M. Nakajima", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Example-based color transformation of image and video using basic color categories", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "M. Nakajima", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Example-based color transform", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "article", "label": "has_page_range", "title": "Relation: has_page_range\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "1\u201311", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "article", "label": "has_year", "title": "Relation: has_year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "2013", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Z. Farbman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Tonal stabilization of video", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "D. Lischinski", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Tonal stabilization of video", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "P. F. Felzenszwalb", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Efficient belief propagation", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "D. P. Huttenlocher", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Efficient belief propagation", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "M. Grundmann", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Post-processing approach", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Hacohen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Non-rigid dense correspondence", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "N. K. Kalantari", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Patch-based high dynamic range video", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "age enhancement", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ACM Trans. Graph.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "N. K. Kalantria", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Patch-based high dynamic range video", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "S. B. Kang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "High dynamic range video", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "High dynamic range video", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ACM Trans. on Graph.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tsinghua University", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beijing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lionel Gueguen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Large-Scale Damage Detection Using Satellite Imagery", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Large-Scale Damage Detection Using Satellite Imagery", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Raffay Hamid", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Large-Scale Damage Detection Using Satellite Imagery", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Raffay Hamid", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "DigitalGlobe Inc.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Raffay Hamid", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "mhamid@digitalGlobe.com", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Satellite imagery", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "assessing damages", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Manual inspection", "label": "is_limited_by", "title": "Relation: is_limited_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "vast amount of data", "width": 2.92}, {"arrows": "to", "color": "#FF5722", "from": "semi-supervised learning", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "crowd counting", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "study", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "88 million images", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "study", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "sun angle", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "study", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "sensor resolution", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "study", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "registration differences", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "study", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "time constraints during offline training", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "4,665 KM2", "label": "is_across", "title": "Relation: is_across\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "12 locations", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "user study", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ten-fold reduction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "user study", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "representation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "ten-fold reduction", "label": "is_in", "title": "Relation: is_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "human annotation time", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "ten-fold reduction", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "efficiency", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "hierarchical shape features", "label": "is_within", "title": "Relation: is_within\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "bag-of-visual words setting", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "representation", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "five alternatives", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "representation", "label": "offers", "title": "Relation: offers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "time efficiency", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "representation", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "annotation process", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "representation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "core challenge", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "representation", "label": "maintains", "title": "Relation: maintains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "rich representation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "detection accuracy", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "manual inspection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "detection accuracy", "label": "experienced", "title": "Relation: experienced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "minimal loss", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "User study", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ten-fold reduction in annotation time", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "User study", "label": "results in", "title": "Relation: results in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "minimal loss in detection accuracy", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Damage detection", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Hierarchical shape features", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Semi-supervised learning", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Novelty detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Semi-supervised learning", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "gigantic image collections", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Xia et al. (2010)", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Shape-based invariant texture indexing", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Markou \u0026 Singh (2003)", "label": "reviews", "title": "Relation: reviews\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Novelty detection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Blanchard et al. (2010)", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Semi-supervised novelty detection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Bruzone \u0026 Prieto (2000)", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Difference image", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Difference image", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Unsupervised change detection", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Satellite imagery analysis", "label": "benefits from", "title": "Relation: benefits from\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Damage detection", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Bruzzone", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Automatic analysis of the difference image", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Prieto", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Automatic analysis of the difference image", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gerard", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A quasi-linear algorithm", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "International Symposium on Mathematical Morphology", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A quasi-linear algorithm", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Monasse", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast computation of a contrast-invariant image representation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Guichard", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast computation of a contrast-invariant image representation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Nielsen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The regularized iteratively reweighted mad method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vaduva", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A latent analysis of earth surface dynamic evolution", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "at", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A latent analysis of earth surface dynamic evolution using change map time series", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lazarescu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A latent analysis of earth surface dynamic evolution using change map time series", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Datcu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A latent anisotropy of earth surface dynamic evolution using change map time series", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gomez-Chova", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Kernel-based framework for multitemporal and multisource remote sensing data classification and change detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Locality-constrained linear coding for image classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Semi-supervised hashing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Weakly Supervised Localization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "LIBLINEAR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Locality-constrained linear coding for image classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yang", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A survey on transfer learning", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Song", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fusing Subcategory Probabilities for Texture Classi\ufb01cation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cai", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fusing Subcategory Probabilities for Texture Classi\ufb01cation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gueguen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "DigitalGlobe Inc.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hamid", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "DigitalGlobe Inc.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Song", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fusing Subcategory Probabilities for Texture Classification", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Song", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "BMIT Research Group", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Fusing Subcategory Probabilities for Texture Classification", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fusing Subcategory Probabilities for Texture Classification", "label": "is_located_at", "title": "Relation: is_located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Fusing Subcategory Probabilities for Texture Classification", "label": "has_file_name", "title": "Relation: has_file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Song_Fusing_Subcategory_Probabilities_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Qing Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fusing SubCategory Probabilities for Texture Classification", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Fan Zhang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fusing Subcategory Probabilities for Texture Classification", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "David Dagan Feng", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fusing Subcategory Probabilities for Texture Classification", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "David Dagan Feng", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "BMIT Research Group", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Heng Huang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fusing Subcategory Probabilities for Texture Classification", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Heng Huang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Computer Science and Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Texture classification", "label": "remains", "title": "Relation: remains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "challenging", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Texture classification", "label": "faces", "title": "Relation: faces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "high intra-class variation", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "sub-categorization model", "label": "applied to", "title": "Relation: applied to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "texture classification", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "class", "label": "is divided into", "title": "Relation: is divided into\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "subcategories", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "subcategories", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "distinctiveness", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "subcategories", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "representativeness", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "subcategory probabilities", "label": "are fused based on", "title": "Relation: are fused based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "contribution levels", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "subcategory probabilities", "label": "are fused based on", "title": "Relation: are fused based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "cluster qualities", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "fused probability", "label": "added to", "title": "Relation: added to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "multiclass classification probability", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Texture Classification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Method", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "BMIT Research Group", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Sydney", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "BMIT Research Group", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of IT", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "University of Sydney", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Australia", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "School of IT", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Sydney", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Computer Science and Engineering", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "University of Texas, Arlington", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Manohar Paluri", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Frontal Faces", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Manohar Paluri", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Manohar Paluri", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Facebook AI Research", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond Frontal Faces", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yaniv Taigman", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Frontal Faces", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yaniv Taigman", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yaniv Taigman", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Facebook AI Research", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Rob Fergus", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Frontal Faces", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Rob Fergus", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Rob Fergus", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Facebook AI Research", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Lubomir Bourdev", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Frontal Faces", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Lubomir Bourdev", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lubomir Bourdev", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Facebook AI Research", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_Beyond_Frontal_Faces_2015_CVPR_paper", "label": "explores_task", "title": "Relation: explores_task\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "recognizing peoples\u2019 identities", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "PIPA dataset", "label": "facilitates", "title": "Relation: facilitates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "recognizing peoples\u2019 identities", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "PIPA dataset", "label": "consists_of", "title": "Relation: consists_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "60000 instances", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "PIPA dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "2000 individuals", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "PIPER method", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "face recognizer", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "PIPER method", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "global recognizer", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "face recognizer", "label": "combined_with", "title": "Relation: combined_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "global recognizer", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "person images", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "frontal face", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "person recognizers", "label": "trained_by", "title": "Relation: trained_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep convolutional networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "deep convolutional networks", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "discount pose variations", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "PIPER", "label": "improves_performance_on", "title": "Relation: improves_performance_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "DeepFace", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "PIPER", "label": "operates_in", "title": "Relation: operates_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "unconstrained setup", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "DeepFace", "label": "is_regarded_as", "title": "Relation: is_regarded_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "best face recognizers", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "DeepFace", "label": "measured_on", "title": "Relation: measured_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "LFW dataset", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "DeepFace", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "face recognizer", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Pose Invariant Recognition", "label": "is_setting_for", "title": "Relation: is_setting_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "PIPER", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Wohlhart", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Institute for Computer Vision and Graphics, Graz University of Technology, Austria", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Wohlhart", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Learning Descriptors for Object Recognition and 3D Pose Estimation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Wohlhart", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute for Computer Vision and Graphics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Wohlhart", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "{wohlhart}@icg.tugraz.at", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Wohlhart", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "2015 CVPR paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Wohlhart", "label": "works_in", "title": "Relation: works_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Computer Graphics", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Wohlhart", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Austria", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Learning Descriptors for Object Recognition and 3D Pose Estimation", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "cvpr_papers", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "cvpr_papers", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Institute for Computer Vision and Graphics", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Graz University of Technology", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Institute for Computer Vision and Graphics", "label": "research_area", "title": "Relation: research_area\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Graz University of Technology", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Austria", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Graz University of Technology", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Institute for Computer Vision and Graphics", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Graz University of Technology", "label": "has_institute", "title": "Relation: has_institute\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute for Computer Graphics and Vision", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "2015 CVPR paper", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Learning Descriptors", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "2015 CVPR paper", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.65\u003cbr\u003eSource: unknown", "to": "IEEE", "width": 2.3}, {"arrows": "to", "color": "#2196F3", "from": "Learning Descriptors", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A shape-preserving approach to image resizing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Vincent LePetit", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute for Computer Vision and Graphics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vincent LePetit", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Austria", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Joe Yue-Hei Ng", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Short Snippets", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Joe Yue-Hei Ng", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Maryland, College Park", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond Short Snippets", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Matthew Hausknecht", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Short Snippets", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Matthew Hausknecht", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Texas at Austin", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Sudheendra Vijayanarasimhan", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Short Snippets", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Sudheendra Vijayanarasimhan", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Google, Inc.", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Oriol Vinyals", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Short Snippets", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Oriol Vinyals", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Google, Inc.", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Rajat Monga", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Short Snppets", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Rajat Monga", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Google, Inc.", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "George Toderici", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Beyond Short Snippets", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "George Toderici", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Google, Inc.", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional neural networks (CNNs)", "label": "applied_for", "title": "Relation: applied_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "image recognition problems", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional neural networks (CNNs)", "label": "yields", "title": "Relation: yields\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art results", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "deep neural network architectures", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "image information", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "image information", "label": "spans", "title": "Relation: spans\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "longer time periods", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "video", "label": "models_as", "title": "Relation: models_as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ordered sequence of frames", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "video", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "novel object", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "video", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "frames", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "recurrent neural network", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Long Short-Term Memory (LSTM) cells", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "LSTM cells", "label": "connected_to", "title": "Relation: connected_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "output of CNN", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "networks", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "performance improvements", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "networks", "label": "performs_on", "title": "Relation: performs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "UCF-101 datasets", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "networks", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "local contextual information", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "networks", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "global contextual information", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "networks", "label": "operates_on", "title": "Relation: operates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "RGB values", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "performance improvements", "label": "over", "title": "Relation: over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "alternative algorithms", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "UCF-101 datasets", "label": "has_performance", "title": "Relation: has_performance\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "88.6%", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "UCF-101 datasets", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "88.0%", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "UCF-101 datasets", "label": "has_performance_without", "title": "Relation: has_performance_without\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "optical flow information", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "UCF-101 datasets", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "73.0%", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "UCF-101 datasets", "label": "has_accuracy", "title": "Relation: has_accuracy\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "82.6%", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sports 1 million dataset", "label": "has_accuracy", "title": "Relation: has_accuracy\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "73.1%", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sports 1 million dataset", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "60.9%", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ioannis Gkiouslekas", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "On the Appearance of Translucnt Edges", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ioannis Gkiouslekas", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Harvard SEAS", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Gkiouslekas", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Harvard SEAS", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Harvard SEAS", "label": "is_an_institution_of", "title": "Relation: is_an_institution_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Higher Education", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Bruce Walter", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Cornell University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Bruce Walter", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "bruce.walter@cornell.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bruce Walter", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On the Appearance of Translueceny Edges", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Cornell University", "label": "is_an_institution_of", "title": "Relation: is_an_institution_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Higher Education", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Cornell University", "label": "has_department", "title": "Relation: has_department\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Computer Science", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Edward H. Adelson", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Massachusetts Institute of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Edward H. Adelson", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "adelson@cail.mit.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Edward H. Adelson", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On the Appearance of Translueceny Edges", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Massachusetts Institute of Technology", "label": "is_an_institution_of", "title": "Relation: is_an_institution_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Higher Education", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Massachusetts Institute of Technology", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CSAIL", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Massachusetts Institute of Technology", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LIDS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Walter", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Microfacet models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Microfacet models", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "refraction through rough surfaces", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Microfacet models", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "EGSR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Ioannis Gkioleakas", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Harvard SEAS", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ioannis Gkioleakas", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "igkio@seas.harvard.edu", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Higher Education", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Academic Degrees", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Ioannis Gkiousleas", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Harvard SEAS", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Todd Zickler", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Harvard SEAS", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Todd Zickler", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On the Appearence of Translueceny Edges", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kavita Bala", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cornell University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kavita Bala", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Material recognition in 2015 CVPR paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kavita Bala", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bell_Material_Recognition_in_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kavita Bala", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Computer Science, Cornell University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kavita Bala", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "kb@cs.cornell.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kavita Bala", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On the Appearance of Translueceny Edges", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Naeemullah Khan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shape-Tailored Local Descriptors", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Shape-Tailored Local Descriptors", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-Tailored Local Descriptors", "label": "has_application_in", "title": "Relation: has_application_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-Tailored Local Descriptors", "label": "has_application_in", "title": "Relation: has_application_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Tracking", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Marei Algarni", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shape-Tailored Local Descriptors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Marei Algarni", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "King Abdullah University of Science \u0026 Technology (KAUST)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Anthony Yezzi", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shape-Tailed Local Descriptors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Anthony Yezzi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Georgia Institute of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ganesh Sundaramoorthi", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shape-Tailored Local Descriptors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ganesh Sundaramoorthi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "King Abdullah University of Science \u0026 Technology (KAUST)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "descriptors", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "dense descriptors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "descriptors", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "texture segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "descriptors", "label": "formed from", "title": "Relation: formed from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "shape-dependent scale spaces", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "descriptors", "label": "do not", "title": "Relation: do not\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "aggregate image data across boundary", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "descriptors", "label": "lead_to", "title": "Relation: lead_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "accurate segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "descriptors", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "shape-dependent", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "descriptors", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "state-of-the-art", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "descriptors", "label": "are", "title": "Relation: are\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "non-shape dependent", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "datasets", "label": "contain", "title": "Relation: contain\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "3D models", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "datasets", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "SIFTs", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "accurate segmentation", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "texture segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "oriented gradients", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "existing descriptors", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "textured object tracking", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "texture segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-Tailored Descriptors (STLD)", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "texture segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-Tailori Descriptors (STLD)", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "non-shape dependent descriptors", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Local Descriptors", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "texture segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "De-An Huang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "How Do We Use Our Hands?", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "De-An Huang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Common Grasps", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "De-An Huang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Cnegie Mellon University", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "How Do We Use Our Hands?", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "common grasps", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Partial Differential Equations (PDE)", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "texture segmentation", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Minghuang Ma", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "How DoWe Use Our Hands?", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Minghuang Ma", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Common Grasps", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Minghuang Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Cnegie Mellon University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Minghuang Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Canezie Mellon University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Minghuang Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Carnegie Mellon University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wei-Chiu Ma", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "How Do We Use Our Hands?", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wei-Chiu Ma", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Common Grasps", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wei-Chiu Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Cnegie Mellon University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Wei-Chiu Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Canezie Mellon University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wei-Chiu Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Carnegie Mellon University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kris M. Kitani", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "How Do We Use Our Hands?", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kris M. Kitani", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Common Graspt", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kris M. Kitani", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Canezie Mellon University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "KAUST", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Saudi Arabia", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ganesh.sundaramoorthi@kust.edu.sa", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "KAUST", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Huang_How_Do_We2015_CVPR_paper.pdf", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "How Do We Use Our Hands?", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "computer vision techniques", "label": "can_be_used_to", "title": "Relation: can_be_used_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "advance prehensile analysis", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "prehensile analysis", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "multi-disciplinary field", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "researchers", "label": "analyze", "title": "Relation: analyze\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "hand-object interaction videos", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "wearable cameras", "label": "can_be_used_to", "title": "Relation: can_be_used_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "automatically discover common modes of human hand use", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "wearable cameras", "label": "led to", "title": "Relation: led to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "increase in egocentric videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "unsupervised clustering techniques", "label": "can_be_used_to", "title": "Relation: can_be_used_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "automatically discover common modes of human hand use", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "first-person point-of-view camera", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "observing human hand use", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "common modes of human hand use", "label": "are_discovered_by", "title": "Relation: are_discovered_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "wearable cameras", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "first-person point-of-view videos", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "choreographed scenarios", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Grasp Taxonomy", "label": "is_taxonomy_of", "title": "Relation: is_taxonomy_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "hand-object interaction", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Determinantal Point Process (DPP)", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "N. Ailon", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Streaming k-means approximation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "W. Barbakh", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Online clustering algorithms", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "A. Fathi", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Social interactions: A first-person perspective", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "R. Filipovych", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Recognizing primitive interactions", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "J. Case-Smith", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Development of hand skills in children", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Development of hand skills in children", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "hand skills", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "L. Cheng", "label": "coauthored", "title": "Relation: coauthored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Pixel-level hand detection in ego-centric videos", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "American Occupational Therapy Association", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Development of hand skills in children", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "M. Cutkosky", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "On grasp choice, grasp models", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "H. N. Djidjev", "label": "coauthored", "title": "Relation: coauthored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Computing shortest paths", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "C. Desai", "label": "coauthored", "title": "Relation: coauthored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Discriminaitive models for static human-object interactions", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Kris M. Kitan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cnegie Mellon University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Canezie Mellon University", "label": "has_affiliation", "title": "Relation: has_affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Kris M. Kitani", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Canezie Mellon University", "label": "has_affiliation", "title": "Relation: has_affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Wei-Chiu Ma", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Canezie Mellon University", "label": "has_affiliation", "title": "Relation: has_affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Minghuang Ma", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "deanh@andrew.cmu.edu", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Canezie Mellon University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "deanh@andrew.cmu.edu", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Carnegie Mellon University", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "minghuam@andrew.cmu.edu", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Canezie Mellon University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "weichium@andrew.cmu.edu", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Canezie Mellon University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Edward Johns", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Becoming the Expert", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Becoming the Expert", "label": "is_paper_about", "title": "Relation: is_paper_about\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Machine Teaching", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Becoming the Expert", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Oisin Mac Aodha", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Becoming the Efficient", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Gabriel J. Brostow", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Becoming the Expert", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Johns_Becoming_the_Expert_2015_CVPR_paper.pdf", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Becoming the Expert", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "computer", "label": "teaches", "title": "Relation: teaches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "challenging visual concepts", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "teaching strategy", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "experts", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "challenge", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "annotators", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "challenge", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "stereo matching", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "challenge", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "ground control points", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "challenge", "label": "of", "title": "Relation: of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "interpreting line drawings", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "annotators", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "expertise", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Interactive Machine Teaching", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Human Learning", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Interactive Machine Teaching", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Adaptive Algorithms", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Interactive Machine Teaching", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Visual Classification", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Bruner", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "The Process of Education", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "The Process of Education", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "foundational concepts", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "foundational concepts", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "teaching and learning", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Curriculum learning", "label": "aligns_with", "title": "Relation: aligns_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "teaching strategies", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Love", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Categorization", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Categorization", "label": "is_element_of", "title": "Relation: is_element_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "cognitive neuroscience", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Categorization", "label": "is_element_of", "title": "Relation: is_element_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "core tasks", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "cognitive neuroscience", "label": "provides_perspective_on", "title": "Relation: provides_perspective_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Categorization", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "active learning", "label": "is_explored_in", "title": "Relation: is_explored_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "active learning", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "overview", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "active learning", "label": "is_key", "title": "Relation: is_key\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Machine teaching", "label": "is_problem_of", "title": "Relation: is_problem_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "machine learning", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Machine teaching", "label": "is_approach_to", "title": "Relation: is_approach_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "education", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "overview", "label": "is_about", "title": "Relation: is_about\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "transparent object reconstruction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "technique", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "video segmentation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "technique", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "CNN", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "technique", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "high accuracy", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "technique", "label": "detects", "title": "Relation: detects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "salient objects", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "technique", "label": "predicts", "title": "Relation: predicts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "number of objects", "width": 2.92}, {"arrows": "to", "color": "#FF5722", "from": "sampling estimation", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "error", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "machine teaching", "label": "is_relevant_to", "title": "Relation: is_relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "approach toward optimal education", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "approach toward optimal education", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "machine teaching", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "paper\u0027s design", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "learners with limited cognitive capacity", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "algorithmic teaching", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "background", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Love \u0026 Patil", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "teaching learners", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Balbach \u0026 Zeugmann", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "algorithmic teaching methods", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Basu \u0026 Christensen", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "teaching classification boundaries", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Basu \u0026 Christensen", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "teaching classification tasks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Language and Automata Theory and Applications", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.68\u003cbr\u003eSource: unknown", "to": "Recent developments in algorithmic teaching", "width": 2.3600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "teaching classification tasks", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "algorithmic teaching methods", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Gigu`ere \u0026 Love", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "cognitive limitations", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "cognitive limitations", "label": "influences", "title": "Relation: influences\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "teaching strategies", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Chin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "University College London", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Eriksson", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "University College London", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Suter", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "University College London", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chin_Efficient_Globally_Optimal_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Efficient Globally Optimal Consensus Maximisation", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chin_Efficient_Globally_Optimal_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#9E9E9E", "from": "Maximum Consensus", "label": "is_criterion_for", "title": "Relation: is_criterion_for\u003cbr\u003eType: definitional\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust Estimation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Maximum Consensus", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Optimization Problems", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "randomized sample-and-test techniques", "label": "does_not_guarantee", "title": "Relation: does_not_guarantee\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "optimality", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "globally optimal algorithms", "label": "is_too_slow_compared_to", "title": "Relation: is_too_slow_compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "randomized methods", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "tree search problem", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "LP-type methods", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "A* Search", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Search Algorithm", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "A* Search", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "globally optimal results", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Tree Search", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Search Algorithm", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "LP-type Methods", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Optimization Problems", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "N. Amenta", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Optimal Point Placement for Mesh Smoothing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "M. Bern", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Optimal Point Placement for Mesh Smoothing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. Eppstein", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Optimal Point Placement for Mesh Smoothing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "B. Chazelle", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On Linear-Time Deterministic Algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "J. Matou\u02c7sek", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On Linear-Time Deterministic Algorithms", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Quasiconvex Programming", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Optimization Technique", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "optimization algorithms", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "core theme", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "optimization algorithms", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "RANSA algorithm", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "outlier rejection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "RANSA algorithm", "label": "applies_to", "title": "Relation: applies_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "image analysis", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "RANSA algorithm", "label": "applies_to", "title": "Relation: applies_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "automated cartography", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "multiple view geometry", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "central topic", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "multiple view geometry", "label": "is_reference_for", "title": "Relation: is_reference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "l\u221e triangulation", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "outlier handling", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "H. Li", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "algorithm for l\u221e triangulation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithm for l\u221e triangulation", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "outliers", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "geometric optimization", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "constraints", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "C. Olsson, O. Enqvist, and F. Kahl", "label": "focused_on", "title": "Relation: focused_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "outlier handling in matching", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "matching", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "registration", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "C. Olsson, A. Eriksson, and F. Kahl", "label": "addressed", "title": "Relation: addressed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "optimization techniques", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "optimization techniques", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "l\u221e-norm problems", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "optimization techniques", "label": "important_for", "title": "Relation: important_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "efficient computation", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Tat-Jun Chin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Tat-Jun Chin", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer Science, The University of Adelaide", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "University of Adelaide", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "University of Adelaide", "label": "has_author", "title": "Relation: has_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Bolei Zhou", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "University of Adelaide", "label": "has_author", "title": "Relation: has_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Fuyuan Hu", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "University of Adelaide", "label": "has_author", "title": "Relation: has_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Zhen Zhang", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "University of Adelaide", "label": "has_author", "title": "Relation: has_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Anton van den Hengel", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "University of Adelaide", "label": "has_author", "title": "Relation: has_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Chunhua Shen", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Anders Eriksson", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Anders Eriksson", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Electrical Engineering and Computer Science, Queensland University of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pulak Purkait", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer Science, The University of Adelaide", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Julian Straub", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Small-Variance Nonparametric Clustering on the Hypsphere", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Julian Straub", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CSAIL", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Julian Straub", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LIDS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Small-Variance Nonparametric Clustering on the Hypsphere", "label": "is_located_at", "title": "Relation: is_located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Trevor Campbell", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Small-Variance Nonparametric Clustering on the Hypsphere", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Trevor Campbell", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CSAIL", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Trevor Campbell", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "LIDS", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jonathan P. How", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Small-Variance Nonparametric Clustering on the Hypsphere", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jonathan P. How", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CSAIL", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jonathan P. How", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LIDS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "John W. Fisher III", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Small-Variance Nonparametric Clustering on the Hypsphere", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "John W. Fisher III", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CSAIL", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "John W. Fisher III", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LIDS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "John W. Fisher III", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "fisher@csaill.mit.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.pdf", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Small-Variance Nonparametric Clustering on the Hypshere", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "surface normals", "label": "reflect", "title": "Relation: reflect\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "distribution of structural regularities", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "algorithms", "label": "derived from", "title": "Relation: derived from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Bayesian nonparametric von-Mises-Fisher (vMF) mixture distributions", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithms", "label": "respect", "title": "Relation: respect\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "geometry of directional data", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "algorithms", "label": "demonstrates_performance_on", "title": "Relation: demonstrates_performance_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "synthetic directional data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "algorithms", "label": "demonstrated on", "title": "Relation: demonstrated on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "real 3D surface normals", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "algorithms", "label": "respects", "title": "Relation: respects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "geometry", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "algorithms", "label": "demonstrates_performance_on", "title": "Relation: demonstrates_performance_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D surface normals", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "algorithms", "label": "generalizes_to", "title": "Relation: generalizes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "high dimensional directional data", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "DDP-vMF-means", "label": "infers", "title": "Relation: infers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "temporally evolving cluster structure", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "DDP-vMF-means", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "streaming data", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "directional data", "label": "lies_on", "title": "Relation: lies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "unit sphere", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "DP-vMF-means", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Dirichlet process (DP) vMF mixture", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "high dimensional directional data", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "protein backbone configurations", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "high dimensional directional data", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "semantic word vectors", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Algorithms", "label": "utilize", "title": "Relation: utilize\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "RGB-D sensors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Algorithms", "label": "generalize_to", "title": "Relation: generalize_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "protein backbone configurations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Algorithms", "label": "generalize_to", "title": "Relation: generalize_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "semantic word vectors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Algorithms", "label": "measured_by", "title": "Relation: measured_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Runtime", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Algorithms", "label": "measured_by", "title": "Relation: measured_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Solution Quality", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Surface Normals", "label": "derived_from", "title": "Relation: derived_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "RGB-D sensors", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian Nonparametric Clustering", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "von-Mises-Fisher Distributions", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "von-Mises-Fisher Distributions", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Bayesian Nonparametric Clustering", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Streaming Data Analysis", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Bayesian Nonparametric Clustering", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Abramowitz \u0026 Stegun", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "mathematical background", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Neal", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Markov chain sampling", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Markov chain sampling", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "DPMMs", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jiang, Kulis, \u0026 Jordan", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "theoretical analysis", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "DPMMs", "label": "analyzed_by", "title": "Relation: analyzed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Jiang, Kulis, \u0026 Jordan", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "DPMMs", "label": "analyzed by", "title": "Relation: analyzed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Jiang, K., Kulis, B., and Jordan, M.", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "DPMMs", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Bayesian nonparametrics", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "DPMMs", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "spherical data", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Latent Dirichlet Allocation", "label": "is_relevant_to", "title": "Relation: is_relevant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "spherical topic models", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Latent Dirichlet Allocation", "label": "presented in", "title": "Relation: presented in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "JMLR", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "k-means", "label": "connected_to", "title": "Relation: connected_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Bayesian nonparametrics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Directional statistics", "label": "treated in", "title": "Relation: treated in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Mardia, K. V. and Jupp, P. E.", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Directional statistics", "label": "is_described_in", "title": "Relation: is_described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "John Wiley \u0026 Sons", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian nonparametric methods", "label": "analyzed in", "title": "Relation: analyzed in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Ferguson, T.", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian nonparametric methods", "label": "is_foundational_to", "title": "Relation: is_foundational_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "DPMMs", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Ferguson distributions", "label": "introduced_through", "title": "Relation: introduced_through\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "p\u00b4olya urn schemes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dirichlet processes", "label": "provides_overview_in", "title": "Relation: provides_overview_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Encyclopedia of Machine Learning", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian analysis", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "nonparametric problems", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Dingwen Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Co-Saliency Detection via Looking Deep and Wide", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Dingwen Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Northwestern Polytechnical University", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Co-Saliency Detection via Looking Deep and Wide", "label": "published_as", "title": "Relation: published_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "cvpr_papers/Zhang_Co-Saliency_Detection_via_2015_CVPR_paper.pdf", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Junwei Han", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Co-Saliency Detection via Looking Deep and Wide", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Junwei Han", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Northwestern Polytechnical University", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Chao Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Co-Saliency Detection via Looking Deep and Wide", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chao Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Northwestern Polytechnical University", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Jingdong Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Co-Saliency Detection via Looking Deep and Wide", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jingdong Wang", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jingdong Wang", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "jingdw@microsoft.com", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "co-saliency detection", "label": "is_essential_for", "title": "Relation: is_essential_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "video foreground extraction", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "co-saliency detection", "label": "is_essential_for", "title": "Relation: is_essential_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "surveillance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "co-saliency detection", "label": "is_essential_for", "title": "Relation: is_essential_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image retrieval", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "co-saliency detection", "label": "is_essential_for", "title": "Relation: is_essential_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image annotation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "network", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "representation of co-salient objects", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "network", "label": "outputs", "title": "Relation: outputs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "similarity value", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "network", "label": "achieves_results", "title": "Relation: achieves_results\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state of the art", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "network", "label": "fine-tuned_on", "title": "Relation: fine-tuned_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "small target data set", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "network", "label": "trained_on", "title": "Relation: trained_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "large data set", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "neighbors", "label": "suppresses", "title": "Relation: suppresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "common background regions", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "co-salience scores", "label": "calculated_by", "title": "Relation: calculated_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "intra-image contrast", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "co-salience scores", "label": "calculated_by", "title": "Relation: calculated_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "intra-group consistency", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "window-level co-salience scores", "label": "converted_to", "title": "Relation: converted_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "superpixel-level co-salience maps", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "superpixel-level co-salience maps", "label": "generated_by", "title": "Relation: generated_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "foreground region agreement strategy", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian formulation", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.83\u003cbr\u003eSource: unknown", "to": "intra-image contrast", "width": 2.66}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian formulation", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.83\u003cbr\u003eSource: unknown", "to": "intra-group consistency", "width": 2.66}, {"arrows": "to", "color": "#4CAF50", "from": "l-level co-saliency maps", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "foreground region agreement", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "consistent performance gain", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "demonstrates_superiority_over", "title": "Relation: demonstrates_superiority_over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "state-of-the-art hashing methods", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "current state of the art", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "robust object discovery", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "shows superiority over", "title": "Relation: shows superiority over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "state-of-the-arts", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "operates on", "title": "Relation: operates on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "fluorescence microscopy cell images", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "operates on", "title": "Relation: operates on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "UCSD pedestrians", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "operates on", "title": "Relation: operates on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "small animals", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "operates on", "title": "Relation: operates on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "insects", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "is_effective", "title": "Relation: is_effective\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Visual Object Tracking", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "proposed approach", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art trackers", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Co-salient object detection", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "multiple images", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Unified approach", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "low rank matrix recovery", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "iCoseg", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "intelligent scribble guidance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Co-salience detection", "label": "relates to", "title": "Relation: relates to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks (CNNs)", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Co-salience detection", "label": "relates to", "title": "Relation: relates to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Image Group Consistency", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks (CNNs)", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "images", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks (CNNs)", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "image recognition accuracy", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks (CNNs)", "label": "increasingly", "title": "Relation: increasingly\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "complex", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks (CNNs)", "label": "increasingly", "title": "Relation: increasingly\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "time-consuming", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Neural Networks (CNNs)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Pose Estimation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Neural Networks (CNNs)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks (CNNs)", "label": "analyzed_in", "title": "Relation: analyzed_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Song_Joint_Multi-Feature_Spatial_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks (CNNs)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Deep Convolutional Networks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks (CNNs)", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "ImageNet classification", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Neural Networks (CNNs)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "deep learning", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian Formulation", "label": "is used in", "title": "Relation: is used in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "salient object detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "discriminative regional feature integration", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Visual Attention", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "co-salience detection", "width": 2.56}, {"arrows": "to", "color": "#2196F3", "from": "Visual Attention", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Binary Linear Integer Programming", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "alient object detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR (Conference)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xie, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Bayesian salience", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian salience", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "low and mid level cues", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Han, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "object-oriented visual salieny detection framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "object-oriented visual salieny detection framework", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "sparse coding representations", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Rubinstein, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "joint object discovery", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "joint object discovery", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "internet images", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Jiang, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "salient object segmentation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "salient object segmentation", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "context prior", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "IEEE Trans. Image Process.", "label": "is_journal_of", "title": "Relation: is_journal_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Image Processing", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Image Processing", "label": "includes_applications", "title": "Relation: includes_applications\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Stereo/Inpainting", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "is_author_of", "label": "writes", "title": "Relation: writes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cong Zhang", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "is_author_of", "label": "writes", "title": "Relation: writes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hongsheng Li", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "is_author_of", "label": "writes", "title": "Relation: writes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Xiaogang Wang", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "is_author_of", "label": "writes", "title": "Relation: writes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Xiaokang Yang", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cong Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Cross-Scene Crowd Counting", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Cong Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hongsheng Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Department of Electronic Engineering, The Chinese University of Hong Kong", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hongsheng Li", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saliency Detection by Multi-Context Deep Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hongsheng Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Electronic Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hongsheng Li", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "hsli@ee.cuhk.edu.hk", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaogang Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Cross-Scene Crowd Counting", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaogang Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Department of Electronic Engineering, The Chinese University of Hong Kong", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaogang Wang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saliency Detection by Multi-Content Deep Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaogang Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Shenzhen Institutes of Advanced Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaogang Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Deeply Learned Attributes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaokang Yang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Cross-Scene Crowd Counting", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaokang Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaokang Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Chinese University of Hong Kong", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaokang Yang", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "xgwang@ee.cuhk.edu.hk", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaokang Yang", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "xk yang@sjtu.edu.cn", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaokang Yang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Motion Part Regularization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Automatic salient object segmentation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "BMVC", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Self-Adaptively Weighted Co-Saliency Detection", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE Trans. Image Process.", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Cross-Scene Crowd Counting", "label": "publication_venue", "title": "Relation: publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cross-Scene Crowd Counting", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Cross-Scene Crowd Counting", "label": "method", "title": "Relation: method\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Deep Convolutional Neural Networks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_Cross-Scene_Crowd_Counting_2015_CVPR_paper.pdf", "label": "document_of", "title": "Relation: document_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Cross-Scene Crowd Counting", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Cross-scene crowd counting", "label": "is_task", "title": "Relation: is_task\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "crowd counting", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cross-scene crowd counting", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "no laborious data annotation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing crowd counting methods", "label": "experiences", "title": "Relation: experiences\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "significant performance drop", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "deep convolutional neural network (CNN)", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "crowd counting", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "deep convolutional neural network (CNN)", "label": "is_trained_with", "title": "Relation: is_trained_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "crowd density", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "deep convolutional neural network (CNN)", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object detection benchmarks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "switchable learning approach", "label": "aims_to_achieve", "title": "Relation: aims_to_achieve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "better local optimum", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "data-driven method", "label": "is_used_to", "title": "Relation: is_used_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "fine-tune CNN model", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "CNN model", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "trained", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Crowd Counting", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Deep Convolutional Neural Networks (CNNs)", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Crowd Counting", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object counting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Crowd Counting", "label": "addressed_by", "title": "Relation: addressed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Chen et al. (2013)", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Crowd Counting", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Deep Convolutional Neural Networks (CNNs)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Convolutional Neural Networks (CNNs)", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Deep Convolutional Neural Networks (CNNs)", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Dimensionality Reduction", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chen et al. (2013)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "cumulative attribute space", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chen et al. (2013)", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "cross-scene crowd counting methods", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "cumulative attribute space", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "crowd density estimation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Lempitsky \u0026 Zisserman (2010)", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "object counting", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Chen et al. (2012)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "feature mining", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "feature mining", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "localized crowd counting", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "localized crowd counting", "label": "is_aspect_of", "title": "Relation: is_aspect_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Loy et al. (2012) research", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "localized crowd counting", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "An et al. (2007) research", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "kernel ridge regression", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "kernel ridge regression", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "vision tasks", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Kai et al. (2014) research", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "fully convolutional network", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "fully convolutional network", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "crowd segmentation", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "fully convolutional network", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "neural network", "width": 2.8200000000000003}, {"arrows": "to", "color": "#2196F3", "from": "crowd segmentation", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kong et al. (2006) research", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "viewpoint invariance", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Kong et al. (2006)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "viewpoint invariance in crowd counting", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "viewpoint invariance in crowd counting", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "practical consideration", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jing et al. (2015)", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "deep learning for attribute extraction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "attribute extraction", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "crowd scene understanding", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Fiaschi et al. (2012)", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "regression forest for counting", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "regression forest for counting", "label": "is_alternative_to", "title": "Relation: is_alternative_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "neural networks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "neural networks", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "dimensionality reduction", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Loy et al. (2013)", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "semi-supervised learning for crowd counting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Loy et al. (2013)", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "transfer learning for crowd counting", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "ICPR", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "conference", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "ICCV", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "conference", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "ICCV", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Class-specific material categorisation", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "ICCV", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Conference", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ICCV", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "1841\u20131848", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ICCV", "label": "publication_venue", "title": "Relation: publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Ground truth dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gong, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "From semi-supervised to transfer counting of crowds", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiang, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "From semi-supervised to transfer counting of crowds", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lowe, D. G.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Distinctive image features from scale-invariant keypoints", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Distinctive image features from scale-invariant keypoints", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "feature extraction", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "SIFT features", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Distinctive image features from scale-invariant keypoints", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "SIFT features", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "crowd analysis", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "SIFT features", "label": "is_building_block_for", "title": "Relation: is_building_block_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "image representation techniques", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "SIFT features", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "keypoints", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "SIFT features", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IJCV, 60:91\u2013110, 2004", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "SIFT features", "label": "is_component_of", "title": "Relation: is_component_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image processing tasks", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "SIFT features", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "key component", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "SIFT features", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "distinctive image features", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "SIFT features", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "feature detection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "SIFT features", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "feature matching", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Yongzhen Huang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep SemanticRanking Based Hashing", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Yongzhen Huang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Center for Research on Intelligent Perception and Computing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Liang Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Semantic Ranking Based Hashing", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Liang Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Center for Research on Intelligent Perception and Computing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Semantic Ranking Based Hashing", "label": "is_paper_in", "title": "Relation: is_paper_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Deep Semantic Ranking Based Hashing", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Multi-Label Image Retrieval", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Tieniu Tan", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Semantic Ranking Based Hashing", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Tieniu Tan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Center for Research on Intelligent Perception and Computing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Institute of Image Communication and Network Engineering", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Shanghai Jiao Tong University", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "deep hash functions", "label": "overcomes_limitation_of", "title": "Relation: overcomes_limitation_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "hand-crafted features", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "deep hash functions", "label": "learns_from", "title": "Relation: learns_from\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "ranking list", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "ranking list", "label": "encodes", "title": "Relation: encodes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "multilevel similarity information", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "multilevel similarity information", "label": "is_encoded_by", "title": "Relation: is_encoded_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ranking list", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "semantic representation", "label": "is_limited_by", "title": "Relation: is_limited_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "hand-crafted features", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "hash codes", "label": "derived_from", "title": "Relation: derived_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "semantic representation", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Deep Hash Functions", "label": "guided_by", "title": "Relation: guided_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Similarity Information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed Approach", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Hashing Methods", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet Classification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Convolutional Neural Networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Convolutional Ranking", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Multi-label Image Annotation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Iterative Quantization", "label": "aims_to_learn", "title": "Relation: aims_to_learn\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Binary Codes", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Binary Codes", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Image Retrieval", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Image Retrieval", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Hashing", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "ImageNet Classification", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky", "label": "co_authors_with", "title": "Relation: co_authors_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hinton", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Imaginet classification with deep convolutional neural networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Gong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Convolutional Ranking", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Gong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Iterative Quantization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep convolutional ranking", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Maximum Entropy Feature Descriptor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "sequential subset selection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Perronnin", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Iterative quantization", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Iterative quantization", "label": "applies", "title": "Relation: applies\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "binary codes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "binary codes", "label": "distribute evenly", "title": "Relation: distribute evenly\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "each bit", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Norouzi", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Hamming distance metric learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Norouzi", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Minimal loss hashing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hamming distance metric learning", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Advances in Neural Information Processing Systems", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Semi-supervised hashing", "label": "aims_for", "title": "Relation: aims_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "scalable image retrieval", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Semi-supervised hashing", "label": "is_presented_in", "title": "Relation: is_presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "*CVPR*", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Semi-supervised hashing", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "techniques", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Torralba", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Small codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Torralba", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning to Predict Where Humans Look", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Small codes", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "image databases", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Deep convolutional ranking", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "multilabel image annotation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Deep convolutional ranking", "label": "is_application_of", "title": "Relation: is_application_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "multilable image annotation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gong, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep convolutional ranking", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "One weird trick", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ImageNet classification with deep convolutional neural networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky, A.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ImageNet Classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "ImageNet classification", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky, A.", "label": "co_author_of", "title": "Relation: co_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sutskever, I.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevsky, A.", "label": "co_author_of", "title": "Relation: co_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Hinton, G. E.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "One weird trick", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "parallelizing convolutional neural networks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Minimal loss hashing", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "compact binary codes", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "compact binary codes", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "loss", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lin, G.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Optimizing ranking measures", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Optimizing ranking measures", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "compact binary code learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fang Zhao", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Center for Research on Intelligent Perception and Computing", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Center for Research on Intelligent Perception and Computing", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Institute of Automation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Institute of Automation", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Institute of Automation", "label": "houses", "title": "Relation: houses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Center for Biometrics and Security Research", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Institute of Automation", "label": "houses", "title": "Relation: houses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "National Laboratory of Pattern Recognition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "David Perra", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adaptive Eye-Camera Calibration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "David Perra", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Google Inc.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive Eye-Camera Calibration", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Rohit Kumar Gupta", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adaptive Eye-Camera Calibration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rohit Kumar Gupta", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The University of North Carolina at Chapel Hill", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rohit Kumar Gupta", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "rkgupta@cs.unc.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "fang.zhao@nlpr.ia.ac.cn", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Center for Research on Intelligent Perception and Computing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Perra_Adaptive_Eye-Camera_Calibration_2015_CVPR_paper.pdf", "label": "is_file", "title": "Relation: is_file\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "calibration scheme", "label": "solves_for", "title": "Relation: solves_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "globally optimal model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "calibration scheme", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "changes in calibration", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "calibration scheme", "label": "calculates", "title": "Relation: calculates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "locally optimal eye-device transformation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "calibration scheme", "label": "computes_from", "title": "Relation: computes_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "local window of previous frames", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "calibration scheme", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "continuous", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "calibration scheme", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "locally optimal", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "calibration scheme", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state of the art systems", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "calibration scheme", "label": "is less restrictive to", "title": "Relation: is less restrictive to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "environment", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "calibration schemes", "label": "performed_on", "title": "Relation: performed_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "per-user basis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "interest regions", "label": "located within", "title": "Relation: located within\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "user\u2019s environment", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "eye-device transformation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "locally optimal", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "proposed calibration scheme", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "existing state of the art systems", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "proposed calibration scheme", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "less restrictive", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "proposed calibration scheme", "label": "is less restrictive to", "title": "Relation: is less restrictive to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "environment", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Alnajar et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Calibration-free gaze estimation", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Calibration-free gaze estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "human gaze patterns", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chen and Ji", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Probabilistic gaze estimation", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Probabilistic gaze estimation", "label": "avoids", "title": "Relation: avoids\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "active personal calibration", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Corno et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "cost-effective solution", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "cost-effective solution", "label": "is for", "title": "Relation: is for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "eye-gaze assistive technology", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "eye-camera calibration", "label": "is related to", "title": "Relation: is related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "gaze tracking", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "F. Corno", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE International Conference on Multimedia and Expo", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE International Conference on Multimedia and Expo", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "research on assistive technology", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "E. Guestrin", "label": "researched", "title": "Relation: researched\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "remote gaze estimation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "remote gaze estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "pupil center", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "D. Hansen", "label": "surveyed", "title": "Relation: surveyed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "models for eyes and gaze", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "J. Harel", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "graph-based visual saliency", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "J. Harel", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Graph-based visual salience", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "graph-based visual saliency", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "neural processing method", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "X. Hou", "label": "researched", "title": "Relation: researched\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "image signature", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "X. Hou", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "image signature", "label": "highlights", "title": "Relation: highlights\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "sparse salient regions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Transactions on Biomedical Engineering", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "research on remote gaze estimation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "U. Lahiri", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Neural Systems and Rehabilitation Engineering, IEEE Transactions on", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "U. Lahiri", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Virtual Rehabilitation (ICVR)", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "U. Lahiri", "label": "developed_system_for", "title": "Relation: developed_system_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "children with autism", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "U. Lahiri", "label": "developed_system_for", "title": "Relation: developed_system_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "social communication", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "R. Kumar", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision and Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jan-Micheal Frahm", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The University of North Carolian at Chapel Hill", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jan-Micheal Frahm", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The University of North Carolina at Chapel Hill", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jan-Micheal Frahm", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "jmf@cs.unc.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Nianuan Jiang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Direct Structure Estimation for 3D Reconstruction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Nianuan Jiang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Nianuan Jiang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center, Singapore", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Direct Structure Estimation for 3D Reconstruction", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Wen-Yan Lin", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Direct Structure Estimated for 3D Reconstruction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Wen-Yan Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Wen-Yan Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center, Singapore", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Minh N. Do", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Direct Structure Estimation for 3D Reconstruction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Minh N. Do", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Minh N. Do", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Illinois at Urbana-Champaign", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiangbo Lu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Direct Structure Estimation for 3D Reconstruction", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jiangbo Lu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center, Singapore", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiang_Direct_Structure_Estimation_2015_CVPR_paper.pdf", "label": "documents", "title": "Relation: documents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Direct Structure Estimation for 3D Reconstruction", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Structure from Motion (SFM)", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "camera pose estimation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Structure from Motion (SFM)", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Euclidean Rigidity", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Structure from Motion (SFM)", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "scene reconstruction", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Structure from Motion (SFM)", "label": "relies on", "title": "Relation: relies on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Homography Estimation", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "camera pose estimation", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "visual SLAM", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Euclidean Rigidity", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "scene structure recovery", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Direct StructureEstimation (DSE)", "label": "combines with", "title": "Relation: combines with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "homography estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Direct Structure Estimation (DSE)", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "formulation for scene structure recovery", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Direct Structure Estimation (DSE)", "label": "works well for", "title": "Relation: works well for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "recovering scene structure", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Direct Structure Estimation (DSE)", "label": "works well for", "title": "Relation: works well for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "recovering camera poses", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Direct Structure Estimation (DSE)", "label": "is a method in", "title": "Relation: is a method in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Structure from Motion (SFM)", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "scene structure", "label": "is recovered from", "title": "Relation: is recovered from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "sideway motion", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "scene structure", "label": "occurs in", "title": "Relation: occurs in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "planar or general man-made scenes", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Camera Pose Estimation", "label": "is part of", "title": "Relation: is part of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Structure from Motion (SFM)", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Camera Pose Estimation", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Non-Rigid Structure from Motion", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "D. Nist\u00e9r", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "solution to five-point relative pose problem", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. G. Aliaga", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "simplifying reconstruction of 3d models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "K. S. Arun", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "least-squares fitting of two 3-d point sets", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. Crandall", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "discrete-continuous optimization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. W. Eggert", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "comparison of four major algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. W. Eggert", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Estimating 3-d rigid body transformations", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "least-squares fitting", "label": "is a technique in", "title": "Relation: is a technique in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "3d point set alignment", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "M. A. Fischler", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Random sample consensus", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Random sample consensus", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Communications of the ACM", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Random sample consensus", "label": "is_paradigm_for", "title": "Relation: is_paradigm_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "model fitting", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Random sample consensus", "label": "applies_to", "title": "Relation: applies_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "image analysis", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Advanced Digital Sciences Center", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Singapore", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Structure from motion", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "R. Hartley", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "In defense of the eight-point algorithm", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "H. Isack", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Energy-based geometric multi-model fitting", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "N. Jiang", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A global linear method for camera pose registration", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Stefan Roth", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Richter_Discriminative_Shape_From_2015_CVPR_supplemental", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stefan Roth", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Computer Science, TU Darmstadt", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stefan Roth", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "TU Darmstadt", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stefan Roth", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stefan Roth", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Discriminaitve Shape from Shading", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Stefan Roth", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Department of Computer Science", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Richter_Discriminative_Shape_From_2015_CVPR_supplemental", "label": "publication_venue", "title": "Relation: publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Richter_Discriminative_Shape_From_2015_CVPR_supplemental", "label": "publication_year", "title": "Relation: publication_year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Richter_Discriminative_Shape_From_2015_CVPR_supplemental", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Discriminative Shape from Shading", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Shape from shading method", "label": "is_compared_to", "title": "Relation: is_compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "other approaches", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Shape from shading method", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "local context", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shape from shading method", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "learning framework", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Shape from shading method", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "improved reconstructions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Shape from shading method", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "smooth local context", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Results", "label": "presented_on", "title": "Relation: presented_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "real images", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Dataset", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ground truth dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "real objects", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Dataset", "label": "consists_of", "title": "Relation: consists_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Real Objects", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Shape from Shading", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Surface Reconstruction", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Shape from Shading", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Illumination Estimation", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Shape from Shading", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Local and Global Context", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Shape from Shading", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Shape from Shading", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "research area", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Surface Reconstruction", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Light_Field_From_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Surface Reconstruction", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "RGB-D Cameras", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Barron, J. T., \u0026 Malik, J.", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Color Constancy", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Johnson, M. K., \u0026 Adelson, E. H.", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shape Estimation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Johnson, M. K., \u0026 Adelson, E. H.", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Natural Illumination", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Shape Estimation", "label": "addressed in", "title": "Relation: addressed in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Johnson \u0026 Adelson (2011) paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jacobs, D. W.", "label": "appears_in_author_list_for", "title": "Relation: appears_in_author_list_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "reference [4]", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Basri, R.", "label": "appears_in_author_list_for", "title": "Relation: appears_in_author_list_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "reference [4]", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stephan R. Richter", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Computer Science, TU Darmstadt", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stephan R. Richter", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "TU Darmstadt", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stephan R. Richter", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stephan R. Richter", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Discriminaitve Shape from Shading", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Stephan R. Richter", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Department of Computer Science", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Computer Science, TU Darmstadt", "label": "is_affiliation_of", "title": "Relation: is_affiliation_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Stephan R. Richter", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Computer Science, TU Darmstadt", "label": "is_affiliation_of", "title": "Relation: is_affiliation_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Stefan Roth", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "TU Darmstadt", "label": "hosts_department", "title": "Relation: hosts_department\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Computer Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Andr\u00e1s B\u00f3dis-Sz\u0151m\u0151ru", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Superpixel Meshes", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Superpixel Meshes", "label": "publication_venue", "title": "Relation: publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Superpixel Meshes", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Superpixel Meshes", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "surface reconstruction", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Superpixel Meshes", "label": "preserves", "title": "Relation: preserves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "edges", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Hayko Riemenschneider", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Superpixel Meses", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Hayko Riemenschneider", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "ETH Zurich, Computer Vision Lab", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Luc Van Gool", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Superpixel Meshes", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Luc Van Gool", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "PSI-VISICS, KU Leuven", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Luc Van Gool", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Metric imitation by manifold transfer", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Luc Van Gool", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "VISICS, ESAT/PSI, KU Leuven", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Luc Van Gool", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Lab, ETH Zurich", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Luc Van Gool", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Privacy Preserving Optics for Miniature Vision Sensors", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Bodis-Szomoru_Superpixel_Meshes_for_2015_CVPR_supplemental.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Superpixel Meshes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-View-Stereo methods", "label": "aim_for", "title": "Relation: aim_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "highest detail", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "surface reconstruction method", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image edges", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "surface reconstruction method", "label": "is_constrained_by", "title": "Relation: is_constrained_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "second-order smoothness constraints", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "meshes", "label": "have_quality", "title": "Relation: have_quality\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "classic MVS surfaces", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "meshes", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "edge-aligned", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "meshes", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "compact", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "meshes", "label": "aligned_with", "title": "Relation: aligned_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "image gradients", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "dense depth optimization", "label": "occurs_over", "title": "Relation: occurs_over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Ground Control Points", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "SfM points", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "GCPs", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "LiDAR", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "GCPs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "RGB-D", "label": "can_be_used_as", "title": "Relation: can_be_used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "GCPs", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Structure-from-Motion (SfM) points", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "GCPs", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "renderings", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "lightweight", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "renderings", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "per-face flat", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_Light_Field_From_2015_CVPR_paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Didyk et.al", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "Zhang_Light_Field_From_2015_CVPR_paper", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "surface quality", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Superpixels", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Light_Light_Field_From_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Structure-from-Motion (SfM)", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Light_Field_From_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Mesh Generation", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Light_Field_From_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Edge-Preerving Methods", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Light_Field_From_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Andr\u00b4as B\u00b4odis-Szomor\u00b4u", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "ETH Zurich, Computer Vision Lab", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "intermediate views", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "light field synthesis", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Depth Estimation", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "existing methods", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "existing methods", "label": "use", "title": "Relation: use\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "pixel-coordinates", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing methods", "label": "has_issue", "title": "Relation: has_issue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "failure to enforce consistency constraints", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "View Synthesis", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Light Field Reconstruction", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Disparity Refinement", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Iterative View Generation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Jan Hosang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Taking a Deeper Look at Pedestrians", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Taking a Deeper Look at Pedestrians", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Mohamed Omran", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Taking a Deeper Look at Pedestrians", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mohamed Omran", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "CifarNet", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "pedestrian detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "AlexNet", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "pedestrian detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "AlexNet", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Krizhevsky, A., Sutskever, I., and Hinton, G. E.", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "AlexNet", "label": "precedes", "title": "Relation: precedes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "re-identification models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "AlexNet", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep learning", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "AlexNet", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep convolutional neural network", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "AlexNet", "label": "achieved", "title": "Relation: achieved\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "breakthrough performance", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "AlexNet", "label": "influences", "title": "Relation: influences\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "research in intrinsic image decomposition", "width": 2.76}, {"arrows": "to", "color": "#FF5722", "from": "AlexNet", "label": "influences", "title": "Relation: influences\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "subsequent research", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "filter size", "label": "affects", "title": "Relation: affects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "layer width", "label": "affects", "title": "Relation: affects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "learning rate policies", "label": "affects", "title": "Relation: affects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "pedestrian heights", "label": "distributed_in", "title": "Relation: distributed_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "datasets", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Calttech dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "pedestrian heights", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "pedestrian heights", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "KITTI dataset", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "benchmark", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI dataset", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI dataset", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "robotics", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI dataset", "label": "is_benchmark_for", "title": "Relation: is_benchmark_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "vision and robotics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "transferability", "label": "varies_between", "title": "Relation: varies_between\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "datasets", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "neural network training", "label": "is_sensitive_to", "title": "Relation: is_sensitive_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "parameter choices", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "parameter optimization", "label": "is_important_for", "title": "Relation: is_important_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "optimal results", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Pedestrian Detection", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Neural Network Training", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pedestrian Detection", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Parameter Optimization", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "Parameter Optimization", "label": "influences", "title": "Relation: influences\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "optimal results", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Dataset Analysis", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Neural Network Training", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Transfer Learning", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Neural Network Training", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Benenson, R.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Benenson, R.", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "rodrigo.benenson@mpi-inf.mpg.de", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Max Planck Institute for Informatics", "label": "research_area", "title": "Relation: research_area\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "informatics", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Max Planck Institute for Informatics", "label": "research_area", "title": "Relation: research_area\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Omran, M.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Omran, M.", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "mohamed.omran@mpi-inf.mpg.de", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Schiele, B.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Schiele, B.", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "unspecified", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Hosang, J.", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "jan.hosang@mpi-inf.mpg.de", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kiyoshi Matsuo", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Depth Image Enhancement Using Local Tangent Plane Approximations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kiyoshi Matsuo", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Hokuyo Automatic Co., LTD.", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Depth Image Enhancement Using Local Tangent Plane Approximations", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Depth Image Enhancement Using Local Tangent Plane Approximations", "label": "publication_date", "title": "Relation: publication_date\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Yoshimitsu Aoki", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Depth Image Enhancement Using Local Tangent Plane Approximations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yoshimitsu Aoki", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Keio University", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "depth image enhancement method", "label": "aims_for", "title": "Relation: aims_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "consumer RGB-D cameras", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "pixel-coordinates", "label": "is_unsuitable_for", "title": "Relation: is_unsuitable_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "handling local geometries", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "two steps", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "calculation of local tangents", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "two steps", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "surface reconstruction", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "depth image enhancement", "label": "achieved_by", "title": "Relation: achieved_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "local geometries", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Local Tangent Planes", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Depth Image Enhancement", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "RGB-D Cameras", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Surface Reconstruction", "width": 2.76}, {"arrows": "to", "color": "#FF5722", "from": "Noise Reduction", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Completion Rate", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Asus Xtion Pro Live", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "RGB-D Cameras", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Kim et al. (2013)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "joint intensity and depth analysis model", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Kim et al. (2014)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "depth map upsampling", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lee et al.", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Journal of Signal Processing Systems", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "depth map upsampling method", "label": "is_robust_to", "title": "Relation: is_robust_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "misalignment of depth and color boundaries", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Kopf et al.", "label": "develops", "title": "Relation: develops\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Joint bilateral upsampling", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Joint bilateral upsampling", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "upsampling method", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Li et al.", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Joint example-based depth map super-resolution", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Joint example-based depth map super-resolution", "label": "aims_to_improve", "title": "Relation: aims_to_improve\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "depth map resolution", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Lu et al.", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Depth enhancement", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Depth enhancement", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "low-rank matrix completion", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Joint geodesic up-sampling", "label": "targets", "title": "Relation: targets\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "depth images", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "S. Lu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Depth enhancement via low-rank matrix completion", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "S. Lu", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR 2014", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. Scharstein", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning conditional random fields for stereo", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J. Papon", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Point cloud video object segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J. Papon", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IROS 2013", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sean Bell", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Material Recognition in the Wild", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Sean Bell", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Material Recognition in 2015 CVPR paper", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Sean Bell", "label": "works_in_field", "title": "Relation: works_in_field\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Material Recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Sean Bell", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Materials in Context Database", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Sean Bell", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bell_Material_Recognition_in_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sean Bell", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Computer Science, Cornell University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Sean Bell", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "sbell@cs.cornell.edu", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Material Recognition in the Wild", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Materials in Context Database", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Upchurch", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Material Recognition in the Wild", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Upchurch", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Material Recognition in 2015 CVPR paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Upchurch", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bell_Material_Detection_in_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Paul Upchurch", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "paulu@cs.cornell.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Material Recognition in 2015 CVPR paper", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Material Recognition in 2015 CVPR paper", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Material Recognition in 2015 CVPR paper", "label": "addresses_topic", "title": "Relation: addresses_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Material Recognition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Noah Snavely", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Material Recognition in 2015 CVPR paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Noah Snavely", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bell_Material_Recognition_in_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Noah Snavely", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Computer Science, Cornell University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Noah Snavely", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "snavely@cs.cornell.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Material Recognition", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "large, well-sampled datasets", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "material recognition", "label": "is_challenging_due_to", "title": "Relation: is_challenging_due_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "rich surface texture", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "material recognition", "label": "is_challenging_due_to", "title": "Relation: is_challenging_due_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "geometry", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "material recognition", "label": "is_challenging_due_to", "title": "Relation: is_challenging_due_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "lighting conditions", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "MINC", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "MINC", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "large-scale", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "MINC", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "open", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "CNNs", "label": "are_used_for", "title": "Relation: are_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "material classification", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "CNNs", "label": "are_used_for", "title": "Relation: are_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "material segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "patch-based classification", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "85.2% mean class accuracy", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "full image segmentation", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "73.1% mean class accuracy", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Dataset Creation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "MINC", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "G. Patterson et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "The SUN Attribute Database", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "The SUN Attribute Database", "label": "facilitates", "title": "Relation: facilitates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Deeper Scene Understanding", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "S. Bell et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "OpenSurposes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "OpenSurfaces", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "richly annotated catalog", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "X. Qi et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Pairwise rotation invariant co-occurrence local binary pattern", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "B. Caputo et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Class-speci\ufb01c material categorisation", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "variant co-occurrence local binary pattern", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image processing", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "ImageNet Large Scale Visual Recognition Challenge", "label": "is_event", "title": "Relation: is_event\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "visual recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet Large Scale Visual Recognition Challenge", "label": "is_benchmark_for", "title": "Relation: is_benchmark_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Image Classification", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "ACM Transactions on Graphics (TOG)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Re\ufb02ectence and texture of real-world surfaces", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "LabelMe", "label": "is_database_and_tool_for", "title": "Relation: is_database_and_tool_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "image annotation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Re\ufb02ectance", "label": "is_property_of", "title": "Relation: is_property_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "real-world surfaces", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "texture", "label": "is_property_of", "title": "Relation: is_property_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "real-world surfaces", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Describing textures in the wild", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "texture", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "TOG", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Graphics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pascal VOC Challenge", "label": "is_challenge_in", "title": "Relation: is_challenge_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Visual Object Classes", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Computer Science", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Canada", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Wonmin Byeon", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Scene Labeling with LSTM Recurrent Neural Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Wonmin Byeon", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "German Research Center for Arti\ufb01cial Intelligence (DFKI)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Scene Labeling with LSTM Recurrent Neural Networks", "label": "is_paper_type", "title": "Relation: is_paper_type\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Thomas M. Breuel", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Scene Labeling with LSTM Recurrent Neural Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Thomas M. Breuel", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of Kaiserslautern", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Federico Raue", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Scene Labeling with LSTM Recurrent Neural Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Federico Raue", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "German Research Center for Arti\ufb01cial Intelligence (DFKI)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Scene Labeling with LSTM Recurrent Neural Networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Accurate scene labeling", "label": "is_step_towards", "title": "Relation: is_step_towards\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "image understanding", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "LSTM recurrent neural networks", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "neural network", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art performance", "label": "measured_on", "title": "Relation: measured_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "benchmark datasets", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Networks", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "local contextual information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Networks", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "global contextual information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Networks", "label": "operates_on", "title": "Relation: operates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "raw RGB values", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Networks", "label": "adapts_well_for", "title": "Relation: adapts_well_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "complex scene images", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Thalaiyasingam Ajanthan", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Iteratively Reweighted Graph Cut", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Thalaiyasingam Ajanthan", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Australian National University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Iteratively Reweighted Graph Cut", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Multi-label MRFs", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "energy", "label": "of", "title": "Relation: of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Multi-label Markov Random Fields (MRFs)", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "energy", "label": "takes_into_account", "title": "Relation: takes_into_account\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "piecewise constant model assumption", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "energy", "label": "takes_into_account", "title": "Relation: takes_into_account\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "flow field continuity constraint", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "MRFs", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Non-convex Priors", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-label Markov Random Fields", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "graph-cut-based algorithms", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-label Markov Random Fields", "label": "yields", "title": "Relation: yields\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "lower energy values", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-label Markov Random Fields", "label": "has_optimization_method", "title": "Relation: has_optimization_method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Graph Cut Optimization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Ishikawa, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Exact optimization for Markov random fields with convex priors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ishikawa, H.", "label": "is_foundational_work_on", "title": "Relation: is_foundational_work_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "MRF optimization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Boykov, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast approximate energy minimization via graph cuts", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Boykov, Y.", "label": "method_uses", "title": "Relation: method_uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "graph cut methods", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Boykov, Y.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Fast approximate energy minimization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fast approximate energy minimization via graph cuts", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PAMI", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Fast approximate energy minimization via graph cuts", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "graph cuts", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kolmogorov, V.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Convergent tree-reweighted message passing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kolmogorov, V.", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "reweighted message passing", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "reweighted message passing", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "energy minimization", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Iteratively Reweighted Algorithms", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "reweighted message passing", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "energy minimization", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "pattern analysis", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "geometric relationships", "label": "studied_in", "title": "Relation: studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Multiple view geometry", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "energy minimization techniques", "label": "is_analyzed_in", "title": "Relation: is_analyzed_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "comparative study", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "energy minimization techniques", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "smoothness-based priors", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "comparative study", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "comparative study", "label": "examines", "title": "Relation: examines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "inference techniques", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Markov random fields", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "energy minimization methods", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "smoothness-based priors", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Markov random fields", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Pattern Analysis and Machine Intelligence", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ds with smoothness-based priors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pattern Analysis and Machine Intelligence", "label": "is_journal_of", "title": "Relation: is_journal_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Large Displacement Optical Flow", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ds with smoothness-based priors", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "energy minimization techniques", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Boykov et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "An experimental comparison", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Boykov et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Boykov et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Fast approximate energy minimization via graph cuts", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "An experimental comparison", "label": "compares", "title": "Relation: compares\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "min-cut/max-flow algorithms", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "min-cut/max-flow algorithms", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "energy minimization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Pock et al.", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "convex formulation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pock et al.", "label": "presented in", "title": "Relation: presented in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Computer Vision\u2013ECCV 2008", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "convex formulation", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "multi-label problems", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "multi-label problems", "label": "addressed_by", "title": "Relation: addressed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "convex formulation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision\u2013ECCV 2008", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "convex formulation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "H. f.", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "convex formulation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kappes et al.", "label": "conducts", "title": "Relation: conducts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "comparative study", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Scharstein \u0026 Szeliski", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "dense two-frame stereo correspondence algorithms", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "dense two-frame stereo correspondence algorithms", "label": "is_important_for", "title": "Relation: is_important_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "understanding", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "stereo correspondence algorithms", "label": "addressed by", "title": "Relation: addressed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "International journal of computer vision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vekler", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Multi-label moves for mrfs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-label moves for mrfs", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "truncated convex priors", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Mathieu Salzmann", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Australian National University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mathieu Salzmann", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Riemannian Coding and Dictionary Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Mathieu Salzmann", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "NICITA", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hongdong Li", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Australian National University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Hongdong Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Dense, Accurate Optical Flow Estimation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hongdong Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Research School of Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hongdong Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The Australian National University (ANU)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hongdong Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NICTA", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rui Zhao", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saliency Detection by Multi-Context Deep Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Rui Zhao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Shenzhen Institutes of Advanced Technology", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Saliency Detection by Multi-Context Deep Learning", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Multi-Context Deep Learning", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Wanli Ouyang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saliency Detection by Multi-Context Deep Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wanli Ouyang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Electronic Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wanli Ouyang", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "wlouyang@ee.cuhk.edu.hk", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Image salience detection", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "highlight visually salient regions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Conventional approaches", "label": "struggle_with", "title": "Relation: struggle_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.50\u003cbr\u003eSource: unknown", "to": "salient objects in low-contrast backgrounds", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "from": "multi-context deep learning framework", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "multi-context deep learning framework", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "global context", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "multi-context deep learning framework", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "local context", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "salience", "label": "connects_to", "title": "Relation: connects_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "probabilistic inference", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "salience", "label": "is_aware_of", "title": "Relation: is_aware_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "unsupervised method", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "pre-training scheme", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Task-specific pre-training scheme", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Frequency-tuned salient region detection", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Frequency-tuned salient region detection", "label": "is_foundational_work_in", "title": "Relation: is_foundational_work_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Training products of experts", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Neural computation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Saliency detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Category-independent object-level saliency detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Graph-based visual saliency", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Detection", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Detection", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Multi-Context Modeling", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "bootstrap learning", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Salient Object Detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Salient Object Detection", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Bootstrap Learning", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Salient Object Detection", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "challenging datasets", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Detection", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Deep Learning Features", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Detection", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Multiscale Analysis", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "ik", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "arXiv", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "ik", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "ik", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "semantic segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "A. Borji", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Boosting bottom-up and top-down visual features", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "A. Borji", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "visual attention modeling", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "M.-M. Cheng", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Global contrast based salient region detection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Global contrast based salient region detection", "label": "is_foundational_work_in", "title": "Relation: is_foundational_work_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Global contrast based salient region detection", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "TRAMI", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "R. Mairon", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "A closer look at context", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Shenzhen Institutes of Advanced Technology", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Advanced Technology", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Baohua Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Subspace Clustering by Mixture of Gaussian Regression", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Baohua Li", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dalian University of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Subspace Clustering by Mixture of Gaussian Regression", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Ying Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Subspace Clustering by Mixture of Gaussian Regression", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ying Zhang", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Dalian\u003c0xC2\u003e\u003c0xA0\u003eUniversity of Technology", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Ying Zhang", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dalian University of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhouchen Lin", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Subclone Clustering by Mixture of Gaussian Regression", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhouchen Lin", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Dalian University of Technology", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Zhouchen Lin", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of EECS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Huchuan Lu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Subspace Clustering by Mixture of Gaussian Regression", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Huchuan Lu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Dalian University of Technology", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Huchuan Lu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Detectio", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Huchuan Lu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Saliency Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Huchuan Lu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Salience Detected", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Subspace clustering", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "multi-subspace representation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Subspace clustering", "label": "operates_in", "title": "Relation: operates_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "high-dimensional space", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Existing methods", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "norms", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "MoG Regression", "label": "approaches", "title": "Relation: approaches\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "subspace clustering", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "MoG Regression", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "affinity matrix", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "MoG Regression", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "clustering performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "MoG Regression", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "noise distributions", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Mixture of Gausians (MoG)", "label": "models", "title": "Relation: models\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "noise", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Noise Modeling", "label": "is_approach_in", "title": "Relation: is_approach_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Subspace clustering", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Noise Modeling", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "clustering", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Subspace Clustering", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state-of-the-art subspace clustering methods", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "K-plane clustering", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "K-plane clustering", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Journal of Global Optimization", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "segmentation", "label": "results_in", "title": "Relation: results_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "geo-referenced images", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "segmentation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "hierarchical", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "segmentation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "graph-based", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "segmentation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "object identification", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "segmentation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "motion analysis", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "power factorization", "label": "utilized_for", "title": "Relation: utilized_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "motion segmentation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "motion segmentation", "label": "covers", "title": "Relation: covers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "various types of motion", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "motion segmentation", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "broad framework", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "motion segmentation", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "object and motion segmentation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "GPCA", "label": "utilized_for", "title": "Relation: utilized_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "motion segmentation", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "GPCA", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "GPCA", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "referenced papers", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Mixture of Gaussian Regression", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "clustering", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Affinity Matrix Construction", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "clustering", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Spectral clustering", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "tutorial", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "overview", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "tutorial", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Spectral clustering", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Sparse representation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "technique", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Sparse representation", "label": "informs", "title": "Relation: informs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Approaches", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Sparse representation", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Pattern Analysis", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Wright et al.", "label": "develops", "title": "Relation: develops\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "face recognition approach", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "face recognition approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Sparse representation", "width": 2.6399999999999997}, {"arrows": "to", "color": "#9E9E9E", "from": "EM algorithm", "label": "facilitates", "title": "Relation: facilitates\u003cbr\u003eType: causation\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Segmentation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "EM algorithm", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Convergence properties", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "EM algorithm", "label": "is_algorithm", "title": "Relation: is_algorithm\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Gaussian mixtures", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Motion segmentation", "label": "covered_by", "title": "Relation: covered_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Framework", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Motion segmentation", "label": "is_process", "title": "Relation: is_process\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Motion segmentation", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Optical flow estimation", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Framework", "label": "covers", "title": "Relation: covers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Types of motion", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Framework", "label": "extracts", "title": "Relation: extracts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "region-keyword pairs", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Framework", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Image Quality", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "lossy data compression", "label": "is_methodology", "title": "Relation: is_methodology\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "image segmentation", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "robust PCA", "label": "is_consideration_for", "title": "Relation: is_consideration_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "segmentation", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "A Convolutional Neural Network Cascade", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Face Detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "A Convolutional Neural Network Cascade", "label": "publication_venue", "title": "Relation: publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Face Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Face Detection", "label": "runs_at", "title": "Relation: runs_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "14 FPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Face Detection", "label": "runs_at", "title": "Relation: runs_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "100 FPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Face Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks (CNNs)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Haoxiang Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Convolutional Neural Network Cascade", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Haoxiang Li", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Stevens Institute of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Haoxiang Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hierarchical-PEP Model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhe Lin", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Convolutional Neural Network Cascade", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhe Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Zhe Lin", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Jonathan Brandt", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Convolutional Neural Network Cascade", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gang Hua", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Convolutional Neural Network Cascade", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gang Hua", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Stevens Institute of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gang Hua", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hierarchical-PEP Model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gang Hua", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "{ghua}@steverns.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Face detection", "label": "faces", "title": "Relation: faces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "large visual variations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Face detection", "label": "faces", "title": "Relation: faces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "large search space", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Advanced models", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "visual variations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Advanced models", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "computationally expensive", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "CNN cascade architecture", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Approach", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "subgraph matching formulation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "CNN cascade architecture", "label": "balances", "title": "Relation: balances\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "conflicting demands", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Cascade", "label": "rejects", "title": "Relation: rejects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "background regions", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "CNN-based calibration stage", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "localization effectiveness", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "100 FPS", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "GPU", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Cascade Architecture", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Real-time Performance", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "Cascade Architecture", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Face Detection", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Bounding Box Calibration", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Face Detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "LeCun", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Convolutional networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional networks", "label": "processes", "title": "Relation: processes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "speech", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Rowley", "label": "researched", "title": "Relation: researched\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Neural network-based face detection", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "part-based models", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "part-based models", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "P. F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatatively trained part-based models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "P. F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatively trained part-based models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "P. F.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "IEEE Trans. Pattern Anal. Mach. Intell", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Object detection with discriminatively trained part-based models", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jain, V.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fddb: A benchmark for face detection in unconstrained settings", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fddb: A benchmark for face detection in unconstrained settings", "label": "is_report_from", "title": "Relation: is_report_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Massachusetts, Amherst", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Rich feature hierarchies for accurate object detection and semantic segmentation", "label": "published_as", "title": "Relation: published_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "arXiv preprint arXiv:1311.2524", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet classification with deep convolutional neural networks", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Advances in neural information processing systems", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jia, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Caffe: Convolutional architecture for fast feature embedding", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Advances in neural information processing systems", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "conference", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "helhamer, E.", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Caffe", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Vaillant, R.", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object localization approach", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yang, B.", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "multi-view face detection method", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stevens Institute of Technology", "label": "has_author", "title": "Relation: has_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Haoxiang Li", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Na Tong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Na Tong", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Dalian University of Technology", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Xiang Ruan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiang Ruan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "OMRON Corporation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Xiang Ruan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Saliency Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiang Ruan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Salience Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ming-Hsuan Yang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ming-Hsuan Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "University of California at Merced", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Ming-Hsuan Yang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Saliency Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ming-Hsuan Yang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Salience Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ming-Hsuan Yang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "JOTS", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ming-Hsuan Yang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Adaptive Region Pooling for Object Detection", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ming-Hsuan Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "UC Merced", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Bootstrap Learning", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Tong_Salient_Object_Detection_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Salient Object Detection", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "bootstrap learning algorithm", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "weak models", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "bootstrap learning algorithm", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "strong models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "bootstrap learning algorithm", "label": "performs_favorably_against", "title": "Relation: performs_favorably_against\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "state-of-the-art salience detection methods", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "weak salience map", "label": "generated_from", "title": "Relation: generated_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "image priors", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "weak salience map", "label": "generates", "title": "Relation: generates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "training samples", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "strong classi\ufb01er", "label": "detects", "title": "Relation: detects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "salient pixels", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "strong classi\ufb01er", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "input image", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "multiscale salience maps", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "detection performance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "bootstrap learning approach", "label": "results_in", "title": "Relation: results_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "signi\ufb01cant improvement", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Salieny Detection Methods", "label": "is_state_of_the_art", "title": "Relation: is_state_of_the_art\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bootstrap Learning Approach", "label": "is_applicable_to", "title": "Relation: is_applicable_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Bottom-up Salieny Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Li et al. (2014)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Salient Object Segmentation", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Segmentation", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Achanta et al. (2009)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Frequency-tuned Salient Region Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Movahedi \u0026 Elder (2010)", "label": "designs", "title": "Relation: designs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Performance Measures", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Performance Measures", "label": "validates", "title": "Relation: validates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Salient Object Segmentation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Achanta et al. (2010)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Slic Superpixels", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Achanta, R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Slic superpixels", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ojala, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiresolution gray-scale texture classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bach, F. R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple kernel learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple kernel learning", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "SMO algorithm", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Perazzi, F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Saliency filters", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Borji, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient object detection benchmark", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Borji, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Salient Object Detection: A Benchmark", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "authored", "label": "Segmenting salient objects", "title": "Relation: Segmenting salient objects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rahtu, E.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Salient object segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "performance measures", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "superpixels", "label": "classified_by", "title": "Relation: classified_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "feedforward multilayer network", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "superpixels", "label": "builds", "title": "Relation: builds\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "primitive saliency dictionary", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Local binary patterns", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "texture classification", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "J. Heikkil\u00e4", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Segmenting salient objects from images and videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Segmenting salient objects from images and videos", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kaiming He", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks at Constrained Time Cost", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kaiming He", "label": "is author of", "title": "Relation: is author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Kaiming He", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Kaiming He", "label": "author", "title": "Relation: author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A Geodesic-Prepreserving Method for Image Warping", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kaiming He", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A Geolesic-Preerving Method for Image Warping", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kaiming He", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse Projections for High-Dimensional Binary Codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Neural Networks at Constained Time Cost", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "University of California at Merced", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "USA", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "architecture", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "competitive accuracy", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "architecture", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "20% faster than AlexNet", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "architecture", "label": "designed_for", "title": "Relation: designed_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "person re-identification", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "architecture", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "application domain", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "architecture", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "69.6% average accuracy", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "architecture", "label": "tested_on", "title": "Relation: tested_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "PAS-CAL VOC 2012 test set", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "accuracy improvements", "label": "influenced_by", "title": "Relation: influenced_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "factors", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet dataset", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "11.8% top-5 error", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Offline Training", "label": "has_constraint", "title": "Relation: has_constraint\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Time Constraints", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Accuracy Improvements", "label": "influenced_by", "title": "Relation: influenced_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Factors", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "Accuracy Improvements", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Limited Time Budget", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Architecture", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Computer-Aided Design application", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Architecture", "label": "achieves_accuracy", "title": "Relation: achieves_accuracy\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "PAS-CAL VOC 2012 test set", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Architecture", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "recurrent convolutional", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Architecture", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "large-scale visual learning", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet Dataset", "label": "is_foundational_for", "title": "Relation: is_foundational_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision Tasks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet Dataset", "label": "is_hierarchical", "title": "Relation: is_hierarchical\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Image Database", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Deng et al. (2009)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ImageNet Dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Deng et al. (2009)", "label": "creates", "title": "Relation: creates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ImageNet", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Layer Replacement", "label": "is_optimization_strategy", "title": "Relation: is_optimization_strategy\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Architecture Optimization", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "computer vision tasks", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "ImageNet", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "hierarchical image database", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "is_database_for", "title": "Relation: is_database_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hierarchical Image Database", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "is_competition", "title": "Relation: is_competition\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "ILSVRC2012", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "large dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "training computer vision models", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "is_used_by", "title": "Relation: is_used_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "AlexNet", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "is_classified_with", "title": "Relation: is_classified_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "deep convolutional neural networks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "ImageNet", "label": "is_database_of", "title": "Relation: is_database_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "hierarchical image", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "very deep convolutional networks", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "development", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "very deep convolutional networks", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "network architecture", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "multi-column deep neural networks", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "power of deep learning", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "multi-column deep neural networks", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "image classification", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "rich feature hierarchies", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "rich feature hierarchies", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "semantic segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "deep learning", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "multi-column deep neural networks", "width": 2.7199999999999998}, {"arrows": "to", "color": "#2196F3", "from": "deep learning", "label": "encompasses", "title": "Relation: encompasses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "AlexNet", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "deep learning", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Malik et al. (2014)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "rich feature hierarchies", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zeiler et al. (2014)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "convolutional neural networks", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "convolutional neural networks", "label": "important_for", "title": "Relation: important_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "interpretability", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Eigen et al. (2013)", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "deep architectures", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "deep architectures", "label": "understood_using", "title": "Relation: understood_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "recursive convolutional networks", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "recursive convolutional networks", "label": "used_to_understand", "title": "Relation: used_to_understand\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "deep architectures", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Chatfield et al. (2014)", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "convolutional networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chatfield et al. (2014)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "details", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "convolutional networks", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image processing", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "convolutional networks", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "output of last layer", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Return of the devil in the details", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "convolutional networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Overfeat", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "integrated recognition, localization, and detection system", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Going deeper with convolutions", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "convolutions", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Lei Zhang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yanning Zhang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yanning Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chunna Tian", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chunna Tian", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reweighted Laplace Prior Based Hyperspectra Compressives Sensing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chunna Tian", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Reweighted_Lapless_Prior_2015_CVPR_supplemental.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fei Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fei Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fei Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wei Wei", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reweighted Laplace Prior Based Hyperspectral Compressive Sensing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Hyperspectral Compressives Sensing", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Laplace Prior", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Reweighted Laplace Prior Based Hyperspectral Compressives Sensing", "label": "is_supplemental_material_for", "title": "Relation: is_supplemental_material_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf", "label": "is_located_at", "title": "Relation: is_located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_Reweighted_Laplace_Prior_2015_CVPR_supplemental.pdf", "label": "details", "title": "Relation: details\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "hyperspectral compressive sensing method", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "hyperspectral compressive sensing method", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "reweighted Laplace prior", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "optimization procedure", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "matrix algebra manipulations", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "optimization procedure", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "conjugate functions", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "optimization procedure", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "sparsity learning over \u03b3", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "optimization procedure", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "noise estimation over \u03bb", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "conjugate functions", "label": "transforms", "title": "Relation: transforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "non-convex optimization problems", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Hyberspectral Compressive Sensing", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Reweighted Laplace Prior", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "optimization technique", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Sparsity Learning", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "optimization technique", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Noise Estimation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "optimization technique", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Fang_Collaborative_Feature_Learning_2015_CVPR_paper", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "research paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Fang_Collaborative_Feature_Learning_2015_CVPR_paper", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Paper Abstract", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "readable text", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Research", "label": "potentially covers", "title": "Relation: potentially covers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Data Encoding/Decoding", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Research", "label": "potentially covers", "title": "Relation: potentially covers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Text Corruption/Error Correction", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Research", "label": "potentially covers", "title": "Relation: potentially covers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Pattern Recognition", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Research", "label": "potentially covers", "title": "Relation: potentially covers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Information Retrieval", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Research", "label": "connects", "title": "Relation: connects\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Salience", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Research", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Material Metamers", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Research", "label": "has implications for", "title": "Relation: has implications for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Visual Inference tasks", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Victor Escorcia", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "On the Relationship between Visual Attributes and Convolutional Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Victor Escorcia", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Victor Escorcia", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Victor Escorcia", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "King Abdullah University of Science and Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Juan Carlos Niebles", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "On the Relationship between Visual Attributes and Convolutional Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Juan Carlos Niebles", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Juan Carlos Niebles", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Juan Carlos Niebles", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Universidad del Norte", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bernard Ghanem", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "On the Relationship between Visual Attributes and Convolutional Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Bernard Ghanem", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bernard Ghanem", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bernard Ghanem", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "King Abdullah University of Science and Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bernard Ghanem", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "\u21130TV: A New Method", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Bernard Ghanem", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "King Abdullah University of Science and Technology (KAUST)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bernard Ghanem", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "bernard.ghanem@kust.edu.sa", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Convolutional Networks", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Visual Attributes", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Visual Attributes", "label": "influence", "title": "Relation: influence\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "conv-net based object recognition", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "visual attributes", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "convolutional networks", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Escorcia_On_the_Relationship_2015_CVPR_paper.pdf", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucomaa/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "conv-nets", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "abstract concepts", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "conv-nets", "label": "use", "title": "Relation: use\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "semantic visual attributes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "abstract concepts", "label": "are_examples_of", "title": "Relation: are_examples_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "objects in images", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "semantic visual attributes", "label": "impact", "title": "Relation: impact\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "object description", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Attribute Centric Nodes (ACNs)", "label": "exist_in", "title": "Relation: exist_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "conv-net", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Attribute Centric Nodes (ACNs)", "label": "encode", "title": "Relation: encode\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "visual attribute representation", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Attribute Centric Nodes (ACNs)", "label": "contribute_to", "title": "Relation: contribute_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "discrimination", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "conv-net", "label": "is_trained_to_recognize", "title": "Relation: is_trained_to_recognize\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "objects", "width": 2.7800000000000002}, {"arrows": "to", "color": "#2196F3", "from": "conv-net", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "object recognition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "visual attribute representation", "label": "encoded by", "title": "Relation: encoded by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "conv-net nodes", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "conv-net nodes", "label": "encode", "title": "Relation: encode\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "information", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "conv-net nodes", "label": "distributed across", "title": "Relation: distributed across\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "layers", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "conv-net nodes", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "sparsely distributed", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "conv-net nodes", "label": "play a role in", "title": "Relation: play a role in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "object recognition", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "conv-net nodes", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "unevenly distributed", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "information", "label": "pertinent to", "title": "Relation: pertinent to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "visual attribute representation and discrimination", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Zero-Shot Object Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Semantic Manifold Distance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenyong Fu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zero-Shot Object Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhenyong Fu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Queen Mary, University of London", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tao Xiang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zero-Shot Object Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tao Xiang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Queen Mary, University of London", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tao Xiang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "QueenMary, University of London", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Elyor Kodirov", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zero-Shot Object Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Elyor Kodirov", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Queen Mary, University of London", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shaogang Gong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Zero-Shot Object Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zero-shot learning", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "recognise objects", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Zero-shot learning", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "knowledge transfer", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing works", "label": "measures", "title": "Relation: measures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "similarity", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "similarity", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "semantic embedding space", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "semantic embedding space", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "distance metrics", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "distance metrics", "label": "do_not_consider", "title": "Relation: do_not_consider\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "intrinsic structure", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "semantic categories", "label": "has", "title": "Relation: has\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "intrinsic structure", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "absorbing Markov chain process", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "semantic manifold distance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "performance gains", "label": "observed_on", "title": "Relation: observed_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "ImageNet", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "performance gains", "label": "observed_on", "title": "Relation: observed_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "AwA datasets", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "proposed model", "label": "unifies", "title": "Relation: unifies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ZSL algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "proposed model", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "performance gains", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "semantic manifold", "label": "used_by", "title": "Relation: used_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "AMP", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "AMP", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "semantic manifold distance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Label-embedding", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Akata et al. (2013)", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Label-embedding", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "attribute-based classification", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Single-example learning", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Bart \u0026 Ullman (2005)", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Cluster kernels", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Chapelle et al. (2002)", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Zero-shot learning (ZSL)", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "knowledge transfer", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Chapelle", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cluster kernels", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Weston", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cluster kernels", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sch\u00f6lkopf", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cluster kernels", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Large-scale object classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ImageNet", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ding", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Large-scale object classification", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ding", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning higher-order graph structure", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ding", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Advances in Neural Information Processing Systems", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Label relation graphs", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Large-scale object classification", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Dong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ImageNet", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Frome", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Devise", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Devise", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "embedding model", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Devise", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Advances in Neural Information Processing Systems", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Devise", "label": "implements", "title": "Relation: implements\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "visual-semantic embedding", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Transductive multi-view embedding", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Transductive multi-view embedding", "label": "aims_for", "title": "Relation: aims_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "zero-shot recognition", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Zero shot recognition with unreliable attributes", "label": "published_as", "title": "Relation: published_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "arXiv preprint", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet classification", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ImageNet classification", "label": "used", "title": "Relation: used\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "deep convolutional neural networks", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "ImageNet classification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "SIFT features", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Efficient estimation of word representations", "label": "published_as", "title": "Relation: published_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "arXiv preprint", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Sakrapee Paisitkriangkrai", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sakrapee Paisitkriangkrai", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "The University of Adelaide", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Sakrapee Paisitkriangkrai", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Australian Centre for Robotic Vision", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "label": "is_paper_of", "title": "Relation: is_paper_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "label": "file_name", "title": "Relation: file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Paisitkriangrai_Learning_to_Rank_2015_CVPR_paper.pdf", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Chunhua Shen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chunhua Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "The University of Adelaide", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chunhua Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Australian Centre for Robotic Vision", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chunhua Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "The University of Adelaide, Australia", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chunhua Shen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Supervised Discrete Hashing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chunhua Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Adelaide", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chunhua Shen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning graph structure...", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Anton van den Hengel", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning to rank in person re-identi\ufb01cation with metric ensembles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Anton van den Hengel", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "The University of Adelaide, Australia", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Anton van den Hengel", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Australian Centre for Robotic Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Anton van den Hengel", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Robust Multiple Homography Estimation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Anton van den Hengel", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning graph structure...", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Anton van den Hengel", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Adelaide", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "predefined weights", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "not adaptable", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "two principled approaches", "label": "optimize", "title": "Relation: optimize\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "relative distance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "two principled approaches", "label": "maximize", "title": "Relation: maximize\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "average rank-k recognition rate", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "RMS methods", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "rank-1 recognition rates", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ensemble-based approaches", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "flexible", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ensemble-based approaches", "label": "can be combined with", "title": "Relation: can be combined with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "linear metrics", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Ensemble-based approaches", "label": "can be combined with", "title": "Relation: can be combined with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "non-linear metrics", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Similarity metric", "label": "introduced in", "title": "Relation: introduced in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Chopra et al. (2005)", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Person Re-Identification", "label": "is covered in", "title": "Relation: is covered in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Gong et al. (2014)", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Person Re-Identification", "label": "relies on", "title": "Relation: relies on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Similarity metric", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Person Re-Identification", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gong, S., Crisitan, M., Yan, S., and Loy, C. C.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gong et al. (2014)", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "techniques", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "techniques", "label": "adopt", "title": "Relation: adopt\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "solution frameworks", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Gong, S., Crisitan, M., Yan, S., and Loy, C. C.", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "techniques", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "support vector method", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "performance measures", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "support vector method", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Joachims, T.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "re-identification models", "label": "builds_upon", "title": "Relation: builds_upon\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "AlexNet", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "re-identification systems", "label": "evaluated_using", "title": "Relation: evaluated_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "performance measures", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Imaginet classification", "label": "utilized", "title": "Relation: utilized\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "deep convolutional neural networks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Mahalanobis distance", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "metric learning", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Mahalanobis distance", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "person re-identification", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "metric learning", "label": "is_aspect_of", "title": "Relation: is_aspect_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "scalability", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "distance metric learning", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computational challenges", "width": 2.7}, {"arrows": "to", "color": "#FF5722", "from": "distance metric learning", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "scalability", "width": 2.76}, {"arrows": "to", "color": "#FF5722", "from": "computational challenges", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "scalability", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "paper (Felzenszwalb et al., 2010)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "part-based model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "paper (Felzenszwalb et al., 2010)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "part-based model", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "pedestrian detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "image representation techniques", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "re-identification", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "shape and appearance information", "label": "is_strategy_for", "title": "Relation: is_strategy_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "robust re-identification", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "kernel methods", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "metric learning", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "kernel methods", "label": "operates_on", "title": "Relation: operates_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "geodesic metric spaces", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "kernel methods", "label": "include", "title": "Relation: include\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "geodesic Laplacian kernels", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Australian Centre for Robotic Vision", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Australia", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Australian Centre for Robotic Vision", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Adelaide", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Adelaide, Australia", "label": "is_located_in", "title": "Relation: is_located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Australia", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "The University of Adelaide, Australia", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Australia", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Dengxin Dai", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Metric imitation by manifold transfer", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Dengxin Dai", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision Lab, ETH Zurich", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Metric imitation by manifold transfer", "label": "application_area", "title": "Relation: application_area\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "efficient vision applications", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Till Kroeger", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Metric imitation by manifold transfer", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Radu Timofte", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Metric imitation by manifold transfer", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Radu Timofte", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Lab, ETH Zurich", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Metric Imitation", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "improve performance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Imitation", "label": "transfers", "title": "Relation: transfers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "manifold structure", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Imitation", "label": "demonstrated_on", "title": "Relation: demonstrated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "instance-based object retrieval", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Imitation", "label": "demonstrated_on", "title": "Relation: demonstrated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "image clustering", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Imitation", "label": "demonstrated_on", "title": "Relation: demonstrated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "category-based image retrieval", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Imitation", "label": "yields", "title": "Relation: yields\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "better performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "vision applications", "label": "benefits_from", "title": "Relation: benefits_from\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Metric Imitation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "GIST features", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "target features", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "SIFT-llc", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "source features", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "object-bank", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "source features", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "CNN features", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "source features", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "CNN features", "label": "is_source_feature", "title": "Relation: is_source_feature\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Imitation (MI)", "label": "yields", "title": "Relation: yields\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "better performance", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Imitation (MI)", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "original target features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bosch, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Image classification using random forests and ferns", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chatfield, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Return of the devil in the details", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Dai, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Ensemble partitioning", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "llc", "label": "is_source_feature", "title": "Relation: is_source_feature\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Object Retrieval", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Object-bank (OB)", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Image Clustering", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Ensemble partitioning", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Dana et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reflectance and texture of real-world surfaces", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Reflectance and texture of real-world surfaces", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "*ACM Trans. Graph.*", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fei-Fei et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning generative visual models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Learning generative visual models", "label": "presented at", "title": "Relation: presented at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Workshop on Generative-Model Based Vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Lazebnik et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Spatial pyramid matching", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Spatial pyramid matching", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "recognizing natural scene categories", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Li \u0026 Fei-Fei", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "What, where and who?", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "What, where and who?", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Li, L.-J.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "What, where and who?", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Li et al. (2010)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Object bank", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Object bank", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "scene classification", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Object bank", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Li, L.-J. et al. (2010)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "*NIPS*", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Nist\u00b4er, D. \u0026 Stew\u00b4enius, H. (2006)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "*CVPR*", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Vocabulary tree", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "scalable recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Oliva, A. \u0026 Torralba, A. (2001)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "*IJCV*", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Spatial envelope", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "shape of the scene", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Tuytelaars, T. et al. (2009)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "*IJCLP*", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Object discovery", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "unsupervised", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Wang, J. et al. (2010)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "*CVPR*", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Locality-constrained linear coding", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "image classification", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision Lab, ETH Zurich", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ETH Zurich", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Francesco Pittaluca", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Lab, ETH Zurich", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Francesco Pittaluca", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Privacy Preserving Optics for Miniature Vision Sensors", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Sanjeev J. Koppal", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Lab, ETH Zurich", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sanjeev J. Koppal", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Privacy Preserving Optics for Miniature Vision Sensors", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Pittaluga_Privacy_Preserving_Optics_2015_CVPR_supplemental.pdf", "label": "is_supplement_to", "title": "Relation: is_supplement_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Privacy Preserving Optics for Miniature Vision Sensors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Privacy Preseving Optics for Miniature Vision Sensors", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "supplementary material", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "privacy-preserving optics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "privacy-preserving optics", "label": "designed for", "title": "Relation: designed for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "minature vision sensors", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "impact of defocusing optics", "label": "on", "title": "Relation: on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "performance of face recognition algorithms", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "angular support", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "FLIR One thermal sensor", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "angular support", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Kinect time-of-flight sensor", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "FLIR One thermal sensor", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Angular support derivation", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Kinect time-of-flight sensor", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Angular support derivation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "effect of blur", "label": "on", "title": "Relation: on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "face recognition rates", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "geometric derivations", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "determining angular support", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Privacy-preserving optics", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Facial images", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Feret methodology", "label": "is_standard_for", "title": "Relation: is_standard_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "face recognition evaluation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CSU face identification evaluation system", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Face identification", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Angular support derivation", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Sensor positioning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Bolme, D. S. et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CSU face identification evaluation system", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Newton, E. et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Privacy-preserving techniques", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Phillips, P. J. et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Feret evaluation methodology", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Feret evaluation methodology", "label": "standard_for", "title": "Relation: standard_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Face recognition evaluation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Park, Min-Gyu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Leveraging Stereo Matching with Learning-based Con\ufb01dence Measures", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Park, Min-Gyu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "University of Florida", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Yoon, Kuk-Jin", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Leverging Stereo Matching with Learning-based Con\ufb01dence Measures", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pittaluga, Francesco", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "P. J. The furet evaluation methodology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pittaluga, Francesco", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "University of Florida", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Random Forests", "label": "is_machine_learning_algorithm", "title": "Relation: is_machine_learning_algorithm\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "algorithm", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Random Forests", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "machine learning algorithm", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Random Forests", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "machine learning", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Random Forests", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Breiman, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Random forests", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Random forests", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "real time 3d face analysis", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Koppal, Sanjeev J.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "University of Florida", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Breiman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Random Forests", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "stereo confidence metric", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "key aspect of stereo vision", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "stereo confidence metric", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "stereo vision", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Egnal", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "stereo confidence metric", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hirschm\u00fcller", "label": "presented", "title": "Relation: presented\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "semiglobal matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "semiglobal matching", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "mutual information", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "semiglobal matching", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "stereo processing", "width": 2.8200000000000003}, {"arrows": "to", "color": "#2196F3", "from": "stereo vision", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "confidence measures", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Hu, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "quantitative evaluation", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "quantitative evaluation", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "confidence measures", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "confidence measures", "label": "is_aspect_of", "title": "Relation: is_aspect_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "stereo vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "dense matching", "label": "occurs_in", "title": "Relation: occurs_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "complex scenes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Manduchi, R.", "label": "proposed", "title": "Relation: proposed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "distinctiveness maps", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "distinctiveness maps", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "image matching", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "image matching", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "distinctiveness maps", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "pose estimation", "label": "is_problem_of", "title": "Relation: is_problem_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "determining viewpoint", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "pose estimation", "label": "is_problem_in", "title": "Relation: is_problem_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "viewpoint", "label": "explains", "title": "Relation: explains\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "coarse pose", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "keypoint prediction", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "finer details", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "constrained setting", "label": "has_input", "title": "Relation: has_input\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "bounding boxes", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "detection setting", "label": "is_more_challenging_than", "title": "Relation: is_more_challenging_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "constrained setting", "width": 2.92}, {"arrows": "to", "color": "#FF5722", "from": "viewpoint estimates", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "keypoint predictions", "width": 2.94}, {"arrows": "to", "color": "#FF5722", "from": "object characteristics", "label": "affects", "title": "Relation: affects\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Shubham Tulsiani", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Jitendra Malik", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Shubham Tulsiani", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California, Berkeley", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shubham Tulsiani", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "shubhtuls@eecs.berkeley.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jitendra Malik", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California, Berkeley", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jitendra Malik", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "malik@eecs.berkeley.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jitendra Malik", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Category-Speci\ufb01c Object Reconstruction from a Single Image", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "effort", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "goal", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "future efforts", "label": "guided_by", "title": "Relation: guided_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "analysis", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "analysis", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "error modes", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "analysis", "label": "examines", "title": "Relation: examines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "effect", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Pose Estimation", "label": "improves_via", "title": "Relation: improves_via\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks (CNNs)", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Pose Estimation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Keypoint Prediction", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Pose Estimation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Viewpoint Prediction", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Pose Estimation", "label": "affected_by", "title": "Relation: affected_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Refraction", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Abed Malti", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Malti_A_Linear_Least-Squares_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Abed Malti", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Fluminance/INRIA", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Abed Malti", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fuminance/INRIA", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Adrien Bartoli", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Maiti_A_Linear_Least-Squares_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Adrien Bartoli", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "ALCoV/ISIT", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Richard Hartley", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Malti_A_Linear_Least-Squares_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Richard Hartley", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Australian National University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Richard Hartley", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "NICTA", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-from-Template methods", "label": "struggles_with", "title": "Relation: struggles_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "balancing accuracy, speed, and robustness", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "non-linear optimization", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "existing approach", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Kalman filtering", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "existing approach", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "proposed solution", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "mechanical constraints", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "proposed solution", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "finite element methods", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "proposed solution", "label": "allows_for", "title": "Relation: allows_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "accurate reconstruction", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "proposed solution", "label": "offers", "title": "Relation: offers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "efficient reconstruction", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "proposed solution", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "linear least-squares SfT method", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "finite element methods", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "surface", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "finite element methods", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "deformation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-from-Template (SfT)", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "elastic deformations", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-from-Template (SfT)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "linear least-squares estimation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "elastic deformations", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "accurate reconstruction", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "elastic deformations", "label": "is_modeled_by", "title": "Relation: is_modeled_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "fully linear least-squares SfT method", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Finite Element Methods (FEM)", "label": "codes", "title": "Relation: codes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "non-rigid EKF monocular SLAM", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Finite Element Methods (FEM)", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "sequential bayesian non-rigid structure from motion", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Agudo, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "FEM models to code non-rigid EKF monocular SLAM", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Agudo, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Finite element based sequential bayesian non-rigid structure from motion", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Finite element based sequential bayesian non-rigid structure from motion", "label": "is_cited", "title": "Relation: is_cited\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "frequently", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "FEM models", "label": "is_cited", "title": "Relation: is_cited\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "frequently", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Agudo et al.", "label": "cited_by", "title": "Relation: cited_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "related work", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Agudo et al.", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "structure from motion", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Bartoli et al.", "label": "cited_by", "title": "Relation: cited_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "methodology", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Bartoli et al.", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "surface reconstruction", "width": 2.56}, {"arrows": "to", "color": "#4CAF50", "from": "Salzmann and Urtasun", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Moreno-Noguer and Porta", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Moreno-Noguer and Porta", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.72\u003cbr\u003eSource: unknown", "to": "shape recovery", "width": 2.44}, {"arrows": "to", "color": "#4CAF50", "from": "Finite Element Methods", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Chaskalovic", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Salzmann and Urutasun", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "3D reconstruction", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "ape recovery", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chaskaloric", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Finite Elements Methods for Engineering Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Finite Elements Methods for Engineering Sciences", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "background knowledge", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Reconstructing sharply folding surfaces", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Salzmann, M., and Fua, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Linear local models for monocular reconstruction", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Linear local models for monocular reconstruction", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Matthews, I., and Baker, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Active appearance models revisited", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Active appearance models revisited", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "modeling techniques", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "appearance models", "label": "revisited in", "title": "Relation: revisited in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "appearance models", "label": "of", "title": "Relation: of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "familiar objects", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Riemannian Coding", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Kernels", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mehrtash Harandi", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Riemannian Coding and Dictionary Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "covariance descriptors", "label": "lies_on", "title": "Relation: lies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Riemannian manifolds", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Riemannian manifolds", "label": "relevant to", "title": "Relation: relevant to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "geodesic Laplacian kernels", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "normalized histograms", "label": "lies_on", "title": "Relation: lies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Riemannian manifolds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "linear subspaces", "label": "lies_on", "title": "Relation: lies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Riemannianmanifolds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "2D shape outlines", "label": "lies_on", "title": "Relation: lies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Riemannian manifolds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing solutions", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "dedicated to specific manifolds", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "existing solutions", "label": "rely_on", "title": "Relation: rely_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "optimization problems", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "optimization problems", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "difficult to solve", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "general Riemannian coding framework", "label": "has_counterpart", "title": "Relation: has_counterpart\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "kernel-based counterpart", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "kernel-based counterpart", "label": "allows_for", "title": "Relation: allows_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "generalization beyond sparse coding", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "kernel-based counterpart", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.84\u003cbr\u003eSource: unknown", "to": "kernel parameters", "width": 2.6799999999999997}, {"arrows": "to", "color": "#2196F3", "from": "Riemannian coding framework", "label": "has_counterpart", "title": "Relation: has_counterpart\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "kernel-based counterpart", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Riemannian coding framework", "label": "allows", "title": "Relation: allows\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "generalization beyond sparse coding", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Riemannian coding framework", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "learning of kernel parameters", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Riemannian coding framework", "label": "simplifies", "title": "Relation: simplifies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "dictionary learning", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "sparse coding", "label": "limited_by", "title": "Relation: limited_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "flat data", "width": 2.6399999999999997}, {"arrows": "to", "color": "#2196F3", "from": "coding schemes", "label": "require", "title": "Relation: require\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "efficient solutions", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Riemannian Manifolds", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Dictionary Learning", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Coding Theory", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Mehrtas Harandi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Australian National University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mehrtas Harandi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "NICITA", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yuting Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Improving Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yuting Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Computer Science, Zhejiang University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Improving Object Detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Kihyuk Sohn", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Improving ObjectDetection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kihyuk Sohn", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Electrical Engineering and Computer Science, University of Michigan", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ruben Villegas", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Improving Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ruben Villegas", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Electrical Engineering and Computer Science, University of Michigan", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Gang Pan", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Improving Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gang Pan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Computer Science, Zhejiang University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Honglak Lee", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Improving Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Honglak Lee", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Electrical Engineering and Computer Science, University of Michigan", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "inaccurate localization", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "major source of error", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "search algorithm", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Bayesian optimization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "search algorithm", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "candidate regions", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "structured loss", "label": "penalizes", "title": "Relation: penalizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "localization inaccuracy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "methods", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "detection performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "methods", "label": "improves_over", "title": "Relation: improves_over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "baseline method", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "methods", "label": "impose", "title": "Relation: impose\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "prior over human poses", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "methods", "label": "extend to", "title": "Relation: extend to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "object search", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "methods", "label": "are", "title": "Relation: are\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "state-of-the-art", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "loss", "label": "penalizes", "title": "Relation: penalizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "localization inaccuracy", "width": 2.96}, {"arrows": "to", "color": "#FF5722", "from": "proposed methods", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "detection performance", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "proposed methods", "label": "performs_better_than", "title": "Relation: performs_better_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "baseline method", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "proposed methods", "label": "validates", "title": "Relation: validates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "two methods", "label": "are", "title": "Relation: are\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "complementary", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "combined methods", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "state-of-the-art", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian Optimization", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Structured Prediction (Structured SVM)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Localization Accuracy", "label": "metric_for", "title": "Relation: metric_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Networks", "label": "trained_using", "title": "Relation: trained_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Greedy Layer-Wise Training", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Deep Networks", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Local Estimation", "width": 2.6399999999999997}, {"arrows": "to", "color": "#2196F3", "from": "Deep Networks", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Global Search", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Local Binary Patterns", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Face Recognition", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Representation Learning", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bengio, Y.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Representation Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bengio, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Learning deep architectures for AI", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Girschick, R.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Rich Feature Hierarchies", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Rich Feature Hierarchies", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Rich Feature Hierarchies", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Everingham, M.", "label": "organizes", "title": "Relation: organizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "VOC2007", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Everingham, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PASCAL VOC challenge description", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "VOC2007", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Visual Object Classes Challenge", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "VOC2007", "label": "is_challenge_of", "title": "Relation: is_challenge_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Pascal Network", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deng, J.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ImageNet", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Donahue, J.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "DeCAF", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "DeCAF", "label": "is_for", "title": "Relation: is_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Visual Recognition", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "DeCAF", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CoRR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "DeCAF", "label": "author", "title": "Relation: author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Donahue, J.", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Erhan", "label": "author", "title": "Relation: author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Erhan, D.", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Erhan", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Dongping Li", "label": "author", "title": "Relation: author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A Geodesic-Prepreserving Method for Image Warping", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Dongping Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A Geodesic-Preserving Method for Image Warping", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Dongping Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Zhejiang University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Electrical Engineering and Computer Science", "label": "is_affiliation_of", "title": "Relation: is_affiliation_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Michigan", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A Geodesic-Preserving Method for Image Warping", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "A Geodesic-Preserving Method for Image Warping", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Image Warping", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Kun Zhou", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A Geodesic-Preserving Method for Image Warping", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kun Zhou", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Zhejiang University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "honglak@umich.edu", "label": "is_email_of", "title": "Relation: is_email_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "University of Michigan", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Li_A_Geodesic-Preserving_Method_2015_CVPR_supplemental.pdf", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "A Geodesic-Preserving Method for Image Warping", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Image Warping", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "high-quality warped images", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "geodesic-preserving method", "label": "aims to", "title": "Relation: aims to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "maintain shape", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "geodesic-preserving method", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "distortions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "core of method", "label": "lies in", "title": "Relation: lies in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "preserving geodesic distances", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "preserving geodesic distances", "label": "ensures", "title": "Relation: ensures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "local smoothness", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "preserving geodesic distances", "label": "prevents", "title": "Relation: prevents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "unwanted artifacts", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "energy function", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "shape preservation terms", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "energy function", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "boundary preservation terms", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "energy function", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "geodesic preservation terms", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Gauss-Newton method", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "optimization technique", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Shape and Boundary Preservation", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Image Warping", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Energy Minimization", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Image Warping", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Gausss-Newton Method", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Energy Minimization", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang, G. et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A shape-preserving approach to image resizing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A shape-preserivng approach to image resizing", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Shape and Boundary Preservation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Rotation matrix R\u03b8,\u03c6", "label": "is_component_of", "title": "Relation: is_component_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Eqn. (1)", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Shape-preserving term ES(V)", "label": "is_component_of", "title": "Relation: is_component_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Eqn. (7)", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "shape-preserving approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Eqn. (7) - Shape-preserving term ES(V)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Eqn. (7) - Shape-preserving term ES(V)", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "shape-preserving approach", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "local smoothness preservation", "label": "described_by", "title": "Relation: described_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Eqn. (4) - Local smoothness preservation EC(V)", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Eqn. (4) - Local smoothness preservation EC(V)", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "local smoothness preservation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Eqn. (5) - Combined energy function E(V)", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "overall energy function", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Q", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "orthogonal matrices", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "orthogonal matrices", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "mathematical concept", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "orthogonal matrices", "label": "is_concept_in", "title": "Relation: is_concept_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "mathematics", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "E(V)", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "various terms", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Antonio Agudo", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Antonio Agudo", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Antonio Agudo", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3A)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Francesc Moreno-Noguer", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Francesc Moreno-Noguer", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Francesc Moreno-Noguer", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Institut de Rob`otica i Inform`atica Industrial (CSI-UPC)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous Pose and Non-Rigid Shape", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "particle dynamics", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "particle dynamics", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Simultaneous Pose and Non-Rigid Shape", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "geodesic preservation", "label": "is_concept_in", "title": "Relation: is_concept_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "geometry", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "particle dynamics", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "non-rigid shape", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "simultaneous pose", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Simultaneous Pose and Non-Rigid Shape with Particle Dynamics", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "non-rigid shape", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "particle dynamics", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "camera pose", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "absolute pose problem", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "camera position", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "camera orientation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "translational velocity", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "angular velocity", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "number of inliers", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "RANSA", "width": 2.7199999999999998}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "spatiotemporal filters", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "solution", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "metric-learning framework", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "object", "label": "modeled as", "title": "Relation: modeled as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "ensemble of particles", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "object", "label": "has_relationship", "title": "Relation: has_relationship\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "annotation proposals", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "object", "label": "is_unseen", "title": "Relation: is_unseen\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "object", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "particle", "label": "ruled by", "title": "Relation: ruled by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Newton\u2019s second law of motion", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "dynamic model", "label": "incorporated into", "title": "Relation: incorporated into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "bundle adjustment framework", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "validation", "label": "occurs_in", "title": "Relation: occurs_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "real video sequences", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "motion", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "articulated", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "motion", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "non-rigid", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "shapes", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "continuous", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "shapes", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "discontinuous", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "batch methods", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "computationally expensive", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "System", "label": "performs_comparable_to", "title": "Relation: performs_comparable_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Competing Batch Methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "System", "label": "avoids", "title": "Relation: avoids\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Uncanny Valley Effect", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "System", "label": "evaluated_with", "title": "Relation: evaluated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Qualitative Evaluations", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Non-Rigid Structure from Motion", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Paper", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Particle Dynamics", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Non-Rigid Structure from Motion", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Bundle Adjustment", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Non-Rigid Structure from Motion", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Monocular Video Analysis", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Non-Rigid Structure from Motion", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Instituto de Invesigaci\u00b4on en Ingenier\u00b4\u0131a de Arag\u00b4on (I3a)", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Universidad de Zaragoza", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Simone Frintrop", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simone Frintrop", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rheinische Friedrich-Wilhelms-Universit\u00a8at Bonn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Simone Frintrop", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rheinische Friedrich-Wilhelms-Universit\u00e4t Bonn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Simone Frintrop", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "frintrop@iai.uni-bonn.de", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Thomas Werner", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Thomas Werner", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rheinische Friedrich-Wilhelms-Universit\u00a8at Bonn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Thomas Werner", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rheinische Friedrich-Wilhelms-Universit\u00e4t Bonn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Germ\u00e1n M. Garc\u00eda", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Germ\u00e1n M. Garc\u00eda", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rheinische Friedrich-Wilhelms-Universit\u00e4t Bonn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "salience model", "label": "proposed by", "title": "Relation: proposed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Itti et al.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "adaptations", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "scale-space structure", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "scale-space structure", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "twin pyramid", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "foundational approaches", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "adaptation", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "VOCUS2", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "system", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ration framework", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "segment-based salience maps", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "ration framework", "label": "aims_for", "title": "Relation: aims_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "high performance", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "segment-based salience maps", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "segment-based salience maps", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "modern applications", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "importance", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "revisiting foundational approaches", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "adaptation", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "modern applications", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "t-based salience maps", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Saliency Models", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Itti Model", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Itti Model", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "A cognitive approach for object discovery", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ICPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Discriminant salieny", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "TPAMI", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "State-of-the-art in visual attention modeling", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "A. Borji", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Scale-space representation", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "asri", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Image segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "L. Itti", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "salienicy-based visual attention model", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "N. D. B. Bruce", "label": "proposed", "title": "Relation: proposed\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "information theoretic approach", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "L. Hurvich", "label": "proposed", "title": "Relation: proposed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "opponent-process theory", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Rheinische Friedrich-Wilhelms-Universit\u00e4t Bonn", "label": "location", "title": "Relation: location\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Bonn", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaolong Yang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Dense, Accurate Optical Flow Estimation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaolong Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beijing Lab of Intelligent Information Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaolong Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beijing Institute of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dense, Accurate Optical Flow Estimation", "label": "publication_venue", "title": "Relation: publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Dense, Accurate Optical Flow Estimation", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yang_Dense_Accurate_Optical_2015_CVPR_paper", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "PDF document", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "multi-model fitting scheme", "label": "achieved_by", "title": "Relation: achieved_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "energy minimization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Optical flow benchmarks", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "KITTI", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Optical flow benchmarks", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "MPI Sintel", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI", "label": "is_benchmark_for", "title": "Relation: is_benchmark_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Optical Flow", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI", "label": "is_benchmark_for", "title": "Relation: is_benchmark_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Scene Flow", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Optical flow estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Piecewise parametric models", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Optical flow estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Energy minimization", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Homography transformation", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Optical flow estimation", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Baker et al. (2011)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "database and evaluation methodology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bao et al. (2014)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Fast edge-preserving patchmatch", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Barnes et al. (2009)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PatchMatch", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "PatchMatch", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "structural image editing", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "PatchMatch", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ACM Transactions on Graphics (TOG)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Piecewise image registration", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Multiway cut", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "stereo and motion", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Multiway cut", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "slanted surfaces", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "robust estimation", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "multiple motions", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "robust estimation", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "parametric flow fields", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "robust estimation", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "piecewise-smooth flow fields", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Black", "label": "coauthored_with", "title": "Relation: coauthored_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Anandan", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Black, M. J.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "The robust estimation of multiple motions", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Black, M. J.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Estimating optical flow in segmented images", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Anandan, P.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "The robust estimation of multiple motions", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jepson, A. D.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Estimating optical flow in segmented images", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Bleyer, M.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "PatchMatch Stereo", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Rhemann, C.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "PatchMatch Stereo", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Rother, C.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "PatchMatch Stere", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Braux-Zin et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A general dense image matching framework", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Beijing Lab of Intelligent Information Technology", "label": "is part of", "title": "Relation: is part of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Thomas Mauthner", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Encoding Based Saliency Detection for Videos and Images", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Horst Possegger", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Encoding Based Saliency Detection for Videos and Images", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Horst Possegger", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Mauthner_Encoding_Based_Saliency_2015_CVPR_paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Georg Waltner", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Encoding Based Saliency Detection for Videos and Images", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Georg Waltner", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Mauthner_Encoding_Based_Salieney_2015_CVPR_paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Georg Waltner", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Institute for Computer Graphics and Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Georg Waltner", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "waltner@icg.tugraz.at", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Horst Bischof", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Encoding Based Saliency Detection for Videos and Images", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Horst Bischof", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Mauthne_Encoding_Based_Salieney_2015_CVPR_paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Horst Bischof", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "bischof@icg.tugraz.at", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Mauthner_Encoding_Based_Saliency_2015_CVPR_paper", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "eye-traking data", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "predicting human gaze", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "reliance on human gaze", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "bias", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "encoding method", "label": "approximates", "title": "Relation: approximates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "joint feature distributions", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "salience computation", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "efficient", "width": 2.7199999999999998}, {"arrows": "to", "color": "#2196F3", "from": "salience computation", "label": "enforces", "title": "Relation: enforces\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.84\u003cbr\u003eSource: unknown", "to": "Gestalt principle of figure-ground segregation", "width": 2.6799999999999997}, {"arrows": "to", "color": "#2196F3", "from": "re-ground segregation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "method", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Video Salience Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Gestalt Principles", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Video Salience Detection", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Encoding Methods", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Video Salience Detection", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Human Activity Recognition", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Itti, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "model of salience-based visual attention", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Alexe, B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "What is an object?", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Liu, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning to Detect A Salient Object", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Johansson, G.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "model for analysis of biological motion", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gorelick, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Actions as Space-Time Shapes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gorelick", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Actions as Space-Time Shapes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Blank", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Actions as Space-Time Shapes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shechtman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Actions as Space-Time Shapes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Irani", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Actions as Space-Time Shapes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Basri", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Actions as Space-Time Shapes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Borji", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Detection: A Benchmark", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sihte", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Determination: A Benchmark", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Itti", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Detection: A Benchmark", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Guo", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Spatio-temporal Saliency detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Spatio-temporal Saliency detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Judd", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning to Predict Where Humans Look", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ehinger", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning to Predict Where Humans Look", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Durand", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning to Predict Where Humans Look", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Harel", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Graph-based Visual Saliency", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Koch", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Graph-based Visual Saliency", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Perona", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Graph-based Visual Saliency", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Perona", "label": "co-developed", "title": "Relation: co-developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Caltech-256 object category dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Rahtu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Segmenting Salient Objects from Images and Videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kannala", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Segmenting Salient Objects from Images and Videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Salo", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Segmenting Salient Objects from Images and Videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Heikkil\u00a8a", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Segmenting Salient Objects from Images and Videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Mauthner", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Institute for Computer Graphics and Vision, Graz University of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Possegger", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Institute for Computer Graphics and Vision, Graz University of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Waltner", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Institute for Computer Graphics and Vision, Graz University of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Institute for Computer Graphics and Vision", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Graz University of Technology", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Institute for Computer Graphics and Vision", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "possegger@icg.tugraz.at", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Guanbin Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Visual Saliency Based on Multiscale Deep Features", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Visual Saliency Based on Multiscale Deep Features", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Yizhou Yu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Visual Saliency Based on Multiscale Deep Features", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Features", "label": "extracted at", "title": "Relation: extracted at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Multiple Scales", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "MDF approach", "label": "generates", "title": "Relation: generates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Salience maps", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "MDF approach", "label": "generates", "title": "Relation: generates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "accurate salience maps", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Spectral residual approach", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Salience detection", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Salience detection", "label": "is_field_within", "title": "Relation: is_field_within\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Image Processing", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Salient object detection", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "discriminative regional feature integration", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Salient object detection", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Salient object detection", "label": "is_benchmark", "title": "Relation: is_benchmark\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yuan et al. (2013)", "label": "is_foundational_work_in", "title": "Relation: is_foundational_work_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Perazzi et al. (2012)", "label": "is_foundational_work_in", "title": "Relation: is_foundational_work_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salient region detection", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "salient region detection", "label": "is_task_in", "title": "Relation: is_task_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Wei et al. (2012)", "label": "is_foundational_work_in", "title": "Relation: is_foundational_work_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salient region detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yan et al. (2013)", "label": "is_foundational_work_in", "title": "Relation: is_foundational_work_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Yang et al. (2013)", "label": "is_foundational_work", "title": "Relation: is_foundational_work\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yang et al. (2013)", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Salient region detection", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Salience filters", "label": "method_for", "title": "Relation: method_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "salient region detection", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Zhu et al. (2014)", "label": "is_foundational_work", "title": "Relation: is_foundational_work\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sun et al. (2014)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sun et al. (2014)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "discriminative manifold-based approach", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Sun et al. (2014)", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Minsu Cho", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Discovery and Localization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Minsu Cho", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Discovery and Localization in the Wild", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Minsu Cho", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Inria", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Unsupervised Object Discovery and Localization", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "bottom-up region proposals", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Suha Kwak", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Discovery and Localization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Suha Kwak", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Discovery and Localization in the Wild", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Suha Kwak", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Inria", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cordelia Schmid", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Unsupervised Object Detection and Localization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cordelia Schmid", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Inria", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Unsupervised Object Discovery and Localization in the Wild", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Unsupervised Object Discovery and Localization in the Wild", "label": "has_topic", "title": "Relation: has_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "object discovery", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Unsupervised Object Discovery and Localization in the Wild", "label": "has_topic", "title": "Relation: has_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "object localization", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Unsupervised Object Discovery and Localization in the Wild", "label": "uses_method", "title": "Relation: uses_method\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "part-based matching", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "object discovery", "label": "occurs in", "title": "Relation: occurs in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "mixed-class datasets", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Unsupervised Object Localization", "label": "uses_approach", "title": "Relation: uses_approach\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "bottom-up region proposals", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "setting", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "fully unsupervised", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "region proposals", "label": "form", "title": "Relation: form\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "candidate bounding boxes", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "correspondence", "label": "evaluated_using", "title": "Relation: evaluated_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "probabilistic Hough transform", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Hough transform", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "appearance", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Hough transform", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "spatial consistency", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "candidate correspondence", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "appearance", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "candidate correspondence", "label": "considers", "title": "Relation: considers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "spatial consistency", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "dominant objects", "label": "are discovered by", "title": "Relation: are discovered by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "comparing scores", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "dominant objects", "label": "are localized by", "title": "Relation: are localized by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "selecting regions", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "regions", "label": "contain", "title": "Relation: contain\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "dominant objects", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "regions", "label": "delineate", "title": "Relation: delineate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "candidate objects", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "evaluations", "label": "occur on", "title": "Relation: occur on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "standard benchmarks", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "rd benchmarks", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "proposed approach", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Probabiltistic Hough transform", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "multiple object detection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Alexe et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Measuring the object-ness of image windows", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ballard", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Generalizing the Hough transform", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Joulin et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Discriminative clustering for image co-segmentation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Cho et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Learning graphs to match", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Learning graphs to match", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Proceedings of the IEEE International Conference on Computer Vision", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Unsupervised object localization", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "object discovery", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Image Co-segmentation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Learning Graphs", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Efficient Image Localization", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pictoiral Structures", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IJCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IJCV", "label": "is_publication_platform_for", "title": "Relation: is_publication_platform_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Architectural modeling", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IJCV", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Dynamic textures", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "IJCV", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Dynamic texture detection based on motion analysis", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Ijaz Akhter", "label": "contributor_to", "title": "Relation: contributor_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Pose-Conditioned Joint Angle Limits", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ijaz Akhter", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Intelligent Systems", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ijaz Akhter", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ijaz.akhter@tuebingen.mpg.de", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Pose-Conditioned Joint Angle Limits", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pose-Conditioned Joint Angle Limits", "label": "file_name", "title": "Relation: file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Akhter_Pose-Conditioned_Joint_Angle_2015_CVPR_paper.pdf", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Michael J. Black", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Pose-Conditioning Joint Angle Limits", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Michael J. Black", "label": "contributor_to", "title": "Relation: contributor_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Pose-Conditioned Joint Angle Limits", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Michael J. Black", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Intelligent Systems", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "3D human pose estimation", "label": "is_central_to", "title": "Relation: is_central_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "analysis of people in images and video", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "joint limits", "label": "vary_with", "title": "Relation: vary_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "pose", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "motion capture dataset", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "range of human poses", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "3D pose", "label": "derived from", "title": "Relation: derived from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "2D joint locations", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "detections", "label": "performed on", "title": "Relation: performed on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Leeds sports pose dataset", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "he-art results", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "2D to 3D pose estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "he-art results", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CMU mocap dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "superior results", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "manual annotations", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "superior results", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "automatic detections", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "automatic detections", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Leeds sports pose dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Andriluka, M. et al. (2010)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "monocular 3D pose estimation and tracking", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Barr`on, C. \u0026 Kakadiaris, I. (2001)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "estimating anthropometry and pose", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "BenAbdelkader, C. \u0026 Yacoob, Y. (2008)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "statistical estimation of human anthropometry", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Human Pose Reconstruction", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Motion Capture Data", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Prior Models", "label": "inform", "title": "Relation: inform\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Human Pose Reconstruction", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Bourdev \u0026 Malik", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "International Conference on Computer Vision", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Poselets", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "body part detector", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Poselets", "label": "trained_using", "title": "Relation: trained_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "3D human pose annotations", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, Nie, \u0026 Ji", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Image Processing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Guan et al.", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Int. Conf. on Computer Vision (ICCV)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Estimating human shape", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "single image", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Grochow et al.", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ACM Transactions on Graphics (TOG)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Grochow et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Style-based inverse kinematics", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Style-based inverse kinematics", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "method", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Style-based inverse kinematics", "label": "appeared_in", "title": "Relation: appeared_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ACM Transactions on Graphics (TOG)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "human anthropometry", "label": "estimated_from", "title": "Relation: estimated_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "single uncalibrated image", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "three-dimensional multivariate model", "label": "appeared_in", "title": "Relation: appeared_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Clinical Biomechanics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Herda et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hierarchical implicit surface joint limits", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical implicit surface joint limits", "label": "appeared_in", "title": "Relation: appeared_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision and Image Understanding", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lin et al.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "sketching interface", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lin et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft COCO: Common objects in context", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "sketching interface", "label": "appeared_in", "title": "Relation: appeared_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Visualization and Computer Graphics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Max Planck Institute for Intelligent Systems", "label": "location", "title": "Relation: location\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Tuebingen", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Ran Tao", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Attributes and Categories for Generic Instance Search from One Example", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Ran Tao", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Attributes and Categories for Generic Instance Search from One Example", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Arnold W.M. Smeulders", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Attributes and Categories for Generic Instance Search from One Example", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Arnold W.M. Smeulders", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tao_Attributes_and_Categories_2015_CVPR_paper", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Attributes and Categories for Generic Instance Search from One Example", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "instance search methods", "label": "struggle with", "title": "Relation: struggle with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "arbitrary 3D objects", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "arbitrary 3D objects", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "shoes", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "category-specific attributes", "label": "propose using", "title": "Relation: propose using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "authors", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "category-specific attributes", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "appearance variations", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "category-level information", "label": "combines_with", "title": "Relation: combines_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "category-specific attributes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "combination", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "approaches relying on low-level features", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "core challenge", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "representing query image", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "query image", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "robust representation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "robust representation", "label": "is_resistant_to", "title": "Relation: is_resistant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "appearance variations", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "robust representation", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Appearance Variation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "rich representation", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "distinction from similar instances", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "distinction", "label": "is_between", "title": "Relation: is_between\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "similar instances", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Generic Instance Search", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "low-level features", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Core Challenge", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "robust representation", "width": 2.7}, {"arrows": "to", "color": "#FF5722", "from": "Appearance Variation", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "robust representation", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Attribute Representation", "label": "facilitates", "title": "Relation: facilitates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "distinction", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Large Scale Visual Recognition Challenge", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Attribute Transfer", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "detecting unseen object classes", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple queries", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "large scale specific object retrieval", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Aranandjelovic", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple queries", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zisserman", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple queries", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Naphade", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "concept ontology", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "concept ontology", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE MultiMedia", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Perdoch", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "efficient representation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Farhad", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "describing objects", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Farhad", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Farhad", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "ISLA", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "describing objects", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "object attributes", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Recognition algorithms", "label": "based on", "title": "Relation: based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "convolutional networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "last layer output", "label": "acts as", "title": "Relation: acts as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "feature representation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "last layer output", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "spatially coarse", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "earlier layers", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "precise in localization", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "earlier layers", "label": "lacks", "title": "Relation: lacks\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "semantics", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "hypercolumn", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "vector of activations", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "pixel", "label": "above", "title": "Relation: above\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "CNN units", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "hypercolumns", "label": "acts as", "title": "Relation: acts as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "pixel descriptors", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "hypercolumns", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "improvements", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "hypercolumns", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "state-of-the-art results", "width": 2.8200000000000003}, {"arrows": "to", "color": "#2196F3", "from": "simultaneous detection", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "localization task", "width": 2.7199999999999998}, {"arrows": "to", "color": "#2196F3", "from": "keypoint localization", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "localization task", "width": 2.7199999999999998}, {"arrows": "to", "color": "#2196F3", "from": "part labeling", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "localization task", "width": 2.7199999999999998}, {"arrows": "to", "color": "#2196F3", "from": "Keypoint Localization", "label": "is_task", "title": "Relation: is_task\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fine-grained Localization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Spatial Pyramid Pooling", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Visual Recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-scale Feature Integration", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Object Segmentation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Multiscale Combinatorial Grouping", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "He, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Spatial Pyramid Pooling", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Barron, J. T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Volumetric Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Hypercolumn Representation", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Object Segmentation", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Barron et al.", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hubel \u0026 Wiesel", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The Journal of Physiology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bo \u0026 Fowlakes", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ionescu et al.", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jones \u0026 Malik", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Koenderink \u0026 van Doorn", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Biological Cybernetics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Volumetric semantic segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "pyramid context features", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Visual cortex", "label": "studied_in", "title": "Relation: studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Hubel \u0026 Wiesel\u0027s work", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Pedestrian parsing", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "shape-based methods", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Biological cybernetics", "label": "is_journal", "title": "Relation: is_journal\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "visual system", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Malik", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California, Berkeley", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xie", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "DeepShape", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "DeepShape", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "shape descriptor", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "DeepShape", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D shape matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "DeepShape", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D shape retrieval", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "shape descriptor", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "3D shape matching and retrieval", "width": 2.92}, {"arrows": "to", "color": "#9E9E9E", "from": "shape descriptor", "label": "is_formed_by", "title": "Relation: is_formed_by\u003cbr\u003eType: structural\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "multiple discriminative auto-encoders", "width": 2.96}, {"arrows": "to", "color": "#9E9E9E", "from": "shape descriptor", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D shape matching", "width": 2.9}, {"arrows": "to", "color": "#9E9E9E", "from": "shape descriptor", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D shape retrieval", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "3D model", "label": "poses challenge to", "title": "Relation: poses challenge to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "3D shape matching and retrieval", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "shape feature learning scheme", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "multiscale shape distribution", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "auto-encoder", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "discriminative deep auto-encoder", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "shape distribution", "label": "is used as input to", "title": "Relation: is used as input to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "auto-encoder", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Fisher discrimination criterion", "label": "is imposed on", "title": "Relation: is imposed on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "neurons", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Fisher discrimination criterion", "label": "applied to", "title": "Relation: applied to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "hidden layer neurons", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "neurons", "label": "are concatenated to form", "title": "Relation: are concatenated to form\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "shape descriptor", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "3D models", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "geometric variations", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed Method", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "3D shape matching and retrieval", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Proposed Method", "label": "demonstrated_by", "title": "Relation: demonstrated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Experimental results", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Agathos et al. (2009)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Retrieval of 3D articulated objects", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Assfalg et al. (2007)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Content-based retrieval of 3D objects", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Belongie et al. (2000)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Shape context", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Belongie et al. (2000)", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Shape Context", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Shape context", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "shape matching and object recognition", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Geometric Feature Learning", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "3D shape matching", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Auto-encoders", "label": "applied_in", "title": "Relation: applied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "3D shape matching", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Ric variations", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Mcgill dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Ric variations", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "SHREC\u002710 Shape dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shape Context", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "shape matching", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shape Context", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object recognition", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Deep Architectures", "label": "relevant to", "title": "Relation: relevant to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "AI", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Shape Google", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "geometric words", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Isometry-invariant distances", "label": "computed by", "title": "Relation: computed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Bronstein et al. (2006)", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Gromov-Hausdorff framework", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "non-rigid shape matching", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Diffusion geometry", "label": "contributes to", "title": "Relation: contributes to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "topologically-robust matching", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Bronstein et al. (2011)", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Shape Google", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Mahmoudi, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Gromov-Hausdorff framework", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A Gromov-Hausdorff framework", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "shape matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A Gromov-Hausdorff framework", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, D.-Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "On visual similarity based 3D model retrieval", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "On visual similarity based 3D model retrieval", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D model retrieval", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A benchmark for 3D mesh segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Locally linear regression for pose-invariant face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A benchmark", "label": "is_for", "title": "Relation: is_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D mesh segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "De Goes, F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A hierarchical segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A hierarchical segmentation", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "articulated bodies", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jin Xie", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "New York University Abu Dhabi", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Jin Xie", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "jin.xie@nyu.edu", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yi Fang", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "New York University Abu Dhabi", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yi Fang", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "yfang@nyu.edu", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Fan Zhu", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Electrical and Computer Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Electrical and ComputerEngineering", "label": "is_located_at", "title": "Relation: is_located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "New York University Abu Dhabi", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Edward Wong", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Polytechnic School of Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Polytechnic School of Engineering", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "New York University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bingbing Ni", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Motion Part Regularization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Bingbing Ni", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ADSC Singapore", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Motion Part Regularization", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Action Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pierre Moulin", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Motion Part Regularization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Pierre Moulin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Department of ECE", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "golf", "label": "is_an_action_label", "title": "Relation: is_an_action_label\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Action", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "punch", "label": "is_an_action_label", "title": "Relation: is_an_action_label\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Action", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Fisher vector", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Action Recognition", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Ni_Motion_Part_Regularization_2015_CVPR_paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Motion Part Regularization framework", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Motion Part Regularization framework", "label": "aims_to_improve", "title": "Relation: aims_to_improve\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "action recognition", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Motion Part Regularization framework", "label": "mines", "title": "Relation: mines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "dense trajectories", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "action recognition", "label": "implemented_in", "title": "Relation: implemented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "3D natural scenes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "action recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "depth cameras", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "discriminativeness weighted Fisher vector representation", "label": "is_more_discriminative_than", "title": "Relation: is_more_discriminative_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "traditional Fisher vector", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "objective function", "label": "encourages", "title": "Relation: encourages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "sparse selection of trajectory groups", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "objective function", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "action class discriminative term", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "objective function", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "discriminative term", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "optimization algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "auxiliary variables", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Optimization Algorithm", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Action Recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Motion Part", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Discriminative Weights", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Dense Trajectories", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Wang et al. (2011)", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Behavior Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Spatio-Temporal Grouping", "width": 2.6399999999999997}, {"arrows": "to", "color": "#2196F3", "from": "LIBSVM", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "library", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Automatic Annotation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Human Actions", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "O. Duchenne", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Automatic annotation of human actions in video", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "I. Laptev", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Automatic annotation of human actions in video", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "J. Sivic", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Automatic annotation of human actions in video", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "J. Ponce", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Automatic annotation of human actions in video", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "H. Wang", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Action recognition with improved trajectories", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "C. Schmid", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Action recognition with improved trajectories", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "C. Schmid", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Multi-fold mil training", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "P. Felzenszwalb", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatively trained part based models", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "R. Girshick", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatively trained part based models", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "R. Girshick", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Efficient regression of general-activity human poses", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. McAlleser", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatively trained part based models", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "D. Ramanan", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Object description with discriminatively trained part based models", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "J. Wang", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Mining actionlet ensemble for action recognition with depth cameras", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Z. Liu", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Mining actionlet ensemble for action recognition with depth cameras", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Wu", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Mining actionlet ensemble for action recognition with depth cameras", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "J. Yuan", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Mining actionlet ensemble for action recognition with depth cameras", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "M. Jain", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Better exploiting motion for better action recognition", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "H. Jegou", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Better exploiting motion for better action recognition", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "P. Bouthemy", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Better exploiting motion for better action recognition", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Y.-G. Jiang", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Trajectory-based modeling of human actions with motion reference points", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Q. Dai", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Trajectory-based modeling of human actions with motion reference points", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "X. Xue", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Trajectory-based modeling of human actions with motion reference points", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "W. Liu", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Trajectory-based modeling of human actions with motion reference points", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "C.-W. Ngo", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Trajectory-based modeling of human actions with motion reference points", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Pierre Bounameaux", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ADSC Singapore", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "gaze correction solutions", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "additional hardware", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "pixel replacement operations", "label": "localized_around", "title": "Relation: localized_around\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "eyes", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Monocular Gaze Correction", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Monocular Gaze Correction", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Uncanny Valley Effect", "label": "is_effect_of", "title": "Relation: is_effect_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Localized Pixel Replacement", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Amit", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Shape Quantization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shape Quantization", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Doll\u00e1r", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Structured Forests", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Structured Forests", "label": "facilitates", "title": "Relation: facilitates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Fast Edge Detection", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Fanelli", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Random Forests for 3D Face Analysis", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Random Forests for 3D Face Analysis", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Fanelli, G.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Random forests for real time 3d face analysis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gaze correction", "label": "achieved with", "title": "Relation: achieved with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "single webcam", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Gall, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Class-specific hough forests for object detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hough forests", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jones, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Achieving eye contact in a one-to-many 3D video teleconferecing system", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "eye contact", "label": "achieved in", "title": "Relation: achieved in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "3D video teleconferencing system", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kazemi, V.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "One milliseccond face alignment with an ensemble of regression trees", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kazemi, V.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "One milliseccond face alignment", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kazemi, V.", "label": "collaborated_with", "title": "Relation: collaborated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Sullivan, J.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "face alignment", "label": "achieved with", "title": "Relation: achieved with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "regression trees", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Kuster, C.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaze correction", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ren, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Face alignment", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ren, S.", "label": "collaborated_with", "title": "Relation: collaborated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cao, X.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cao, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "practical transfer learning algorithm", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kononenko, Daniil", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Skolkovo Institute of Science and Technology (Skoltech)", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Lempitsky, Victor", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Skolkovo Institute of Science and Technology (Skeltech)", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Zhao, Kaili", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Joint Patch and Multi-label Learning", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Joint Patch and Multi-label Learning", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Facial Action Unit Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhao_Joint_Patch_and_2015_CVPR_paper.pdf", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Joint Patch and Multi-label Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Facial Action Coding System", "label": "is_system_for", "title": "Relation: is_system_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "describing facial movements", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Facial Action Coding System", "label": "is_reference_for", "title": "Relation: is_reference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "human face", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Facial Action Coding System", "label": "defines", "title": "Relation: defines\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "facial action units", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Facial Action Coding System", "label": "is_reference_for", "title": "Relation: is_reference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "facial action unit detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Action Units", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Facial Action Coding System", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "JPML", "label": "is_instance_of", "title": "Relation: is_instance_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-label Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "JPML", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "highest average F1 scores", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "JPML", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "CK+", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "BP4D", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Machine learning", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "facial expression recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Machine learning", "label": "is_publication_venue_for", "title": "Relation: is_publication_venue_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Support-vector networks", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "FACIAL Action Coding System (FACS)", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "facial expression recognition", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Action Unit (AU) Detection", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "FACIAL Action Coding System (FACS)", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Patch Learning", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "JPML", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Alternating direction method of multipliers", "label": "utilized_in", "title": "Relation: utilized_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "optimization techniques", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Alternating Direction Method of Multipliers", "label": "is_optimization_technique", "title": "Relation: is_optimization_technique\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "optimization techniques", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Affective Computing", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Facial Action Unit Event Detection", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Facial Action Unit Event Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "cascade of tasks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "X. Ding", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Facial Action Unit Event Detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "P. Ekman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Facial Action Coding System", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "F. De la Torre", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Intraface", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "F. De la Torre", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Selective transfer machine", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "J. C. Hager", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Facial Action Coding System", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Selective transfer machine", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "personalization in facial action unit detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "W.-S. Chu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Selective transfer machine", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "J. F. Cohn", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Selective transfer machine", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Facing imbalanced data", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "imbalanced datasets", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "L. A. Jeni", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Facing imbalanced data", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Data-free prior model", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "data-free approach", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Data-free prior model", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "facial action unit recognition", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Li", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Data-free prior model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Zhao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Comm. and Info. Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "School of Comm. and Info. Engineering", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Beijing University of Posts and Telecom.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Beijing University of Posts and Telecom.", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Beijing", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "G. Littlewort", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Dynamics of facial expression", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Dynamics of facial expression", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "AU-cascades", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "AU-cascades", "label": "for", "title": "Relation: for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "action unit detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Wen-Sheng Chu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robotics Institute", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Robotics Institute", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Carnegie Mellon University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fernando De la Torre", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robotics Institute", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jeffrey F. Cohn", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robotic Institute", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jeffrey F. Cohn", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robotics Institute", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Honggang Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Comm. and Info. Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Beijing University of Posts and Telecom", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "China", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "TVSum", "label": "summarizes", "title": "Relation: summarizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Web Videos", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "TVSum", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Titles", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "TVSum", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "video summarization framework", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "TVSum", "label": "guides", "title": "Relation: guides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "title-based image search results", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "TVSum", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "superior quality summaries", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "TVSum", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "existing approaches", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "TVSum", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "summaries", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "TVSum", "label": "has_quality", "title": "Relation: has_quality\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "superior", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Yale Song", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "TVSum", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Yale Song", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Yahoo Labs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yale Song", "label": "has_contact", "title": "Relation: has_contact\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "yalessong@yahoo-inc.com", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jordi Vallmitjana", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "TVSum", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jordi Vallmitjana", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Yahoo Labs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Amanda Stent", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "TVSum", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Amanda Stent", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Yahoo Labs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Alejandro Jaimes", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "TVSum", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Alejandro Jaimes", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Yahoo Labs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Video summarization", "label": "is_challenging_problem_due_to", "title": "Relation: is_challenging_problem_due_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "need for prior knowledge", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "video titles", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "descriptive", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "co-archetypal analysis", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "novel technique", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "co-archetypal analysis", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "visual concepts", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "visual concepts", "label": "are_shared_between", "title": "Relation: are_shared_between\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "video and images", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "TVSum50", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "benchmark dataset", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "TVSum50", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "TVSum50", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "study", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "image search results", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "noise and variance", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Co-Archetypal Analysis", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "analysis method", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Canonical Visual Concepts", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "concept", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "M. Basseville", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Detection of abrupt changes", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "A. Beck", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "shrinkage-thresholding algorithm", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "K. Bleakley", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "group fused lasso", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Chen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "archetypal analysis", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "S. Fidler", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "sentence is worth a thousand pixels", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "S. Fidler", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A sentence is worth a thousand pixels", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Airal", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast and robust archetypal analysis", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fast and robust archetypal analysis", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "M. Gygli", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Creating summaries from user videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Creating summaries from user videos", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Jia", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Visual concept learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Visual concept learning", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Y. J. Lee", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Discovering important people and objects", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Y. J. Lee", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Object-graphs for context-aware category discovery", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Discovering important people and objects", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "L. Li", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Video summarization via transferrable structured learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Video summarization via transferrable structured learning", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "WWW", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "D. Lin", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Visual semantic search", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Visual semantic search", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Visual semantic search", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Retrieving videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Visual semantic search", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "complex textual queries", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Yahoo Labs", "label": "is_organization", "title": "Relation: is_organization\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "research institution", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "isual semantic search", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "video retrieval", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "isual semantic search", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tianjun Xiao", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The Application of Two-level Attention Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tianjun Xiao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Computer Science and Technologies", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "The Application of Two-level Attention Models", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Deep Convolutional Neural Network", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Yichong Xu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The Application of Two-level Attention Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yichong Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kuiyuan Yang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The Application of Two-level Attention Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kuiyuan Yang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaxing Zhang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The Application of Two-level Attention Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jiaxing Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yuxin Peng", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The Application of Two-level Attack Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yuxin Peng", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Computer Science and Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng Zhang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The Application of Two-level Attention Models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "New York University Shanghai", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fine-grained classification", "label": "is_challenging_due_to", "title": "Relation: is_challenging_due_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "subtle differences between categories", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "pipeline", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "bottom-up attention", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "pipeline", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "object-level top-down attention", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "pipeline", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "part-level top-down attention", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Fine-grained image classification", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Visual attention models", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Fine-grained image classification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Deep convolutional neural networks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Deep convolutional neural networks", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "ImageNet classification", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Weak supervision", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "additional annotations", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Institute of Computer Science and Technology", "label": "located_at", "title": "Relation: located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Peking University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Geodesic Exponential Kernel", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "curvature and linearity conflict", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Aasa Feragen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Geodesic Exponential Kernel", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Aasa Feragen", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "DIKU, University of Copenhagen", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fran\u00e7ois Lauze", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Geodesic Exponential Kernel", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fran\u00e7ois Lauze", "label": "is_associated_with", "title": "Relation: is_associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Feragen", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Fran\u00e7ois Lauze", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "DIKU, University of Copenhagen", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "S\u00f8ren Hauberg", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Geodesic Exponential Kernel", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "S\u00f8ren Hauberg", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "DTU Compute", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "geodesic metric spaces", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "geodesic Laplacian kernels", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Gaussian kernel", "label": "is_generalized_to", "title": "Relation: is_generalized_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "positive definite kernel", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "positive definite kernel", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "flat space", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "geodesic Gaussian kernel", "label": "is_positive_definite_if_and_only_if", "title": "Relation: is_positive_definite_if_and_only_if\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Riemannian manifold is Euclidean", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "geodesic Laplacian kernel", "label": "retains", "title": "Relation: retains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "positive de\ufb01niteness", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "geodesic Laplacian kernel", "label": "is applicable to", "title": "Relation: is applicable to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "curved spaces", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "geodesic Laplacian kernel", "label": "generalized to", "title": "Relation: generalized to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "spheres", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "geodesic Laplacian kernel", "label": "generalized to", "title": "Relation: generalized to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "hyperbolic spaces", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "geodesic Laplacian kernel", "label": "is a type of", "title": "Relation: is a type of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "kernel", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "curved spaces", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "spheres", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "curved spaces", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "hyperbolic spaces", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "spaces", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "conditionally negative de\ufb01nite distances", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "theoretical results", "label": "are verified", "title": "Relation: are verified\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "empirically", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "geodesic Laplacian kernels", "label": "can be generalized to", "title": "Relation: can be generalized to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "curved spaces", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Gaussian kernels", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "kernel methods", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Laplacian kernels", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "kernel methods", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "M. Alamgir and U. von Luxburg", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shortest path distance in random k-nearest neighbor graphs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "N. Dalal and B. Triggs", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Histograms of oriented gradients for human detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "S. Amar\u00ed and H. Nagaoka", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Methods of information geometry", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Arsigny et al.", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast and simple calculus on tensors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fast and simple calculus on tensors", "label": "appears_in", "title": "Relation: appears_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "MICCAI", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Feragen et al.", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Means in spaces of tree-like shapes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Feragen et al.", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Scalable kernels for graphs", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Means in spaces of tree-like shapes", "label": "appears_in", "title": "Relation: appears_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Scalable kernels for graphs", "label": "appears_in", "title": "Relation: appears_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bekka and de la Harple", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Kazhdan\u2019s Property (T)", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Kazhdan\u2019s Property (T)", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "mathematical_property", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kazhdan\u2019s Property (T)", "label": "is_presented_in", "title": "Relation: is_presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "New Mathematical Monographs", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bridson and Hae\ufb02iger", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Metric spaces of non-positive curvature", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ganzhao Yuan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "\u21130TV: A New Method", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ganzhao Yuan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ganzhao Yuan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "South China University of Technology (SCUT)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ganzhao Yuan", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "yuan Ganzhao@gmail.com", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "\u21130TV: A New Method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Restoration", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Image Restoration", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Total Variation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Image Restoration", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "PADMM", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yuan_L0TV_A_New_2015_CVPR_paper", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "image restoration", "label": "affected_by", "title": "Relation: affected_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Impulse Noise", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "\u21130TV-PADMM", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "TV-based restoration problem", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "TV-based restoration problem", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "\u21130-norm data fidelity", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "MPEC", "label": "solved_with", "title": "Relation: solved_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PADMM", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "PADMM", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Alternating Direction Method of Multipliers", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Ejaz Ahmed", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "An Improved Deep Learning Architecture", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Ejaz Ahmed", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of Maryland", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "An Improved Deep Learning Architecture", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Michael Jones", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "An Improved Deep Learning Architecture", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Michael Jones", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Mitsubishi Electric Research Labs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tim K. Marks", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "An Improved Deep Learning Architecture", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Tim K. Marks", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Mitsubishi Electric Research Labs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "similarity value", "label": "indicates", "title": "Relation: indicates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "same person", "width": 2.94}, {"arrows": "to", "color": "#9E9E9E", "from": "layer", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: operational\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "cross-input neighborhood differences", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "cross-input neighborhood differences", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "local relationships", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "local relationships", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "mid-level features", "width": 2.84}, {"arrows": "to", "color": "#9E9E9E", "from": "patch summary features", "label": "computed_by", "title": "Relation: computed_by\u003cbr\u003eType: operational\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "layer", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "layer of patch summary features", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "high-level summary", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "CUHK03", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "large data set", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "CUHK01", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "medium-sized data set", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "VIPeR", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "small data set", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "initial training", "label": "improves results", "title": "Relation: improves results\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "fine-tuning", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Convolutional Architecture", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "person re-identification", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Similarity Metric Learning", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "person re-identification", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Neighborhood Difference Layer", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "person re-identification", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Metric Learning", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "person re-identification", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Metric Learning", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Distribution Divergence", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "[Li, W., \u0026 Wang, X. (2013)]", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Z.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Learning locally-adaptive decision functions", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Z.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Analyzing the harmonic structure in graph-based learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bazzani, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Multiple-shot person re-identi\ufb01cation", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple-shot person re-identi\ufb01cation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "chromatic analyses", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Bottou, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Stochastic gradient tricks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Davis, J. V.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Information-theoretic metric learning", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Farenzena, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Person re-identi\ufb01cation by symmetry-driven accumulation", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Person re-identi\ufb01cation", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "local features", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "local features", "label": "capture", "title": "Relation: capture\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "local contrast", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "local features", "label": "capture", "title": "Relation: capture\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "shape information", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "McAllester, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Object detection with discriminatively trained part-based models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vassileios Balntas", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "BOLD", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Vassileios Balntas", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Surrey, UK", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "BOLD", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Binary Online Learned Descriptor", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lilian Tang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "BOLD", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lilian Tang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Surrey, UK", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Krystian Mikolajczyk", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "BOLD", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Krystian Mikolajczyk", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Surrey, UK", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "BOLD (Binary Online Learned Descriptor)", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "BOLD (Binary Online Learned Descriptor)", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "image patch", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "binary strings", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "test results", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "binary strings", "label": "indicates", "title": "Relation: indicates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "subset of robust tests", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "per-patch optimization", "label": "performs_better_than", "title": "Relation: performs_better_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "global optimization", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Masked Hamming distance", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "tests", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Per-patch optimization", "label": "benefits_over", "title": "Relation: benefits_over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Global optimization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "D. G. Lowe", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SIFT features", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Local descriptors", "label": "compared_in", "title": "Relation: compared_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "IEEE TPAMI, 27(10):1615\u20131630, 2005", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "SURF descriptor", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "ECCV, 2006", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "SURF descriptor", "label": "introduced_by", "title": "Relation: introduced_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "G. H. M. Brown and S. Winder", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Local image descriptors", "label": "explores_learning", "title": "Relation: explores_learning\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Discriminative learning", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Discriminative learning", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "IEEE TPAMI, 33(1):43\u201357, 2010", "width": 2.8200000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Binary descriptors", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Image matching", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Online descriptor optimization", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Image matching", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "G. H. M. Brown and S. Winder", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "discriminative learning", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "discriminative learning", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "SURF descriptor", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "interest point detection", "label": "addressed_by", "title": "Relation: addressed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "K. Mikolajczyk and C. Schmid", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "tracking applications", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Struck", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tracking-learning-detection", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "integration", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Tracking-learning-detection", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "tracking", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "keypoint recognition", "label": "method", "title": "Relation: method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "random ferns", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "random ferns", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "keypoint recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "M. Ozuysal", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "random ferns", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "M. Ozuysal", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast keypoint recognition method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "tracking", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "topological constraints", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "tracking", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "deformable objects", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "tracking", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "occluded objects", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "tracking", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "dynamic graph", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Fast keypoint recognition method", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE TPAMI", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE TPAMI", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "annotation of pictures", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ORB", "label": "is_alternative_to", "title": "Relation: is_alternative_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SIFT", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ORB", "label": "is_alternative_to", "title": "Relation: is_alternative_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SURF", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "SURF", "label": "developed by", "title": "Relation: developed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Bay, H.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "SURF", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision and Image Understanding", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "V. L. T. Trzcinski", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Boosting Binary Keypoint Descriptors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiajun Wu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Multiple Instance Learning for Image Classi\ufb01cation and Auto-Annotation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiajun Wu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Multiple Instance Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Multiple Instance Learning for Image Classi\ufb01cation and Auto-Annotation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Multiple Instance Learning", "label": "is_presented_at", "title": "Relation: is_presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Deep Multiple Instance Learning", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Learning Algorithm", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Multiple Instance Learning", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Glaucoma", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Yinan Yu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Multiple Instance Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yinan Yu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Institute of Deep Learning", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kai Yu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Multiple instance Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wu_Deep_Multiple_Instance_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Deep Multiple Instance Learning", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Deep learning", "label": "achieved", "title": "Relation: achieved\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "tremendous improvements", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "object proposals", "label": "regarded as", "title": "Relation: regarded as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "instance sets", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "text annotations", "label": "regarded as", "title": "Relation: regarded as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "instance sets", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "systems", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "MIL property", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "systems", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "deep learning strategies", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "region-keyword pairs", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "reasonable", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "extraction", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "little supervision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Region-keyword pairs", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "little supervision", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Multiple Instance Learning (MIL)", "label": "is a field of", "title": "Relation: is a field of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.56}, {"arrows": "to", "color": "#4CAF50", "from": "Andrews et al.", "label": "studies", "title": "Relation: studies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Support vector machines", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Li \u0026 Wang", "label": "studies", "title": "Relation: studies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "computerized annotation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "computerized annotation", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "pictures", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Barnard et al.", "label": "studies", "title": "Relation: studies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Matching words and pictures", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Image Annotation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Deep Learning", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Barnard", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Matching words and pictures", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Li, L.-J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Object bank", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Hierarchical matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of California, Los Angeles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical matching", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Q.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Harvesting mid-level visual concepts", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Harvesting mid-level visual concepts", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bing: Binarized normed gradients", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Imaginet", "label": "is_database_of", "title": "Relation: is_database_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "hierarchical image", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Imaginet", "label": "is_database_of", "title": "Relation: is_database_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "hierarchical images", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Imaginet", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "hierarchical image database", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Imaginet", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision and Pattern Recognition, 2009", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Rochan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Weakly Supervised Localization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Weakly Supervised Localization", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Mrigank Rochan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Massachusetts Institute of Technology", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Mrigank Rochan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Manitoba", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Mrigank Rochan", "label": "works_in", "title": "Relation: works_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Computer Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chang Huang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Institute of Deep Learning", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "training images", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "object bounding boxes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "weakly labeled data", "label": "is_easier_to_collect_than", "title": "Relation: is_easier_to_collect_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "training images", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "YouTube videos", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "user-generated tags", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "image search", "label": "enables_collection_of", "title": "Relation: enables_collection_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "weakly labeled images", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "collection of images", "label": "labeled_with", "title": "Relation: labeled_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "object category", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "bounding box", "label": "estimated_using", "title": "Relation: estimated_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "local density map", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "image datasets", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "experimental results", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "video datasets", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "experimental results", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lampert et al. (2009)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "unseen object classes", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "K. Grauman", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Object-graphs for context-aware category discovery", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "R. G. Cinbis", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Multi-fold mil training", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "J. Verbeek", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Multi-fold mil training", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "T. Mikolov", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Distributed representations of words and phrases", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "I. Sutskever", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Distributed representations of words and phrases", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "M. H. Nguyen", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Weakly supervised discrimiative localization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A. Papazoglou", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast object segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fast object segmentation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE International Conference on Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "V. Ferrari", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Fast object segmentation", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Object-graphs", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "context-aware category discovery", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Distributed representations", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "compositionality", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE International Conference on Computer Vision", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Graph structured sparsity model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A. Prest", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning object class detectors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "M. Rohrbach", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Evaluating knowledge transfer", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "M. Rohrbach", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "What helps where", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Evaluating knowledge transfer", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Conference on Computer Vision and Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "What helps where", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "University of Manitoba", "label": "has_department", "title": "Relation: has_department\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Department of Computer Science", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Manitoba", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Wang", "label": "works_in", "title": "Relation: works_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Computer Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mriganka Rochan", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "mrochan@cs.umanitoba.ca", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "rigank Rochan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Manitoba", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wei Liu", "label": "contributor_to", "title": "Relation: contributor_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Towards 3D Object Detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Wei Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dep. of Cognitive Science", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wei Liu", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Xiamen University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wei Liu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Supervised Discrete Hashing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wei Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IBM Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Towards 3D Object Detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Rongrong Ji", "label": "contributor_to", "title": "Relation: contributor_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Towards 3D Object Detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Rongrong Ji", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dep. of Cognitive Space", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rongrong Ji", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Xiamen University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shaozi Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Towards 3D Object Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shaozi Li", "label": "contributor_to", "title": "Relation: contributor_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Towards 3D ObjectDetection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shaozi Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dep. of Cognitive Science", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ywang@cs.umanitoba.ca", "label": "contact_email", "title": "Relation: contact_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Yang Wang", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "accurate detection algorithm", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "RGB and depth modalities", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "RGB and depth modalities", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "correlated", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "cross-modality deep learning framework", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "deep Boltzmann Machines", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "cross-modality deep learning framework", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "lack of 3D training data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "labeled 2D samples", "label": "from", "title": "Relation: from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "existing datasets", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "3D CAD models", "label": "are", "title": "Relation: are\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "models", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "RMRC dataset", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "effectiveness", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "RMRC dataset", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "cross-modality features", "label": "captured from", "title": "Relation: captured from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "RGBD data", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "models", "label": "can be", "title": "Relation: can be\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "compositional", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "models", "label": "optimized_with", "title": "Relation: optimized_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "backpropagation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "models", "label": "learn", "title": "Relation: learn\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "temporal dynamics", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "models", "label": "learn", "title": "Relation: learn\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "convolutional perceptual representations", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "models", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "distinct advantages", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "k", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "labeled 2D samples", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "k", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "3D CAD models", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "k", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "lack of 3D training data", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Semantic labeling", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "3d point clouds", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Semantic labeling", "label": "is_described_in", "title": "Relation: is_described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Advances in Neural Information Processing Systems", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Learning rich features", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "RGBD images", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Learning rich features", "label": "is_presented_in", "title": "Relation: is_presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "ILSVRC2012", "label": "held_in", "title": "Relation: held_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "2012", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Efficient 3d scene labeling", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "field-s of trees", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Efficient 3d scene labeling", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "International Conference on Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "geNet", "label": "is_competition", "title": "Relation: is_competition\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ILSVRC2012", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "O. Kahler", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Efficient 3d scene labeling", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "N. Srivastava", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Multimodal learning", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "K. Lai", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Detection-based object labeling", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Detection-based object labeling", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE International Conference on Robotics and Automation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "L. Bo", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Unsupervised feature learning", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Unsupervised feature learning", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "rgb-d based object recognition", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "X. Xiong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3-d scene analysis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "3-d scene analysis", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "sequenced predictions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "A. Wang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Multi-modal unsupervised feature learning", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-modal unsupervised feature learning", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "rgb-d scene labeling", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-modal unsupervised feature learning", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Sharma", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Deep Hierarchical Parsing", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Sharma", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sharma_Deep_Hierarial_Parsing_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Sharma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Science Department", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Sharma", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "bhokaal@cs.umd.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Sharma", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of Maryland", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Hierarchical Parsing", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Oncel Tuzel", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Deep Hierarchical Parsing", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Oncel Tuzel", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Sharma_Deep_Hierarial_Parsing_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Oncel Tuzel", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "MERL", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "David W. Jacobs", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Deep Hierarchical Parsing", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "David W. Jacobs", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Sharma_Deep_Hierarial_Parsing_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "David W. Jacobs", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of Maryland", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "David W. Jacobs", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Computer Science Department", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Sliding shapes", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sharma_Deep_Hierarial_Parsing_2015_CVPR_paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "improvements to RCPN", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "RCPN", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "deep feed-forward neural network", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "RCPN", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "semantic segmentation", "width": 2.88}, {"arrows": "to", "color": "#FF5722", "from": "bypass error paths", "label": "hinders", "title": "Relation: hinders\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "contextual propagation", "width": 2.84}, {"arrows": "to", "color": "#9E9E9E", "from": "bypass error paths", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: caushal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "modifications", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "classification loss", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "modifications", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "tree-style MRF", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "modifications", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "state-of-the-art results", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "classification loss", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "random parse trees", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "tree-style MRF", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "hierarchical dependencies", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Tree-Style MRF", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "hierarchical dependencies", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Modifications", "label": "enhance", "title": "Relation: enhance\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Modifications", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "state-of-the-art results", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Semantic Segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Deep Neural Networks", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Semantic Segmentation", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Image Alignment", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Semantic Segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Regions", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Semantic Segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Parts", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Recursive Context Propagation Network (RCPN)", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Contextual Propagation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Socher et al. (2011)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Recursive Neural Networks", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Farabet et al. (2013)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "scene labeling", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Fergus and Eigen (2012)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "image parsing", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Markov Random Fields (MRF)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Semantic Segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Najman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning hierarchical features for scene labeling", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Learning hierarchical features for scene labeling", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE TPAM", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "R. Fergus", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Nonparametric image parsing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Nonparametric image parsing", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "A. Torralba", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Context-based vision system", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Context-based vision system", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "P. H. O. Pinheiro", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Recurrent convolutional neural networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Recurrent convolutional neural networks", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ICML", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "A. Sharma", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Recursive context propagation network", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Recursive context propagation network", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "J. Tighe", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Finding things", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J. Tighe", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Superparsing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Finding things", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "R. Mottaghi", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Analyzing semantic segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Analyzing semantic segmentation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Superparsing", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Int. J. Comput. Vision", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "IEEE CVPR", "label": "is_conference_of", "title": "Relation: is_conference_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE CVPR", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Bell et al.", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "ICML", "label": "is_publication_venue", "title": "Relation: is_publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "research paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junlin Hu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Deep Transfer Metric Learning", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Junlin Hu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Computer Science Department", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Junlin Hu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of Electrical and Electronic Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junlin Hu", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "jhu007@e.ntu.edu.sg", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Transfer Metric Learning", "label": "is_paper_in", "title": "Relation: is_paper_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jiwen Lu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Deep Transfer Metric Learning", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Jiwen Lu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jiwen Lu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Nanyang Technological University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiwen Lu", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "jiwen.lu@adsc.com.sg", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "metric learning methods", "label": "typically_assume", "title": "Relation: typically_assume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "similar scenarios", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "real-world visual recognition applications", "label": "often_unmet", "title": "Relation: often_unmet\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "similar scenarios", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "DTML method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "challenge", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "DTML method", "label": "transfers", "title": "Relation: transfers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "discriminative knowledge", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "DTML method", "label": "maximizes", "title": "Relation: maximizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "inter-class variations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "DTML method", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "intra-class variations", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "DTML method", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "distribution divergence", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "DSTML method", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "outputs of hidden and top layers", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "DSTML method", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "deeply supervised transfer metric learning", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "DSTML method", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "transfer metric learning method", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "DSTML method", "label": "developed_for", "title": "Relation: developed_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "cross-dataset tasks", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "vergence", "label": "exists_between", "title": "Relation: exists_between\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "source and target domains", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "hidden layers", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "neural network", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "top layers", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "neural network", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Deep Transfer Metric Learning (DTML)", "label": "is_subfield_of", "title": "Relation: is_subfield_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Metric Learning", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Deep Transfer Metric Learning (DTML)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Cross-Domain Visual Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Transfer Metric Learning (DTML)", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Deep Neural Networks", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Cross-Domain Visual Recognition", "label": "benefits_from", "title": "Relation: benefits_from\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Deep Neural Networks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Face Description", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Local Binary Patterns", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Learning Deep Architectures", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "AI", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Predictive Structures", "label": "learned_from", "title": "Relation: learned_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "Multiple Tasks", "width": 2.7199999999999998}, {"arrows": "to", "color": "#4CAF50", "from": "Journal of Machine Learning Research", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Foundations and Trends in Machine Learning", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ACM Multimedia", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ACM", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ACM Multimedia", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Graph-based search methods", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Bayesian face revisited", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian face revisited", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "joint formulation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Duan, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Domain transfer SVM", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Conference on Computer Vision and Pattern Recognition", "label": "is_conference_of", "title": "Relation: is_conference_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Gray \u0026 Tao (2008)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gretton et al. (2006)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Neural Information Processing Systems", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Neural Information Processing Systems", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Imaginet classification with deep convolutional neural networks", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Hinton et al. (2006)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Neural Computation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Huang et al. (2012)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Conference on Computer Vision and Pattern Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Nanyang Technological University", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Singapore", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yap-Peng Tan", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "eyptan@ntu.edu.sg", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Takuya Narihira", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Learning Lightness from Human Judgement", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Learning Lightness from Human Judgement", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Michael Maire", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Learning Lightness from Human Judgement", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Michael Maire", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "TTI Chicago", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Stella X. Yu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Learning Lightness from Human Judgement", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Stella X. Yu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "UC Berkeley", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Stella X. Yu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "ICSI", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Narihira_Learning_Lightness_From_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Learning Lightness from Human Judgement", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Narihira_Learning_Lightness_From_2015_CVPR_paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "inferring lightness", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "inferring lightness", "label": "is_problem_of", "title": "Relation: is_problem_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "perceived re\ufb02ectance", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "classic methods", "label": "view problem_as", "title": "Relation: view problem_as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "intrinsic image decomposition", "label": "separates", "title": "Relation: separates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "re\ufb02ectance and shading components", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "intrinsic image decomposition", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "lightness perception", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "patch representations", "label": "are_built_using", "title": "Relation: are_built_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "deep networks", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "deep networks", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "global saliency cues", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "local lightness model", "label": "achieves_performance", "title": "Relation: achieves_performance\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "on-par with global lightness model", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "local lightness model", "label": "achieves_performance", "title": "Relation: achieves_performance\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "on-par performance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "local lightness model", "label": "competes_with", "title": "Relation: competes_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art global lightness model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "local lightness model", "label": "is_dataset", "title": "Relation: is_dataset\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ld dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "global lightness model", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "shading/re\ufb02ectance priors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "global lightness model", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "dense conditional random field formulation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art global lightness model", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "shading/reflectance priors", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art global lightness model", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "dense conditional random field formulation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art global lightness model", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "multiple priors", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "dense conditional random field formulation", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "simultaneous reasoning", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "simultaneous reasoning", "label": "occurs_between", "title": "Relation: occurs_between\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "pairs of pixels", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "lightness perception", "label": "is_concept_in", "title": "Relation: is_concept_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "cognitive neurosciences", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "lightness perception", "label": "is_foundation_for", "title": "Relation: is_foundation_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lightness perception and lightness illusions", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "foundational work", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "foundational work", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "feature learning", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "H. G. Barrow", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Recovering intrinsic scene characteristics from images", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Recovering intrinsic scene characteristics from images", "label": "lays_groundwork_for", "title": "Relation: lays_groundwork_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "intrinsic image algorithms", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "intrinsic image algorithms", "label": "evaluated_using", "title": "Relation: evaluated_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "baseline evaluations", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "relative reflectance", "label": "is_concept_in", "title": "Relation: is_concept_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "human judgment data", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "lightness perception", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision Systems", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "scene characteristics from images", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "scene characteristics from images", "label": "lays groundwork for", "title": "Relation: lays groundwork for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "intrinsic image algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Retinex theory", "label": "introduced by", "title": "Relation: introduced by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "E. H. Land and J. J. McCann", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Retinex theory", "label": "explains", "title": "Relation: explains\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "brightness perception", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Retinex theory", "label": "relevant to", "title": "Relation: relevant to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "intrinsic image recovery", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "determining lightness from an image", "label": "is part of", "title": "Relation: is part of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "M. Tappen, W. Freeman, and E. Adelson", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "intrinsic image recovery", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "intrinsic image recovery", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "single image", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "intrinsic image recovery", "label": "addressed_in", "title": "Relation: addressed_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2005", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "R. Grosse", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Ground truth dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ground truth dataset", "label": "evaluated_for", "title": "Relation: evaluated_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "intrinsic image algorithms", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "International Conference on Computer Vision, 2009", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Ground truth dataset", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Tang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deep Lambertian networks", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Deep Lambertian networks", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Lambertian reflectance models", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Deep Lambertian networks", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Lambertian reflectance models", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Lambertian networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Lambertian reflectance models", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "deep learning approaches", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "International Conference on Machine Learning, 2012", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Deep Lambertian networks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Lambertian networks", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep learning approaches", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "deep learning approaches", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "intrinsic image decomposition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Takaya Narihira", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "UC Berkeley", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Takaya Narihira", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "ICSI", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Takaya Narihira", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Sony Corp.", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "ICSI", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "UC Berkeley", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP Model", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "face recognition", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "face recognition", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Labelled faces in the wild", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Pose variation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "is_inspired_by", "title": "Relation: is_inspired_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Probabilistic Elastic Part (PEP) model", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "is_inspired_by", "title": "Relation: is_inspired_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Deep Hierarchical Architectures", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Fine-grained Structures", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "is_guided_by", "title": "Relation: is_guided_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "Supervised Information", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "is_verified_on", "title": "Relation: is_verified_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LFW", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "is_verified_on", "title": "Relation: is_verified_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "YouTube Faces", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hierarchical-PEP model", "label": "is_verified_on", "title": "Relation: is_verified_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PaSC", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Face Image", "label": "is_decomposed_into", "title": "Relation: is_decomposed_into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Face Parts", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Face Parts", "label": "has_level", "title": "Relation: has_level\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Detail Level", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Face Part Representations", "label": "is_stacked_at", "title": "Relation: is_stacked_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Layer", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Layer", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Dimensionality", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Face Representation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Invariant", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "LFW", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "LFW", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "experiments", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "face parts", "label": "is_analyzed_by", "title": "Relation: is_analyzed_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "supervised information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "face recognition challenge", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "PaSC", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "PEP (Probabilistic Elastic Part) Model", "label": "is_guided_by", "title": "Relation: is_guided_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "supervised information", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Ahonen, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Face recognition with local binary patterns", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Face recognition with local binary patterns", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Grauman, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The pyramid match kernel", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "The pyramid match kernel", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE International Conference on Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hu, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Discriminative deep metric learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hu, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Large margin multi-metric learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hu, J.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Stevens Institute of Technology", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Discriminative deep metric learning", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "face verification", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Eigenfaces", "label": "compared_with", "title": "Relation: compared_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Fisherfaces", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Fisherfaces", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "linear projection", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Unsupervised joint alignment", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "complex images", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Labeled faces in the wild", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "reporting procedures", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Large margin multi-metric learning", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "face verification", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Large margin multi-metric learning", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "kinship verification", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Asian Conference on Computer Vision (ACCV)", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "conference", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "publication", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lei, Z.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "discriminant face descriptor", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Simonyan, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deep fisher networks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simonyan, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Very deep convolutional networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Yu Kong", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Bilinear Heterogeneous Information Machine", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yu Kong", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "low-rank bilinear classification", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Bilinear Heterogeneous Information Machine", "label": "is_paper_title", "title": "Relation: is_paper_title\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Kong_Bilinear_Heterogeneous_Information_2015_CVPR_paper.pdf", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Bilinear Heterogeneous Information Machine", "label": "addresses_problem", "title": "Relation: addresses_problem\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "RGB-D Action Recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Yun Fu", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Bilinear Heterogeneous Information Machine", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yun Fu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Northeastern University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yun Fu", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "yunfu@ece.neu.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kong_Bilinear_Heterogeneous_Information_2015_CVPR_paper.pdf", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "space", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "learned", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "knowledge", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "shared", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "RGB-D action datasets", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "public datasets", "width": 2.7}, {"arrows": "to", "color": "#9E9E9E", "from": "low-rank classifier", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "generalization power", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "low-rank classifier", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "eter", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "promising results", "label": "when", "title": "Relation: when\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "RGB data are missing", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "promising results", "label": "when", "title": "Relation: when\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "depth data are missing", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Argyriou et al. (2008)", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "foundational work", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "feature learning", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Action Recognition", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Bo et al. (2011)", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "object recognition", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Bo et al. (2011)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "kernel descriptors", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Do and Artieres (2009)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "training method", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "HMMs", "label": "often_used_in", "title": "Relation: often_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Action Recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Artieres et al.", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "training method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hidden Markov Models", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "action recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Had\ufb01eld and Bowden", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "action recognition", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ji et al.", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "3D Convolutional Neural Networks", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "3D Convolutional Neural Networks", "label": "dominant_in", "title": "Relation: dominant_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "action recognition", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Kobayashi", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "low-rank bilinear classification", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "low-rank bilinear classification", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "modeling complex interactions", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "spatio-temporal depth cuboid similarity feature", "label": "is_feature_representation_for", "title": "Relation: is_feature_representation_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "activity recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "activity recognition", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "depth data", "width": 2.6399999999999997}, {"arrows": "to", "color": "#2196F3", "from": "information bottleneck method", "label": "is_applicable_to", "title": "Relation: is_applicable_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "feature selection", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "information bottleneck method", "label": "is_applicable_to", "title": "Relation: is_applicable_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "representation learning", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "depth camera", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "activity recognition", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "depth sequences", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "action recognition", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "HON4D", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "oriented 4D normals", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "information bottlenecks", "label": "is_concept", "title": "Relation: is_concept\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "feature selection", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "information bottlenecks", "label": "is_concept", "title": "Relation: is_concept\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "representation learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sebastian Haner", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Absolute Pose for Cameras", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Sebastian Haner", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Centre for Mathematical Sciences", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sebastian Haner", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Lund University", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Sebastian Haner", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Centre for Mathematical Sciences, Lund University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sebastian Haner", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "haner@maths.lth.se", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Absolute Pose for Cameras", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Absolute Pose for Cameras", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "camera pose estimation", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Absolute Pose for Cameras", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "refractive interfaces", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Kalle \u02daAstr\u00a8om", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Absolute Pose for Cameras", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Kalle \u02daAstr\u00a8om", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Workshop on Omnidirectional Vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kalle \u02daAstr\u00a8om", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Centre for Mathematical Sciences, Lund University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kalle \u02daAstr\u00a8om", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "kalle@maths.lth.se", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yukong", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "yukong@ece.neu.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "perspective camera", "label": "observes", "title": "Relation: observes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "scene", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "scene", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "rigidity", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "refractive plane", "label": "is_boundary_between", "title": "Relation: is_boundary_between\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "transparent media", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "solvers", "label": "developed_for", "title": "Relation: developed_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "2D cases", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "solvers", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "minimal", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "solvers", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "synthetic data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "solvers", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "real data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Snell\u2019s law", "label": "gives_rise_to", "title": "Relation: gives_rise_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "false solutions", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "false solutions", "label": "increases", "title": "Relation: increases\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "complexity of problem", "width": 2.8600000000000003}, {"arrows": "to", "color": "#FF5722", "from": "pose estimates", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "explicitly modelling refraction", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Absolute Pose Estimation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Refractive Interfaces Modelling", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Refractive Interfaces", "label": "governed_by", "title": "Relation: governed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Snell\u0027s Law", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Structure-and-Motion", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Camera Calibration", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Structure-and-Motion", "label": "benefits_from", "title": "Relation: benefits_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Polynomial Equation Solving", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Agrawal et al. (2012)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Multi-layer Flat Refractive Geometry Theory", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Byr\u00a8od et al. (2009)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Polynomial Equation Solving", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Polynomial Equation Solving", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.76}, {"arrows": "to", "color": "#FF5722", "from": "Multi-layer Flat Refractive Geometry", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Pose Estimation Accuracy", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "polynomial equation solving", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Ideals, Varieties, and Algorithms", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "computational algebraic geometry", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Ideals, Varieties, and Algorithms", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "commutative algebra", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "\u02daAstr\u00a8om, Kuang, \u0026 Ask", "label": "researched", "title": "Relation: researched\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "polynomial equation solving optimization", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "polynomial equation solving optimization", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "p-fold symmetries", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Chari \u0026 Sturm", "label": "researched", "title": "Relation: researched\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "multi-view geometry", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "multi-view geometry", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "refractive plane", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Chari, V.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-view geometry of the refractive plane", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-view geometry of the refractive plane", "label": "cited_by", "title": "Relation: cited_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "British Machine Vision Conference", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sturm, P. F.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multi-view geometry of the refractive plane", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fitzgibbon, A. W.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Simultaneous linear estimation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fitzgibbon, A. W.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Conference on Computer Vision and Pattern Recognition", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous linear estimation", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "geometric estimation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Simultaneous linear estimation", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "lens distortion", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Kuang, Y.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Numerically stable optimization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Numerically stable optimization", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "polynomial solvers", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "chmid", "label": "edited", "title": "Relation: edited\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "European Conference on ComputerVision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "European Conference on ComputerVision", "label": "is_volume_of", "title": "Relation: is_volume_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Lecture Notes in Computer Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "European Conference on ComputerVision", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "polynomial solver optimization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Lecture Notes in Computer Science", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computer Vision - ECCV 2008", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lecture Notes in Computer Science", "label": "has_volume", "title": "Relation: has_volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "5304", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Nist\u00e9r", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "generalized 3-point pose problem", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Stew\u00e9nius", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "generalized relative pose problems", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Stew\u00e9nius", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "pose estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Kukelova", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "polynomial eigenvalue solutions", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kukelova", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "minimal problems", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "R6P", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Albl_R6P_-_Rolling_2015_CVPR_paper", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Albl_R6P_-_Rolling_2015_CVPR_paper", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Albl_R6P_-_Rolling_2015_CVPR_paper", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "polynomial solutions", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Cenek Albl", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Albl_R6P_-_Rolling_2015_CVPR_paper", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Cenek Albl", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Czech Technical University in Prague", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zuana Kukelova", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Albi_R6P_-_Rolling_2015_CVPR_paper", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Zuana Kukelova", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Microsoft Research Ltd", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Tomas Pajdla", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Albl_R6P_-_Rolling_2015_CVPR_paper", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Tomas Pajdla", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Czech Technical University in Prague", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "absolute pose problem", "label": "is_problem_in", "title": "Relation: is_problem_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "rolling shutter", "label": "present_in", "title": "Relation: present_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "digital cameras", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "camera model", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "model", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "camera model", "label": "is_verified_for", "title": "Relation: is_verified_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "polynomial solver", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "camera orientation", "label": "is_approximated_by", "title": "Relation: is_approximated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "linear approximation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "camera orientation", "label": "has_error", "title": "Relation: has_error\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "6 degrees", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "linear approximation", "label": "is_valid_around", "title": "Relation: is_valid_around\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "identity rotation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "P3P algorithm", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "camera orientation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "P3P algorithm", "label": "can_be_used_to", "title": "Relation: can_be_used_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "estimate camera orientation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "P3P algorithm", "label": "brings", "title": "Relation: brings\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "camera rotation matrix", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "camera rotation velocity", "label": "reaches", "title": "Relation: reaches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "30deg/frame", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Ithm", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "camera orientation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "camera rotation matrix", "label": "approaches", "title": "Relation: approaches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "identity", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "camera position", "label": "has_error", "title": "Relation: has_error\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "2%", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "orientation error", "label": "is_less_than", "title": "Relation: is_less_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "0.5 degrees", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "orientation error", "label": "is_less_than", "title": "Relation: is_less_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "half a degree", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Rolling Shutter Cameras", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Absolute Pose Problem", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Absolute Pose Problem", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Polynomial Solvers", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Linearized Camera Models", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Absolute Pose Problem", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "relative position error", "label": "is_less_than", "title": "Relation: is_less_than\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2%", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "RANSAC", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "robust model fitting", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "RANSAC", "label": "is_algorithm_for", "title": "Relation: is_algorithm_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "model fitting", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "robust model fitting", "label": "is_relevant_to", "title": "Relation: is_relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "computer vision problems", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "structure and motion estimation", "label": "is_focus_of", "title": "Relation: is_focus_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "structure and motion estimation", "label": "is_problem_in", "title": "Relation: is_problem_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Haralick", "label": "authored_paper", "title": "Relation: authored_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "pose estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Hedborg", "label": "authored_paper", "title": "Relation: authored_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "structure and motion estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "RANAC", "label": "is_core_technique", "title": "Relation: is_core_technique\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "automated cartography", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "RANAC", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "robust model fitting", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "RANAC", "label": "is_relevant_to", "title": "Relation: is_relevant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "computer vision problems", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "rolling shutter video", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "structure and motion estimation", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "rolling shutter video", "label": "benefits_from", "title": "Relation: benefits_from\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "inertial measurements", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "rolling shutter video", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "motion estimation", "width": 2.7}, {"arrows": "to", "color": "#FF5722", "from": "rolling shutter video", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "accuracy", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "rolling shutter data", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "bundle adjustment", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "bundle adjustment", "label": "applies_to", "title": "Relation: applies_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "rolling shutter data", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "C. Jia and B. L. Evans", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "rolling shutter video", "width": 2.94}, {"arrows": "to", "color": "#FF5722", "from": "inertial measurements", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "accuracy", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "motion estimation", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "video analysis", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "ter video recti\ufb01cation", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "rolling shutter video", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ter video recti\ufb01cation", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "inertial measurements", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "visual SLAM", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "camera pose estimation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "parallel tracking and mapping", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ISMAR \u201909", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "EEE International Symposium on Mixed and augmented Reality", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "visual SLAM", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Z. Kukelova", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Singly-bordered block-diagonal form", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Z. Kukelova", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Automatic generator of minimal problem solvers", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Singly-bordered block-diagonal form", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "optimization techniques", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "efficient computation", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "salient regions", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Automatic generator of minimal problem solvers", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "efficient solvers", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "efficient solvers", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "efficient computation", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "ECCV 2008", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Automatic generator of minimal problem solvers", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Proceedings", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Lecture Notes in Computer Science", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cox", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Using Algebraic Geometry", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Using Algebraic Geometry", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Springer", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Springer", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Line Drawing Interpretation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sridhar", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Fast and Robust Hand Tracking", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Sridhar", "label": "collaborated_with", "title": "Relation: collaborated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Theobalt", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Fast and Robust Hand Tracking", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Detection-Guided Optimization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Baak et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "full body pose reconstruction", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "full body pose reconstruction", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "depth camera", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Ballan et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "motion capture of hands", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Bhattacharyya", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "measure of divergence", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Criminisi and Shotton", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Decision forests", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Srinath Srilhar", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A. Criminisi", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Decision forests for computer vision", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "A. Criminisi", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Learning to be a depth camera", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "A. Criminisi", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Efficient regression of general-activity human poses", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A. Criminisi", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Geodesic image and video editing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "J. Shotton", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Decision forests for computer vision", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "J. Shotton", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Learning to be a depth camera", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "J. Shotton", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Efficient regression of general-activity human poses", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "S. R. Fanello", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Learning to be a depth camera", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "H. Hamer", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Tracking a hand manipulating an object", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "C. Keskin", "label": "co_authored", "title": "Relation: co_authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Real time hand pose estimation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "C. Keskin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ICCV Workshops", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "F. Kirac", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ICCV Workshops", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Kara", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "L. Akarun", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ICCV Workshops", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Srinath Sridhar", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Max Planck Institute for Informatics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Antti Oulasvirta", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Aalto University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fumin Shen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Supervised Discrete Hashing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fumin Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of Electronic Science and Technology of China", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Supervised Discrete Hashing", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Heng Tao Shen", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Supervised Discrete Hashing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Heng Tao Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "The University of Queensland", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Supervised Discrete Hanning (SDH)", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "hashing framework", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Supervised Discrete Hanning (SDH)", "label": "designed_for", "title": "Relation: designed_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "linear classification", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "handling discrete constraints", "label": "leads_to", "title": "Relation: leads_to\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "NP-hard optimization problems", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "objective", "label": "reformulated_by", "title": "Relation: reformulated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "introducing an auxiliary variable and regularization algorithm", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "cyclic coordinate descent", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "regularization sub-problem", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "SDH", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "high-quality discrete solutions", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "SDH", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "handling of massive datasets", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "SDH", "label": "superior_to", "title": "Relation: superior_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state-of-the-art hashing methods", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "SDH", "label": "extends", "title": "Relation: extends\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "DH", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "SDH", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "discriminative term", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hashing", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "handling of massive datasets", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hashing", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "image datasets", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "p-stable distributions", "label": "basis_for", "title": "Relation: basis_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "hashing technique", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "bilinear projections", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "learning binary codes", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "bilinear projections", "label": "relate_to", "title": "Relation: relate_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "binary code learning", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "learning binary codes", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "bilinear projections", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Belkin, M., \u0026 Niyogi, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "foundational paper", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Datar, N., et al.", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "hashing technique", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gong, Y., et al.", "label": "explored", "title": "Relation: explored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "bilinear projections", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Rowley et al. (2013) paper", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "learning binary codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Weiss et al. (2008) paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "spectral hashing", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "spectral hashing", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "contribution to field", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Gong et al. (2013) paper", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "iterative quantization approach", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "iterative quantization approach", "label": "aims at", "title": "Relation: aims at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "learning binary codes", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "iterative quantization approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "procustean approach", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Kulis \u0026 Darrell (2009) paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "method for learning to hash", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "method for learning to hash", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "binary reconstructive embeddings", "width": 2.8200000000000003}, {"arrows": "to", "color": "#2196F3", "from": "binary reconstructive embeddings", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "method", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kulis \u0026 Darrell (2009)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "binary reconstructive embeddings hashing method", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "binary reconstructive embeddings hashing method", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "hashing technique", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Liu, Wang, Kumar, \u0026 Chang (2011)", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "hashing techniques", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "hashing techniques", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "graph structures", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "hashing techniques", "label": "are_used_for", "title": "Relation: are_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "efficient similarity search", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Wang, Kumar, \u0026 Chang (2012)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "hashing", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "hashing", "label": "operates_in", "title": "Relation: operates_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "semi-supervised setting", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Shen \u0026 Hao (2011)", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "learning and classification", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Norouzi \u0026 Blei (2011)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "minimal loss hashing", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "minimal loss hashing", "label": "creates", "title": "Relation: creates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "compact binary codes", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Blei", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Minimal loss hashing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A Maximum Entropy Feature Descriptor", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Age Invariant Face Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Zhifeng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Maximum Entropy Feature Descriptor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Zhifeng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Nonparametric Discriminent Analysis for Face Recognition", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Tao, Dacheng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Maximum Entropy Feature Descriptor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Liu, Jianzhang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Maximum Entropy Feature Descriptor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Xuelong", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Maximum Entropy Feature Descriptor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "maximum entropy feature descriptor", "label": "encodes", "title": "Relation: encodes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "microstructure", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "maximum entropy feature descriptor", "label": "transforms into", "title": "Relation: transforms into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "discrete codes", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "maximum entropy feature descriptor", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "feature descriptor", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "sampling", "label": "extracts", "title": "Relation: extracts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "discriminatory information", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "identity factor analysis", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "probability of same identity", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "experimentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "MORPH dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "experimentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "FGNET dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "experimentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "LFW dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "experimentation", "label": "performed_on", "title": "Relation: performed_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "MORPH", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "MORPH", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "face aging dataset", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "FGNET", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "face aging dataset", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Age Invariant Face Recognition (AIFR)", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "MORPH", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Age Invariant Face Recognition (AIFR)", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LFW dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Age Incompliant Face Recognition (AIFR)", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "FGNET", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Maximum Entropy Feature Descriptor (MEFD)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Age Invariant Face Recognition (AIFR)", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Identity Factor Analysis (IFA)", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Age Invariant Face Recognition (AIFR)", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Nonparametric Discriminent Analysis for Face Recognition", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wang, Xiaogang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "A unified framework for subspace face recognition", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "A unified framework for subspace face recognition", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Trans. Pattern Anal. Mach. Intell.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Unsang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "A discriminative model for age invariant face recognition", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Unsang", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Information Forensics and Security", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Unsang", "label": "collaborated_with", "title": "Relation: collaborated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Zhifeng Li", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "A discriminative model for age invariant face recognition", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Information Forensics and Security", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Trans. Pattern Anal. Mach. Intell.", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Semi-supervised hashing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Park, Unsav", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Trans. Pattern Anal. Mach. Intell.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Park, Unsav", "label": "collaborated_with", "title": "Relation: collaborated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Yiying Tong", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Belhumeur, Peter N.", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Trans. Pattern Anal. Mach. Intell.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gong, D.", "label": "presented", "title": "Relation: presented\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ICCV 2013", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Huang, G.B.", "label": "created", "title": "Relation: created\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Labelled faces in the wild", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Labelled faces in the wild", "label": "is_database_for", "title": "Relation: is_database_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "face recognition", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Labelled faces in the wild", "label": "studies", "title": "Relation: studies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "face recognition in unconstrained environments", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Zhifeng Li", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Zhifeng Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Shenzhen Key Lab of Computer Vision and Pattern Recogniton", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Technical Report 07-49", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "University of Massachusetts, Amherst", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Nonparametric Discriminant Analysis for Face Recognition", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "face recognition", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Random sampling LDA", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "face recognition", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "DiHong Gong", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 2.00\u003cbr\u003eSource: unknown", "to": "Shenzhen Key Lab of Computer Vision and Pattern Recognition", "width": 5.0}, {"arrows": "to", "color": "#4CAF50", "from": "Shenzhen Key Lab of Computer Vision and Pattern Recognition", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Shenzhen Institutes of Advanced Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dihong Gong", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Shenzhen Key Lab of Computer Vision and Pattern Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dacheng Tao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Technology, Sydney", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jianzhuang Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Dept. of Information Engineering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jianzhuang Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Huawei Technologies Co. Ltd.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xuelong Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Xi\u0027an Institute of Optics and Precision Mechanics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xi\u0027an Institute of Optics and Precision Mechanics", "label": "part_of", "title": "Relation: part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sayed Hossein Khatoonabadi", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "research paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sayed Hossein Khatoonabadi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Simon Fraser University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sayed Hosheen Khatoonabadi", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "How Many Bits Does It Take for a Stimulus to Be Salient?", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "How Many Bits Does It Take for a Stimulus to Be Salient?", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Nuno Vasconcelos", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "How Many Bits Does It Take for a Stimulus to Be Salient?", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Nuno Vasconcelos", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of California, San Diego", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yuifeng Shan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "How Many Bits Does It Take for a Stimulus to Be Salient?", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Khatoonabadi_How_Many_Bits_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "How Many Bits Does It Take for a Stimulus to Be Salient?", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "xuelong_li@opt.ac.cn", "label": "is_email_contact", "title": "Relation: is_email_contact\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "hanics", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Stimulus", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "salience", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "computational models", "label": "focus_of_research", "title": "Relation: focus_of_research\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salience", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "early approaches", "label": "model_salience_as", "title": "Relation: model_salience_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "center-surround filters", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "recent works", "label": "seek", "title": "Relation: seek\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "general computational principles", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "measure of salience", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "bits required by video compressor", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "measure of salience", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "predictive power", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "measure of salience", "label": "is_embedded_in", "title": "Relation: is_embedded_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Markov random field model", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "probabilistic inference", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "salience", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "brain", "label": "viewed_as", "title": "Relation: viewed_as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "universal compression device", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "universal compression device", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "brain", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Fixation Prediction", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state-of-the-art accuracy", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "view of the brain", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "universal compression device", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Agarwal et al. (2003)", "label": "develops", "title": "Relation: develops\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "algorithm", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "region-of-interest", "label": "is_in", "title": "Relation: is_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "compressed MPEG domain", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Hou and Zhang (2007)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "spectral residual approach", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "spectral residual approach", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "salience detection method", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Helbing and Molnar (1995)", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "pedestrian dynamics", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "EE CVPR\u201907", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Agarwal, G.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "algorithm", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Anstis, S. M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "perception of apparent movement", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Attneave, F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Informational aspects of visual perception", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Barlow, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Cerebral cortex as a model builder", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Barlow, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Redundancy reduction revisited", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Besag, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Spatial interaction", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Royal Statistical Society", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Series B", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Series B", "label": "volume", "title": "Relation: volume\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "36", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Series B", "label": "issue", "title": "Relation: issue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "192\u2013236", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ivan V. Bajic", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Simon Fraser University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Limin Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Limin Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Department of Information Engineering", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Limin Wang", "label": "contact_email", "title": "Relation: contact_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "07wanglimin@gmail.com", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yu Qiao", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Yu Qiao", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "researcher", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Yu Qiao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Shenzhen Institutes of Advanced Technology", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Yu Qiao", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "CAS", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaoou Tang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Action Recognized with Trajectory-Pooled Deep-Convolutional Descriptors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaoou Tang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Department of Information Engineering", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "TDD", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "video representation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "TDD", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "hand-crafted features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "TDD", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "deep architectures", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "TDD", "label": "employs", "title": "Relation: employs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "trajectory-constrained pooling", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "trajectory-constrained pooling", "label": "aggregates", "title": "Relation: aggregates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "feature maps", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "feature maps", "label": "are_generated_by", "title": "Relation: are_generated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "deep architectures", "width": 2.7}, {"arrows": "to", "color": "#FF5722", "from": "normalization methods", "label": "enhance", "title": "Relation: enhance\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "robustness", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "TDDs", "label": "outperform", "title": "Relation: outperform\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "hand-crafted features", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "TDDs", "label": "outperform", "title": "Relation: outperform\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "deep-learned features", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "HMD-B51", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "UCF101", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Human Action Recognition", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "state-of-the-art performance", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Deep Convolutional Descriptors", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Human Action Recognition", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Trajectory-Constrained Pooling", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Human Action Recognition", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-view super vector", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "action recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Convolutional Nets", "label": "delves into", "title": "Relation: delves into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "details", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Aggarwal, J. K., \u0026 Ryoo, M. S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Human activity analysis review", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Bay, H., Tuytelaars, T., \u0026 Van Gool, L. J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "SURF description", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Karpathy et al.", "label": "used", "title": "Relation: used\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "convolutional neural networks", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "HMDB", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "video database", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "HMDB", "label": "is_database_for", "title": "Relation: is_database_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "human motion recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "T", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "HMDB", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "T", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jing Shao", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Deeply Learned Attributes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jing Shao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Electronic Engineering", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Deeply Learned Attributes", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Kai Kang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Deeply Learned Attributes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Kai Kang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Department of Electronic Engineering", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chen Change Loy", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Deeply Learned Attributes", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Crowded scene understanding", "label": "is_problem_in", "title": "Relation: is_problem_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deep model", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "appearance features", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Deep model", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "motion features", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Crowd motion channels", "label": "is_input_of", "title": "Relation: is_input_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "deep model", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Crowd motion channels", "label": "inspired_by", "title": "Relation: inspired_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "generic properties of crowd systems", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "WWW Crowd dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "10,000 videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "WWW Crowd dataset", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "8,257 crowded scenes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "WWW Crowd dataset", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "cross-scene attribute recognition", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Attribute set", "label": "has_quantity", "title": "Relation: has_quantity\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "94 attributes", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Deep models", "label": "displays", "title": "Relation: displays\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "significant performance improvements", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "significant performance improvements", "label": "occurs_in", "title": "Relation: occurs_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "cross-scene attribute recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "deep models", "label": "displays", "title": "Relation: displays\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "significant performance improvements", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "deep models", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "feature-based baselines", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "deep models", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "deep models", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "deeply learned features", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "deeply learned features", "label": "behaves with", "title": "Relation: behaves with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "superior performance", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "deeply learned features", "label": "utilized_in", "title": "Relation: utilized_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "multi-task learning", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "attribute recognition", "label": "occurs_in", "title": "Relation: occurs_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "cross-scene", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "attribute recognition", "label": "relies on", "title": "Relation: relies on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "crowd-related features", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "baselines", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "feature-based", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Deep learning models", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "cross-scene attribute recognition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Deep learning models", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "crowd motion channels", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Ali and Shah (2007)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "crowd flow segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Ali and Shah (2008)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "tracking in high density crowd scenes", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Andrade, Blunsden, and Fisher (2006)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "event detection in crowd scenes", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Chan and Vasconcelos (2008)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "video segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "video segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "eye tracking prior", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "video segmentation", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "dynamic textures", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "oring", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR 2008", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vasconcelos, N.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Modeling, clustering, and segmenting video", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Dalal, N.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Histograms of oriented gradients", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Triggers, B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Histograms of oriented gradients", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Farhad, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Describing objects by their attributes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hospedales, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "A markov clustering topic model", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Kang, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Fully convolutional neural networks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Wang, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Fully convolutional neural networks", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "eye tracking data", "label": "identifies", "title": "Relation: identifies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "dominant visual tracks", "width": 2.8600000000000003}, {"arrows": "to", "color": "#FF5722", "from": "eye tracking data", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Object Extraction", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "dominant visual tracks", "label": "guides", "title": "Relation: guides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "object search algorithm", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "object boundaries", "label": "refined_by", "title": "Relation: refined_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "grabcut segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Intriligator \u0026 Cavanagh", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Cognitive psychology article", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cognitive psychology article", "label": "studies", "title": "Relation: studies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "visual attention", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Itti, Koch, \u0026 Niebur", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "salience-based visual attention model", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "salience-based visual attention model", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "rapid scene analysis", "width": 2.88}, {"arrows": "to", "color": "#FF5722", "from": "salience-based visual attention model", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "scene analysis", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Judd, Ehinger, Durand, \u0026 Torralba", "label": "researched", "title": "Relation: researched\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "human gaze prediction", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Object Extraction", "label": "benefits_from", "title": "Relation: benefits_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "eye tracking data", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Video Segmentation", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Visual Attention", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Video Segmentation", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Energy Function Optimization", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Judd et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning to predict where humans look", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Judd et al.", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision, 2009 IEEE 12th international conference on", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Karthikeyan et al. (2012)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Uni\ufb01ed probabilistic framework", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Borji \u0026 Itti", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "State-of-the-art in visual attention modeling", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Borji \u0026 Itti", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Pattern Analysis and Machine Intelligence, IEEE Transactions on", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Borji, Sihite, \u0026 Itti", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient object detection: A benchmark", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Borji, Sihite, \u0026 Itti", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision\u2013ECCV 2012", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision\u2013ECCV 2012", "label": "appears_in", "title": "Relation: appears_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "pages 414\u2013429", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision\u2013ECCV 2012", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Bayesian face revisited", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Karthikeyan et al. (2013)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning top-down scene context", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Karthikeyan et al. (2013)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ICIP, IEEE", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Karthikeyan, S.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of California Santa Barbara", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Karthikeyan, S.", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "{karthikeyan, thuyen, manj}@ece.ucsb.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "{karthikeyan, thuyen, manj}@ece.ucsb.edu", "label": "contact_email", "title": "Relation: contact_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "B.S. Manjunath", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Thuyen Ngo", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "{karthikeyan, thuyen, manj}@ece.ucsb.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Thuyen Ngo", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California Santa Barbara", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Miguel Eckstein", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California Santa Barbara", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Miguel Eckstein", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "eckstein@psych.ucsb.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "eckstein@psych.ucsb.edu", "label": "contact_email", "title": "Relation: contact_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Miguel Eckstein", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "B.S. Manjunath", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of California Santa Barbara", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Felzenszwalb, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A discriminatively trained, multiscale, deformable part model", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Eckstein, M. P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Visual search: A retrospective", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shervin Ardeshir", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Geo-Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Geo-Semantic Segmentation", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Ko\ufb01 Malcolm Collins-Sibley", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Geo-Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mubarak Shah", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Geo-Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mubarak Shah", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of  Central Florida", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Mubarak Shah", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "shah@crcv.ucf.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "geo-semantic segmentation method", "label": "leverages", "title": "Relation: leverages\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "GIS databases", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "geo-semantic segmentation method", "label": "refines", "title": "Relation: refines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "GIS projections alignment", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "GIS data", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "building locations", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "GIS data", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "street locations", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "projections", "label": "affected_by", "title": "Relation: affected_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "GPS errors", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "projections", "label": "affected_by", "title": "Relation: affected_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.72\u003cbr\u003eSource: unknown", "to": "camera parameter inaccuracies", "width": 2.44}, {"arrows": "to", "color": "#4CAF50", "from": "projections", "label": "refined_by", "title": "Relation: refined_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "random walks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "projections", "label": "refined_by", "title": "Relation: refined_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "global transformations", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "projections", "label": "results in", "title": "Relation: results in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "fast and efficient projections", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "alignment", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "random walks", "width": 2.56}, {"arrows": "to", "color": "#4CAF50", "from": "alignment", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "global transformations", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "random walks", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "optimization technique", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "global transformations", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "image processing technique", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "segmentations", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "alignment of projections", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "geo-references", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "addresses", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "geo-references", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "geo-locations", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Geo-semantic Segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Random Walks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Geo-semantic Segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Global Transformations", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Geo-semantic Segmentation", "label": "results_in", "title": "Relation: results_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Semantically Segmented Images", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Geo-semantic Segmentation", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "GIS Data Integration", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Geo-semantic Segmentation", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Iterative Data Fusion", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Semantically Segmented Images", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Geo-references", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Geo-references", "label": "include", "title": "Relation: include\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Addresses", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "P. Zhao et al. [17]", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Rectilinear parsing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "O. Teboul et al. [10]", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Segmentation of building facades", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "G. J. Brostow et al. [2]", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Segmentation and recognition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "EE", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "2010", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Brostow", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Segmentation and recognition using structure from motion point clouds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "He", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Multiscale conditional random fields for image labeling", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CVPR 2004", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Multiscale conditional random fields for image labeling", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Liu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Entropy rate superpixel segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Liu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Separation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "M\u00fcller", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Procedural modeling of buildings", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Musialski", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Interactive coherence-based fac\u00b8ade modeling", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Graphics Forum", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Interactive coherence-based fac\u00b8ade modeling", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "dings", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ACM", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ardeshir", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Central Florida", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ardeshir", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Gis-assisted object detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lerma", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Semantic segmentation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Hoiem", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Automatic photo popup", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Collins-Sibley", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Northeaster University", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shah", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Central Florida", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Huang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Bayesian Inference", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chao-Tsung Huang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Bayesian Inference for Neighborhood Filters", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chao-Tsung Huang", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "collins-sibley.k@husky.neu.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian Inference for Neighborhood Filters", "label": "application_in", "title": "Relation: application_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Denoising", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian Inference for Neighborhood Filters", "label": "field_of_study", "title": "Relation: field_of_study\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Image Processing", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Denoising", "label": "is_application_of", "title": "Relation: is_application_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Image Processing", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Huang_Bayesian_Infrenence_for_2015_CVPR_paper.pdf", "label": "publication_date", "title": "Relation: publication_date\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Huang_Bayesian_Infrenence_for_2015_CVPR_paper.pdf", "label": "conference", "title": "Relation: conference\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Range-weighted neighborhood filters", "label": "useful for", "title": "Relation: useful for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "edge-preserving denoising", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Range-weighted neighborhood filters", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "limited theoretical understanding", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "unified empirical Bayesian framework", "label": "directly infers", "title": "Relation: directly infers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "filters", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "unified empirical Bayesian framework", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "range variance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "range variance", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "accurate estimation", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "neighborhood noise model", "label": "reasons", "title": "Relation: reasons\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Yaroslavsky, bilateral, and modified non-local means filters", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "EM+ algorithm", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "range variance", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "EM+ algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "model fitting", "width": 2.76}, {"arrows": "to", "color": "#FF5722", "from": "noisy images", "label": "affects", "title": "Relation: affects\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image quality", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "color-image denoising", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "model\u0027s effectiveness", "width": 2.7800000000000002}, {"arrows": "to", "color": "#FF5722", "from": "recursive fitting", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "image quality", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Paris, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bilateral filtering", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Bilateral filtering", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image processing technique", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bilateral filtering", "label": "is_introduced_in", "title": "Relation: is_introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "International Conference on Computer Vision", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Buades, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "image denoising algorithms review", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "image denoising algorithms review", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SIAM Journal on Multi-scale Modeling and Simulation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chatterjee, P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Patch-based near-optimal image denoising", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Patch-based near-optimal image denoising", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Image Processing", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Peng, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bilateral kernel parameter optimization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Peng, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multispectral image denoising", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bilateral kernel parameter optimization", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "International Conference on Image Processing", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Multispectral image denoising", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "vector bilateral filter", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Multispectral image denoising", "label": "is_addressed_in", "title": "Relation: is_addressed_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Image Processing", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "vector bilateral filter", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "image filtering technique", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Vector bilateral filter", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Multispectral image denoising", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Image denoising", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "scale mixtures of gausians", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bilateral filter", "label": "is_improved_in", "title": "Relation: is_improved_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Image Processing", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Local Estimation", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Networks for Saliency Detection", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Local Estimation", "label": "is_technique_in", "title": "Relation: is_technique_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Deep Neural Networks", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Global Search", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Deep Networks for Saliency Detection", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Global Search", "label": "is_technique_in", "title": "Relation: is_technique_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Deep Neural Networks", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Chao-Tsun Huang", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "National Tsing Hua University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Lijun Wang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Saliency Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lijun Wang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Deep Networks for Salience Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Networks for Salience Detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Deep Networks for Salience Detection", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Wang_Deep_Networks_for_2015_CVPR_paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wang_Deep_Networks_for_2015_CVPR_paper", "label": "is_file", "title": "Relation: is_file\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Wang_Deep_Networks_for_2015_CVPR_paper.pdf", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Salience Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Deep Networks", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Salience Detection", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Sparse Coding", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Salience Detection", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Visual Attention", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "local estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "DNN-L", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "local estimation", "label": "refines", "title": "Relation: refines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "object concepts", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "global search", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "geometric information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "global search", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "global contrast", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "DNN-L", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "local patch features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "DNN-L", "label": "determines", "title": "Relation: determines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "salience value", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "DNN-G", "label": "trained_to_predict", "title": "Relation: trained_to_predict\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "salient score", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "salient object regions", "label": "generated_by", "title": "Relation: generated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "weighted sum", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "saliency map", "label": "generated_by", "title": "Relation: generated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "weighted sum", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "object region", "label": "predicted_by", "title": "Relation: predicted_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "saliency score", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "saliency score", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "global features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Algorithm", "label": "performs_favorably_against", "title": "Relation: performs_favorably_against\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaussian Mixture Model", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Salient Region Detection", "label": "is_concept_in", "title": "Relation: is_concept_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "field", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Salient Region Detection", "label": "precursor_to", "title": "Relation: precursor_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Video Object Segmentation", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Salient Region Detection", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "CVPR, 2012", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "R. Achanta et al.", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "foundational work", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "J. Carreira and C. Sminchisescu", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "method", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Constrained parametric min-cuts", "label": "is_work_by", "title": "Relation: is_work_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "J. Carreira and C. Sminchisescu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Constrained parametric min-cuts", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "automatic object segmentation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Constrained parametric min-cuts", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "min-cut approach", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Constrained parametric min-cuts", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object segmentation", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Object Candidate Regions", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.65\u003cbr\u003eSource: unknown", "to": "Deep Neural Networks", "width": 2.3}, {"arrows": "to", "color": "#4CAF50", "from": "tric min-cuts", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "visual salience", "label": "established_by", "title": "Relation: established_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Itti, Koch, and Niebur (1998)", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Itti, Koch, and Niebur (1998)", "label": "presented", "title": "Relation: presented\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "computational model", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Itti, Koch, and Niebur (1998)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "PAMI", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "saliency detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "absorbing Markov chain", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "absorbing Markov chain", "label": "is_approach_for", "title": "Relation: is_approach_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "saliency detection", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Markov Chain approach", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "saliency detection", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Hierarchical approaches", "label": "are_common_in", "title": "Relation: are_common_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Selective search", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "generating object proposals", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Selective search", "label": "used_as", "title": "Relation: used_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "preprocessing step", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "salient object detection pipelines", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Selective search", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "simultaneous detection and segmentation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "related task", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "simultaneous detection and segmentation", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "salient region detection", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian models", "label": "are_used_in", "title": "Relation: are_used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ICC paper", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "efficient computation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "ECCV paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "simultaneous detection and segmentation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "ICIP paper", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Bayesian model", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Kar", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California, Berkeley", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Kar", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "akar@eecs.berkeley.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Abhishek Kar", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Category-Speci\ufb01c Object Reconstruction from a Single Image", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Jo\u02dcao Carreira", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of California, Berkeley", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jo\u02dcao Carreira", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "carreira@eecs.berkeley.edu", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jo\u02dcao Carreira", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Category-Speci\ufb01c Object Reconstruction from a Single Image", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shubham Tulisiani", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Category-Speci\ufb01c Object Reconstruction from a Single Image", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Thorsten Beier", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Fusion Moves for Correlation Clustering", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Thorsten Beier", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Heidelberg", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Thorsten Beier", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "thorsten.beier@iwr.uni-heidelberg.de", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Thorsten Beier", "label": "associated_with", "title": "Relation: associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Beier_Fusion_Moves_for_2015_CVPR_supplemental", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Thorsten Beier", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Heidelberg (Iwr)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fusion Moves for Correlation Clustering", "label": "is_paper_of", "title": "Relation: is_paper_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Fusion Moves for Correlation Clustering", "label": "is_supplement_for", "title": "Relation: is_supplement_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Beier_Fusion_Moves_for_2015_CVPR_supplemental.pdf", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fred A. Hamprecht", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Fusion Moves for Correlation Clustering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fred A. Hamprecht", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Heidelberg", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fred A. Hamprecht", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "fred.hamprecht@iwr.uni-heidelberg.de", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fred A. Hamprecht", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Heidelberg (Iwr)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J\u00f6rg H. Kappes", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "University of Heidelberg", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "J\u00f6rg H. Kappes", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Math", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "J\u00f6rg H. Kappes", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "kappes@math.uni-heidelberg.de", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "J\u00f6rg H. Kappes", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Fusion Moves for Correlation Clustering", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Hossein Rahmani", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The University of Western Australia", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hossein Rahmani", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning a Non-linear Knowledge Transfer Model for Cross-View Action Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hossein Rahmani", "label": "is_author", "title": "Relation: is_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rahmani_Learning_a_Non-Linear_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hossein Rahman\u0131", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "hossein@csse.uwa.edu.au", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ajmal Mian", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The University of Western Canada", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ajmal Mian", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "ajmal.mian@uwa.edu.au", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ajmal Mian", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning a Non-linear Knowledge Transfer Model for Cross-View Action Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ajmal Mian", "label": "is_author", "title": "Relation: is_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rahmani_Learning_a_Non-Linear_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Learning a Non-linear Knowledge Transfer Model for Cross-View Action Recognition", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Sparse Kernel Multi-task Learning (SKMTL) models", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Convex Multi-task Cluster Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sparse Kernel Multi-task Learning (SKMTL) models", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Laplacian Eigenmaps", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "SKMTL problem", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "jointly convex", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "clustered structures", "label": "of", "title": "Relation: of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "tasks", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "tasks", "label": "serve as", "title": "Relation: serve as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "benchmarks", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "tasks", "label": "evaluating", "title": "Relation: evaluating\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "progress", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Robotics (Sarcos) dataset", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "sparse structure", "label": "has_implications_in", "title": "Relation: has_implications_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "settings beyond computer vision", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Laplacian Eigenmaps", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Sparse Kernel Multi-task Learning", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Sparse Kernel Multi-task Learning", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Joint Convexity", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Sparse Kernel Multi-task Learning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Cluster Multi-task Learning", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Sparse Kernel Multi-task Learning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Robotics", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Sarcos dataset", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Robust Multiple Homography Estimation", "label": "is_problem", "title": "Relation: is_problem\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ill-solved problem", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Zygmunt L. Szpak", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Robust Multiple Homography Estimation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wojciech Chojnacki", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Robust Multiple Homography Estimation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Szpak_Robust_Multiple_Homography_2015_CVPR_paper.pdf", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Robust Multiple Homography Estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "multiple homographies estimation", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ill-solved problem", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "rigidity", "label": "implies", "title": "Relation: implies\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "consistency constraints", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "homographies", "label": "must_satisfy", "title": "Relation: must_satisfy\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "new constraints", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "homographies", "label": "are_related_to", "title": "Relation: are_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "views", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "epipolar geometries", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "inconsistent", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "robust multi-structure estimation methods", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "enforcing constraints on homography matrices", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "multi-structure estimation methods", "label": "is_capable_of", "title": "Relation: is_capable_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "enforcing constraints", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "multi-structure estimation methods", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "robust", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "homography matrices", "label": "has_constraint", "title": "Relation: has_constraint\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "constraints", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "new generation", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "robust multi-structure estimation methods", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "critiques", "label": "targets", "title": "Relation: targets\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "existing approaches", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Robust Multi-Structure Estimation", "label": "enforces", "title": "Relation: enforces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "constraints on homography matrices", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Robust Multi-Structure Estimation", "label": "critiques", "title": "Relation: critiques\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "existing approaches", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Homography Matrices", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Projective Geometry", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Homography Matrices", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Epiopolar Geometry", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Baker, S., Datta, A., and Kanade, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Parameterizing homographies", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Parameterizing homographies", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "tech. rep. CMU-RI-TR-06-11", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Bernstein, D. S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Matrix Mathematics", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, P., and Suter, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Rank constraints for homographies", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, P.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rank constraints", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rank constraints", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "homographies", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Suter, D.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rank constraints", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chojnacki, W.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple homography estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chojnacki, W.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dimensionality result", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple homography estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "consistency constraints", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Szpak, Z.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple homography estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "van den Hengel, A.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple homography estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "van den Hengel, A.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dimensionality result", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dimensionality result", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "homography matrices", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fouhey, D. F.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple plane detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Multiple plane detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "J-linkage", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Scharstein, D.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple plane detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Briggs, A. J.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multiple plane detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Goldberger, J.", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Camera projection matrices", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Goldberger", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Reconstructing camera projection matrices", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Irving", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Integers, Polynomials, and Rings", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Szpak", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chojnicki", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "van den Hengel", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Saturation-Preerving Specular Reflection Separation", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Yuan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Separation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Separation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Separation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wu", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "University of Delaware", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Wu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Robust Regression on Image Manifolds", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Wu", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "nianyi@eecis.udel.edu", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Yuanliu Liu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yuanliu Liu", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Institute of Artificial AI and Robotics", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yuanliu Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Artificial Intelligence and Robotics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Saturation-Preerving Specular Reflection Paper", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Saturation-Preerving Specular Reflection Paper", "label": "publication_year", "title": "Relation: publication_year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zejian Yuan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zejian Yuan", "label": "associated with", "title": "Relation: associated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Yuanliu Liu", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Zejian Yuan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Artificial AI and Robotics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Nanning Zheng", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Nanning Zheng", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Artificial AI and Robotics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Wu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Wu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Nara Institute of Science and Technology", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Reflection", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Saturation-Preerving Specular Reflection Paper", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Specular Reflection", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Saturation-Preserving Specular Reflection Paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Specular Reflection", "label": "is_separated_by", "title": "Relation: is_separated_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Linear Programming", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Specular Reflection", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Diffuse Reflection", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Liu_Saturation-Preerving Specular Reflection Paper", "label": "file_path", "title": "Relation: file_path\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Liu_Saturation-Preerving_Specular_Reflection_2015_CVPR_paper.pdf", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Specular reflection", "label": "decreases", "title": "Relation: decreases\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "saturation of surface colors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "decreased saturation", "label": "leads to", "title": "Relation: leads to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "confusion with other colors", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Traditional methods", "label": "suffer from", "title": "Relation: suffer from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "hue-saturation ambiguity", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Specular-free images", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "oversaturated", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "This paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "two-step approach", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "two-step approach", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "over-saturated specular-free image", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "over-saturated specular-free image", "label": "is produced through", "title": "Relation: is produced through\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "global chromaticity propagation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Saturation", "label": "is recovered based on", "title": "Relation: is recovered based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "piecewise constancy of diffuse chromaticity", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Saturation", "label": "is recovered based on", "title": "Relation: is recovered based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "spatial sparsity/smoothness of specular reflection", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "achieved by increasing", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "linear programming", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "linear programming", "label": "is_used_to", "title": "Relation: is_used_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "increase achromatic component", "width": 2.7800000000000002}, {"arrows": "to", "color": "#2196F3", "from": "diffuse chromaticity", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "chromaticity", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "specular reflection", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "spatial sparsity", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "specular reflection", "label": "is_separated_from", "title": "Relation: is_separated_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "surface colors", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "spatial sparsity", "label": "is_property_of", "title": "Relation: is_property_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "specular reflection", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "achromatic component", "label": "used_with", "title": "Relation: used_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "linear programming", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "surface colors", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "saturation", "width": 2.8200000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Diffuse Chromaticity", "label": "is_component_of", "title": "Relation: is_component_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Linear Programming", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Linear Programming", "label": "preserves", "title": "Relation: preserves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "surface color saturation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Linear Programming", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "reflection component separation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shafer, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "foundational work", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Artusi, A. et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "survey of specular removal methods", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hue-Saturation Ambiguity", "label": "is_addressed_by", "title": "Relation: is_addressed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Linear Programming", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Chromaticity Propagation", "label": "is_related_to", "title": "Relation: is_related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Diffuse Chromaticity", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Diffuse and specular interface reflections", "label": "studied_in", "title": "Relation: studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gonzalez \u0026 Woods", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Digital Image Processing", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Land \u0026 McCann", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "retinex theory", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "retinex theory", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "color constancy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kim et al.", "label": "utilized", "title": "Relation: utilized\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "dark channel prior", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "dark channel prior", "label": "technique_for", "title": "Relation: technique_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "specular reflection separation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Mallick et al.", "label": "explored", "title": "Relation: explored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "specular surfaces", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Mallick et al.", "label": "used", "title": "Relation: used\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "color information", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "specular surfaces", "label": "reconstructed using", "title": "Relation: reconstructed using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "color information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "S. P.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond lambert", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond lambert", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "reconstructing specular surfaces", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zickler", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond lambert", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond lambert", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "P. N. Belhumeur", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond lambert", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "D. J. Kriegman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond lambert", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "P., Zickler, T., Belhumeur, P. N., \u0026 Kriegman, D. J.", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "specular surfaces", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lin, S., \u0026 Shum, H.-Y.", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "separation of diffuse and specular reflection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Tan, R. T., Nishino, K., \u0026 Ikeuchi, K.", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "color constancy", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Mallick, S. P., Zickler, T., Kriegman, D. J., \u0026 Belhumeur, P. N.", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PDE approach", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "PDE approach", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "specular removal", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "diffuse reflection", "label": "related to", "title": "Relation: related to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "specular reflection", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Wuyuan Xie", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Photometric Stereo with Near Point Lighting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Photometric Stereo with Near Point Lighting", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "PDE approach", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Photometric Stereo with Near Point Lighting", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chengkai Dai", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Photometric Stereo with Near Point Lighting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Charlie C. L. Wang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Photometric Stereo with Near Point Lighting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xie_Photometric_Stereo_With_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "photometric stereo", "label": "occurs under", "title": "Relation: occurs under\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "near point lighting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "near point lighting", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "nonlinear relationship", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "nonlinear relationship", "label": "links", "title": "Relation: links\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "local surface normals", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "nonlinear relationship", "label": "links", "title": "Relation: links\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "light source positions", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "mesh deformation approach", "label": "determines", "title": "Relation: determines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "facet position", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "mesh deformation approach", "label": "determines", "title": "Relation: determines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "facet orientation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "mesh deformation approach", "label": "decomposes into", "title": "Relation: decomposes into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "local projection", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "mesh deformation approach", "label": "decomposes into", "title": "Relation: decomposes into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "global blending", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Photometric Stereo", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Nonlinear Optimization", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "S. Barsky", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "4-source photometric stereo technique", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "4-source photometric stereo technique", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "highlights and shadows", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "D. Nehab", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Efficiently combining positions and normals", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Efficiently combining positions and normals", "label": "aims_for", "title": "Relation: aims_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "precise 3d geometry", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "A. Hertzmann", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Example-based photometric stereo", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Example-based photometric stereo", "label": "reconstructs", "title": "Relation: reconstructs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "shape", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Shape and spatially-ranging brdfs", "label": "derived_from", "title": "Relation: derived_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "photometric stereo", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Mesh Deformation", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Surface Reconstruction", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Near Point Lighting", "label": "influences", "title": "Relation: influences\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Photometric Stereo", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Photometric stereo", "label": "is_studied_in", "title": "Relation: is_studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Photometric stereo", "label": "is_studied_in", "title": "Relation: is_studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Computer Vision Workshops (ICCV Workshops)", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Photometric stereo", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "multiple images", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Photometric stereo", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "point light sources", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Shape", "label": "is_studied_in", "title": "Relation: is_studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Proceedings of the Fifth Eurographics Symposium on Geometry Processing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Surface orientation", "label": "is_determined_by", "title": "Relation: is_determined_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "photometric method", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Surface modeling", "label": "is_approached_by", "title": "Relation: is_approached_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "as-rigid-as-possible surface modeling", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "Discrete geometry", "label": "is_shaped_by", "title": "Relation: is_shaped_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "projections", "width": 2.7199999999999998}, {"arrows": "to", "color": "#4CAF50", "from": "BRDF", "label": "is_studied_in", "title": "Relation: is_studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "urographics Symposium on Geometry Processing", "label": "held in", "title": "Relation: held in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "2007", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "S. Bouaziz", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "urographics Symposium on Geometry Processing", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "deep hashing (DH) approach", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "compact binary codes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "existing binary codes learning methods", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "single linear projection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "deep neural network", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "hierarchical non-linear transformations", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "deep neural network", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "nonlinear relationship of samples", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "loss minimization", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "real-valued feature descriptor", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "different bits", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "independent", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "different bits", "label": "are independent", "title": "Relation: are independent\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "each other", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "nary vector", "label": "is_minimized", "title": "Relation: is_minimized\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "binary codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "discriminative term", "label": "maximizes", "title": "Relation: maximizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "inter-class variations", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "discriminative term", "label": "minimizes", "title": "Relation: minimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "intra-class variations", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "learned binary codes", "label": "have", "title": "Relation: have\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "discriminative power", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Deep Hashing", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Binary Codes Learning", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Deep Hashing", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Large-Scale Visual Search", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Binary Codes Learning", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "maximize inter-class variations", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Binary Codes Learning", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "minimize intra-class variations", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Hashing Functions", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Deep HHashing", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Andoni \u0026 Indyk (2006)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Near-optimal Hashing Algorithms", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Near-optimal Hashing Algorithms", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Approximate Nearest Neighbor Search", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Gong et al. (2012)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Angular Quantization-based Binary Codes", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Angular Quantization-based Binary Codes", "label": "facilitates", "title": "Relation: facilitates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Fast Similarity Search", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Hinton \u0026 Salakhutdinov (2006)", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Reducing Data Dimensionality", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Neural Networks", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "data dimensionality", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Neural Networks", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "background knowledge", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Neural Networks", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Object Recognition", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Tiny Images", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "nonparametric object recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Hash Bit Selection", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "unified solution", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Shift-invariant kernels", "label": "generates", "title": "Relation: generates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "locality-sensitive binary codes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Minimal Loss Hashing", "label": "creates", "title": "Relation: creates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "compact binary codes", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Science", "label": "is_publication_venue", "title": "Relation: is_publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "research paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Torralba, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "80 million tiny images", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "80 million tiny images", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "*PAM*I", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wang, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Semi-supervised hashing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Venice Erin Liong", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Advanced Digital Sciences Center", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Gang Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "School of Electrical and Electronic Engineering", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jie Zhou", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Department of Automation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Department of Automation", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Tsinghua University", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Dongyoon Han", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Unsupervised Simultaneous Orthogonal Basis Clustering Feature Selection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dongyoon Han", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Department of Automation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dongyoon Han", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "jzhou@tsinghua.edu.cn", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Unsupervised Simultaneous Orthogonal Basis Clustering Feature Selection", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Han_Unpublished_Simultaneous_Orthogonal_2015_CVPR_paper", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Han_Unsupervised_Simultaneous_Orthogonal_2015_CVPR_paper", "label": "publication_venue", "title": "Relation: publication_venue\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Han_Unsupervised_Simultaneous_Orthogonal_2015_CVPR_paper", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "feature selection methods", "label": "is_characterized_as", "title": "Relation: is_characterized_as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "supervised and unsupervised feature selection methods", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "SOCFS", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "unsupervised feature selection method", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "SOCFS", "label": "designed_for", "title": "Relation: designed_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "feature selection on unlabeled data", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "SOCFS", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "regularized regression-based formulation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "SOCFS", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "state-of-the-art results", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "SOCFS", "label": "performs_on", "title": "Relation: performs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "real world datasets", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "regularized regression-based formulation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "target matrix", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "target matrix", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "latent cluster centers", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "target matrix", "label": "guides", "title": "Relation: guides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "projection matrix", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "projection matrix", "label": "selects", "title": "Relation: selects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "discriminative features", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "projection matrix", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "sparse nature", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Nie et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "feature selection via joint l2,1-norms minimization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "feature selection via joint l2,1-norms minimization", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Nene et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Columbia object image library (coil-20)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Columbia object image library (coil-20)", "label": "is_technical_report", "title": "Relation: is_technical_report\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CCUCS-005-96", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Yang et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "l2,1-norm regularized discriminative feature selection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Qian and Zhai", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust unsupervised feature selection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Robust unsupervised feature selection", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IJCAI", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sch\u00a8onemann", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "generalized solution of the orthogonal Procustes problem", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhao and Liu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Spectral feature selection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Spectral feature selection", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ICML", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Procrustes problem", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Psychometrika", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhao, Z.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Spectral feature selection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Samaria, F. S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "stochastic model", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Jianming Zhang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jianming Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Boston University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Shugao Ma", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Shugao Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Boston University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Mehrnooush Sameki", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Stan Sclaroff", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stan Sclaroff", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Boston University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Margrit Betke", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Margrit Betke", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Boston University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Radom\u00edr M\u011bch", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "People", "label": "can", "title": "Relation: can\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "subitizing", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Salient Object Subitizing (SOS)", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "predict existence and number", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Salient Object Subitizing (SOS)", "label": "has_application_in", "title": "Relation: has_application_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "salient object detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Salient Object Subitizing (SOS)", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Convolutional Neural Networks (CNNs)", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Crowd Sourcing", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Dataset Creation", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Holistic Image Analysis", "label": "encompasses", "title": "Relation: encompasses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Salient Object Subitizing (SOS)", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision Applications", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Computer Vision Applications", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "robot vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mehrnoosh Sameki", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Boston University", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Radom\u00b4\u0131r M\u02d8ech", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Adobe Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Discriminaitve Shape from Shading", "label": "is_paper_title", "title": "Relation: is_paper_title\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Richter_Discriminaitve_Shape_From_2015_CVPR_paper.pdf", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Discriminaitve Shape from Shading", "label": "addresses_topic", "title": "Relation: addresses_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Shape from Shading", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Richter_Discriminaitve_Shape_From_2015_CVPR_paper.pdf", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Estimating surface normals", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "challenging problem", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Estimating surface normals", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "under-constrained problem", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simplifying assumptions", "label": "example_includes", "title": "Relation: example_includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "directional lighting", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Simplifying assumptions", "label": "example_includes", "title": "Relation: example_includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "known reflectance maps", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "regression forests", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Von Mises-Fisher distributions", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "spatial features", "label": "example_includes", "title": "Relation: example_includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "textons", "width": 2.7199999999999998}, {"arrows": "to", "color": "#4CAF50", "from": "spatial features", "label": "example_includes", "title": "Relation: example_includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.84\u003cbr\u003eSource: unknown", "to": "novel silhouette features", "width": 2.6799999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "generalization", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "uncalibrated illumination", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "pixel-independent prediction", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "efficient estimation", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Discrimiative Learning", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "research area", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "J. T. Barron", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Color constancy, intrinsic images, and shape estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J. T. Barron", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Shape, albedo, and illumination from a single image", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J. Ben-Arie", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A neural network approach", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "L. Breiman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Random forests", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ShapeCollage", "label": "interprets", "title": "Relation: interprets\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "shape", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "ShapeCollage", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "example-based methods", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "ShapeCollage", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "ShapeCollage", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "occlusion-aware shape interpretation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Image-to-geometry registration", "label": "method_uses", "title": "Relation: method_uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "mutual information", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Image-to-geometry registration", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "geometric properties", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Modeling data", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "directional distributions", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Dispersion", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "P. Roy. Soc. Lond. B", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Floating scale reconstruction", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "SIGGRAPH", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "SIGGRAPH", "label": "is_conference_for", "title": "Relation: is_conference_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Debevec et al.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Adelson", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Ground truth dataset", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "W. T. Freeman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Ground truth dataset", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Jean-Dominique FAVREAU", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Line Drawing Interpretation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jean-Dominique FAVREAU", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "INRIA Sophia-Antippolis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Line Drawing Interpretation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Line Drawing Interpretation", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "3D Scene Understanding", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Adrien Bousseau", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Line Drawing Interpretation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Adrien Bousseau", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "INRIA Sophia-Antipollis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Adrien Bousseau", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "INRIAL Sophia-Antipolis", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "line drawings", "label": "of", "title": "Relation: of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "imaginary objects", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "line drawings", "label": "drawn over", "title": "Relation: drawn over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "photographs", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "photographs", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "desired scene", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "photographs", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "undesired reflections", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "computer vision algorithms", "label": "offer", "title": "Relation: offer\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "limited support", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "multi-view stereo algorithms", "label": "reconstruct", "title": "Relation: reconstruct\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "real-world scenes", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "line-drawing interpretation algorithms", "label": "lack", "title": "Relation: lack\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "contextual awareness", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "polygon", "label": "belongs to", "title": "Relation: belongs to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "orientation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "new structures", "label": "present_in", "title": "Relation: present_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "real world", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "furniture design", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "application domain", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "archaeology", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "application domain", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "new orientation", "label": "allows", "title": "Relation: allows\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "creation of new structures", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "new orientation", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "unknown orientation", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Computer-Aided Design", "label": "facilitates", "title": "Relation: facilitates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "creation of new structures", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Furniture Design", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Computer-Aided Design application", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "O-snap", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "optimization-based snapping method", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "M. Arikan", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "O-snap", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "H. Barrow", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Line Drawing Interpretation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Y. Boykov", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "energy minimization algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A.-L. Chauve", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D reconstruction methods", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Multi-View Stereo Reconstruction", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "energy minimization algorithms", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Furukawa et al.", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Manhattan-world stereo", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wiley-ISTE", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Stochastic geometry for image analysis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Florent LAFARGE", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "INRIA Sophia-Antipollis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Florent LAFARGE", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "INRIA Sophia-Antipolis", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bis Publishers", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": " Sketching: The Basics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "jean-dominuque.favreau@inria.fr", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "INRIA Sophia-Antipolis", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Olga Russakovsky", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Best of both worlds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Olga Russakovsky", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Stanford University", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Best of both worlds", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Li-Jia Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Best of both worlds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Li-Jia Li", "label": "works_at", "title": "Relation: works_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Snapchat", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Li Fei-Fei", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Best of both worlds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Li Fei-Fei", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Stanford University", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Russakovsky_Best_of_Both_2015_CVPR_paper.pdf", "label": "is_an_example_of", "title": "Relation: is_an_example_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "jean-dominique.favreau@inria.fr", "label": "is_email_of", "title": "Relation: is_email_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "jean-dominique.favreau", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "florent.lafarge@inria.fr", "label": "is_email_of", "title": "Relation: is_email_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Florent LAFARGE", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "adrien.bousseau@inria.fr", "label": "is_email_of", "title": "Relation: is_email_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Adrien Bousseau", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "manual annotation", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "quite expensive", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "manual annotation", "label": "influenced by", "title": "Relation: influenced by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "crowd engineering innovations", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "automatic object detectors", "label": "detect", "title": "Relation: detect\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "at most a few objects per image", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "object annotations", "label": "informed_by", "title": "Relation: informed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "human feedback", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "object annotations", "label": "informed_by", "title": "Relation: informed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "computer vision", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "computer vision models", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "object annotations", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "human input", "label": "source_of", "title": "Relation: source_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "feedback", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Visesh Chari", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "On Pairwise Costs for Network Flow Multi-Object Tracking", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Visesh Chari", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "INRIA", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Visesh Chari", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Ecole Normale Sup\u00b4erieure", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ivan Laptev", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "On Pairwise Costs for Network Flow Multi-Object Tracking", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Ivan Laptev", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "INRIA", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Josef Sivic", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "On Pairwise Costs for Network Flow Multi-Object Tracking", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Josef Sivic", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "INRIA", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Chari_On_Pairwise_Costs_2015_CVPR_supplemental", "label": "is_supplement_to", "title": "Relation: is_supplement_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On Pairwise Costs for Network Flow Multi-Object Tracking", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-object Tracking", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Network Flow Optimization", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Multi-object Tracking", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Network Flow Optimization", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "dependencies among tracks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pairwise Costs", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "object detector failures", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Pairwise Costs", "label": "introduced_to", "title": "Relation: introduced_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "min-cost network flow framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Convex Relaxation", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "efficient rounding heuristic", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "pairwise costs", "label": "evaluated_in", "title": "Relation: evaluated_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "real-world video sequences", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "pairwise costs", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "recent tracking methods", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Tracking-by-Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "pairwise costs", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Tracking-by-Detection", "label": "is_approach_in", "title": "Relation: is_approach_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Multi-object Tracking", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "TILDE", "label": "is_method", "title": "Relation: is_method\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Temporally Invariant Learned Detector", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Yannick Verdie", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "TILDE", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yannick Verdie", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Laboratory, EPFL", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kwang Moo Yi", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "TILDE", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kwang Moo Yi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computer Vision Laboratory, EPFL", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pascal Fua", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "TILDE", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Vincent Lepetit", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "TILDE", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simon Lacoste-Julien", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "INRIO", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Cortes, C.", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Support-Vector Networks", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Cortes, C.", "label": "co_author_of", "title": "Relation: co_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Vapnik, V.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Support-Vector Networks", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vapnik, V.", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Support-Vector Networks", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Harris, C.", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Combined Corner and Edge Detector", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Stephens, M.", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Combined Corner and Edge Detector", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "C.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Support-Vector Networks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Corner Detector", "label": "developed by", "title": "Relation: developed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Harris, C.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Corner Detector", "label": "developed by", "title": "Relation: developed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Stephens, M.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hinging Hyperplanes", "label": "developed by", "title": "Relation: developed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Breiman, L.", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hinging Hyperplanes", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Information Theory", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gradient-Based Learning", "label": "applied to", "title": "Relation: applied to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Document Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Af\ufb01ne Region Detectors", "label": "compared in", "title": "Relation: compared in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mikolajczyk, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Comparison of Af\ufb01ne Region Detectors", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "rs", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Comparison of Af\ufb01ne Region Detectors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zisserma", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Comparison of Af\ufb01ne Region Detectors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Mata", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Comparison of Af\ufb01ne Region Detectors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Schaffalitzky", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Comparison of Af\ufb01ne Region Detectors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kadir", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Comparison of Af\ufb01ne Region Detectors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Van Gool", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Review of Af\ufb01ne Region Detectors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dollar", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Supervised Learning of Edges and Object Boundaries", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Supervised Learning of Edges and Object Boundaries", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Belongie", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Supervised Learning of Edges and Object Boundaries", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rosten", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Machine Learning for High-Speed Corner Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Drummond", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Machine Learning for High-Speed Corner Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lowe", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Distinctive Image Features from Scale-Invariant Keypoints", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fan", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "LIBLINEAR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fan", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Journal of Machine Learning Research", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Chang", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "LIBLINEAR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chang", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "tracking", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Hsieh", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "LIBLINEAR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lin", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "LIBLINEAR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Verdie", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "EPFL", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "EPFL", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Vincent Le Petit", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute for Computer Graphics and Vision, Graz University of Technology", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "JOTS", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Joint Online Tracking and Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Joint Online Tracking and Segmentation", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Video Segmentation task", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Joint Online Tracking and Segmentation", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Multi-part tracking", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Joint Online Tracking and Segmentation", "label": "integrates", "title": "Relation: integrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Joint Online Tracking and Segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Energy Function Optimization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Joint Online Tracking and Segmentation", "label": "demonstrated_effectiveness_on", "title": "Relation: demonstrated_effectiveness_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "SegTrack database", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Joint Online Tracking and Segmentation", "label": "demonstrated_effectiveness_on", "title": "Relation: demonstrated_effectiveness_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "SegTrack v2 database", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Longyin Wen", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "JOTS", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Longyin Wen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NLPR, Institute of Automation, Chinese Academy of Sciences", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dawei Du", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "JETS", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Dawei Du", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "SCCE, University of Chinese Academy of Sciences", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhen Lei", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "JOTS", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zhen Lei", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NLPR, Institute of Automation, Chinese Academy of Sciences", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhen Lei", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhen Lei", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "High-Fidelity Pose and Expression Normalization for FaceRecognition in the Wild", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhen Lei", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Center for Biometrics and Security Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhen Lei", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "National Laboratory of Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stan Z. Li", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "JOTS", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Stan Z. Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "NLPR", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Stan Z. Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Center for Biometrics and Security Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stan Z. Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "National Laboratory of Pattern Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stan Z. Li", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "szli@nlpr.ia.ac.cn", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Wen_JOTS_Joint_Online_2015_CVPR_paper.pdf", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Tracking and Segmentation stages", "label": "optimized_using", "title": "Relation: optimized_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "RANSA-style approach", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Multi-part Models", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Tracking and Segmentation", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "multi-target tracking", "label": "is_task_of", "title": "Relation: is_task_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "video analysis", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "topological constraints", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "tracking", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Vasconcelos", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NLPR, Institute of Automation, Chinese Academy of Sciences", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vasconcelos", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "tracking deformable and occluded objects", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "S. Z. Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NLPR, Institute of Automation, Chinese Academy of Sciences", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Delong", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "optimization method", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "NLPR", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Chinese Academy of Sciences", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Philipp Kr\u00e4henbuhl", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Learning to Propose Objects", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Learning to Propose Objects", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Vladlen Koltun", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Learning to Propose Objects", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Krahenbuhl_Learning_to_Propos_2015_CVPR_paper.pdf", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Learning to Propose Objects", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "zlei", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "NLPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ensemble", "label": "trained", "title": "Relation: trained\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "jointly", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ensemble", "label": "operates_on", "title": "Relation: operates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "elementary image features", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ensemble", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "rapid image analysis", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "ensemble", "label": "has", "title": "Relation: has\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "composition", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "ensemble", "label": "has", "title": "Relation: has\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "parameters", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "ensemble training", "label": "reduced_to", "title": "Relation: reduced_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "sequence of uncapacitated facility location problems", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "procedure", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "size of the ensemble", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "procedure", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "composition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "procedure", "label": "is_scalable", "title": "Relation: is_scalable\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "set of cliques", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "procedure", "label": "activates", "title": "Relation: activates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "cliques", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ensembles", "label": "operate_on", "title": "Relation: operate_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "elementary image features", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "presented approach", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "prior object proposal algorithms", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "presented approach", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "lowest running time", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "presented approach", "label": "capable_of_learning", "title": "Relation: capable_of_learning\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "bottom-up segmentation model", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "presented approach", "label": "learns", "title": "Relation: learns\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "generally applicable model", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "trained ensembles", "label": "generalize across", "title": "Relation: generalize across\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "datasets", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "bottom-up segmentation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "model", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Ensemble Methods", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "running time", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Arbel\u00e1ez et al. (2012)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Semantic segmentation using regions and parts", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Carreira et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Free-form region description with second-order pooling", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Free-form region description with second-order pooling", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "PAMI", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Microsoft COCO", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "common objects", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Objectness", "label": "is measured by", "title": "Relation: is measured by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Alexe et al.", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Structured forests", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "BING", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Geometry of cuts and metrics", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Springer", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Aravindh Mahendran", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Understanding Deep Image Representations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Aravindh Mahendran", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Understanding Deep Image Representations by Inverting Them", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Aravindh Mahendran", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Intel Labs", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Andrea Vedaldi", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Understanding Deep Image Representations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Andrea Vedaldi", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Understanding Deep Image Representations by Inverting Them", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Understanding Deep Image Representations by Inverting Them", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Understanding Deep Image Representations by Inverting Them", "label": "concerns", "title": "Relation: concerns\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Deep Image Representations", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Understanding Deep Image Presentations by Inverting Them", "label": "year", "title": "Relation: year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf", "label": "is_file_of", "title": "Relation: is_file_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Image Representations", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "geometric and photometric invariance", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Bishop", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Neural Networks for Pattern Recognition", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "deformable part models", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "3D textons", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "material recognition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "SIFT detector", "label": "is_implementation", "title": "Relation: is_implementation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "open-source implementation", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "SIFT detector", "label": "is_part_of", "title": "Relation: is_part_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image processing tasks", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Zeiler \u0026 Fergus", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "visualizing convolutional networks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Hinton \u0026 Salakhutdinov", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "dimensionality reduction", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Wang et al.", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "locality-constrained linear coding", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Arvindh Mahendran", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Oxford", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yan Xia", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse Projections for High-Dimensional Binary Codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yan Xia", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Sparse Projections", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yan Xia", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Science and Technology of China", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Pushmeet Kohli", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Sparse Projections for High-Dimensional Binary Codes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pushmeet Kohli", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pushmeet Kohli", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Computationally Bounded Retrieval", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Sparse Projections", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "problem of learning long binary codes", "label": "has_challenge", "title": "Relation: has_challenge\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "lack of effective regularizer", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "sparsity encouraging regularizer", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "number of parameters", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "sparsity encouraging regularizer", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "overfitting", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "sparse projection matrix", "label": "leads_to", "title": "Relation: leads_to\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "reduction in computational cost", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "dense projections", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "ITQ", "width": 2.7}, {"arrows": "to", "color": "#FF5722", "from": "rix", "label": "leads_to", "title": "Relation: leads_to\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "reduction in computational cost", "width": 2.96}, {"arrows": "to", "color": "#FF5722", "from": "other methods", "label": "speeds_up", "title": "Relation: speeds_up\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "high-dimensional binary encoding", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Agrawal et al. (2014)", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Foundational context", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Agrawal et al. (2014)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Neural Networks", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Object Recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Local Scale-Invariant Features", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Fan et al. (2008)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Liblinear", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Liblinear", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "library", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "binary code learning", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "efficient similarity search", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "approximate nearest neighbor search", "label": "is_task_in", "title": "Relation: is_task_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "many applications", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "sparse approximation techniques", "label": "can_be_used_for", "title": "Relation: can_be_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "feature selection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "sparse approximation techniques", "label": "can_be_used_for", "title": "Relation: can_be_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "dimensionality reduction", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "product quantization", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "approximate nearest neighbor search", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "atomic decomposition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "basis pursuit", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "basis pursuit", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "atomic decomposition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "hashing algorithms", "label": "aim_for", "title": "Relation: aim_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "approximate nearest neighbor search", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "ear-optimal hashing algorithms", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "approximate nearest neighbor search", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ear-optimal hashing algorithms", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "FOCS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "locality-sensitive hashing", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "approximate nearest neighbor search", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "locality-sensitive hashing", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Symposium on Computational Geometry", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Procrustes analysis", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "finding optimal transformation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Procrustes problems", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Oxford University Press", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Huazhu Fu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dong Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stephen Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jiang Liu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Object-based RGBD Image Co-segmentation with Mutex Constraint", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Object-based RGBD Image Co-segmentation with Mutex Constraint", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Huazhu Fu", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Object-based RGBD Image Co-segmentation with Mutux Constraint", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Dong Xu", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Object-based RGBD Image Co-segmentation with Mutux Constraint", "label": "authored_by", "title": "Relation: authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Stephen Lin", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "depth channel", "label": "enhances", "title": "Relation: enhances\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "identification of similar foreground objects", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "co-segmentation", "label": "formulated_in", "title": "Relation: formulated_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "fully-connected graph structure", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "graph structure", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "mutex constraints", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "mutex constraints", "label": "prevents", "title": "Relation: prevents\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "improper solutions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "object-based RGBD co-segmentation", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "related methods", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "object-based RGBD co-segmentation", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "mutex constraints", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "object-based RGBD co-segmentation", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "segmentation accuracy", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "RGBD co-segmentation", "label": "outperforms", "title": "Relation: outperforms\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "related techniques", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "comparable performance", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "RGB co-segmentation techniques", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "RGB co-segmentation techniques", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "depth maps", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "depth maps", "label": "estimated_from", "title": "Relation: estimated_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "RGB images", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Depth maps", "label": "estimated from", "title": "Relation: estimated from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "RGB images", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Object-Based Methods", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Method", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Mutual Exclusion Constraints", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Method", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Co-Saliency Maps", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Method", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Graph Formulation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "Method", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-Plane Block-Coordinate Frank-Wilfe Algorithm", "label": "trains", "title": "Relation: trains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Structural SVMs", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-Plane Block-Coordinate Frank-Wilfe Algorithm", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "max-Oracle", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Neel Shah", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Neel Shah", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IST Austria", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vladimir Kolmogorov", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Vladimir Kolmogorov", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IST Austria", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chris H. Lampert", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chris H. Lampert", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IST Australia", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Structural Support Vector Machines", "label": "is_effective_for", "title": "Relation: is_effective_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "structured computer vision tasks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Structural Support Vector Machines", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Max-Oracle", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Structural Support Vector Machines", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Frank-Wolfe Algorithm", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Structural Support Vector Machines", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Block-Coordinate Methods", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Frank-Wolfe algorithm", "label": "is_designed_for", "title": "Relation: is_designed_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "training SSVMs", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Frank-Wolfe algorithm", "label": "combines_with", "title": "Relation: combines_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "caching mechanism", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "criterion", "label": "decides_whether_to", "title": "Relation: decides_whether_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "call max-oracle", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "max-oracle", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "bottleneck", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Max-Oracle", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "optimization technique", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Beier_Fusion_Moves_for_2015_CVPR_supplemental", "label": "is_supplemental_material_for", "title": "Relation: is_supplemental_material_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fusion Moves for Correlation Clustering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "PIVOT-BOEM", "label": "is_algorithm", "title": "Relation: is_algorithm\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Correlation Clustering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "HC", "label": "is_algorithm", "title": "Relation: is_algorithm\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Correlation Clustering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CGC", "label": "is_algorithm", "title": "Relation: is_algorithm\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Correlation Clustering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fusion Moves", "label": "is_variant_of", "title": "Relation: is_variant_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Correlation Clustering", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Experimental Analysis", "label": "evaluates", "title": "Relation: evaluates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Algorithms", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Anytime Algorithms", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Anytime Behavior", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Anytime Behavior", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Progressive Improvement", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Dataset Performance", "label": "evaluated_on", "title": "Relation: evaluated_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Instances", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "University of Heidelberg (Iwr)", "label": "affiliation_of", "title": "Relation: affiliation_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Thorsten Beier", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "University of Heidelberg (Iwr)", "label": "affiliation_of", "title": "Relation: affiliation_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Fred A. Hamprecht", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Mohammadreza Mostajabi", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Feedforward Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mohammadreza Mostajabi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Toyota Technological Institute at Chicago", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Feedforward Semantic Segmentation", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Payman Yadollahpour", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Feedforward Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Payman Yadollahpour", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Toyota Technological Institute at Chicago", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Gregory Shakhnarovich", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Feedforward Semantic Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gregory Shakhnarovich", "label": "authors", "title": "Relation: authors\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gregory Shakhnarovich", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Toyota Technological Institute at Chicago", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "University of Heidelberg (Department of Mathematics)", "label": "affiliation_of", "title": "Relation: affiliation_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "J\u00f6rg H. Kappes", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Mostajabi_Feedforwad_Semantic_Segmentation_2015_CVPR_paper", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "feed-forward architecture", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "feed-forward architecture", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "semantic segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "image elements", "label": "mapped_to", "title": "Relation: mapped_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "rich feature representations", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "nested regions", "label": "obtained_by", "title": "Relation: obtained_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "zoom-out", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "zoom-out", "label": "starts_from", "title": "Relation: starts_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "superpixel", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Hypercolumns for object segmentation and fine-grained localization", "label": "is_publication_type", "title": "Relation: is_publication_type\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "arXiv preprint", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Hypercolumns for object segmentation and fine-grained localization", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "object segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Chen et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "label": "is_publication_type", "title": "Relation: is_publication_type\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "arXiv preprint", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Long et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fully convolutional networks for semantic segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fully convolutional networks for semantic segmentation", "label": "is_publication_type", "title": "Relation: is_publication_type\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "arXiv preprint", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Fully convolutional networks for semantic segmentation", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "semantic segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Associative hierarchical CRFs for object class image segmentation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Carreira and Sminchisescu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CPMC: Automatic object segmentation using constrained parametric min-cuts", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "CPMC: Automatic object segmentation using constrained parametric min-cuts", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "CPMC", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Carreira, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CPMC", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Sminchisescu, C.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "CPMC", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zisserma, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Very deep convolutional networks", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fr\u00b4edo Durand", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Reflection Removal using Ghosting Cues", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Fr\u00b4edo Durand", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Ghosting Cues", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fr\u00b4edo Durand", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "MIT CSAIL", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "YiChang Shih", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Reflection Removal using Ghosting Cues", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "YiChang Shih", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Ghosting Cues", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "YiChang Shih", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "MIT CSAIL", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Dilip Krishnan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Reflection Removal using Ghosting Cues", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Dilip Krishnan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Ghosting Cues", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dilip Krishnan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Google Research", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "William T. Freeman", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Reflection Removal using Ghosting Cues", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "William T. Freeman", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Ghosting Cunes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "William T. Freeman", "label": "affilates_with", "title": "Relation: affilates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "MIT CSAIL", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "William T. Freeman", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "billf@mit.edu", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ghosting Cues", "label": "is_discussed_in", "title": "Relation: is_discussed_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Shih_Reflection_Removal_Using_2015_CVPR_paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Shih_Reflection_Removal_Using_2015_CVPR_paper", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shih_Reflection_Removal_Using_2015_CVPR_paper", "label": "is_authored_by", "title": "Relation: is_authored_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "YiChang Shih", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Shih_Reflection_Removal_Using_2015_CVPR_paper", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "reflection removal", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "reflection removal", "label": "occurs_on", "title": "Relation: occurs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "synthetic inputs", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "reflection removal", "label": "occurs_on", "title": "Relation: occurs_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "real-world inputs", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "layer separation", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ill-posed problem", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "ghosting cues", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "asymmetry", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ghosting cues", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "barely perceptible", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "ghosting cues", "label": "arises from", "title": "Relation: arises from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "shifted double reflections", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ghosted reflection", "label": "modeled using", "title": "Relation: modeled using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "double-impulse convolution kernel", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "ghosted reflection components", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "relative attenuation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Reflection Removal", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "synthetic inputs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Reflection Removal", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "real-world inputs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Soonmin Hwang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multispectral Pedestrian Detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Soonmin Hwang", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "author", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Multispectral Pedestrian Detection", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Benchmark Dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "pedestrian datasets", "label": "focus_on", "title": "Relation: focus_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "color channel", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "thermal channel", "label": "is_helpful_for", "title": "Relation: is_helpful_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "detection", "width": 2.92}, {"arrows": "to", "color": "#FF5722", "from": "multispectral pedestrian dataset", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "limitation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "multispectral pedestrian dataset", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "color-thermal image pairs", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "multispectral pedestrian dataset", "label": "is_as_large_as", "title": "Relation: is_as_large_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "previous color-based datasets", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "multispectral pedestrian dataset", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "dense annotations", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "color-thermal image pairs", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "image type", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "multispectral ACF", "label": "is_extension_of", "title": "Relation: is_extension_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "aggregated channel features (ACF)", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "multispectral ACF", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "color-thermal image pairs", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "multispectral ACF", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "average miss rate of ACF", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "spectral ACF", "label": "is_extension_of", "title": "Relation: is_extension_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "aggregated channel features", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "spectral ACF", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "color-thermal image pairs", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "aggregated channel features", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "image feature", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Multispectral ACF", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "average miss rate", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Multispectral ACF", "label": "reduces_by", "title": "Relation: reduces_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "15%", "width": 2.98}, {"arrows": "to", "color": "#FF5722", "from": "Multispectral ACF", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "pedestrian detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Multispectral ACF", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "miss rate", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Multispectral ACF", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "color-thermal image pairs", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Multispectral ACF", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "breakthrough in pedestrian detection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "RGBD-Fusion", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "real-time", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "RGBD-Fusion", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "high precision", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Jaesik Park", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "author", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Namil Kim", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "author", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Roy Or", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "author", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Roy Or", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Technion, Israel Institute of Technology", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "RGB-D scanners", "label": "has_limitation", "title": "Relation: has_limitation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "subtle details", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "RGB-D scanners", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Depth map enhancement", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "lighting model", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "natural scene illumination", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "lighting model", "label": "integrated_into", "title": "Relation: integrated_into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "shape from shading-like technique", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "detailed geometry", "label": "calculated_via", "title": "Relation: calculated_via\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "method", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "evidence", "label": "supports", "title": "Relation: supports\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "improvement in depth", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "Depth map enhancement", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Shape from shading", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Depth map enhancement", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "depth", "width": 2.6399999999999997}, {"arrows": "to", "color": "#2196F3", "from": "Shape from shading", "label": "influenced_by", "title": "Relation: influenced_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Lighting models", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Shape from shading", "label": "studied_in", "title": "Relation: studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision, Graphics, and Image Processing", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Shape from shading", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "computer vision technique", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Real-time processing", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Depth map enhancement", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Lambertian reflectance", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian nonparametric intrinsic image decomposition", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "European Conference on Computer Vision", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Variable-source shading analysis", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Variable-source shading analysis", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "computer vision technique", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Grosse, R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Ground-truth dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ground-truth dataset", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "intrinsic image algorithms", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Han, Y.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "High quality shape", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "High quality shape", "label": "derived_from", "title": "Relation: derived_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "RGB-D image", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Horn, B. K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "PhD thesis", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Horn, B. K.", "label": "coauthored", "title": "Relation: coauthored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "The variational approach", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Horn \u0026 Brooks", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The variational approach to shape from shading", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Horn \u0026 Brooks", "label": "published in", "title": "Relation: published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision, Graphics, and Image Processing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Johnson \u0026 Adelison", "label": "presented at", "title": "Relation: presented at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Conference on Computer Vision and Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Guy Rosman", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Computer Science and Artificial Intelligence Lab, MIT", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Aaron Wetzler", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Technion, Israel Institute of Technology", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Ron Kimmel", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Technion, Israel Institute of Technology", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Alfred M. Bruckstein", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Technion, Israel Institute of Technology", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Xiangyu Zhu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiangyu Zhu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Center for Biometrics and Security Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiangyu Zhu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "National Laboratory of Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Stan Z. Li", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Junnie Yan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junjie Yan", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Junjie Yan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Center for Biomatrics and Security Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Junjie Yan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "National Laboratory of Pattern Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Junjie Yan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Center for Biometrics and Security Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Junjie Yan", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "jjyan@nlpr.ia.ac.cn", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Dong Yi", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "High-Fidelity Pose and Expression Normalization for Face Recognition in the Wild", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dong Yi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Center for Biometrics and Security Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dong Yi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "National Laboratory of Pattern Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "freddy@cs.technion.ac.il", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Technion - Israel Institute of Technology", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhu_High-Fidelity_Pose_and_2015_CVPR_paper.pdf", "label": "is_file_of", "title": "Relation: is_file_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "cvpr_papers", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "face recognition performance", "label": "impacted_by", "title": "Relation: impacted_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "pose variations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "HPEN method", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "challenge", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "HPEN method", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "3D Morphable Model", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "HPEN method", "label": "generates", "title": "Relation: generates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "face images", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "HPEN method", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "landmark marching", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "HPEN method", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "3DMM fitting", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "HPEN method", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "3D meshing", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "HPEN method", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Poisson Editing", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "face images", "label": "has_pose", "title": "Relation: has_pose\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "frontal pose", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "face images", "label": "has_expression", "title": "Relation: has_expression\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "neutral expression", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Poisson Editing", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "inpainting", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-PIE", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "experiments", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-PIE", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "dataset", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Amberg, B.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Optimal step non-rigid icp algorithms for surface registration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Romdhani, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Optimal step non-rigid icp algorithms for surface registration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vetter, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Optimal step non-rigid icp algorithms for surface registration", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chai, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Locally linear regression for pose-invariant face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shan, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Locally linear regression for pose-invariant face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Gao, W.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Locably linear regression for pose-invariant face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Arashloo, S. R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Pose-invariant face matching using MRF energy minimization framework", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kittler, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Pose-invariant face matching using MRF energy minimization framework", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chan, C. H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multisculse local phase quantization for robust component-based face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tahir, M. A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Multisculse local phase quantization for robust component-based face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "local phase quantization", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "robust component-based face recognition", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "component-based face recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "kernel fusion", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "kernel fusion", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "multiple descriptors", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Chen, D. (2012)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bayesian face revisited", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "high-dimensional feature", "label": "benefits", "title": "Relation: benefits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "efficient compression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Asthana, A. (2013)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "discriminative response map fitting", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "discriminative response map fitting", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "constrained local models", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "2013 IEEE Conference on Computer Vision and Pattern Recognition", "label": "hosts", "title": "Relation: hosts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "high-dimensional feature compression", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Robust discriminative response map fitting", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Robust discriminative response map fitting", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "constrained local models", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Barkan, O.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast high dimensional vector multiplication face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Weill, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast high dimensional vector multiplication face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wolf, L.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast high dimensional vector multiplication face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Aronowitz, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fast high dimensional vector multiplication face recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Parsing Occluded People", "label": "is_paper", "title": "Relation: is_paper\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Parsing Occluded People", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Xianjie Chen", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Parsing Occluded People", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Alan Yuille", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Parsing Occluded People", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "graphical model", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "tree structure", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "connected subtree", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "flexible composition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "inference", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "search over models", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "inference", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "part sharing", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "computations", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "twice as many", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "searching", "label": "searches_for", "title": "Relation: searches_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "entire object", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Stickmen dataset", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "standard benchmarked dataset", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "alternative algorithms", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "best", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "modeling", "label": "avoids", "title": "Relation: avoids\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "occlusion", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Graphical models", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Yuilie, A.", "label": "co_author_of", "title": "Relation: co_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Chen, X.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ferrari, V.", "label": "co_author_of", "title": "Relation: co_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Marin-Jimenez, M.", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "human pose estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "progressive search space reduction", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "support-vector networks", "label": "is_method_in", "title": "Relation: is_method_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "machine learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cortes", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Support-vector networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dalal", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Histograms of oriented gradients", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Triggs", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Histograms of oriented gradients", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sapp", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adaptive pose priors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jordan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adaptive pose priors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Taskar", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adaptive pose priors", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yuille", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "University of California, Los Angeles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Alabort-i-Medina", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Unifying Holistic and Parts-Based Deformable Model Fitting", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "deformable models", "label": "captures", "title": "Relation: captures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "degrees of freedom", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Face Alignment", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Holistic Deformable Models", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Face Alignment", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Parts-Based Deformable Models", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Holistic Deformable Models", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deformable Models", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Parts-Based Deformable Models", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deformable Models", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Active Appearance Models", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Face Alignment", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Active Appearance Models", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "T. F. Cootes, G. J. Edwards, and C. J. Taylor (2001)", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Active Shape Models", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Face Alignment", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Active Shape Models", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "T. F. Cootes, C. J. Taylor, D. H. Cooper, and J. Graham (1995)", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Lucas-Kanade Method", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Face Alignment", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian Active Appearance Models", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "J. Alabort-i-Medina and S. Zafeiriou (2014)", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Conference on Computer Vision and Pattern Recognition (CVPR)", "label": "held_in", "title": "Relation: held_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "2014", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lucas-Kanade", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "International Journal of Computer Vision (IJCR)", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Lucas-Kanade", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "unifying framework", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "X. Cao", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Face alignment by explicit shape regression", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Face alignment by explicit shape regression", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Conference on Computer Vision and Pattern Recognition (CVPR)", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "G. Papandreou", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Adaptive and constrained algorithms", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive and constrained algorithms", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "inverse compositional active appearance model fitting", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "A. Asthana", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Robust discriminative response map fitting", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A. Asthana", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Conference on Computer Vision and Pattern Recognition (CVPR)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "S. Zafeiriou", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Conference on Computer Vision and Pattern Reduction (CVPR)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "J. Sragih", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Conference on Computer Vision and Pattern Recognition (CVPR)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Joan Alabort-i-Medina", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Imperial College London", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Joan Alabort-i-Medina", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ja310@imperial.ac.uk", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stefanos Zafeiriou", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Computing", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stefanos Zafeiriou", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Imperial College London", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stefanos Zafeiriou", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "s.zafeiriou@imperial.ac.uk", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jia Xu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaze-Enabled Egocentric Video Summarization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jia Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Wisconsin-Madison", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Lopamudra Mukherjee", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaze-Enabled Egocentric Video Summarization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lopamudra Mukherjee", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "University of Wisconsin-Whitewater", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Yin Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaze-Enabled Egocentric Video Summarization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yin Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Georgia Institute of Technology", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jamieson Warner", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaze-Enabled Egocentric Video Summarization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "James M. Rehg", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaze-Enabled Egocentric Video Summarization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "James M. Rehg", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Georgia Institute of Technology", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Vikas Singh", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Gaze-Enabled Egocentric Video Summarization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "egocentric videos", "label": "necessitate", "title": "Relation: necessitate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "compact representation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "egocentric video summarization", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "unique challenges", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "gaze tracking information", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "summarization", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "gaze tracking information", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "frame comparison", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "summarization", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "personalized summaries", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "summarization model", "label": "is based on", "title": "Relation: is based on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "submodular function maximization", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Egocentric Video Summarization", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Submodular Function Maximization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Submodular Function Maximization", "label": "solved_via", "title": "Relation: solved_via\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Multilinear Relaxation", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Personalized Summarization", "label": "is_a_type_of", "title": "Relation: is_a_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Egocentric Video Summarization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Almeida et al.", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "VISON", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "VISON", "label": "is_for", "title": "Relation: is_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Online Applications", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Submodular Maximization", "label": "constrained_by", "title": "Relation: constrained_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Partition Matroid", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Filmus \u0026 Ward", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "Combinatorial Algorithm", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Fujishige", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Submodular Functions and Optimization", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Fujishige", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Submodular functions and optimization", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Gaze Tracking", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Personalized Summarization", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Wearable Cameras", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Egocentric Video Summarization", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Ward", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "algorithm", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Submodular functions and optimization", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "submodular maximization", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Iyer", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "optimization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Krause", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "information gathering", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Xu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Wisconsin-Madison", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Andreas Geiger", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Object Scene Flow for Autonomous Vehicles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Andreas Geiger", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "MPI Tubingen", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Object Scene Flow for Autonomous Vehicles", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Object Scene Flow for Autonomous Vehicles", "label": "supplemental_material_location", "title": "Relation: supplemental_material_location\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Menze_Object_Scene_Flow_2015_CVPR_supplemental.pdf", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Moritz Menze", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Object Scene Flow for Autonomous Vehicles", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Menze_Object_Scene_Flow_2015_CVPR_supplemental", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Object Scene Flow for Autonomous Vehicles", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "supplementary document", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "additional descriptions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "supplementary document", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "visualizations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "supplementary document", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "experiments", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "scene flow ground truth", "label": "generated_from", "title": "Relation: generated_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "3D CAD models", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "model parameters", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "model sensitivity", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI stereo", "label": "is_benchmark_for", "title": "Relation: is_benchmark_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "optical flow", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "KITTI stereo", "label": "is_benchmark_for", "title": "Relation: is_benchmark_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "stereo", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "scene flow dataset", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "novel", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "sphere sequence", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "qualitative results", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Optical Flow", "label": "is_used_in", "title": "Relation: is_used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Scene Flow", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Brox, T. \u0026 Malik, J.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Large Displacement Optical Flow", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Large Displacement Optical Flow", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Variational Motion Estimation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Hirschmueller, H.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Stereo Processing", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Scene Flow Datasets", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Quantitative Results", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Scene Flow Datasets", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Qualitative Results", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Stereo processing", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "semiglobal matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Stereo processing", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "mutual information", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Scene flow estimation", "label": "method", "title": "Relation: method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "growing correspondence seeds", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Scene flow estimation", "label": "approach", "title": "Relation: approach\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "piecewise rigid scene flow", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Scene flow estimation", "label": "method", "title": "Relation: method\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "variational method", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cech et al. (2011)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Scene flow estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Vogel et al. (2013)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Scene flow estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Huguet \u0026 Devernay (2007)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Scene flow estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Huguet \u0026 Devernay (2007)", "label": "is_methodology_reference", "title": "Relation: is_methodology_reference\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "scene flow estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Huguet \u0026 Devernay (2007)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ICVV", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Semiglobal matching", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Stereo processing", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Mutual information", "label": "is_technique_for", "title": "Relation: is_technique_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Stereo processing", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "scene flow estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "stereo sequences", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Sun, Roth, \u0026 Black (2013)", "label": "provides_analysis", "title": "Relation: provides_analysis\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "optical flow estimation", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "optical flow estimation", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "scene flow estimation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Hornacek, Fitzgibbon, \u0026 Rother (2014)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SphereFlow", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Hornacek, Fitzgibbon, \u0026 Rother (2014)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "SphereFlow", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "scene flow", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Valgaerts et al. (2010)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "motion and geometry estimation", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "stereo sequences", "label": "provides_data_for", "title": "Relation: provides_data_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "motion estimation", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Kert et al. (2010)", "label": "references", "title": "Relation: references\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "motion and geometry estimation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wedel et al. (2008)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "scene flow computation", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Geiger et al. (2011)", "label": "focuses on", "title": "Relation: focuses on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "3D reconstruction techniques", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Menz", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Leibniz Universit\u00a8at Hannover", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Tal Hassner", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Effective Face Frontalization", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Shai Harel", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Effective Face Frontalization", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Eran Paz", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Effective Face Frontalization", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Roee Enbar", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Effective Face Frontalization", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Hassner_Effective_Face_Frontalization_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Effective Face Frontalization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "face recognition systems", "label": "operates_in", "title": "Relation: operates_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "unconstrained images", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "unconstrained images", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "varying poses", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "unconstrained images", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "varying expressions", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "unconstrained images", "label": "exhibits", "title": "Relation: exhibits\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "varying lighting", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "Fronalization", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "problem of varying poses", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "Fronalization", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "problem of varying lighting", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "previous methods", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "estimating 3D facial shapes", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "this paper", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "simpler approach", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "this paper", "label": "proposes leveraging", "title": "Relation: proposes leveraging\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "visual common sense", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "this paper", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "novel method", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "simpler approach", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "single 3D surface", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "frontal views", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "aesthetically pleasing", "width": 2.76}, {"arrows": "to", "color": "#FF5722", "from": "frontal views", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "face recognition", "width": 2.8}, {"arrows": "to", "color": "#FF5722", "from": "frontal views", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "gender estimation", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "Face frontalization", "label": "produces", "title": "Relation: produces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "aesthetically pleasing frontal views", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "AI systems", "label": "excels at", "title": "Relation: excels at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "factual question answering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "AI systems", "label": "struggles with", "title": "Relation: struggles with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "common sense reasoning", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "visual common sense", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "semantic knowledge", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao Lin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Virginia Tech", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Xiao Lin", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "linxiao@vt.edu", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Visual Common Sense", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "AI Reasoning", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Visual Paraphasing", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "AI Reasoning", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Hsu_Robust_Image_Alignment_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Hsu_Robust_Image_Alignment_2015_CVPR_paper.pdf", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "image alignment", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "process", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "process", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "data analysis", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "process", "label": "involves", "title": "Relation: involves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.78\u003cbr\u003eSource: unknown", "to": "optimization", "width": 2.56}, {"arrows": "to", "color": "#4CAF50", "from": "Data Analysis", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Parameter Estimation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Optimization", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "System Dynamics", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Parameter Estimation", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Relationship Modeling", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Rock_Compleeting_3D_Object_2015_CVPR_paper.pdf", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jason Rock", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jason Rock", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Illinois at Urbana-Champaign", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Justin Thorsten", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "JunYoung Gwak", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "JunYoung Gwak", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Illinois at Urbana-Champaign", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Daeyun Shin", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rock_Completing_3D_Object_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Daeyun Shin", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Illinois at Urbana-Champaign", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "3D Shape Reconstruction", "label": "is a", "title": "Relation: is a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "topic", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "3D Shape Reconstruction", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "View-Based Matching", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "3D Shape Reconstruction", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Shape Completion", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "3D Shape Reconstruction", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "3D Model Synthesis", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "3D Shape Reconstruction", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Symmetry Transfer", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Tanmay Gupta", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Illinois at Urbana-Champaign", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Liu_Data-Driven_Sparsity-Based_Restoration_2015_CVPR_paper.pdf", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Rui Caseiro", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond the Shortest Path", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Rui Caseiro", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Institute of Systems and Robotics - University of Coimbra", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond the Shortest Path", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Beyond the Shortest Path", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "domain adaptation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Beyond the Shortest Path", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "spline flow", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Pedro Martins", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond the Shortest Path", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Pedro Martins", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Systems and Robotics - University of Coimbra", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jorge Batista", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beyond the Shortest Path", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jorge Batista", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Institute of Systems and Robotics - University of Coimbra", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Jorge Batista", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Institute of Sistemas and Robotics - University of Coimbra", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "domain adaptation", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "improve_performance", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "spline flow", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "method", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "domain adaptation paradigm", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "source and target domains", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "shortest path", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "geodesic curve", "width": 2.98}, {"arrows": "to", "color": "#FF5722", "from": "shortest path", "label": "is insufficient", "title": "Relation: is insufficient\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "modeling complex domain shifts", "width": 2.84}, {"arrows": "to", "color": "#FF5722", "from": "shortest path", "label": "restricts", "title": "Relation: restricts\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "use of multiple datasets", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "novel approach", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "spline curves", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "novel approach", "label": "allows for", "title": "Relation: allows for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "integration of multiple source domains", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "novel approach", "label": "models", "title": "Relation: models\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "domain shifts", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "novel approach", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "improved performance", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "spline curves", "label": "computed via", "title": "Relation: computed via\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "rolling maps", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Domain Adaptation", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "domain shifts", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Domain Adaptation", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "performance", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Subspace Representation", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Domain Adaptation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Baktas et al. (2013)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Domain Invariant Projection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Gopalan et al. (2013)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "location recognition", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Gopalan et al. (2011)", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Unsupervised approach", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Carreira et al. (2012)", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Semantic segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Caseiro et al. (2010)", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "cast shadows", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Gopalan et al. (2014)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "intermediate data representations", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "Spline Flow", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Domain Adaptation", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Grasmannn Manifold", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Domain Adaptation", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Rolling Maps", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.65\u003cbr\u003eSource: unknown", "to": "Domain Adaptation", "width": 2.3}, {"arrows": "to", "color": "#4CAF50", "from": "Gopalan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Unsupervised adaptation across domain shifts by generating intermediate data representations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Li", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Unsupervised adaptation across domain shifts by generating intermediate data representations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Griffin", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Caltech-256 object category dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Holub", "label": "co-developed", "title": "Relation: co-developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Cal tech-256 object category dataset", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Caseiro", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "non-parametric riemannian framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Henriques", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "non-parametric riemannian framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Martins", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "non-parametric riemannian framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Batista", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "non-parametric riemannian framework", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Hays", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Im2gps", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Efroos", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Im2gps", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pan", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A survey on transfer learning", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Jo\u00e3o F. Henriques", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Institute of Systems and Robotics - University of Coimbra", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Sparse Composite Quantization", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Sparse Composite Quantization", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Sparse Composite Quantization", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "quantization techniques", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_Sparse_Composite_Quantization_2015_CVPR_paper", "label": "is_file_name", "title": "Relation: is_file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "PDF document", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "sparse composite quantization", "label": "is_approach_for", "title": "Relation: is_approach_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "approximate nearest neighbor search", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "sparse composite quantization", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "competitive search accuracy", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "sparse composite quantization", "label": "builds_on", "title": "Relation: builds_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "product quantization", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "sparse composite quantization", "label": "builds_on", "title": "Relation: builds_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Cartesian k-means", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "sparse composite quantization", "label": "builds_on", "title": "Relation: builds_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "composite quantization", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "sparse composite quantization", "label": "constructs", "title": "Relation: constructs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "sparse dictionaries", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "sparse composite quantization", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "distance table computation time", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Cartesian k-means", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "variation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Cartesian k-means", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR (2013)", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "distance table computation", "label": "is_bottleneck_in", "title": "Relation: is_bottleneck_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "composite quantization", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "distance table computation", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "time", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "sparse dictionaries", "label": "accelerates", "title": "Relation: accelerates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "distance evaluation", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "large-scale datasets", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "SIFTs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "SIFTs", "label": "has_scale", "title": "Relation: has_scale\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "1M", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "SIFTs", "label": "scale", "title": "Relation: scale\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "1B", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "search times", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "faster", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "SIFTS", "label": "has_scale", "title": "Relation: has_scale\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "1B", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "ANN", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "nearest neighbor search", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Product Quantization", "label": "is_technique", "title": "Relation: is_technique\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "for nearest neighbor search", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Babenko and Lempitsky (2012)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "inverted multi-index", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Babenko and Lempitsky (2014)", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "bilayer product quantization", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Babenko and Lempitsky (2014)", "label": "targets", "title": "Relation: targets\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "billion-scale approximate nearest neighbors", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "bilayer product quantization", "label": "builds_upon", "title": "Relation: builds_upon\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "product quantization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "bilayer product quantization", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "large-scale applications", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "High-Dimensional Data", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "approximate nearest neighbors", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "vocabulary trees", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "scalable recognition", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Hamming embedding", "label": "utilized_for", "title": "Relation: utilized_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.89\u003cbr\u003eSource: unknown", "to": "large scale image search", "width": 2.7800000000000002}, {"arrows": "to", "color": "#4CAF50", "from": "semi-supervised hashing", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "large-scale search", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Re-ranking strategies", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "large-scale search", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Graph-based search methods", "label": "focuses on", "title": "Relation: focuses on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "search", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Angular quantization", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "binary codes", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Guo-Jun Qi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Central Florida", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jinhui Tang", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Unknown", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Jinhui Tang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Nanjing University of Science and Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ting Zhang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "University of Science and Technology of China", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jingding Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ioannis Gkioulekalas", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On the Appearance of Translueceny Edges", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "On the Appearence of Translueceny Edges", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Gkiooulekas_On_the_Appearance_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "On the Appearence of Translueceny Edges", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Edges in images", "label": "differ from", "title": "Relation: differ from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Edges in opaque objects", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Edges", "label": "caused by", "title": "Relation: caused by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Discontinuity in surface orientation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Authors", "label": "explain", "title": "Relation: explain\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Edge patterns", "width": 2.9}, {"arrows": "to", "color": "#FF5722", "from": "Edge patterns", "label": "result from", "title": "Relation: result from\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Light Transport", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Simulations", "label": "utilize", "title": "Relation: utilize\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Scattering parameters", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Visual Inference tasks", "label": "involve", "title": "Relation: involve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Shape estimation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Visual Inference tasks", "label": "involve", "title": "Relation: involve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Material estimation", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Light Transport", "label": "addressed_in", "title": "Relation: addressed_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Jensen et al. (2001)", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Wave Propagation", "label": "described_in", "title": "Relation: described_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Ishimaru (1978)", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Stereo Reconstruction", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Wave Propagation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Human Perception", "label": "studied_in", "title": "Relation: studied_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Adelson (2001)", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Machine Vision", "label": "informed_by", "title": "Relation: informed_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Human Perception", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Rendering", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Light Transport", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Reconstruction", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Light Transport", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Translucent Objects", "label": "involved_in", "title": "Relation: involved_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Shape Estimation", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Translucent Objects", "label": "involved_in", "title": "Relation: involved_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Material Estimation", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Material Metameters", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Translucent Objects", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "light transport", "label": "occurs_within", "title": "Relation: occurs_within\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "translucient materials", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "rendering", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "accurate light transport", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "translucent materials", "label": "exhibit", "title": "Relation: exhibit\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "translucent appearance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "translucent materials", "label": "has_property", "title": "Relation: has_property\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "translucency", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "phase functions", "label": "important_for", "title": "Relation: important_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "translucent appearance", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "reconstruction", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "accurate rendering", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "phase function", "label": "affects", "title": "Relation: affects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "translucent appearance", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "photon diffusion", "label": "is_rendering_technique_for", "title": "Relation: is_rendering_technique_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "translucent materials", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Open-surfaces catalog", "label": "is_dataset_of", "title": "Relation: is_dataset_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "surface appearances", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "surface appearances", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "training", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "surface appearances", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "evaluation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "evaluation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "hybrid multi-camera and marker-based capture dataset", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "ACM Transactions on Graphics", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "research on phase function", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "ACM Transactions on Graphics", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Bala. Open-surfaces", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Journal of Vision", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "research on translucency", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "ACM SIGGRAPH", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "research on rendering techniques", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Bala. Open-surfaces", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "dataset of surface appearances", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Gkiouslekas et al.", "label": "examines", "title": "Relation: examines\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "phase function in translucent appearance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "materials in context database", "label": "relevant for", "title": "Relation: relevant for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "translucent objects", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Mingkui Tan", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning graph structure...", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mingkui Tan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Adelaide", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Learning graph structure...", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Learning graph structure...", "label": "file_name", "title": "Relation: file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Tan_Learning_Graph_Structure_2015_CVPR_paper.pdf", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Qinfeng Shi", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning graph structure...", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Qinfeng Shi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Adelaide", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Fuyuan Hu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning graph structure...", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Zhen Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning graph structure...", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Multi-label image classification", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Classification performance", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Multi-label image classification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Probablistic Graphical Models", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Probabilistic Graphical Models", "label": "represents", "title": "Relation: represents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Label dependency", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Graphical model structure", "label": "determined by", "title": "Relation: determined by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Heuristic methods", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Graphical model structure", "label": "learned from", "title": "Relation: learned from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Limited information", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Problem", "label": "formulated into", "title": "Relation: formulated into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Max-margin framework", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Problem", "label": "transformed into", "title": "Relation: transformed into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Convex programming problem", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Max-margin framework", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.65\u003cbr\u003eSource: unknown", "to": "learning", "width": 2.3}, {"arrows": "to", "color": "#4CAF50", "from": "Procedure", "label": "activates", "title": "Relation: activates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Set of cliques", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "performance improvement", "label": "over", "title": "Relation: over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "methods", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Graph structure learning", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Probablistic Graphical Models", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Clique generation", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Graph structure learning", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Boutell et al. (2004)", "label": "studied", "title": "Relation: studied\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "scene classification", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Bradley \u0026 Guestrin (2010)", "label": "studied", "title": "Relation: studied\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "tree conditional random fields", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Bucak et al. (2009)", "label": "studied", "title": "Relation: studied\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "multi-label ranking", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Efficient multi-label ranking", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Efficient multi-label ranking", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Conference on Computer Vision and Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jain, A. K.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Efficient multi-label ranking", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cai, X.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Graph structured sparsity model", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chow, C.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Approximating discrete probability distributions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Approximating discrete probability distributions", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Information Theory", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Liu, C.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Approximating discrete probability distributions", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dembczy\u0144ski, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Label dependence and loss minimization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Label dependence and loss minimization", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Machine Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Waegeman, W.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Label dependence and loss minimization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Waegeman, W.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Analysis of chaining", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng, W.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Label dependence and loss minimization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "H\u00fcllermeier, E.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Label dependence and loss minimization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "H\u00fcllermeier, E.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Analysis of chaining", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dembczynski, K.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Analysis of chaining", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Analysis of chaining", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "European Conference on Artificial Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Dembczynski", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "analysis of chaining", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Dembczynski", "label": "affilates_with", "title": "Relation: affilates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "European Conference on Artificial Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Everingham", "label": "created", "title": "Relation: created\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "PASUAL Visual Object Classes Challenge 2012", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bolei Zhou", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ConceptLearner", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bolei Zhou", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "MIT", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ConceptLearner", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ConceptLearner", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "scalable approach", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "ConceptLearner", "label": "discovers", "title": "Relation: discovers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "visual concepts", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "ConceptLearner", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "promising performance", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "ConceptLearner", "label": "compared to", "title": "Relation: compared to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "fully supervised methods", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "ConceptLearner", "label": "compared to", "title": "Relation: compared to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "weakly supervised methods", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Vignesh Jagadeesh", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ConceptLearner", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Vignesh Jagadeesh", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "eBay Research Labs", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhou_ConceptLearner_Discovering_Visual_2015_CVPR_paper.pdf", "label": "is_file_of", "title": "Relation: is_file_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Charles Sturt University", "label": "has_author", "title": "Relation: has_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Junbin Gao", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "computer vision recognition systems", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "visual knowledge", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "fully labeled data", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "expensive", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "visual concept detectors", "label": "are learned", "title": "Relation: are learned\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "automatically", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "visual concept detectors", "label": "applied to", "title": "Relation: applied to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "image region-level detection", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "learned concepts", "label": "evaluated_for", "title": "Relation: evaluated_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "scene recognition", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "learned concepts", "label": "evaluated_for", "title": "Relation: evaluated_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "fully supervised methods", "label": "outperformed_by", "title": "Relation: outperformed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "weakly supervised methods", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "weakly supervised methods", "label": "outperformed_by", "title": "Relation: outperformed_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "domain-specific supervision", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "automatic attribute discovery", "label": "characterized_from", "title": "Relation: characterized_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "noisy web data", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Im2text", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "images", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Im2text", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "captioned photographs", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "object detectors", "label": "adapted_from", "title": "Relation: adapted_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "images", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "object detectors", "label": "adapted_to", "title": "Relation: adapted_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "video", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Deng et al.", "label": "created", "title": "Relation: created\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Imaginet", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Places database", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "scene recognition", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Zhou et al.", "label": "utilized", "title": "Relation: utilized\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Places database", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Piction", "label": "labels", "title": "Relation: labels\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "human faces", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Srihari", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Piction", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Divvala et al.", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "webly-supervised visual concept learning", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Tang et al.", "label": "adapted", "title": "Relation: adapted\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "object detectors", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "AAAI", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "AAAI Press", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "AAAI", "label": "published_by", "title": "Relation: published_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The MIT Press", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Divvala, S. K.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Robinson Piramuthu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "eBay Research Labs", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yumin Suh", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Subgraph Matching using Compactness Prior", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yumin Suh", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Seoul National University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Subgraph Matching using Compactness Prior", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kamil Adamczewski", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Subgraph Matching using Compactness Prior", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kamil Adamczewski", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Seoul National University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Suh_Subgraph_Matching_Using_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Subgraph Matching using Compactness Prior", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Feature correspondence", "label": "plays_role_in", "title": "Relation: plays_role_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "computer vision applications", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Feature correspondence", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "2009 IEEE 12th International Conference on Computer Vision", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Graph matching", "label": "is_formulated_as", "title": "Relation: is_formulated_as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "problem", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Graph matching algorithms", "label": "rarely_considers", "title": "Relation: rarely_considers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "precision", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Solutions", "label": "have", "title": "Relation: have\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "outliers", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Subgraph matching formulation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "compactness prior", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "compactness prior", "label": "prefers", "title": "Relation: prefers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "sparsity", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "compactness prior", "label": "eliminates", "title": "Relation: eliminates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "outliers", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Meta-algorithm", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Markov chain Monte Carlo", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Formulation and algorithm", "label": "improve", "title": "Relation: improve\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "baseline performance", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cho, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Learning graphs to match", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cho, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Feature correspondence", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Cho, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Reweighted random walks", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Cho, M.", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "max-pooling strategy", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Reweighted random walks", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Computer Vision\u2013ECCV 2010", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Progressive graph matching", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Alahari, K.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Learning graphs to match", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Ponce, J.", "label": "co-authored", "title": "Relation: co-authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Learning graphs to match", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Lee, Kyoung Mu", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Seoul National University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lee, Kyoung Mu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "progressive graph matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Adamczewski, Kamil", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Seoul National University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Suh, Yumin", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Seoul National University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Duchenne, O.", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "tensor-based algorithm", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Duchenne, O.", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Gilks, W. R.", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Markov chain monte carlo", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cour, T.", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "balanced graph matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "progressive graph matching", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "IEEE Conference on Computer Vision and Pattern Recognition", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Guancong Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Good Features to Track for Visual SLAM", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Guancong Zhang", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Zhang_Good_Features_to_2015_CVPR_paper.pdf", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Good Features to Track for Visual SLAM", "label": "is_publication_of", "title": "Relation: is_publication_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Good Features to Track for Visual SLAM", "label": "published_in_year", "title": "Relation: published_in_year\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "2015", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Patricio A. Vela", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Good Features to Track for Visual SLAM", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Patricio A. Vela", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Zhang_Good_Features_to_2015_CVPR_paper.pdf", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Patricio A. Vela", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "pvela@gatech.edu", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_Good_Features_to_2015_CVPR_paper.pdf", "label": "is_file_of", "title": "Relation: is_file_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "measured features", "label": "contribute_to", "title": "Relation: contribute_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "accurate localization", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "method for selecting features", "label": "is_useful_for", "title": "Relation: is_useful_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "localization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "method for selecting features", "label": "is_derived_from", "title": "Relation: is_derived_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "observability of SLAM", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "method for selecting features", "label": "integrates_into", "title": "Relation: integrates_into\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "existing SLAM systems", "width": 2.88}, {"arrows": "to", "color": "#FF5722", "from": "method for selecting features", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "localization accuracy", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "estimation utility", "label": "is_formulated_with", "title": "Relation: is_formulated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "observability indices", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "observability indices", "label": "are_computed_using", "title": "Relation: are_computed_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "incremental singular value decomposition (SVD)", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "observability indices", "label": "calculated_using", "title": "Relation: calculated_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "greedy selection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "observability indices", "label": "described_by", "title": "Relation: described_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "incremental singular value decomposition", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "greedy selection", "label": "is_approximately", "title": "Relation: is_approximately\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "submodular", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "greedy selection", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "near-optimal", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "SLAM", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "SfM", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "incremental singular value decomposition", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "temporal observability indices", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "synthetic experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "improved localization accuracy", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "SLAM experiments", "label": "demonstrate", "title": "Relation: demonstrate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "improved data association", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "Visual SLAM", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Data Association", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Data Association", "label": "addressed_by", "title": "Relation: addressed_by\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Incremental SVD", "width": 2.76}, {"arrows": "to", "color": "#FF5722", "from": "Observability Analysis", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "map_building", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "MonoSLAM", "label": "implements", "title": "Relation: implements\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "real-time SLAM", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "LSD-SLAM", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "direct monocular SLAM", "width": 2.74}, {"arrows": "to", "color": "#2196F3", "from": "LSD-SLAM", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Slam_Algorithm", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Covariance recovery", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "data association", "width": 2.8600000000000003}, {"arrows": "to", "color": "#FF5722", "from": "Feature Selection", "label": "influences", "title": "Relation: influences\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "localization accuracy", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Andrade-Cetto and Sanfeliu", "label": "analyzed", "title": "Relation: analyzed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "partial observability", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kaess and Dellaert", "label": "proposed", "title": "Relation: proposed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "covariance recovery", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Davison et al.", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "MonoSLAM", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Engel et al.", "label": "created", "title": "Relation: created\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "LSD-SLAM", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Slam_Algorithm", "label": "is_field_of", "title": "Relation: is_field_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Machine Intelligence", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "iSAM2", "label": "is_algorithm", "title": "Relation: is_algorithm\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Bayes Tree", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "iSAM2", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Incremental Smoothing", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "iSAM2", "label": "is_variant_of", "title": "Relation: is_variant_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Slam", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Active search", "label": "is_topic_of", "title": "Relation: is_topic_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "IEEE International Conference on Computer Vision", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Live dense reconstruction", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Single moving camera", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of ECR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng Ma", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "zhanggc@gatech.edu", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Zheng Ma", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "City University of Hong Kong", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lei Yu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of ECR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lei Yu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "City University of Hong Kong", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Antoni B. Chan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of ECR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Antoni B. Chan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "City University of Hong Kong", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Georgia Tech", "label": "has_affiliation", "title": "Relation: has_affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "School of ECE", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ma_Small_Instance_Detection_2015_CVPR_paper", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Ma_Small_Instance_Detection_2015_CVPR_paper", "label": "file_path", "title": "Relation: file_path\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Small Instance Detection", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Integer Programming", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Small Instance Detection", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Object Density Maps", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Small Instance Detection", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Integer Programming", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Object Density Maps", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computer Vision", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "pedestrians", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "partially-occluded small instances", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "cells", "label": "is_example_of", "title": "Relation: is_example_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "partially-occluding small instances", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "2D integer programming", "label": "is_used_to", "title": "Relation: is_used_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "recover object instance locations", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "ROI counts", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2D integer programming", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "density map", "label": "regularizes", "title": "Relation: regularizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "detection performance", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "object instances", "label": "located_using", "title": "Relation: located_using\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "2D integer programming", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "HOG features", "label": "is_feature_descriptor_for", "title": "Relation: is_feature_descriptor_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "human detection", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "HOG features", "label": "used in", "title": "Relation: used in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Bayesian regression", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "crowd counting", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Crowd counting", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "low-level features", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Crowd counting", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "multiple local features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Conf. Computer Vision and Pattern Recognition", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "HOG features", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "IEEE Trans. on Image Processing", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Bayesian regression", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Digital Image Computing: Techniques and Applications", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Crowd counting using multiple local features", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Human detection", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "HOG features", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Sridharan (2009)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "crowd counting", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Sridharan (2009)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "multiple local features", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lowe (2004)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "SIFT features", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Chan (2008)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "privacy concerns", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Chan (2008)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "crowd monitoring", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Zhao (2003)", "label": "focuses on", "title": "Relation: focuses on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Bayesian segmentation", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Bayesian segmentation", "label": "applied to", "title": "Relation: applied to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "crowded scenes", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "R. ia", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Bayesian segmentation", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lemtipsky, V.", "label": "works_on", "title": "Relation: works_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "object counting", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "PASCAL VOC challenge", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "benchmark", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "PASCAL VOC challenge", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "City University of Hong Kong", "label": "has_member", "title": "Relation: has_member\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Antoni B. Chan", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mohammad Rastegari", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computationally Bound Retrieval", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Mohammad Rastegari", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Computationally Bounded Retrieval", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Mohammad Rastegari", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "University of Maryland", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Computationally Bounded Retrieval", "label": "is_paper_from", "title": "Relation: is_paper_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Cem Keskin", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Computationally Bounded Retrieval", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cem Keskin", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shahram Izadi", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Computationally Bounded Retrieval", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shahram Izadi", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Microsoft Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Rastegari_Computationally_Bounded_Retrieval_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Computationally Bounded Retrieval", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Rastegari_Computationality_Bounded_Retrieval_2015_CVPR_paper", "label": "is_title_of", "title": "Relation: is_title_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Computationally Bounded Retrieval", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "large image databases", "label": "makes", "title": "Relation: makes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "efficient retrieval challenging", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "high dimensional data", "label": "poses", "title": "Relation: poses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "retrieval challenge", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "hashing methods", "label": "sacrifices", "title": "Relation: sacrifices\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "accuracy for speed", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "orthogonality constraint", "label": "reduces", "title": "Relation: reduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "bit correlation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "iterative scheme", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "objective", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "Near-optimal Hasing Algorithms", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Approximate Nearest Neighbor", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Near-optimal Hasing Algorithms", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "High Dimensions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Datar et al. (2004)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Locality-Sensitive Hashing Scheme", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Locality-Sensitive Hashing Scheme", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "P-stable Distributions", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Methods", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Speed-up", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Speed-up", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "factor of 100", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Gong et al. (2013)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Computer Vision and Pattern Recognition (CVPR), 2013", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gong et al. (2013)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "bilinear projections", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Gong \u0026 Lazebnik (2011)", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "2011 IEEE Conference on Computer Vision and Pattern Recognition", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Gong \u0026 Lazebnik (2011)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "iterative quantization", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "J\u00e9goeu et al. (2009)", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Searching with quantization", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Searching with quantization", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "short codes", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "J\u00e9gou et al (2009)", "label": "researches", "title": "Relation: researches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "approximate nearest neighbor search", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevskya et al (2012)", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "ImageNet classification", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Krizhevskya et al (2012)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "deep convolutional neural networks", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Majia et al (2013)", "label": "focuses on", "title": "Relation: focuses on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "efficient classification", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Norouzia et al (2011)", "label": "develops", "title": "Relation: develops\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "minimal loss hashing", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "New Insights into Laplacian Similarity Search", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Wu_New_Insights_Into_2015_CVPR_paper.pdf", "label": "is_document_of", "title": "Relation: is_document_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "New Insights into Laplacian Similarity Search", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Graph-based computer vision applications", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "similarity metrics", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "similarity metrics", "label": "computes", "title": "Relation: computes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "pairwise similarity", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "pairwise similarity", "label": "is_between", "title": "Relation: is_between\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "vertices", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "(L + \u03b1\u039b)\u22121", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "graph Laplacian", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "(L + \u03b1\u039b)\u22121", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "positive diagonal matrix", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "(L + \u03b1\u039b)\u22121", "label": "respects", "title": "Relation: respects\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "graph topology", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "positive diagonal matrix", "label": "acts_as", "title": "Relation: acts_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "regularizer", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "regularizer", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "cluster density", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "regularizer", "label": "denotes", "title": "Relation: denotes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "\u039b", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "choices", "label": "lead_to", "title": "Relation: lead_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "complementary behaviors", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Paper (1999)", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Pagerank Citation Ranking", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Paper (1999)", "label": "validates", "title": "Relation: validates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Pagerank Citation Ranking", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "bring order to web", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chung (1997)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Spectral Graph Theory", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Spectral Graph Theory", "label": "covers", "title": "Relation: covers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Graph Topology", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Andersen et al. (2006)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Pagerank Vectors", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Andersen et al. (2006)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Local Graph Partitioning", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Belkin \u0026 Niyogi (2001)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Laplacian Eigenmaps", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shi \u0026 Malik (2000)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Normalized Cuts", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Laplacianfaces", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "face recognition", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Random walks", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "image segmentation", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Wu, X.-M.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Columbia University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wu, X.-M.", "label": "works_in", "title": "Relation: works_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Electrical Engineering", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Wu, X.-M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Analyzing the harmonic structure in graph-based learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wu, X.-M.", "label": "works_in", "title": "Relation: works_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Department of Electrical Engineering", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Wu, X.-M.", "label": "contributes_to", "title": "Relation: contributes_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "graph-based learning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "graph-based learning", "label": "analyzes", "title": "Relation: analyzes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "harmonic structure", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Chang, S.-F.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Analyzing the harmonic structure in graph-based learning", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wenguan Wang", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saliency-Aware Geodesic Video Object Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wenguan Wang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beijing Lab of Intelligent Information Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wenguan Wang", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "School of Computer Science", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wenguan Wang", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beijing Institute of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Saliency-Aware Geodesic Video Object Segmentation", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Jianbing Shen", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saliency-Aware Geodesic Video Object Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jianbing Shen", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beijing Lab of Intelligent Information Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Jianbing Shen", "label": "located_in", "title": "Relation: located_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Beijing Institute of Technology", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fatih Porikli", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Saliency-Aware Geodesic Video Object Segmentation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Fatih Porikli", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Research School of Engineering", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fatih Porikli", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Australian National University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Fatih Porikli", "label": "member_of", "title": "Relation: member_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NICTA Australia", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Saliency-Aware Geosesic Video Object Segmentation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "unsupervised method", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "geodesic distance", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "spatial edges", "label": "are_indicators_of", "title": "Relation: are_indicators_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "spatiotemporal salience maps", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Video Object Segmentation", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Energy Minimization", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Video Object Segmentation", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "spatially and temporally coherent object segmentation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Geos image segmentation", "label": "introduced_in", "title": "Relation: introduced_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "ECCV, 2008", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Geos image segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "geodesic image segmentation approach", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "Motion Boundaries", "label": "relevant_to", "title": "Relation: relevant_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Video Object Segmentation", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Geos", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "geospatial image segmentation approach", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Geos", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "image segmentation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Geodesic graph cut", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "interactive image segmentation", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Grabcut", "label": "is_method_of", "title": "Relation: is_method_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "interactive foreground extraction", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Grabcut", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "iterated graph cuts", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Object segmentation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "trajectory analysis", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Video object segmentation", "label": "addressed by", "title": "Relation: addressed by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "W. Brendel and S. Todorovic", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Geodesic image and video editing", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "geodesic methods", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "J. Carreira", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Constrained parametric min-cuts", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "W. Brendel", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Video object segmentation by tracking regions", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "D. Tsai", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Motion coherent tracking using multi-label mrf optimization", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Tali Dekel", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Best-Buddies Similarity", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Tali Dekel", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "MIT CSAIL", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Best-Buddies Similarity", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Best-Buddies Similarity", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "template matching", "label": "occurs_in", "title": "Relation: occurs_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "unconstrained environments", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Best-Buddies Similarity (BBS)", "label": "is", "title": "Relation: is\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "similarity measure", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Best-Buddies Similarity (BBS)", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "counting Best-Buddie Pairs (BBPs)", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Best-Buddies Similarity (BBS)", "label": "is_robust_against", "title": "Relation: is_robust_against\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "geometric deformations", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Best-Buddies Similarity (BBS)", "label": "is_robust_against", "title": "Relation: is_robust_against\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "outliers", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Best-Buddies Similarity (BSS)", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "parameter-free", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Best-Buddie Pairs (BBPs)", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "pairs of points", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "BBS", "label": "solves", "title": "Relation: solves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "non-rigid object tracking", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "BBS", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "consistent success", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "BBS", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Similarity Measures", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "BBS", "label": "handles", "title": "Relation: handles\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Outlier Robustness", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "BBS", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.65\u003cbr\u003eSource: unknown", "to": "Geometric Deformations", "width": 2.3}, {"arrows": "to", "color": "#4CAF50", "from": "Comaniciu, D. et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "mean shift tracking", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "mean shift tracking", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "non-rigid object tracking", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Rubner, Y. et al.", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Earth Mover\u0027s Distance", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Earth Mover\u0027s Distance", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "metric for image retrieval", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Earth Mover\u0027s Distance", "label": "is_metric_for", "title": "Relation: is_metric_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "image comparison", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Earth Mover\u0027s Distance", "label": "introduced_by", "title": "Relation: introduced_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Rubner et al. (2000)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Pele et al. (2008)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "robust pattern matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simaov et al. (2008)", "label": "explores", "title": "Relation: explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "summarizing visual data", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Simaov et al. (2008)", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "similarity measures", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Hel-Or et al. (2014)", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "photometric invariant template matching", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "photometric invariant template matching", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "matching technique", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Tian et al. (2012)", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "estimating nonrigid image distortions", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "nonrigid image distortions", "label": "impacts", "title": "Relation: impacts\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "image estimation", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Tian \u0026 Narasimhan (2012)", "label": "deals_with", "title": "Relation: deals_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "nonrigid image distortions", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Korman et al. (2013)", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "fast affine template matching algorithm", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Wu et al. (2013)", "label": "provides", "title": "Relation: provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "online object tracking benchmark", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Olson (2002)", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "maximum-likelihood image matching", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Michael Rubinstein", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Google Research", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Shai Avidan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Tel Aviv University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Shai Avidan", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "avidan@eng.tau.ac.il", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Nianyi Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Weighted Sparse Coding Framework for Saliency Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Nianyi Li", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "A Weighted Sparse Coding Framework", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Nianyi Li", "label": "affilates_with", "title": "Relation: affilates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Tel Aviv University", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Bilin Sun", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Weighted Sparse Coding Framework for Saliency Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bilin Sun", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "A Weighted Sparse Coding Framework", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Jingyi", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "A Weighted Sparse Coding Framework for Saliency Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A Weighted Sparse Coding Framework", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Saliency Detection", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "A Weighted Sparse Coding Framework", "label": "is_paper_type", "title": "Relation: is_paper_type\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jingyi Yu", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "A Weighted Sparse Coding Framework", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "avidan@eng.tau.ac.il", "label": "email_associated_with", "title": "Relation: email_associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Nianyi Li", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "billf@mit.edu", "label": "email_associated_with", "title": "Relation: email_associated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "William T. Freeman", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Li_A_Weighted_Sparse_2015_CVPR_paper", "label": "is_file", "title": "Relation: is_file\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "pdf", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "salience detection", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "high-dimensional datasets", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "dictionaries", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "data-speci\ufb01c features", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "dictionary", "label": "prunes", "title": "Relation: prunes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "outliers", "width": 2.8}, {"arrows": "to", "color": "#FF5722", "from": "dictionary", "label": "refined_by", "title": "Relation: refined_by\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "superpixels", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Liu et al. (2011)", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Salience Detection", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Liu et al. (2011)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Achanta et al. (2012)", "label": "compares", "title": "Relation: compares\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Superpixels", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Achanta et al. (2012)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Borji \u0026 Itti (2012)", "label": "exploits", "title": "Relation: exploits\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Patch Rarities", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Borji, Sihite, \u0026 Itti (2012)", "label": "introduces", "title": "Relation: introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Salient Object Detection Benchmark", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Borji, Sihite, \u0026 Itti (2012)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Reynolds \u0026 Desimone", "label": "study", "title": "Relation: study\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "V4", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Reynolds \u0026 Desimone", "label": "investigate", "title": "Relation: investigate\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "attention", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Reynolds \u0026 Desimone", "label": "Published in", "title": "Relation: Published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Neuron", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Nothdurft", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "additivity across dimensions", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Nothdurft", "label": "studies", "title": "Relation: studies\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "salience from feature contrast", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Perazzi et al.", "label": "develops", "title": "Relation: develops\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "salience filters", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Perazzi et al.", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "contrast based filtering", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cheng et al.", "label": "develops", "title": "Relation: develops\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Global contrast based salient region detection", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Borji et al.", "label": "presents", "title": "Relation: presents\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "cal and global patch rarities", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Movahedi \u0026 Elder", "label": "validates", "title": "Relation: validates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "performance measures", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Reynolds \u0026 Desimnone", "label": "studied", "title": "Relation: studied\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "V4", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Itti \u0026 Koch", "label": "Published in", "title": "Relation: Published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Nature Reviews Neuroscience", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Reynolds", "label": "Published in", "title": "Relation: Published in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Souvenir", "label": "affiliated with", "title": "Relation: affiliated with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "University of Delaware", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Souvenir", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Robust Regression on Image Manifolds", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Sun", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "sunbilin@eecis.udel.edu", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Yu", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "yu@eecis.udel.edu", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "robust regression method", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "non-parametric", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "mis-labeled examples", "label": "has", "title": "Relation: has\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "ordered labels", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "label corruption levels", "label": "reaches", "title": "Relation: reaches\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "80%", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "image labels", "label": "describe", "title": "Relation: describe\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "associated images", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Ordered Labels", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Ordinal Data", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Label Denoising", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "accuracy of image labels", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "Building Rome in a day", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE International Conference on Computer Visions", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "R. C. Bolles", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Random sample consensus", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "C.-C. Chang", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LIBSVM", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "C.-J. Lin", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LIBSVM", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "USAC", "label": "framework for", "title": "Relation: framework for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Random sample consensus", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "R. Raguram", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "USAC", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "l-curve", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Analysis of discrete ill-posed problems", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "P. C. Hansen", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "Analysis of discrete ill-posed problems", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Internet photo collections", "label": "used for", "title": "Relation: used for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Modeling the world", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "N. Snavely", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Modeling the world", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "SIAM review", "label": "is_published_in", "title": "Relation: is_published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "journal", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kai Han", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "A Fixed Viewpoint Approach", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Kai Han", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The University of Hokkaido", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "A Fixed Viewpoint Approach", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "paper", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kwan-Yee K. Wong", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "A Fixed Viewpoint Approach", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Kwan-Yee K. Wong", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The University of Hokkaido", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Miaomiao Liu", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "A Fixed View Point Approach", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Miaomiao Liu", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "NICTA", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Miaomiao Liu", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CECS, ANU", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "light path triangulation", "label": "relates_to", "title": "Relation: relates_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "refractive photo-light-path", "width": 2.6399999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "M. Ben-Ezra and S. K. Nayr", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "transparency analysis", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "G. Eren et al.", "label": "proposes", "title": "Relation: proposes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.86\u003cbr\u003eSource: unknown", "to": "shape estimation", "width": 2.7199999999999998}, {"arrows": "to", "color": "#4CAF50", "from": "shape estimation", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.84\u003cbr\u003eSource: unknown", "to": "local surface heating", "width": 2.6799999999999997}, {"arrows": "to", "color": "#4CAF50", "from": "local surface heating", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "shape estimation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Fischler and Bolles", "label": "Introduces", "title": "Relation: Introduces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "RANSAC", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Hata et al.", "label": "Explores", "title": "Relation: Explores\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "genetic algorithm", "width": 2.94}, {"arrows": "to", "color": "#2196F3", "from": "genetic algorithm", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "shape extraction", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Ihrke et al. (2005)", "label": "Demonstrates", "title": "Relation: Demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "geometry reconstruction", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "geometry reconstruction", "label": "occurs_in", "title": "Relation: occurs_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "dynamic environments", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Ihrke et al. (2008)", "label": "Provides", "title": "Relation: Provides\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "overview", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Transparent objects", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "shape estimation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Benjamin Allain", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "An Efficient Volumetric Framework for Shape Tracking", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Benjamin Allain", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Inria Grenoble Rh\u02c6one-Alpes - LJK", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Benjamin Allain", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Inria Grenoble Rh\u02c6one- Alpes", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Benjamin Allain", "label": "is_affiliated_with", "title": "Relation: is_affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "LJK", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "An Efficient Volumetric Framework for Shape Tracking", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "An Efficient Volumetric Framework for Shape Tracking", "label": "file_name", "title": "Relation: file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Allain_An_Efficient_Volumetric_2015_CVPR_paper.pdf", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jean-S\u00e9batian Franco", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "An Efficient Volumetric Framework for Shape Tracking", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Edmond Boyer", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "An Efficient Volumetric Framework for Shape Tracking", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Edmond Boyer", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Inria Grenoble Rh\u02c6one-Alpes - LJK", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "surface-based strategies", "label": "can_fail_when", "title": "Relation: can_fail_when\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "observations define several feasible surfaces", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "this work", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "volumetric shape parametrization", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "volumetric shape parametrization", "label": "utilizes", "title": "Relation: utilizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Centroidal Voronoi Tesselations (CVT)", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "volumetric deformation model", "label": "demonstrates", "title": "Relation: demonstrates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "improved precision and robustness", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "volumetric deformation model", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "volumetric shape tracking", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Centroidal Voronoi Tesselations (CVT)", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Volumetric Shape Tracking", "label": "compares_to", "title": "Relation: compares_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "state-of-the-art methods", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Centroidal Voronoi Tesselations", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "method", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Dynamic Shape Capture", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "method", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Motion Estimation", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "method", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Surface-based Methods", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Volume-based Methods", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Alexa et al. (2000)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "As-rigid-as-possible shape interpolation", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Allain et al. (2014)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "On mean pose and variability of 3d deformable models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Ballan \u0026 Cortelazzo (2008)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Marker-less motion capture of skinned models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Bishop (2006)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Pattern Recognition and Machine Learning", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Botsu et al. (2007)", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Adaptive space deformations based on rigid cells", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive space deformations based on rigid cells", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Comput. Graph. Forum", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Botsu, M.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Adaptive space deformations based on rigid cells", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cagniart, C.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Free-form mesh tracking: a patch-based approach", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cagniart, C.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Probabilistic deformable surface tracking from multiple videos", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Free-form mesh tracking: a patch-based approach", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Probabilistic deformable surface tracking from multiple videos", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "de Aguiar, E.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Performance capture from sparse multi-view video", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Performance capture from sparse multi-view video", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ACM Transactions on Graphics", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "de Aguliar, E.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Marker-less deformable mesh tracking for human shape and motion capture", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Benjamin Allaine", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "firstname.lastname@inria.fr", "width": 2.98}, {"arrows": "to", "color": "#2196F3", "from": "Maximum likelihood", "label": "method_used_in", "title": "Relation: method_used_in\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "em algorithm", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "em algorithm", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Maximum likelihood from incomplete data", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Journal of the Royal Statistical Society, series B", "label": "publishes", "title": "Relation: publishes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Maximum likelihood from incomplete data via the em algorithm", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Jean-S\u00e9bastien Franco", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Inria Grenoble Rh\u02c6one-Alpes - LHK", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yi-Hsuan Tsai", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Adaptive Region Pooling for Object Detection", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Yi-Hsuan Tsai", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "UC Merced", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive Region Pooling for Object Detection", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive Region Pooling for Object Detection", "label": "is_located_at", "title": "Relation: is_located_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "/mnt/DATA/Glucoma/LLM/Ollama_pdf_handle/cvpr_papers/Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental.pdf", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Onur C. Hamsici", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Adaptive Region Pooling for Object Detection", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Onur C. Hamsici", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "Qualcomm Research", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Tsai_Adaptive_Region_Pooling_2015_CVPR_supplemental", "label": "is_file_name", "title": "Relation: is_file_name\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Adaptive Region Pooling for Object Detection", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive Region Pooling", "label": "is_method_for", "title": "Relation: is_method_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "object detection", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive Region Pooling", "label": "discovers", "title": "Relation: discovers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "discriminative object parts", "width": 2.92}, {"arrows": "to", "color": "#2196F3", "from": "Adaptive Region Pooling", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "challenging conditions", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Adaptive Region Pooling", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Adaptive Region Processing", "label": "transfers", "title": "Relation: transfers\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "keypoints", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "representative parts", "label": "transferred_to", "title": "Relation: transferred_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.91\u003cbr\u003eSource: unknown", "to": "detected objects", "width": 2.8200000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "challenging conditions", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "occlusion", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "challenging conditions", "label": "includes", "title": "Relation: includes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.83\u003cbr\u003eSource: unknown", "to": "varying lighting", "width": 2.66}, {"arrows": "to", "color": "#4CAF50", "from": "ARP", "label": "compared_with", "title": "Relation: compared_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.87\u003cbr\u003eSource: unknown", "to": "ESVM", "width": 2.74}, {"arrows": "to", "color": "#4CAF50", "from": "Ensemble of exemplar-svms", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "method", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Ensemble of exemplar-svms", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "ICCV", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Keypoint Transfer", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Object Parts Discovery", "label": "is_topic", "title": "Relation: is_topic\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Object Detection", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Long-term Recurrent Convolutional Networks", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Visual Recognition", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Long-term Recurrent Convolutional Networks", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Visual Description", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Jeff Donahue", "label": "is_author", "title": "Relation: is_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Long-term Recurrent Convolutional Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Jeff Donahue", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "UC Berkeley", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lisa Anne Hendricks", "label": "is_author", "title": "Relation: is_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Long-term Recurrent Convolutional Networks", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Lisa Anne Hendricks", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "UC Berkeley", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Sergio Guadarrama", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Sergio Guadarrama", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "UC Berkeley", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "label": "discusses", "title": "Relation: discusses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Visual Features", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "label": "generates", "title": "Relation: generates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Predictions", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "label": "operates_on", "title": "Relation: operates_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Visual Input", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Marcus Rohrbach", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Subhashini Venugopalan", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Subhashini Venugopalan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "UT Austin", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Kate Saenko", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Kate Saenko", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "UMass Lowell", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Trevor Darrell", "label": "contributed_to", "title": "Relation: contributed_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Trevor Darrell", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "UC Berkeley", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Visual Features", "label": "is_aspect_of", "title": "Relation: is_aspect_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "Models", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "deep convolutional networks", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Models", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "recurrent", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Models", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "temporally deep", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Models", "label": "demonstrate value on", "title": "Relation: demonstrate value on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "video recognition tasks", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Models", "label": "is_used_for", "title": "Relation: is_used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "image description", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Models", "label": "address", "title": "Relation: address\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "video narration challenges", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "recurrent convolutional models", "label": "are", "title": "Relation: are\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "doubly deep", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "recurrent convolutional models", "label": "have_advantage", "title": "Relation: have_advantage\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "complex target concepts", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "recurrent convolutional models", "label": "have_advantage", "title": "Relation: have_advantage\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "limited training data", "width": 2.6}, {"arrows": "to", "color": "#FF5722", "from": "network state updates", "label": "enable", "title": "Relation: enable\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "long-term dependencies", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "long-term RNN models", "label": "map", "title": "Relation: map\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "variable length outputs", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "long-term RNN models", "label": "model", "title": "Relation: model\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "complex temporal dynamics", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "recurrent long-term models", "label": "are_connected_to", "title": "Relation: are_connected_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "visual convnet models", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Recurrent Convolutional Networks (LRCNs)", "label": "applied_to", "title": "Relation: applied_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Video Recognition", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "Recurrent Convolutional Networks (LRCNs)", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Long-Term Dependencies", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Recurrent Convolutional Networks (LRCNs)", "label": "has_advantage_over", "title": "Relation: has_advantage_over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "state-of-the-art models", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Recurrent Convolutional Networks (LRCNs)", "label": "improves", "title": "Relation: improves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "recognition", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Video Recognition", "label": "relies_on", "title": "Relation: relies_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.82\u003cbr\u003eSource: unknown", "to": "Convolutional Networks", "width": 2.6399999999999997}, {"arrows": "to", "color": "#2196F3", "from": "Video Recognition", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Sequence Learning", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Long-Term Dependencies", "label": "requires", "title": "Relation: requires\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Recurrent Convolutional Networks (LRCNs)", "width": 2.6}, {"arrows": "to", "color": "#2196F3", "from": "Sequence Learning", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "Long-Term Dependencies", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "state-of-the-art models", "label": "are", "title": "Relation: are\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "separately optimized", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Action Classification", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Long short-term memory recurrent neural networks", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Action Classification", "label": "occurs_in", "title": "Relation: occurs_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "soccer videos", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Long short-term memory recurrent neural networks", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Long-Term Dependencies", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Multimodal neural language models", "label": "combines", "title": "Relation: combines\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "visual-semantic embeddings", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Unifying visual-semantic embeddings", "label": "achieved_by", "title": "Relation: achieved_by\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "Multimodal neural language models", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Video in sentences out", "label": "investigates", "title": "Relation: investigates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Video Recognition", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Video in sentences out", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "UAI", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "High accuracy optical flow estimation", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "3D convolutional neural networks", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Generating sequences", "label": "published_as", "title": "Relation: published_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "arXiv preprint arXiv:1308.0850", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Recurrent neural networks", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "generating sequences", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "J. Deng", "label": "affilates_with", "title": "Relation: affilates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "W. Dong", "label": "affilates_with", "title": "Relation: affilates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "R. Socher", "label": "affilates_with", "title": "Relation: affilates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "L.-J. Li", "label": "affilages_with", "title": "Relation: affilages_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "K. Li", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "L. Fei-Fei", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "A. Frome", "label": "affiliates_with", "title": "Relation: affiliates_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "NIPS", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "ubhashini Venugopalan", "label": "affiliation", "title": "Relation: affiliation\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "UT Austin", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "SOM", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Semantic Obviousness Metric", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "SOM", "label": "used_for", "title": "Relation: used_for\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Image Quality Assessment", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "SOM", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Peng Zhang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SOM", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Peng Zhang", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "pzhangoo@mail.ustc.edu.cn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Wengang Zhou", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SOM", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Wengang Zhou", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "zhwg@ustc.edu.cn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Lei Wu", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SOM", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Lei Wu", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "wuleibig@gmail.com", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Houqiang Li", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "SOM", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Houqiang Li", "label": "has_email", "title": "Relation: has_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "lihq@ustc.edu.cn", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Zhang_SOM_Semantic_Obviousness_2015_CVPR_paper.pdf", "label": "contains", "title": "Relation: contains\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "SOM", "width": 2.84}, {"arrows": "to", "color": "#9E9E9E", "from": "Image quality assessment (IQA)", "label": "aims_to", "title": "Relation: aims_to\u003cbr\u003eType: definitional\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "objectively estimate human perception", "width": 2.96}, {"arrows": "to", "color": "#9E9E9E", "from": "Image quality assessment (IQA)", "label": "targets", "title": "Relation: targets\u003cbr\u003eType: definitional\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "problem", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "no-referece (NR) image quality assessment (IQA) framework", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "semantic obviousness", "width": 2.92}, {"arrows": "to", "color": "#FF5722", "from": "semantic-level factors", "label": "affects", "title": "Relation: affects\u003cbr\u003eType: causal\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "human perception of image quality", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "comparable results", "label": "related_to", "title": "Relation: related_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "state-of-the-art full-referece IQA (FR-IQA) methods", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "generalization ability", "label": "belongs_to", "title": "Relation: belongs_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "approach", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "NR-IQA algorithms", "label": "are_type_of", "title": "Relation: are_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "IQA algorithms", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "from": "NR-IQA algorithms", "label": "compared_to", "title": "Relation: compared_to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "existing algorithms", "width": 2.7}, {"arrows": "to", "color": "#2196F3", "from": "full-referece IQA (FR-IQA) methods", "label": "are_type_of", "title": "Relation: are_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "IQA methods", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Image Quality Assessment (IQA)", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "assessment method", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "No-Reference Image Quality Assessment (NR-IQA)", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IQA method", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "NR-IQA", "label": "achieves", "title": "Relation: achieves\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "comparable results", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "Damien Teney", "label": "is_author", "title": "Relation: is_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning Similarity Metrics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Learning Similarity Metrics", "label": "addresses", "title": "Relation: addresses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Dynamic Scene Segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Matthew Brown", "label": "is_author", "title": "Relation: is_author\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Learning Similarity Metrics", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "dynamic textures", "label": "exhibit", "title": "Relation: exhibit\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "complex patterns", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "metric-learning framework", "label": "optimizes", "title": "Relation: optimizes\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "representation", "width": 2.8600000000000003}, {"arrows": "to", "color": "#2196F3", "from": "object and motion segmentation", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Dynamic textures", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "video segmentation", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Spatio-temporal filters", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "video segmentation", "width": 2.6}, {"arrows": "to", "color": "#4CAF50", "from": "Metric learning", "label": "used_in", "title": "Relation: used_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.75\u003cbr\u003eSource: unknown", "to": "video segmentation", "width": 2.5}, {"arrows": "to", "color": "#2196F3", "from": "Graph-based segmentation", "label": "is_type_of", "title": "Relation: is_type_of\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "image segmentation", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Alpert et al. (2007)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Brox \u0026 Malik (2010)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "ECCV", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chan \u0026 Vasconcelos (2008)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Chan \u0026 Vasconcelos (2009)", "label": "published_in", "title": "Relation: published_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Variational layered dynamic textures", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "dynamic textures", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Corso", "label": "delivered", "title": "Relation: delivered\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "CVPR tutorial on video segmentation", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "Spacetime texture representation and recognition", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "spatio-temporal orientation analysis", "width": 2.76}, {"arrows": "to", "color": "#2196F3", "from": "Dynamic texture detection", "label": "based_on", "title": "Relation: based_on\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "motion analysis", "width": 2.84}, {"arrows": "to", "color": "#4CAF50", "from": "S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Dynamic textures", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Wu, Y. N.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Dynamic textures", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Fazekas, S.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Dynamic texture detection", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Amiatz, T.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Dynamic texture detection", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Chetverikov, D.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Dynamic texture detection", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Feichtenhofer, C.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Bags of spacetime energies", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Pinz, A.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Bags of spacetime energies", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Wilides, R.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Bags of spacetime energies", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Teney, Damien", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Carnegie Mellon University", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Brown, Matthew", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "University of Bath", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Kit, Dimitry", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "University of Bath", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Hall, Peter", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "University of Bath", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Li, Yang", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Reliable Patch Tracers", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Zhu, Jianke", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Reliable Patch Tracers", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "Hoi, Steven C.H.", "label": "author_of", "title": "Relation: author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 6.00\u003cbr\u003eSource: unknown", "to": "Reliable Patch Tracers", "width": 13}, {"arrows": "to", "color": "#4CAF50", "from": "modern trackers", "label": "use", "title": "Relation: use\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "bounding box", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "tracking results", "label": "sensitive to", "title": "Relation: sensitive to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "initialization", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Reliable Patch Tracers (RPT)", "label": "is", "title": "Relation: is\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "tracking method", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Reliable Patch Tracers (RPT)", "label": "attempts to", "title": "Relation: attempts to\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "identify reliable patches", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "reliable patches", "label": "can be", "title": "Relation: can be\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "tracked effectively", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "reliable patches", "label": "are distributed over", "title": "Relation: are distributed over\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "image", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "tracking reliability metric", "label": "measures", "title": "Relation: measures\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "reliability of patch", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "probability model", "label": "estimates", "title": "Relation: estimates\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "distribution of reliable patches", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "probability model", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "sequential Monte Carlo framework", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "motion trajectories", "label": "distinguish", "title": "Relation: distinguish\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "reliable patches from background", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "visual object", "label": "is defined as", "title": "Relation: is defined as\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "cluster", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "source code", "label": "is_available", "title": "Relation: is_available\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "public", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "Adam, A., Rivlin, E., \u0026 Shimshoni, I. (2006)", "label": "published", "title": "Relation: published\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "Robust fragments-based tracking", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Robust fragments-based tracking", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "integral histogram", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "Lucas, B. D., \u0026 Kanade, T. (1981)", "label": "developed", "title": "Relation: developed\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "iterative image registration technique", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "Poling, B., Lerman, G., \u0026 Szlarm, A. (2014)", "label": "presented", "title": "Relation: presented\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "Better feature tracking", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "Cai, Z., Wen, L., Yang, J., Lei, Z., \u0026 Li, S. (2012)", "label": "introduced", "title": "Relation: introduced\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "Structured visual tracking", "width": 2.84}, {"arrows": "to", "color": "#2196F3", "from": "Sequential Monte Carlo Methods in Practice", "label": "describes", "title": "Relation: describes\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "Sequential Monte Carlo Framework", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "Szlarm", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Cai et al.", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "ACCV", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Mannning et al.", "label": "authored", "title": "Relation: authored\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.99\u003cbr\u003eSource: unknown", "to": "Introduction to Information Retrieval", "width": 2.98}, {"arrows": "to", "color": "#4CAF50", "from": "Danelljan et al.", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Everingham et al.", "label": "created", "title": "Relation: created\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "The pascal visual object classes(voc) challenge", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Grundmann et al.", "label": "presented_in", "title": "Relation: presented_in\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "College of Computer Science", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Li", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Zhejiang University", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Yang Li", "label": "email", "title": "Relation: email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "liyang89@zju.edu.cn", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Jianke Zhu", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "College of Computer Science", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "V.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Han, M.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Essa, I.", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.96}, {"arrows": "to", "color": "#2196F3", "from": "SALICON", "label": "is_effort_to", "title": "Relation: is_effort_to\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "understand and predict visual attention", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "SALICON", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "collecting large-scale human data", "width": 2.9}, {"arrows": "to", "color": "#2196F3", "from": "SALICON", "label": "offers", "title": "Relation: offers\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "new possibilities for visual understanding", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "mouse-contingent paradigm", "label": "replaces", "title": "Relation: replaces\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "eye tracker", "width": 2.8}, {"arrows": "to", "color": "#4CAF50", "from": "SALICON dataset", "label": "is_dataset_of", "title": "Relation: is_dataset_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "human \u0027free-viewing\u0027 data", "width": 2.94}, {"arrows": "to", "color": "#4CAF50", "from": "SALICON dataset", "label": "contains_data_from", "title": "Relation: contains_data_from\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "10,000 images", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "SALICON dataset", "label": "is_based_on", "title": "Relation: is_based_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "Microsoft COCO dataset", "width": 2.88}, {"arrows": "to", "color": "#4CAF50", "from": "SALICON dataset", "label": "serves_as", "title": "Relation: serves_as\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "ground truth for evaluating salience algorithms", "width": 2.8600000000000003}, {"arrows": "to", "color": "#4CAF50", "from": "SALICON dataset", "label": "complements", "title": "Relation: complements\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.88\u003cbr\u003eSource: unknown", "to": "existing annotations", "width": 2.76}, {"arrows": "to", "color": "#4CAF50", "from": "Ming Jiang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Shengshen Huang", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Juanyong Duan", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Qi Zhao", "label": "affiliated_with", "title": "Relation: affiliated_with\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "Deep LAC", "label": "focuses_on", "title": "Relation: focuses_on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "fine-grained recognition", "width": 2.88}, {"arrows": "to", "color": "#2196F3", "from": "Deep LAC", "label": "is_a", "title": "Relation: is_a\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "Fine-grained Recognition", "width": 2.96}, {"arrows": "to", "color": "#4CAF50", "from": "Deep LAC", "label": "is_author_of", "title": "Relation: is_author_of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Xiaoyong Shen", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Deep LAC", "label": "presented_at", "title": "Relation: presented_at\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.90\u003cbr\u003eSource: unknown", "to": "CVPR", "width": 2.8}, {"arrows": "to", "color": "#2196F3", "from": "Deep LAC", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Localization", "width": 2.4}, {"arrows": "to", "color": "#2196F3", "from": "Deep LAC", "label": "performs", "title": "Relation: performs\u003cbr\u003eType: conceptual\u003cbr\u003eConfidence: 0.70\u003cbr\u003eSource: unknown", "to": "Classification", "width": 2.4}, {"arrows": "to", "color": "#4CAF50", "from": "Di Lin", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deep LAC", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Xiaoyong Shen", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deep LAC", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Cewu Lu", "label": "author of", "title": "Relation: author of\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.95\u003cbr\u003eSource: unknown", "to": "Deep LAC", "width": 2.9}, {"arrows": "to", "color": "#4CAF50", "from": "Lin_Deep_LAC_Deep_2015_CVPR_paper", "label": "is_publication", "title": "Relation: is_publication\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.85\u003cbr\u003eSource: unknown", "to": "Deep LAC", "width": 2.7}, {"arrows": "to", "color": "#4CAF50", "from": "eleqiz@nus.edu.sg", "label": "is_contact_email", "title": "Relation: is_contact_email\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.80\u003cbr\u003eSource: unknown", "to": "National University of Singapore", "width": 2.6}, {"arrows": "to", "color": "#9E9E9E", "from": "fine-grained recognition system", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "part localization", "width": 2.96}, {"arrows": "to", "color": "#9E9E9E", "from": "fine-grained recognition system", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "alignment", "width": 2.96}, {"arrows": "to", "color": "#9E9E9E", "from": "fine-grained recognition system", "label": "incorporates", "title": "Relation: incorporates\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.98\u003cbr\u003eSource: unknown", "to": "classification", "width": 2.96}, {"arrows": "to", "color": "#9E9E9E", "from": "valve linkage function", "label": "enables", "title": "Relation: enables\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.97\u003cbr\u003eSource: unknown", "to": "back-propagation chaining", "width": 2.94}, {"arrows": "to", "color": "#9E9E9E", "from": "valve linkage function", "label": "compromises", "title": "Relation: compromises\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "classification errors", "width": 2.88}, {"arrows": "to", "color": "#9E9E9E", "from": "valve linkage function", "label": "compromises", "title": "Relation: compromises\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.94\u003cbr\u003eSource: unknown", "to": "alignment errors", "width": 2.88}, {"arrows": "to", "color": "#9E9E9E", "from": "valve linkage function", "label": "helps", "title": "Relation: helps\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.92\u003cbr\u003eSource: unknown", "to": "update localization", "width": 2.84}, {"arrows": "to", "color": "#9E9E9E", "from": "deep LAC system", "label": "uses", "title": "Relation: uses\u003cbr\u003eType: functional\u003cbr\u003eConfidence: 0.96\u003cbr\u003eSource: unknown", "to": "valve linkage function", "width": 2.92}, {"arrows": "to", "color": "#4CAF50", "from": "LAC system", "label": "performs well on", "title": "Relation: performs well on\u003cbr\u003eType: factual\u003cbr\u003eConfidence: 0.93\u003cbr\u003eSource: unknown", "to": "fine-grained object data", "width": 2.8600000000000003}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"font": {"size": 14, "face": "Tahoma"}}, "edges": {"arrows": {"to": {"enabled": true, "scaleFactor": 0.5}}, "color": {"inherit": true}, "smooth": {"enabled": true, "type": "dynamic"}, "font": {"size": 12, "align": "middle"}}, "physics": {"enabled": true, "stabilization": {"enabled": true, "iterations": 1000, "updateInterval": 100}}, "interaction": {"hover": true, "multiselect": true, "navigationButtons": true, "keyboard": {"enabled": true}}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    
        <style>
            body, html {
                margin: 0;
                padding: 0;
                height: 100%;
                width: 100%;
                font-family: Arial, sans-serif;
            }
            #mynetwork {
                width: 100%;
                height: 100vh;
                border: none;
            }
            #controls {
                position: absolute;
                top: 10px;
                left: 10px;
                z-index: 999;
                background-color: rgba(255, 255, 255, 0.8);
                padding: 10px;
                border-radius: 5px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            }
            #search-panel {
                position: absolute;
                top: 10px;
                right: 10px;
                z-index: 999;
                background-color: rgba(255, 255, 255, 0.8);
                padding: 10px;
                border-radius: 5px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.2);
                width: 200px;
            }
            #info-panel {
                position: absolute;
                bottom: 10px;
                left: 10px;
                z-index: 999;
                background-color: rgba(255, 255, 255, 0.8);
                padding: 10px;
                border-radius: 5px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.2);
                max-width: 300px;
            }
            #legend {
                position: absolute;
                bottom: 10px;
                right: 10px;
                z-index: 999;
                background-color: rgba(255, 255, 255, 0.8);
                padding: 10px;
                border-radius: 5px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            }
            .legend-item {
                display: flex;
                align-items: center;
                margin-bottom: 5px;
            }
            .legend-color {
                width: 15px;
                height: 15px;
                margin-right: 5px;
                border-radius: 2px;
            }
            button {
                margin: 2px;
                padding: 5px 10px;
                cursor: pointer;
            }
            input[type="text"] {
                width: 100%;
                padding: 5px;
                box-sizing: border-box;
                margin-bottom: 5px;
            }
            #search-results {
                max-height: 200px;
                overflow-y: auto;
            }
            .search-result {
                padding: 5px;
                cursor: pointer;
                border-bottom: 1px solid #eee;
            }
            .search-result:hover {
                background-color: #f0f0f0;
            }
        </style>
        
        <div id="controls">
            <button onclick="zoomIn()">Zoom In</button>
            <button onclick="zoomOut()">Zoom Out</button>
            <button onclick="resetView()">Reset View</button>
            <button onclick="togglePhysics()">Toggle Physics</button>
            <button onclick="exportGraph()">Export PNG</button>
        </div>
        
        <div id="search-panel">
            <input type="text" id="search-input" placeholder="Search nodes..." oninput="searchNodes()">
            <div id="search-results"></div>
        </div>
        
        <div id="info-panel">
            <h3>Selected Node/Edge Info</h3>
            <div id="selection-info">Select a node or edge to see details</div>
        </div>
        
        <div id="legend">
            <h3>Legend</h3>
            <div class="legend-item">
                <div class="legend-color" style="background-color: #6FA8DC;"></div>
                <span>Entity</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background-color: #4CAF50;"></div>
                <span>Factual Relation</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background-color: #2196F3;"></div>
                <span>Conceptual Relation</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background-color: #FF5722;"></div>
                <span>Causal Relation</span>
            </div>
        </div>
        
        <script>
            // Wait for network to be defined
            document.addEventListener("DOMContentLoaded", function() {
                // Attach selection event
                network.on("selectNode", function(params) {
                    if (params.nodes.length > 0) {
                        var nodeId = params.nodes[0];
                        var node = network.body.nodes[nodeId];
                        document.getElementById("selection-info").innerHTML = 
                            "<strong>Node:</strong> " + node.options.label + 
                            "<br><strong>Connections:</strong> " + 
                            network.getConnectedNodes(nodeId).length;
                    }
                });
                
                network.on("selectEdge", function(params) {
                    if (params.edges.length > 0) {
                        var edgeId = params.edges[0];
                        var edge = network.body.edges[edgeId];
                        document.getElementById("selection-info").innerHTML = 
                            "<strong>Relation:</strong> " + edge.options.label + 
                            "<br><strong>From:</strong> " + edge.from.options.label +
                            "<br><strong>To:</strong> " + edge.to.options.label;
                    }
                });
                
                network.on("deselectNode", function(params) {
                    document.getElementById("selection-info").innerHTML = 
                        "Select a node or edge to see details";
                });
                
                network.on("deselectEdge", function(params) {
                    document.getElementById("selection-info").innerHTML = 
                        "Select a node or edge to see details";
                });
            });
            
            function zoomIn() {
                network.zoomIn(0.2);
            }
            
            function zoomOut() {
                network.zoomOut(0.2);
            }
            
            function resetView() {
                network.fit({
                    animation: {
                        duration: 1000,
                        easingFunction: "easeInOutQuad"
                    }
                });
            }
            
            function togglePhysics() {
                var physics = network.physics.options.enabled;
                network.setOptions({ physics: { enabled: !physics } });
            }
            
            function exportGraph() {
                var canvas = document.getElementsByTagName("canvas")[0];
                var link = document.createElement('a');
                link.href = canvas.toDataURL("image/png");
                link.download = 'knowledge_graph.png';
                link.click();
            }
            
            function searchNodes() {
                var searchTerm = document.getElementById("search-input").value.toLowerCase();
                var resultsDiv = document.getElementById("search-results");
                resultsDiv.innerHTML = "";
                
                if (searchTerm.length < 2) return;
                
                var nodes = network.body.nodes;
                var results = [];
                
                for (var nodeId in nodes) {
                    var node = nodes[nodeId];
                    if (node.options && node.options.label) {
                        var label = node.options.label.toLowerCase();
                        
                        if (label.includes(searchTerm)) {
                            results.push({
                                id: nodeId,
                                label: node.options.label
                            });
                        }
                    }
                }
                
                results.sort((a, b) => a.label.localeCompare(b.label));
                
                for (var i = 0; i < Math.min(results.length, 10); i++) {
                    var div = document.createElement("div");
                    div.className = "search-result";
                    div.textContent = results[i].label;
                    div.setAttribute("data-node-id", results[i].id);
                    div.onclick = function() {
                        var nodeId = this.getAttribute("data-node-id");
                        network.selectNodes([nodeId]);
                        network.focus(nodeId, {
                            scale: 1.2,
                            animation: {
                                duration: 1000,
                                easingFunction: "easeInOutQuad"
                            }
                        });
                    };
                    resultsDiv.appendChild(div);
                }
                
                if (results.length === 0) {
                    resultsDiv.innerHTML = "<div class='search-result'>No results found</div>";
                }
            }
        </script>
        </body>
</html>